{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganesh1616/Ganesh_INFO5731_Fall2024/blob/main/Ganesh_Marada_Exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBKvD6O_TY6e"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cikVKDXdTbzE"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n",
        "'''\n",
        "\"Research Question: Identify trends and patterns in the success of the top 1000 songs and determine whether there is a correlation between factors such as genre, release date, artist popularity, duration, and critical reception that contribute to their success.\"\n",
        "\n",
        "Here is for this research question, I have to follow the steps below to collect and analyze data:\n",
        "\n",
        "1.Visit a website that provides information about the top 1000 songs, such as Billboard or Spotify Charts. The website should include details such as song title, artist, release year, genre, duration, chart position, stream count, and critical reviews.\n",
        "\n",
        "2.Right-click on the webpage and select the \"Inspect\" option to open the developer tools. This will allow you to access the HTML structure of the page. Use these tools to locate the class or id attributes associated with the data you want to scrape (e.g., song title, artist, release year, genre).\n",
        "\n",
        "3. Python program by importing the necessary libraries such as requests, BeautifulSoup, and pandas to perform the web scraping. Then have to  pass the URL of the website you wish to scrape as a string and send a GET request using the requests library to retrieve the webpage's content.\n",
        "\n",
        "4.Parse the HTML content of the webpage using BeautifulSoup with the \"html.parser\" parser. This will allow you to locate and extract specific HTML elements containing the song data, such as song titles, artists, and chart positions, using the class or id attributes you identified earlier.\n",
        "\n",
        "5.Create lists to store the scraped data for each attribute of interest. For example, create lists for song titles, artists, release years, and chart positions. Once you have collected the data into these lists, organize it into a pandas DataFrame.\n",
        "\n",
        "6.Save the data to a CSV file for further analysis. You can now analyze trends such as the correlation between genre and chart success, the impact of artist popularity on song performance, or the influence of song duration on its success.\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9RqrlwdTfvl"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54AN2nfwpGtI",
        "outputId": "df598c36-b6dc-45d0-e2f0-1a9cd99081e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Song Title                               Artist  \\\n",
            "0   A Bar Song (Tipsy)                            Shaboozey   \n",
            "1      I Had Some Help  Post Malone Featuring Morgan Wallen   \n",
            "2             Espresso                    Sabrina Carpenter   \n",
            "3     Die With A Smile               Lady Gaga & Bruno Mars   \n",
            "4   Birds Of A Feather                        Billie Eilish   \n",
            "..                 ...                                  ...   \n",
            "95        Close To You                        Gracie Abrams   \n",
            "96           Residuals                          Chris Brown   \n",
            "97      Devil Is A Lie                        Tommy Richman   \n",
            "98         Parking Lot               Mustard & Travis Scott   \n",
            "99     American Nights                           Zach Bryan   \n",
            "\n",
            "                           Current Rank Last Week Rank Peak Position  \\\n",
            "0                             Shaboozey            N/A           N/A   \n",
            "1   Post Malone Featuring Morgan Wallen            N/A           N/A   \n",
            "2                     Sabrina Carpenter            N/A           N/A   \n",
            "3                Lady Gaga & Bruno Mars            N/A           N/A   \n",
            "4                         Billie Eilish            N/A           N/A   \n",
            "..                                  ...            ...           ...   \n",
            "95                        Gracie Abrams            N/A           N/A   \n",
            "96                          Chris Brown            N/A           N/A   \n",
            "97                        Tommy Richman            N/A           N/A   \n",
            "98               Mustard & Travis Scott            N/A           N/A   \n",
            "99                           Zach Bryan            N/A           N/A   \n",
            "\n",
            "   Weeks on Chart  \n",
            "0             N/A  \n",
            "1             N/A  \n",
            "2             N/A  \n",
            "3             N/A  \n",
            "4             N/A  \n",
            "..            ...  \n",
            "95            N/A  \n",
            "96            N/A  \n",
            "97            N/A  \n",
            "98            N/A  \n",
            "99            N/A  \n",
            "\n",
            "[100 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.billboard.com/charts/hot-100/'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "song_data = soup.find_all('li', class_='o-chart-results-list__item')\n",
        "\n",
        "song_info = []\n",
        "\n",
        "for store in song_data:\n",
        "\n",
        "    h3_tag = store.find('h3')\n",
        "    if h3_tag:\n",
        "        title = h3_tag.text.strip()\n",
        "\n",
        "        artist = h3_tag.find_next('span').text.strip()\n",
        "        rank = store.find('span', class_='c-label').text.strip()\n",
        "\n",
        "        last_week = store.find('span', class_='c-label--secondary').text.strip() if store.find('span', class_='c-label--secondary') else 'N/A'\n",
        "\n",
        "\n",
        "        peak_position = store.find('span', class_='c-label--tertiary').text.strip() if store.find('span', class_='c-label--tertiary') else 'N/A'\n",
        "\n",
        "        weeks_on_chart = store.find('span', class_='c-label--quaternary').text.strip() if store.find('span', class_='c-label--quaternary') else 'N/A'\n",
        "\n",
        "        song_info.append({\n",
        "            'Song Title': title,\n",
        "            'Artist': artist,\n",
        "            'Current Rank': rank,\n",
        "            'Last Week Rank': last_week,\n",
        "            'Peak Position': peak_position,\n",
        "            'Weeks on Chart': weeks_on_chart\n",
        "        })\n",
        "\n",
        "\n",
        "song_DF = pd.DataFrame(song_info)\n",
        "\n",
        "print(song_DF)\n",
        "\n",
        "song_DF.to_csv('top_100_songs.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4DuUEPlqYHo",
        "outputId": "e37f9355-6478-4e6a-c95d-db1d315f43df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Set Intersection: A Multi-Message Symmetric Private Information Retrieval Perspective\n",
            "Authors: Zhusheng Wang, Karim A. Banawan, S. Ulukus\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We study the problem of private set intersection (PSI). In this problem, there are two entities <inline-formula> <tex-math notation=\"LaTeX\">$E_{i}$ </tex-math></inline-formula>, for <inline-formula> <tex-math notation=\"LaTeX\">$i=1, 2$ </tex-math></inline-formula>, each storing a set <inline-formula> <tex-math notation=\"LaTeX\">$\\mathcal {P}_{i}$ </tex-math></inline-formula>, whose elements are picked from a finite set <inline-formula> <tex-math notation=\"LaTeX\">$\\mathbb {S}_{K}$ </tex-math></inline-formula>, on <inline-formula> <tex-math notation=\"LaTeX\">$N_{i}$ </tex-math></inline-formula> replicated and non-colluding databases. It is required to determine the set intersection <inline-formula> <tex-math notation=\"LaTeX\">${\\mathcal {P}}_{1} \\cap {\\mathcal {P}} _{2}$ </tex-math></inline-formula> without leaking any information about the remaining elements to the other entity, and to do this with the least amount of downloaded bits. We first show that the PSI problem can be recast as a multi-message symmetric private information retrieval (MM-SPIR) problem with certain added restrictions. Next, as a stand-alone result, we derive the information-theoretic sum capacity of MM-SPIR, <inline-formula> <tex-math notation=\"LaTeX\">$C_{MM-SPIR}$ </tex-math></inline-formula>. We show that with <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages, <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> databases, and a given size of the desired message set <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>, the exact capacity of MM-SPIR is <inline-formula> <tex-math notation=\"LaTeX\">$C_{MM-SPIR} = 1 - \\frac {1}{N}$ </tex-math></inline-formula> when <inline-formula> <tex-math notation=\"LaTeX\">$P \\leq K-1$ </tex-math></inline-formula>, provided that the entropy of the common randomness <inline-formula> <tex-math notation=\"LaTeX\">$S$ </tex-math></inline-formula> satisfies <inline-formula> <tex-math notation=\"LaTeX\">$H(S) \\geq \\frac {P}{N-1}$ </tex-math></inline-formula> per desired symbol. When <inline-formula> <tex-math notation=\"LaTeX\">$P = K$ </tex-math></inline-formula>, the MM-SPIR capacity is trivially 1 without the need for any common randomness <inline-formula> <tex-math notation=\"LaTeX\">$S$ </tex-math></inline-formula>. This result implies that there is no gain for MM-SPIR over successive single-message SPIR (SM-SPIR). For the MM-SPIR problem, we present a novel capacity-achieving scheme which builds seamlessly over the near-optimal scheme of Banawan-Ulukus originally proposed for the multi-message PIR (MM-PIR) problem without any database privacy constraints. Surprisingly, our scheme here is exactly optimal for the MM-SPIR problem for any <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>, in contrast to the scheme for the MM-PIR problem, which was proved only to be near-optimal. Our scheme is an alternative to the successive usage of the SM-SPIR scheme of Sun-Jafar. Based on this capacity result for the MM-SPIR problem, and after addressing the added requirements in its conversion to the PSI problem, we show that the optimal download cost for the PSI problem is given by <inline-formula> <tex-math notation=\"LaTeX\">$\\min \\left \\{{\\left \\lceil{ \\frac {P_{1} N_{2}}{N_{2}-1}}\\right \\rceil, \\left \\lceil{ \\frac {P_{2} N_{1}}{N_{1}-1}}\\right \\rceil }\\right \\}$ </tex-math></inline-formula>, where <inline-formula> <tex-math notation=\"LaTeX\">$P_{i}$ </tex-math></inline-formula> is the cardinality of set <inline-formula> <tex-math notation=\"LaTeX\">${\\mathcal {P}}_{i}$ </tex-math></inline-formula>.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Recent Advances in Conversational Information Retrieval\n",
            "Authors: Jianfeng Gao, Chenyan Xiong, Paul N. Bennett\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Recent progress in deep learning has brought tremendous improvements in conversational AI, leading to a plethora of commercial conversational services that allow naturally spoken interactions, increasing the need for more human-centric interactions in IR. As a result, we have witnessed a resurgent interest in developing modern CIR systems in research communities and industry. This tutorial presents recent advances in CIR, focusing mainly on neural approaches and new applications developed in the past five years. Our goal is to provide a thorough and in-depth overview of the general definition of CIR, the components of CIR systems, new applications raised for its conversational aspects, and the (neural) techniques recently developed for it.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the Information Leakage in Private Information Retrieval Systems\n",
            "Authors: Tao Guo, Ruida Zhou, C. Tian\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: We consider information leakage to the user in private information retrieval (PIR) systems. Information leakage can be measured in terms of individual message leakage or total leakage. Individual message leakage, or simply individual leakage, is defined as the amount of information that the user can obtain on any individual message that is not being requested, and the total leakage is defined as the amount of information that the user can obtain about all the other messages except the one being requested. In this work, we characterize the tradeoff between the minimum download cost and the individual leakage, and that for the total leakage, respectively. Coding schemes are proposed to achieve these optimal tradeoffs, which are also shown to be optimal in terms of the message size. We further characterize the optimal tradeoff between the minimum amount of common randomness and the total leakage. Moreover, we show that under individual leakage, common randomness is in fact unnecessary when there are more than two messages.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval: The Early Years\n",
            "Authors: D. Harman\n",
            "Year: 2019\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Information retrieval, the science behind search engines, had its birth in the late 1950s. Its forbearers came from library science, mathematics and linguistics, with later input from computer science. The early work dealt with finding better ways to index text, and then using new algorithms to search these (mostly) automatically built indexes. Like all computer applications, however, the theory and ideas were limited by lack of computer power, and additionally by lack of machine-readable text. But each decade saw progress, and by the 1990s, it had flowered. This monograph tells the story of the early history of information retrieval (up until 2000) in a manner that presents the technical context, the research and the early commercialization efforts. Donna Harman (2019), “Information Retrieval: The Early Years”, Foundations and Trends © in Information Retrieval: Vol. 13, No. 5, pp 425–577. DOI: 10.1561/1500000065. Full text available at: http://dx.doi.org/10.1561/1500000065\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Introduction to Neural Information Retrieval\n",
            "Authors: Bhaskar Mitra, Nick Craswell\n",
            "Year: 2018\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Neural models have been employed in many Information Retrieval scenarios, including ad-hoc retrieval, recommender systems, multi-media search, and even conversational systems that generate answers in response to natural language questions. An Introduction to Neural Information Retrieval provides a tutorial introduction to neural methods for ranking documents in response to a query, an important IR task. The monograph provides a complete picture of neural information retrieval techniques that culminate in supervised neural learning to rank models including deep neural network architectures that are trained end-to-end for ranking tasks. In reaching this point, the authors cover all the important topics, including the learning to rank framework and an overview of deep neural networks. This monograph provides an accessible, yet comprehensive, overview of the state-of-the-art of Neural Information Retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CAIBC: Capturing All-round Information Beyond Color for Text-based Person Retrieval\n",
            "Authors: Zijie Wang, Aichun Zhu, Jingyi Xue, Xili Wan, Chao Liu, Tiang-Cong Wang, Yifeng Li\n",
            "Year: 2022\n",
            "Venue: ACM Multimedia\n",
            "Abstract: Given a natural language description, text-based person retrieval aims to identify images of a target person from a large-scale person image database. Existing methods generally face a color over-reliance problem, which means that the models rely heavily on color information when matching cross-modal data. Indeed, color information is an important decision-making accordance for retrieval, but the over-reliance on color would distract the model from other key clues (e.g. texture information, structural information, etc.), and thereby lead to a sub-optimal retrieval performance. To solve this problem, in this paper, we propose to Capture All-round Information Beyond Color (CAIBC) via a jointly optimized multi-branch architecture for text-based person retrieval. CAIBC contains three branches including an RGB branch, a grayscale (GRS) branch and a color (CLR) branch. Besides, with the aim of making full use of all-round information in a balanced and effective way, a mutual learning mechanism is employed to enable the three branches which attend to varied aspects of information to communicate with and learn from each other. Extensive experimental analysis is carried out to evaluate our proposed CAIBC method on the CUHK-PEDES and RSTPReid datasets in both supervised and weakly supervised text-based person retrieval settings, which demonstrates that CAIBC significantly outperforms existing methods and achieves the state-of-the-art performance on all the three tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Capacity of Quantum Private Information Retrieval with Multiple Servers\n",
            "Authors: Seunghoan Song, Masahito Hayashi\n",
            "Year: 2019\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We study the capacity of quantum private information retrieval (QPIR) with multiple servers. In the QPIR problem with multiple servers, a user retrieves a classical file by downloading quantum systems from multiple servers each of which containing the whole classical file set, without revealing the identity of the retrieved file to any individual server. The QPIR capacity is defined as the maximum rate of the file size over the whole dimension of the downloaded quantum systems. Assuming the preexisting entanglement among servers, we prove that the QPIR capacity with multiple servers is 1 regardless of the number of servers and files. We propose a rate-one protocol which can be implemented by using only two servers. This capacity-achieving protocol outperforms its classical counterpart in the sense of the capacity, server secrecy, and upload cost. The strong converse bound is derived concisely without using the secrecy conditions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Importance of Interaction for Information Retrieval\n",
            "Authors: W. Bruce Croft\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: There has historically been a divide between the user-oriented and system-oriented research communities in information retrieval. In my opinion, this divide is based primarily on a difference in viewpoint about the relative importance of understanding how people search for information compared to developing new retrieval models and ranking algorithms. There is strong agreement, however, that the interaction between the user and the search engine is a fundamental part of the IR process. The IR field was one of the first in computer science to recognize the importance of the user-system interaction, which led to a number of core concepts such as relevance, ranking, result presentation, feedback, evaluation, and browsing. The key message of this talk is that effective information access requires interaction between the user and the system, where both play a role. Additionally, there is growing evidence that even more effective information access can be achieved by a system that actively supports interaction, particularly in the limited-bandwidth environments provided by mobile devices and voice-based assistants. In this talk, I will first give an overview of past IR research on user-system interaction. In much of this research, the system provides passive support for the retrieval process and much of the burden for effective retrieval stays with the user. There has been some research, however, that has attempted to actively support the interaction by designing expert intermediary systems. After this review, I will focus on two current areas of research where active support for interaction is crucial. These are question answering and conversational search. These areas have recently become popular in the NLP community but they have deep roots in IR. I will describe the specific lines of research we have followed at the Center for Intelligent Information Retrieval and RMIT, including interactive answer passage retrieval, studies of information-seeking dialogues, and neural models for selecting responses and answers. Although there are many aspects to this research, I will highlight the parts where interaction is important, how we have attempted to evaluate the research, and where significant progress needs to be made.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Toward the Capacity of Private Information Retrieval From Coded and Colluding Servers\n",
            "Authors: Lukas Holzbaur, Ragnar Freij-Hollanti, Jie Li, C. Hollanti\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: In this work, two practical concepts related to private information retrieval (PIR) are introduced and coined full support-rank PIR and strongly linear PIR. Being of full support-rank is a technical, yet natural condition required to prove a converse result for a capacity expression and satisfied by almost all currently known capacity-achieving schemes, while strong linearity is a practical requirement enabling implementation over small finite fields with low subpacketization degree. Then, the capacity of MDS-coded, linear, full support-rank PIR in the presence of colluding servers is derived, as well as the capacity of symmetric, linear PIR with colluding, adversarial, and nonresponsive servers for the recently introduced concept of matched randomness. This positively settles the capacity conjectures stated by Freij-Hollanti et al. and Tajeddine et al. in the presented cases. It is also shown that, further restricting to strongly-linear PIR schemes with deterministic linear interference cancellation, the so-called star product scheme proposed by Freij-Hollanti et al. is essentially optimal and induces no capacity loss.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Anserini: Enabling the Use of Lucene for Information Retrieval Research\n",
            "Authors: Peilin Yang, Hui Fang, Jimmy J. Lin\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Software toolkits play an essential role in information retrieval research. Most open-source toolkits developed by academics are designed to facilitate the evaluation of retrieval models over standard test collections. Efforts are generally directed toward better ranking and less attention is usually given to scalability and other operational considerations. On the other hand, Lucene has become the de facto platform in industry for building search applications (outside a small number of companies that deploy custom infrastructure). Compared to academic IR toolkits, Lucene can handle heterogeneous web collections at scale, but lacks systematic support for evaluation over standard test collections. This paper introduces Anserini, a new information retrieval toolkit that aims to provide the best of both worlds, to better align information retrieval practice and research. Anserini provides wrappers and extensions on top of core Lucene libraries that allow researchers to use more intuitive APIs to accomplish common research tasks. Our initial efforts have focused on three functionalities: scalable, multi-threaded inverted indexing to handle modern web-scale collections, streamlined IR evaluation for ad hoc retrieval on standard test collections, and an extensible architecture for multi-stage ranking. Anserini ships with support for many TREC test collections, providing a convenient way to replicate competitive baselines right out of the box. Experiments verify that our system is both efficient and effective, providing a solid foundation to support future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Symmetric Private Information Retrieval\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: Private information retrieval (PIR) is the problem of retrieving, as efficiently as possible, one out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating replicated databases (each holds all <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages) while keeping the identity of the desired message index a secret from each individual database. Symmetric PIR (SPIR) is a generalization of PIR to include the requirement that beyond the desired message, the user learns nothing about the other <inline-formula> <tex-math notation=\"LaTeX\">$K-1$ </tex-math></inline-formula> messages. The information theoretic capacity of SPIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. We show that the capacity of SPIR is <inline-formula> <tex-math notation=\"LaTeX\">$1-1/N$ </tex-math></inline-formula> regardless of the number of messages <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula>, if the databases have access to common randomness (not available to the user) that is independent of the messages, in the amount that is at least <inline-formula> <tex-math notation=\"LaTeX\">$1/(N-1)$ </tex-math></inline-formula> bits per desired message bit. Otherwise, if the amount of common randomness is less than <inline-formula> <tex-math notation=\"LaTeX\">$1/(N-1)$ </tex-math></inline-formula> bits per message bit, then the capacity of SPIR is zero. Extensions to the capacity region of SPIR and the capacity of finite length SPIR are provided.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: The Role of Coded Side Information in Single-Server Private Information Retrieval\n",
            "Authors: A. Heidarzadeh, Fatemeh Kazemi, A. Sprintson\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We study the role of coded side information in single-server Private Information Retrieval (PIR). An instance of the single-server PIR problem includes a server that stores a database of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> independently and uniformly distributed messages, and a user who wants to retrieve one of these messages from the server. We consider settings in which the user initially has access to a coded side information which includes a linear combination of a subset of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages in the database. We assume that the identities of the <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages that form the support set of the coded side information as well as the coding coefficients are initially unknown to the server. We consider two different models, depending on whether the support set of the coded side information includes the requested message or not. We also consider the following two privacy requirements: (i) the identities of both the demand and the support set of the coded side information need to be protected, or (ii) only the identity of the demand needs to be protected. For each model and for each of the privacy requirements, we consider the problem of designing a protocol for generating the user’s query and the server’s answer that enables the user to decode the message they need while satisfying the privacy requirement. We characterize the (scalar-linear) capacity of each setting, defined as the ratio of the number of information bits in a message to the minimum number of information bits downloaded from the server over all (scalar-linear) protocols that satisfy the privacy condition. Our converse proofs rely on new information-theoretic arguments—tailored to the setting of single-server PIR and different from the commonly-used techniques in multi-server PIR settings. We also present novel capacity-achieving scalar-linear protocols for each of the settings being considered.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Weakly-Private Information Retrieval\n",
            "Authors: Hsuan-Yin Lin, Siddhartha Kumar, E. Rosnes, A. G. Amat, Eitan Yaakobi\n",
            "Year: 2019\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: Private information retrieval (PIR) protocols make it possible to retrieve a file from a database without disclosing any information about the identity of the file being retrieved. These protocols have been rigorously explored from an information-theoretic perspective in recent years. While existing protocols strictly impose that no information is leaked on the file’s identity, this work initiates the study of the tradeoffs that can be achieved by relaxing the requirement of perfect privacy. In case the user is willing to leak some information on the identity of the retrieved file, we study how the PIR rate, as well as the upload cost and access complexity, can be improved. For the particular case of replicated servers, we propose two weakly-private information retrieval schemes based on two recent PIR protocols and a family of schemes based on partitioning. Lastly, we compare the performance of the proposed schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Single-Server Multi-Message Individually-Private Information Retrieval with Side Information\n",
            "Authors: A. Heidarzadeh, S. Kadhe, S. E. Rouayheb, A. Sprintson\n",
            "Year: 2019\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We consider a multi-user variant of the private information retrieval problem described as follows. Suppose there are D users, each of which wants to privately retrieve a distinct message from a server with the help of a trusted agent. We assume that the agent has a subset of M messages whose indices are unknown to the server. The goal of the agent is to collectively retrieve the users’ requests from the server. For this problem, we introduce the notion of individual-privacy – the agent is required to protect the privacy only for each individual user (but may leak some correlations among user requests). We refer to this problem as Individually-Private Information Retrieval with Side Information (IPIR-SI).We first establish a lower bound on the capacity, which is defined as the maximum achievable download rate, of the IPIR-SI problem by presenting a novel achievability protocol. Next, we characterize the capacity of IPIR-SI problem for M = 1 and D = 2. In the process of characterizing the capacity for arbitrary M and D we present a novel combinatorial conjecture, that may be of independent interest.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the Capacity of Leaky Private Information Retrieval\n",
            "Authors: I. Samy, R. Tandon, Loukas Lazos\n",
            "Year: 2019\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: Private information retrieval (PIR) allows users to retrieve data from databases without revealing the identity of that data. An extensive body of works has investigated efficient schemes to achieve computational and information-theoretic privacy. The latter guarantees that no information is revealed to the databases, irrespective of their computational power. Although information-theoretic PIR (IT-PIR) provides a strong privacy guarantee, it can be too taxing for certain applications. In this paper, we initiate the study of leaky private information retrieval (L-PIR), where a bounded amount of privacy leakage is allowed and measured through a parameter ϵ. The classical IT-PIR formulation is obtained by setting ϵ = 0, and for ϵ > 0, we explore the opportunities offered for reducing the download cost. We derive new upper and lower bounds on the download cost of L-PIR for any arbitrary ϵ, any number of messages K, and for N = 2 databases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the Storage Cost of Private Information Retrieval\n",
            "Authors: C. Tian\n",
            "Year: 2019\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We consider the fundamental tradeoff between the storage cost and the download cost in private information retrieval systems, without any explicit structural restrictions on the storage codes, such as maximum distance separable codes or uncoded storage. Two novel outer bounds are provided, which have the following implications. When the messages are stored without any redundancy across the databases, the optimal PIR strategy is to download all the messages; on the other hand, for PIR capacity-achieving codes, each database can reduce the storage cost, from storing all the messages, by no more than one message on average. We then focus on the two-message two-database case, and show that a stronger outer bound can be derived through a novel pseudo-message technique.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Research on information retrieval model based on ontology\n",
            "Authors: Binbin Yu\n",
            "Year: 2019\n",
            "Venue: EURASIP Journal on Wireless Communications and Networking\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improved Storage for Efficient Private Information Retrieval\n",
            "Authors: Karim A. Banawan, Batuhan Arasli, S. Ulukus\n",
            "Year: 2019\n",
            "Venue: Information Theory Workshop\n",
            "Abstract: We consider the problem of private information retrieval from N storage- constrained databases. In this problem, a user wishes to retrieve a single message out of M messages (of size L) without revealing any information about the identity of the message to individual databases. Each database stores $\\mu M L$ symbols, i.e., a $\\mu$ fraction of the entire library, where $\\frac{1}{N} \\leq \\mu \\leq 1.$ Our goal is to characterize the optimal tradeoff curve for the storage cost (captured by $\\mu$) and the normalized download cost $(D / L).$ We show that the download cost can be reduced by employing a hybrid storage scheme that combines MDS coding ideas with uncoded partial replication ideas. When there is no coding, our scheme reduces to Attia-Kumar-Tandon storage scheme, which was initially introduced by Maddah-AliNiesen in the context of the caching problem, and when there is no uncoded partial replication, our scheme reduces to Banawan-Ulukus storage scheme; in general, our scheme outperforms both.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Statute Law Information Retrieval and Entailment\n",
            "Authors: Mi-Young Kim, J. Rabelo, R. Goebel\n",
            "Year: 2019\n",
            "Venue: International Conference on Artificial Intelligence and Law\n",
            "Abstract: Our Yes/No statute law question answering system combines components for both statute law information retrieval and confirmation of textual entailment between statues and legal questions. We describe a statute law question answering system that exploits TF-IDF and a language model for information retrieval, and inter-paragraph entailment. We have evaluated our system using the data from the competition on legal information extraction/entailment (COLIEE-2019). The competition consists of four tasks: Tasks 1 and 2 are for the case law information extraction/entailment, and Tasks 3 and 4 are for the statute law information extraction/entailment. Here we explain our methods and evaluation results for Tasks 3 and 4. Task 3 requires the identification of civil law articles relevant to Japan legal bar exam query. For this task, we used TF-IDF and language model-based information retrieval approaches. Task 4 requires a decision on yes/no answer for previously unseen queries given relevant civil law articles. Our approach compares the approximate meanings of queries with relevant articles. Because many statute law and queries consist of more than one paragraph, we need an inter-paragraph entailment method. Our inter-paragraph entailment process exploits an analysis of statute law structure, and negation patterns to predict entailments. Using our heuristic selection of attributes, we perform two experiments which provide the basis for making a decision on the yes/no questions. One experiment uses an SVM model, and the other uses a general heuristic rule. Our experimental evaluation demonstrates the value of our method, and the results show that our method was ranked No. 1 in both of the Tasks 3 and 4 in COLIEE 2019.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Personalization in text information retrieval: A survey\n",
            "Authors: Jingjing Liu, Chang Liu, N. Belkin\n",
            "Year: 2019\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: Personalization of information retrieval (PIR) is aimed at tailoring a search toward individual users and user groups by taking account of additional information about users besides their queries. In the past two decades or so, PIR has received extensive attention in both academia and industry. This article surveys the literature of personalization in text retrieval, following a framework for aspects or factors that can be used for personalization. The framework consists of additional information about users that can be explicitly obtained by asking users for their preferences, or implicitly inferred from users' search behaviors. Users' characteristics and contextual factors such as tasks, time, location, etc., can be helpful for personalization. This article also addresses various issues including when to personalize, the evaluation of PIR, privacy, usability, etc. Based on the extensive review, challenges are discussed and directions for future effort are suggested.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Single-Server Single-Message Online Private Information Retrieval with Side Information\n",
            "Authors: Fatemeh Kazemi, Esmaeil Karimi, A. Heidarzadeh, A. Sprintson\n",
            "Year: 2019\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: In many practical settings, the user needs to retrieve information messages from a server in a periodic manner, over multiple rounds of communication. The messages are retrieved one at a time and the identity of future requests are not known to the server. In this paper, we focus on the private information retrieval protocols that ensure that the identities of all the messages retrieved from the server are protected. This scenario can occur in practical settings such as periodic content download from text and multimedia repositories. We refer to this problem of minimizing the rate of data download as online private information retrieval problem.Following the previous line of work by Kadhe et al. we assume that the user knows a subset of M messages in the database as side information. The identities of these M messages are initially unknown to the server. Focusing on scalar-linear settings, we characterize the per-round capacity, i.e., the maximum achievable download rate at each round. In particular, we show that for the setting with K messages stored at the server, the per-round capacity of the scalar-linear setting is C1 = (M + 1)/K for round i = 1 and Ci = (2i −1(M + 1))/KM for round i ≥ 2, provided that K/(M + 1) is a power of 2. The key idea≥of our achievability scheme is to combine the data downloaded during the current round and the previous rounds with the original side information messages and use the resulting data as side information for the subsequent rounds.\n",
            "\n",
            "---\n",
            "\n",
            "Title: cwl_eval: An Evaluation Tool for Information Retrieval\n",
            "Authors: L. Azzopardi, Paul Thomas, Alistair Moffat\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We present a tool (\"cwl_eval\") which unifies many metrics typically used to evaluate information retrieval systems using test collections. In the CWL framework metrics are specified via a single function which can be used to derive a number of related measurements: Expected Utility per item, Expected Total Utility, Expected Cost per item, Expected Total Cost, and Expected Depth. The CWL framework brings together several independent approaches for measuring the quality of a ranked list, and provides a coherent user model-based framework for developing measures based on utility (gain) and cost. Here we outline the CWL measurement framework; describe the cwl_eval architecture; and provide examples of how to use it. We provide implementations of a number of recent metrics, including Time Biased Gain, U-Measure, Bejewelled Measure, and the Information Foraging Based Measure, as well as previous metrics such as Precision, Average Precision, Discounted Cumulative Gain, Rank-Biased Precision, and INST. By providing state-of-the-art and traditional metrics within the same framework, we promote a standardised approach to evaluating search effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Benchmarking Large Language Models in Retrieval-Augmented Generation\n",
            "Authors: Jiawei Chen, Hongyu Lin, Xianpei Han, Le Sun\n",
            "Year: 2023\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: Retrieval-Augmented Generation (RAG) is a promising approach for mitigating the hallucination of large language models (LLMs). However, existing research lacks rigorous evaluation of the impact of retrieval-augmented generation on different large language models, which make it challenging to identify the potential bottlenecks in the capabilities of RAG for different LLMs. In this paper, we systematically investigate the impact of Retrieval-Augmented Generation on large language models. We analyze the performance of different large language models in 4 fundamental abilities required for RAG, including noise robustness, negative rejection, information integration, and counterfactual robustness. To this end, we establish Retrieval-Augmented Generation Benchmark (RGB), a new corpus for RAG evaluation in both English and Chinese. RGB divides the instances within the benchmark into 4 separate testbeds based on the aforementioned fundamental abilities required to resolve the case. Then we evaluate 6 representative LLMs on RGB to diagnose the challenges of current LLMs when applying RAG. Evaluation reveals that while LLMs exhibit a certain degree of noise robustness, they still struggle significantly in terms of negative rejection, information integration, and dealing with false information. The aforementioned assessment outcomes indicate that there is still a considerable journey ahead to effectively apply RAG to LLMs.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Research Frontiers in Information Retrieval: Report from the Third Strategic Workshop on Information Retrieval in Lorne (SWIRL 2018)\n",
            "Authors: N. Kando, Alistair Moffat, Falk Scholer, Laurianne Sitbon, Damiano Spina, A. Trotman, E. Voorhees, Emine Yilmaz, G. Zuccon\n",
            "Year: 2018\n",
            "Venue: SIGF\n",
            "Abstract: The purpose of the Strategic Workshop in Information Retrieval in Lorne is to explore the long-range issues of the Information Retrieval field, to recognize challenges that are on - or even over - the horizon, to build consensus on some of the key challenges, and to disseminate the resulting information to the research community. The intent is that this description of open problems will help to inspire researchers and graduate students to address the questions, and will provide funding agencies data to focus and coordinate support for information retrieval research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Capacity-Achieving Private Information Retrieval Codes with Optimal Message Size and Upload Cost\n",
            "Authors: C. Tian, Hua Sun, Jun Chen\n",
            "Year: 2018\n",
            "Venue: ICC 2019 - 2019 IEEE International Conference on Communications (ICC)\n",
            "Abstract: We propose a new capacity-achieving code for the private information retrieval (PIR) problem, and show that it has the minimum message size (being one less than the number of servers) and the minimum upload cost (being roughly linear in the number of messages) among a general class of capacity-achieving codes, and in particular, among all capacity-achieving linear codes. Different from existing code constructions, the proposed code is asymmetric, and this asymmetry appears to be the key factor leading to the optimal message size and the optimal upload cost. The converse results on the message size and the upload cost are obtained by a strategic analysis of the information theoretic proof of the PIR capacity, from which a set of critical properties of any capacity-achieving code in the code class of interest is extracted.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross Subspace Alignment and the Asymptotic Capacity of $X$ -Secure $T$ -Private Information Retrieval\n",
            "Authors: Zhuqing Jia, Hua Sun, S. Jafar\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: <inline-formula> <tex-math notation=\"LaTeX\">$X$ </tex-math></inline-formula>-secure and <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-private information retrieval (XSTPIR) is a form of private information retrieval where data security is guaranteed against collusion among up to <inline-formula> <tex-math notation=\"LaTeX\">$X$ </tex-math></inline-formula> servers and the user’s privacy is guaranteed against collusion among up to <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula> servers. The capacity of XSTPIR is characterized for an arbitrary number of servers <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> and arbitrary security and privacy thresholds <inline-formula> <tex-math notation=\"LaTeX\">$X$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>, in the limit as the number of messages <inline-formula> <tex-math notation=\"LaTeX\">$K\\rightarrow \\infty $ </tex-math></inline-formula>. Capacity is also characterized for any number of messages if either <inline-formula> <tex-math notation=\"LaTeX\">$N=3, X=T=1$ </tex-math></inline-formula> or if <inline-formula> <tex-math notation=\"LaTeX\">$N\\leq X+T$ </tex-math></inline-formula>. Insights are drawn from these results, about aligning versus decoding noise, dependence of PIR rate on field size, and robustness to symmetric security constraints. In particular, the idea of cross subspace alignment, i.e., introducing a subspace dependence between Reed–Solomon code parameters, emerges as the optimal way to align undesired terms while keeping desired terms resolvable.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Geographic Information Retrieval: Progress and Challenges in Spatial Search of Text\n",
            "Authors: R. Purves, Paul D. Clough, Christopher B. Jones, M. Hall, Vanessa Murdock\n",
            "Year: 2018\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Significant amounts of information available today contain references to places on earth. Traditionally such information has been held as structured data and was the concern of Geographic Information Systems (GIS). However, increasing amounts of data in the form of unstructured text are available for indexing and retrieval that also contain spatial references. This monograph describes the field of Geographic Information Retrieval (GIR) that seeks to develop spatially-aware search systems and support user’s geographical information needs. Important concepts with respect to storing, querying and analysing geographical information in computers are introduced, before user needs and interaction in the context of GIR are explored. The task of associating documents with coordinates, prior to their indexing and ranking forms the core of any GIR system, and different approaches and their implications are discussed. Evaluating the resulting systems and their components, and different paradigms for doing so continue to be an important area of research in GIR and are illustrated through several examples. The monograph provides an overview of the research field, and in so doing identifies key remaining research challenges in GIR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the robustness and discriminative power of information retrieval metrics for top-N recommendation\n",
            "Authors: Daniel Valcarce, Alejandro Bellogín, Javier Parapar, P. Castells\n",
            "Year: 2018\n",
            "Venue: ACM Conference on Recommender Systems\n",
            "Abstract: The evaluation of Recommender Systems is still an open issue in the field. Despite its limitations, offline evaluation usually constitutes the first step in assessing recommendation methods due to its reduced costs and high reproducibility. Selecting the appropriate metric is a critical and ranking accuracy usually attracts the most attention nowadays. In this paper, we aim to shed light on the advantages of different ranking metrics which were previously used in Information Retrieval and are now used for assessing top-N recommenders. We propose methodologies for comparing the robustness and the discriminative power of different metrics. On the one hand, we study cut-offs and we find that deeper cut-offs offer greater robustness and discriminative power. On the other hand, we find that precision offers high robustness and Normalised Discounted Cumulative Gain provides the best discriminative power.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval From Coded Storage Systems With Colluding, Byzantine, and Unresponsive Servers\n",
            "Authors: Razane Tajeddine, O. W. Gnilke, David A. Karpuk, Ragnar Freij-Hollanti, C. Hollanti\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: The problem of private information retrieval (PIR) from coded storage systems with colluding, Byzantine, and unresponsive servers is considered. An explicit scheme using an <inline-formula> <tex-math notation=\"LaTeX\">$[n,k]$ </tex-math></inline-formula> Reed–Solomon storage code is designed, protecting against <inline-formula> <tex-math notation=\"LaTeX\">$t$ </tex-math></inline-formula>-collusion, and handling up to <inline-formula> <tex-math notation=\"LaTeX\">$b$ </tex-math></inline-formula> Byzantine and <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> unresponsive servers, when <inline-formula> <tex-math notation=\"LaTeX\">$n>k+t+2b+r-1$ </tex-math></inline-formula>. This scheme achieves a PIR rate of <inline-formula> <tex-math notation=\"LaTeX\">$(({n-r-(k+2b+t-1)})/{n-r})$ </tex-math></inline-formula>. In the case where the capacity is known, namely, when <inline-formula> <tex-math notation=\"LaTeX\">$k=1$ </tex-math></inline-formula>, it is asymptotically capacity achieving as the number of files grows. Finally, the scheme is adapted to symmetric PIR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Entity-Duet Neural Ranking: Understanding the Role of Knowledge Graph Semantics in Neural Information Retrieval\n",
            "Authors: Zhenghao Liu, Chenyan Xiong, Maosong Sun, Zhiyuan Liu\n",
            "Year: 2018\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: This paper presents the Entity-Duet Neural Ranking Model (EDRM), which introduces knowledge graphs to neural search systems. EDRM represents queries and documents by their words and entity annotations. The semantics from knowledge graphs are integrated in the distributed representations of their entities, while the ranking is conducted by interaction-based neural ranking networks. The two components are learned end-to-end, making EDRM a natural combination of entity-oriented search and neural information retrieval. Our experiments on a commercial search log demonstrate the effectiveness of EDRM. Our analyses reveal that knowledge graph semantics significantly improve the generalization ability of neural ranking models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Adversarial Sampling and Training for Semi-Supervised Information Retrieval\n",
            "Authors: Dae Hoon Park, Yi Chang\n",
            "Year: 2018\n",
            "Venue: The Web Conference\n",
            "Abstract: Ad-hoc retrieval models with implicit feedback often have problems, e.g., the imbalanced classes in the data set. Too few clicked documents may hurt generalization ability of the models, whereas too many non-clicked documents may harm effectiveness of the models and efficiency of training. In addition, recent neural network-based models are vulnerable to adversarial examples due to the linear nature in them. To solve the problems at the same time, we propose an adversarial sampling and training framework to learn ad-hoc retrieval models with implicit feedback. Our key idea is (i) to augment clicked examples by adversarial training for better generalization and (ii) to obtain very informational non-clicked examples by adversarial sampling and training. Experiments are performed on benchmark data sets for common ad-hoc retrieval tasks such as Web search, item recommendation, and question answering. Experimental results indicate that the proposed approaches significantly outperform strong baselines especially for high-ranked documents, and they outperform IRGAN in NDCG@5 using only 5% of labeled data for the Web search task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Unsupervised Cross-Lingual Information Retrieval Using Monolingual Data Only\n",
            "Authors: Robert Litschko, Goran Glavas, Simone Paolo Ponzetto, Ivan Vulic\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We propose a fully unsupervised framework for ad-hoc cross-lingual information retrieval (CLIR) which requires no bilingual data at all. The framework leverages shared cross-lingual word embedding spaces in which terms, queries, and documents can be represented, irrespective of their actual language. The shared embedding spaces are induced solely on the basis of monolingual corpora in two languages through an iterative process based on adversarial neural networks. Our experiments on the standard CLEF CLIR collections for three language pairs of varying degrees of language similarity (English-Dutch/Italian/Finnish) demonstrate the usefulness of the proposed fully unsupervised approach. Our CLIR models with unsupervised cross-lingual embeddings outperform baselines that utilize cross-lingual embeddings induced relying on word-level and document-level alignments. We then demonstrate that further improvements can be achieved by unsupervised ensemble CLIR models. We believe that the proposed framework is the first step towards development of effective CLIR models for language pairs and domains where parallel data are scarce or non-existent.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval From Uncoded Storage Constrained Databases\n",
            "Authors: M. Attia, Deepak Kumar, R. Tandon\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: Private information retrieval (PIR) allows a user to retrieve a desired message from a set of databases without revealing the identity of the desired message. The replicated database scenario, where <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> databases store each of the <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages was considered by Sun and Jafar, and the optimal download cost was characterized as <inline-formula> <tex-math notation=\"LaTeX\">$\\left ({1+ \\frac {1}{N}+ \\frac {1}{N^{2}}+ \\cdots + \\frac {1}{N^{K-1}}}\\right)$ </tex-math></inline-formula>. In this work, we consider the problem of PIR from <italic>uncoded storage constrained</italic> databases. Each database has a storage capacity of <inline-formula> <tex-math notation=\"LaTeX\">$\\mu KL$ </tex-math></inline-formula> bits, where <inline-formula> <tex-math notation=\"LaTeX\">$L$ </tex-math></inline-formula> is the size of each message in bits, and <inline-formula> <tex-math notation=\"LaTeX\">$\\mu \\in [{1/N, 1}]$ </tex-math></inline-formula> is the normalized storage. The novel aspect of this work is to characterize the optimum download cost of PIR from uncoded storage constrained databases for any “normalized storage” value in the range <inline-formula> <tex-math notation=\"LaTeX\">$\\mu \\in [{1/N, 1}]$ </tex-math></inline-formula>. In particular, for any <inline-formula> <tex-math notation=\"LaTeX\">$(N,K)$ </tex-math></inline-formula>, we show that the optimal trade-off between normalized storage, <inline-formula> <tex-math notation=\"LaTeX\">$\\mu $ </tex-math></inline-formula>, and the download cost, <inline-formula> <tex-math notation=\"LaTeX\">$D(\\mu)$ </tex-math></inline-formula>, is a piece-wise linear function given by the lower convex hull of the <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> pairs <inline-formula> <tex-math notation=\"LaTeX\">$\\left ({\\frac {t}{N}, \\left ({1+ \\frac {1}{t}+ \\frac {1}{t^{2}}+ \\cdots + \\frac {1}{t^{K-1}}}\\right)}\\right)$ </tex-math></inline-formula> for <inline-formula> <tex-math notation=\"LaTeX\">$t=1,2,\\ldots, N$ </tex-math></inline-formula>. To prove this result, we first present a storage constrained PIR scheme for any <inline-formula> <tex-math notation=\"LaTeX\">$(N,K)$ </tex-math></inline-formula>. Next, we obtain a general lower bound on the download cost for PIR, which is valid for any arbitrary storage architecture. The uncoded storage assumption is then applied which allows us to express the lower bound as a linear program (LP). Finally, we solve the LP to obtain tight lower bounds on the download cost for different regimes of storage, which match the proposed storage constrained PIR scheme.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Few-Shot Learning Through an Information Retrieval Lens\n",
            "Authors: Eleni Triantafillou, R. Zemel, R. Urtasun\n",
            "Year: 2017\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Few-shot learning refers to understanding new concepts from only a few examples. We propose an information retrieval-inspired approach for this problem that is motivated by the increased importance of maximally leveraging all the available information in this low-data regime. We define a training objective that aims to extract as much information as possible from each training batch by effectively optimizing over all relative orderings of the batch points simultaneously. In particular, we view each batch point as a `query' that ranks the remaining ones based on its predicted relevance to them and we define a model within the framework of structured prediction to optimize mean Average Precision over these rankings. Our method achieves impressive results on the standard few-shot classification benchmarks while is also capable of few-shot retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc Information Retrieval\n",
            "Authors: Canjia Li, Yingfei Sun, Ben He, Le Wang, Kai Hui, Andrew Yates, Le Sun, Jungang Xu\n",
            "Year: 2018\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Pseudo relevance feedback (PRF) is commonly used to boost the performance of traditional information retrieval (IR) models by using top-ranked documents to identify and weight new query terms, thereby reducing the effect of query-document vocabulary mismatches. While neural retrieval models have recently demonstrated strong results for ad-hoc retrieval, combining them with PRF is not straightforward due to incompatibilities between existing PRF approaches and neural architectures. To bridge this gap, we propose an end-to-end neural PRF framework that can be used with existing neural IR models by embedding different neural models as building blocks. Extensive experiments on two standard test collections confirm the effectiveness of the proposed NPRF framework in improving the performance of two state-of-the-art neural IR models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DeepRank: A New Deep Architecture for Relevance Ranking in Information Retrieval\n",
            "Authors: Liang Pang, Yanyan Lan, J. Guo, Jun Xu, Jingfang Xu, Xueqi Cheng\n",
            "Year: 2017\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: This paper concerns a deep learning approach to relevance ranking in information retrieval (IR). Existing deep IR models such as DSSM and CDSSM directly apply neural networks to generate ranking scores, without explicit understandings of the relevance. According to the human judgement process, a relevance label is generated by the following three steps: 1) relevant locations are detected; 2) local relevances are determined; 3) local relevances are aggregated to output the relevance label. In this paper we propose a new deep learning architecture, namely DeepRank, to simulate the above human judgment process. Firstly, a detection strategy is designed to extract the relevant contexts. Then, a measure network is applied to determine the local relevances by utilizing a convolutional neural network (CNN) or two-dimensional gated recurrent units (2D-GRU). Finally, an aggregation network with sequential integration and term gating mechanism is used to produce a global relevance score. DeepRank well captures important IR characteristics, including exact/semantic matching signals, proximity heuristics, query term importance, and diverse relevance requirement. Experiments on both benchmark LETOR dataset and a large scale clickthrough data show that DeepRank can significantly outperform learning to ranking methods, and existing deep learning methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval for Secure Distributed Storage Systems\n",
            "Authors: Heecheol Yang, W. Shin, Jungwoo Lee\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: In this paper, we investigate a private information retrieval (PIR) problem for secure distributed storage systems in the presence of an eavesdropper. We design the secure distributed database and the corresponding PIR scheme, which protect not only user privacy (concealing the index of the desired message) from the databases, but also data security (concealing the messages themselves) from an eavesdropper. In our proposed scheme, we use a secret sharing scheme in storing the messages for data security at each of the databases. We consider two different scenarios on whether the databases are aware of the index sets of the secret shares stored in other databases. The key idea in designing an efficient PIR procedure is to exploit the secret shares of undesired messages as a side information by means of storing the secret shares at multiple databases. In particular, it is shown that the rates of the proposed PIR schemes are within a constant multiplicative factor from the derived upper-bound on the capacity of PIR problem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Searching for studies: a guide to information retrieval for Campbell systematic reviews\n",
            "Authors: \n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: abstracts can be used to eliminate clearly irrelevant reports, obviating the need to obtain the full text of those reports or to return to the bibliographic database at a later time. Accession number/Unique identifier: it is advisable to set aside an unused field for storing the Unique Identifier/Accession Number of records downloaded, such as the ERIC number (EJ or ED). This allows subsequent linkage to the full database record and also facilitates information management such as duplicate detection and removal. Affiliation/address: may include the institutional affiliation and / or e-mail address of the author(s). Article identifier/Digital object identifier (DOI): should be used to cite and link to the full record.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Stateful Information Retrieval\n",
            "Authors: Sarvar Patel, G. Persiano, Kevin Yeo\n",
            "Year: 2018\n",
            "Venue: Conference on Computer and Communications Security\n",
            "Abstract: Private information retrieval (PIR) is a fundamental tool for preserving query privacy when accessing outsourced data. All previous PIR constructions have significant costs preventing widespread use. In this work, we present private stateful information retrieval (PSIR), an extension of PIR, allowing clients to be stateful and maintain information between multiple queries. Our design of the PSIR primitive maintains three important properties of PIR: multiple clients may simultaneously query without complex concurrency primitives, query privacy should be maintained if the server colludes with other clients, and new clients should be able to enroll into the system by exclusively interacting with the server. We present a PSIR framework that reduces an online query to performing one single-server PIR on a sub-linear number of database records. All other operations beyond the single-server PIR consist of cryptographic hashes or plaintext operations. In practice, the dominating costs of resources occur due to the public-key operations involved with PIR. By reducing the input database to PIR, we are able to limit expensive computation and avoid transmitting large ciphertexts. We show that various instantiations of PSIR reduce server CPU by up to 10x and online network costs by up to 10x over the previous best PIR construction.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Active Retrieval Augmented Generation\n",
            "Authors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\n",
            "Year: 2023\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Message Private Information Retrieval with Private Side Information\n",
            "Authors: S. P. Shariatpanahi, M. J. Siavoshani, M. Maddah-ali\n",
            "Year: 2018\n",
            "Venue: Information Theory Workshop\n",
            "Abstract: We consider the problem of private information retrieval (PIR) where a single user with private side information aims to retrieve multiple files from a library stored (uncoded) at a number of servers. We assume the side information at the user includes a subset of files stored privately (i.e., the server does not know the indices of these files). In addition, we require that the identity of requests and side information at the user are not revealed to any of the servers. The problem involves finding the minimum load to be transmitted from the servers to the user such that the requested files can be decoded with the help of received and side information. By providing matching lower and upper bounds, for certain regimes, we characterize the minimum load imposed to all the servers (i.e., the capacity of this PIR problem). Our result shows that the capacity is the same as the capacity of a multi-message PIR problem without private side information, but with a library of reduced size. The effective size of the library is equal to the original library size minus the size of side information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Single-server Multi-message Private Information Retrieval with Side Information\n",
            "Authors: Su Li, M. Gastpar\n",
            "Year: 2018\n",
            "Venue: Allerton Conference on Communication, Control, and Computing\n",
            "Abstract: We study the problem of single-server multi-message private information retrieval with side information. One user wants to recover N out of K independent messages which are stored at a single server. The user initially possesses a subset of M messages as side information. The goal of the user is to download the N demand messages while not leaking any information about the indices of these messages to the server. In this paper, we characterize the minimum number of required transmissions for linear codes. Moreover, we present an optimal coding scheme which enables the user to download the demand messages and preserves the privacy of their indices by using linear codes. Additionally, we show that the trivial MDS coding scheme with K-M transmissions is optimal if $N \\gt M$ or $N^{2}+N \\geq K-M$. This means if one wishes to privately download more than the square-root of the number of files in the database, then one must effectively download the full database (minus the side information), irrespective of the amount of side information one has available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Asymmetry Hurts: Private Information Retrieval Under Asymmetric Traffic Constraints\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the classical setting of private information retrieval (PIR) of a single message (file) out of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> distributed databases under the new constraint of <italic>asymmetric traffic</italic> from databases. In this problem, the <italic>ratios between the traffic</italic> from the databases are constrained, i.e., the ratio of the length of the answer string that the user (retriever) receives from the <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>th database to the total length of all answer strings from all databases is constrained to be <inline-formula> <tex-math notation=\"LaTeX\">$\\tau _{n}$ </tex-math></inline-formula>. This may happen if the user’s access to the databases is restricted due to database availability, channel quality to the databases, and other factors. For this problem, for fixed <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, we develop a general upper bound <inline-formula> <tex-math notation=\"LaTeX\">$\\bar {C}({\\boldsymbol {\\tau }})$ </tex-math></inline-formula>, which generalizes the converse proof of Sun-Jafar, where database symmetry was inherently used. Our converse bound is a piece-wise affine function in the traffic ratio vector <inline-formula> <tex-math notation=\"LaTeX\">${\\boldsymbol {\\tau }}=(\\tau _{1}, \\cdots , \\tau _{N})$ </tex-math></inline-formula>. For the lower bound, we explicitly show the achievability of <inline-formula> <tex-math notation=\"LaTeX\">$\\binom {M+N-1}{M}$ </tex-math></inline-formula> corner points. For the remaining traffic ratio vectors, we perform time-sharing between these corner points. The recursive structure of our achievability scheme is captured via a system of difference equations. The upper and lower bounds exactly match for <inline-formula> <tex-math notation=\"LaTeX\">$M=2$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$M=3$ </tex-math></inline-formula> for any <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> and any <inline-formula> <tex-math notation=\"LaTeX\">${\\boldsymbol {\\tau }}$ </tex-math></inline-formula>. The results show strict loss of PIR capacity due to the asymmetric traffic constraints compared with the symmetric case of Sun-Jafar which implicitly uses <inline-formula> <tex-math notation=\"LaTeX\">$\\tau _{n}=\\frac {1}{N}$ </tex-math></inline-formula> for all <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: Global Communications Conference\n",
            "Abstract: In the private information retrieval (PIR) problem a user wishes to retrieve, as efficiently as possible, one out of K messages from N non-communicating databases (each holds all K messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For K messages and N databases, we show that the PIR capacity is (1 + 1/N + 1/N^2 + &#183; &#183; &#183; + 1/N({K&#8722;1})^{&#8722;1}. A remarkable feature of the capacity achieving scheme is that if it is projected onto any subset of messages by eliminating the remaining messages, it also achieves the PIR capacity for that subset of messages.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ethical Dimensions of Music Information Retrieval Technology\n",
            "Authors: A. Holzapfel, Bob L. Sturm, Mark Coeckelbergh\n",
            "Year: 2018\n",
            "Venue: Transactions of the International Society for Music Information Retrieval\n",
            "Abstract: This article examines ethical dimensions of Music Information Retrieval (MIR) technology.  It uses practical ethics (especially computer ethics and engineering ethics) and socio-technical approache ...\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the Capacity of Single-Server Multi-Message Private Information Retrieval with Side Information\n",
            "Authors: A. Heidarzadeh, B. Garcia, S. Kadhe, S. E. Rouayheb, A. Sprintson\n",
            "Year: 2018\n",
            "Venue: Allerton Conference on Communication, Control, and Computing\n",
            "Abstract: We study Private Information Retrieval with Side Information (PIR-SI) in the single-server multi-message setting. In this setting, a user wants to download D messages from a database of $K \\geq D$ messages, stored on a single server, without revealing any information about the identities of the demanded messages to the server. The goal of the user is to achieve information-theoretic privacy by leveraging the side information about the database. The side information consists of a random subset of M messages. The identities of the messages forming the side information are initially unknown to the server. Our goal is to characterize the capacity of this setting, i.e., the maximum achievable download rate. In our previous work, we have established the PIR-SI capacity for the special case in which the user wants a single message, i.e., $D = 1$ and showed that the capacity can be achieved through the Partition and Code scheme. In this paper, we focus on the case when the user wants multiple messages, i.e., $D\\lt /p\\gt \\gt 1$. Our first result is that if the user wants more messages than what they have as side information, i.e., $D \\gt M$, then the capacity is $\\frac{D}{K-M}$, and it can be achieved using a scheme based on the Generalized Reed-Solomon codes. Our second result shows that when $D\\leq M$ the capacity can be higher. We present a lower bound on the capacity based on an achievability scheme which we call Generalized Partition and Code.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The use of ontologies for effective knowledge modelling and information retrieval\n",
            "Authors: K. Munir, M. Sheraz Anjum\n",
            "Year: 2018\n",
            "Venue: Applied Computing and Informatics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieve-and-Read: Multi-task Learning of Information Retrieval and Reading Comprehension\n",
            "Authors: Kyosuke Nishida, Itsumi Saito, Atsushi Otsuka, Hisako Asano, J. Tomita\n",
            "Year: 2018\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: This study considers the task of machine reading at scale (MRS) wherein, given a question, a system first performs the information retrieval (IR) task of finding relevant passages in a knowledge source and then carries out the reading comprehension (RC) task of extracting an answer span from the passages. Previous MRS studies, in which the IR component was trained without considering answer spans, struggled to accurately find a small number of relevant passages from a large set of passages. In this paper, we propose a simple and effective approach that incorporates the IR and RC tasks by using supervised multi-task learning in order that the IR component can be trained by considering answer spans. Experimental results on the standard benchmark, answering SQuAD questions using the full Wikipedia as the knowledge source, showed that our model achieved state-of-the-art performance. Moreover, we thoroughly evaluated the individual contributions of our model components with our new Japanese dataset and SQuAD. The results showed significant improvements in the IR task and provided a new perspective on IR for RC: it is effective to teach which part of the passage answers the question rather than to give only a relevance score to the whole passage.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural Models for Information Retrieval\n",
            "Authors: Bhaskar Mitra, Nick Craswell\n",
            "Year: 2017\n",
            "Venue: arXiv.org\n",
            "Abstract: Neural ranking models for information retrieval (IR) use shallow or deep neural networks to rank search results in response to a query. Traditional learning to rank models employ machine learning techniques over hand-crafted IR features. By contrast, neural models learn representations of language from raw text that can bridge the gap between query and document vocabulary. Unlike classical IR models, these new machine learning based approaches are data-hungry, requiring large scale training data before they can be deployed. This tutorial introduces basic concepts and intuitions behind neural IR models, and places them in the context of traditional retrieval models. We begin by introducing fundamental concepts of IR and different neural and non-neural approaches to learning vector representations of text. We then review shallow neural IR methods that employ pre-trained neural term embeddings without learning the IR task end-to-end. We introduce deep neural networks next, discussing popular deep architectures. Finally, we review the current DNN models for information retrieval. We conclude with a discussion on potential future directions for neural IR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval and Criticality in Parity-Time-Symmetric Systems.\n",
            "Authors: K. Kawabata, Yuto Ashida, Masahito Ueda\n",
            "Year: 2017\n",
            "Venue: Physical Review Letters\n",
            "Abstract: By investigating information flow between a general parity-time (PT-)symmetric non-Hermitian system and an environment, we find that the complete information retrieval from the environment can be achieved in the PT-unbroken phase, whereas no information can be retrieved in the PT-broken phase. The PT-transition point thus marks the reversible-irreversible criticality of information flow, around which many physical quantities such as the recurrence time and the distinguishability between quantum states exhibit power-law behavior. Moreover, by embedding a PT-symmetric system into a larger Hilbert space so that the entire system obeys unitary dynamics, we reveal that behind the information retrieval lies a hidden entangled partner protected by PT symmetry. Possible experimental situations are also discussed.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modeling Text with Graph Convolutional Network for Cross-Modal Information Retrieval\n",
            "Authors: J. Yu, Yuhang Lu, Zengchang Qin, Yanbing Liu, Jianlong Tan, Li Guo, Weifeng Zhang\n",
            "Year: 2018\n",
            "Venue: Pacific Rim Conference on Multimedia\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval with Eavesdroppers\n",
            "Authors: Qiwen Wang, Hua Sun, M. Skoglund\n",
            "Year: 2018\n",
            "Venue: Asilomar Conference on Signals, Systems and Computers\n",
            "Abstract: We consider the problem of private information retrieval (PIR) with colluding servers and eavesdroppers (abbreviated as ETPIR). The ETPIR problem is comprised of K messages, N servers where each server stores all K messages, a user who wants to retrieve one of the K messages without revealing the desired message index to any set of T colluding servers, and an eavesdropper who can listen to the queries and answers of any E servers but is prevented from learning any information about the messages. The information theoretic capacity of ETPIR is defined to be the maximum number of desired message symbols retrieved privately per information symbol downloaded. We show that the capacity of ETPIR is $C = \\left({1-\\displaystyle \\frac {E}{N}}\\right)\\left({1+ \\frac {T-E}{N-E}+\\cdots + \\left({\\frac {T-E}{N-E}}\\right)^{K-1}}\\right)^{-1}$ when $E \\lt T,$ and $C = \\left({1\\displaystyle-\\frac {E}{N}}\\right)$ when $E \\geq T$. To achieve the capacity, the servers need to share a common random variable (independent of the messages), and its size must be at least $\\displaystyle \\frac {E}{N}. \\displaystyle \\frac {1}{c}$ symbols per message symbol. Otherwise, with less amount of shared common randomness, ETPIR is not feasible and the capacity reduces to zero. An interesting observation is that the ETPIR capacity expression takes different forms in two regimes. When $E \\lt T,$ the capacity equals the inverse of a sum of a geometric series with K terms and decreases with K; this form is typical for capacity expressions of PIR. When $E\\geq T$, the capacity does not depend on K, a typical form for capacity expressions of SPIR (symmetric PIR, which further requires data-privacy, i.e., the user learns no information about other undesired messages); the capacity does not depend on T either. In addition, the ETPIR capacity result includes multiple previous PIR and SPIR capacity results as special cases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The capacity of cache aided private information retrieval\n",
            "Authors: R. Tandon\n",
            "Year: 2017\n",
            "Venue: Allerton Conference on Communication, Control, and Computing\n",
            "Abstract: The problem of cache enabled private information retrieval (PIR) is considered in which a user wishes to privately retrieve one out of K messages, each of size L bits from N distributed databases. The user has a local cache of storage SL bits which can be used to store any function of the K messages. The main contribution of this work is the exact characterization of the capacity of cache enabled PIR as a function of the storage parameter S. In particular, for a given cache storage parameter S, the information-theoretically optimal download cost D∗(S)/L (or the inverse of capacity) is shown to be equal to (1 − S/K)(1 + 1/N + … + 1/NK−1). Special cases of this result correspond to the settings when S = 0, for which the optimal download cost was shown by Sun and Jafar to be (1 + 1/N + … + 1/NK−1), and the case when S = K, i.e., cache size is large enough to store all messages locally, for which the optimal download cost is 0. The intermediate points S ∊ (0, K) can be readily achieved through a simple memory-sharing based PIR scheme. The key technical contribution of this work is the converse, i.e., a lower bound on the download cost as a function of storage S which shows that memory sharing is information-theoretically optimal.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Message Private Information Retrieval: Capacity Results and Near-Optimal Schemes\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of multi-message private information retrieval (MPIR) from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating replicated databases. In MPIR, the user is interested in retrieving <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula> messages out of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> stored messages without leaking the identity of the retrieved messages. The information-theoretic sum capacity of MPIR <inline-formula> <tex-math notation=\"LaTeX\">$C_{s}^{P}$ </tex-math></inline-formula> is the maximum number of desired message symbols that can be retrieved privately per downloaded symbol, where the symbols are defined over the same field. For the case <inline-formula> <tex-math notation=\"LaTeX\">$P \\geq M/2$ </tex-math></inline-formula>, we determine the exact sum capacity of MPIR as <inline-formula> <tex-math notation=\"LaTeX\">$C_{s}^{P}=1/(1+(M-P)/(PN))$ </tex-math></inline-formula>. The achievable scheme in this case is based on downloading MDS-coded mixtures of all messages. For <inline-formula> <tex-math notation=\"LaTeX\">$P \\leq {M}/{2}$ </tex-math></inline-formula>, we develop lower and upper bounds for all <inline-formula> <tex-math notation=\"LaTeX\">$M,P,N$ </tex-math></inline-formula>. These bounds match if the total number of messages <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> is an integer multiple of the number of desired messages <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>, i.e., <inline-formula> <tex-math notation=\"LaTeX\">$M/P \\in \\mathbb {N}$ </tex-math></inline-formula>. In this case, <inline-formula> <tex-math notation=\"LaTeX\">$C_{s}^{P}=(1+1/N+\\cdots +1/N^{M/P-1})^{-1}$ </tex-math></inline-formula>, i.e., <inline-formula> <tex-math notation=\"LaTeX\">$C_{s}^{P}=(1-1/N)/(1-1/N^{M/P})$ </tex-math></inline-formula> for <inline-formula> <tex-math notation=\"LaTeX\">$N>1$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=\"LaTeX\">$C_{s}^{P}=P/M$ </tex-math></inline-formula> for <inline-formula> <tex-math notation=\"LaTeX\">$N=1$ </tex-math></inline-formula>. The achievable scheme in this case generalizes the single-message capacity achieving scheme to have unbalanced number of stages per round of download. For all the remaining cases, the difference between the lower and upper bound is at most 0.0082, which occurs for <inline-formula> <tex-math notation=\"LaTeX\">$M=5$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$P=2$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$N=2$ </tex-math></inline-formula>. Our results indicate that joint retrieval of desired messages is more efficient than successive use of single-message retrieval schemes even after considering the free savings that result from downloading undesired symbols in each single-message retrieval round.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Statistical biases in Information Retrieval metrics for recommender systems\n",
            "Authors: Alejandro Bellogín, P. Castells, Iván Cantador\n",
            "Year: 2017\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval With Side Information\n",
            "Authors: S. Kadhe, B. Garcia, A. Heidarzadeh, Salim el Rouayheb, A. Sprintson\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We study the problem of Private Information Retrieval (PIR) in the presence of prior side information. The problem setup includes a database of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> independent messages possibly replicated on several servers, and a user that needs to retrieve one of these messages. In addition, the user has some prior side information in the form of a subset of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages, not containing the desired message and unknown to the servers. This problem is motivated by practical settings in which the user can obtain side information opportunistically from other users or has previously downloaded some messages using classical PIR schemes. The objective of the user is to retrieve the required message with downloading minimum amount of data from the servers while achieving information-theoretic privacy in one of the following two scenarios: (i) the user wants to protect jointly the identities of the demand and the side information; (ii) the user wants to protect only the identity of the demand, but not necessarily the side information. To highlight the role of side information, we focus first on the case of a single server (single database). In the first scenario, we prove that the minimum download cost is <inline-formula> <tex-math notation=\"LaTeX\">$K-M$ </tex-math></inline-formula> messages, and in the second scenario it is <inline-formula> <tex-math notation=\"LaTeX\">$\\lceil K/(M+1)\\rceil $ </tex-math></inline-formula> messages, which should be compared to <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages—the minimum download cost in the case of no side information. Then, we extend some of our results to the case of the database replicated on multiple servers. Our proof techniques relate PIR with side information to the index coding problem. We leverage this connection to prove converse results, as well as to design achievability schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Hospital nurses’ information retrieval behaviours in relation to evidence based nursing: a literature review\n",
            "Authors: B. Alving, J. B. Christensen, Lars Thrysøe\n",
            "Year: 2018\n",
            "Venue: Health Information and Libraries Journal\n",
            "Abstract: OBJECTIVE\n",
            "The purpose of this literature review is to provide an overview of the information retrieval behaviour of clinical nurses, in terms of the use of databases and other information resources and their frequency of use.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Systematic searches carried out in five databases and handsearching were used to identify the studies from 2010 to 2016, with a populations, exposures and outcomes (PEO) search strategy, focusing on the question: In which databases or other information resources do hospital nurses search for evidence based information, and how often?\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Of 5272 titles retrieved based on the search strategy, only nine studies fulfilled the criteria for inclusion. The studies are from the United States, Canada, Taiwan and Nigeria. The results show that hospital nurses' primary choice of source for evidence based information is Google and peers, while bibliographic databases such as PubMed are secondary choices. Data on frequency are only included in four of the studies, and data are heterogenous.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "The reasons for choosing Google and peers are primarily lack of time; lack of information; lack of retrieval skills; or lack of training in database searching. Only a few studies are published on clinical nurses' retrieval behaviours, and more studies are needed from Europe and Australia.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval Through Wiretap Channel II: Privacy Meets Security\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of private information retrieval through wiretap channel II (PIR-WTC-II). In PIR-WTC-II, a user wants to retrieve a single message (file) privately out of M messages, which are stored in N replicated and non-communicating databases. An external eavesdropper observes a fraction <inline-formula> <tex-math notation=\"LaTeX\">$\\mu _{\\text {n}}$ </tex-math></inline-formula> (of its choice) of the traffic exchanged between the nth database and the user. In addition to the privacy constraint, the databases should encode the returned answer strings such that the eavesdropper learns absolutely nothing about the <italic>contents</italic> of the databases. We aim at characterizing the capacity of the PIR-WTC-II under the combined privacy and security constraints. We obtain a general upper bound for the problem in the form of a max-min optimization problem, which extends the converse proof of the PIR problem under asymmetric traffic constraints. We propose an achievability scheme that satisfies the security constraint by encoding a secret key, which is generated securely at each database, into an artificial noise vector using an MDS code. The user and the databases operate at one of the corner points of the achievable scheme for the PIR under asymmetric traffic constraints such that the retrieval rate is maximized under the imposed security constraint. The upper bound and the lower bound match for the case of <inline-formula> <tex-math notation=\"LaTeX\">$\\text {M}=2$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$\\text {M}=3$ </tex-math></inline-formula> messages, for any N, and any <inline-formula> <tex-math notation=\"LaTeX\">$\\boldsymbol {\\mu }=(\\mu _{1}, \\cdots, \\mu _{\\text {N}})$ </tex-math></inline-formula>.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval in Graph-Based Replication Systems\n",
            "Authors: Netanel Raviv, Itzhak Tamo, Eitan Yaakobi\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: In a Private Information Retrieval (PIR) protocol, a user can download a file from a database without revealing the identity of the file to each individual server. A PIR protocol is called <inline-formula> <tex-math notation=\"LaTeX\">$t$ </tex-math></inline-formula><italic>-private</italic> if the identity of the file remains concealed even if <inline-formula> <tex-math notation=\"LaTeX\">$t$ </tex-math></inline-formula> of the servers collude. Graph based replication is a simple technique, which is prevalent in both theory and practice, for achieving robustness in storage systems. In this technique each file is replicated on two or more storage servers, giving rise to a (hyper-)graph structure. In this paper we study private information retrieval protocols in graph based replication systems. The main interest of this work is understanding the collusion structures which emerge in the underlying graph. Our main contribution is a 2-replication scheme which guarantees perfect privacy from acyclic sets in the graph, and guarantees partial-privacy in the presence of cycles. Furthermore, by providing an upper bound, it is shown that the PIR rate of this scheme is at most a factor of two from its optimal value for regular graphs. Lastly, we extend our results to larger replication factors and to graph-based coding, a generalization of graph based replication that induces smaller storage overhead and larger PIR rate in many cases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval from Byzantine and Colluding Databases\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of single-round private information retrieval (PIR) from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> replicated databases. We consider the case when <inline-formula> <tex-math notation=\"LaTeX\">$B$ </tex-math></inline-formula> databases are outdated (unsynchronized), or even worse, adversarial (Byzantine), and therefore, can return incorrect answers. In the PIR problem with Byzantine databases (BPIR), a user wishes to retrieve a specific message from a set of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages with zero-error, irrespective of the actions performed by the Byzantine databases. We consider the <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-privacy constraint in this paper, where any <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula> databases can collude, and exchange the queries submitted by the user. We derive the information-theoretic capacity of this problem, which is the maximum number of <italic>correct symbols</italic> that can be retrieved privately (under the <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-privacy constraint) for every symbol of the downloaded data. We determine the exact BPIR capacity to be <inline-formula> <tex-math notation=\"LaTeX\">$C=(N-2B)/N \\cdot (1-T/(N-2B))/(1-(T/(N-2B))^{M})$ </tex-math></inline-formula>, if <inline-formula> <tex-math notation=\"LaTeX\">$2B+T < N$ </tex-math></inline-formula>. This capacity expression shows that the effect of Byzantine databases on the retrieval rate is equivalent to removing <inline-formula> <tex-math notation=\"LaTeX\">$2B$ </tex-math></inline-formula> databases from the system, with a penalty factor of <inline-formula> <tex-math notation=\"LaTeX\">$(N-2B)/N$ </tex-math></inline-formula>, which signifies that even though the number of databases needed for PIR is effectively <inline-formula> <tex-math notation=\"LaTeX\">$N-2B$ </tex-math></inline-formula>, the user still needs to access the entire <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> databases. The result shows that for the unsynchronized PIR problem, if the user does not have any knowledge about the fraction of the messages that are mis-synchronized, the single-round capacity is the same as the BPIR capacity. Our achievable scheme extends the optimal achievable scheme for the robust PIR (RPIR) problem to correct the <italic>errors</italic> introduced by the Byzantine databases as opposed to <italic>erasures</italic> in the RPIR problem. Our converse proof uses the idea of the cut-set bound in the network coding problem against adversarial nodes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the Theory of Weak Supervision for Information Retrieval\n",
            "Authors: Hamed Zamani, W. Bruce Croft\n",
            "Year: 2018\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Neural network approaches have recently shown to be effective in several information retrieval (IR) tasks. However, neural approaches often require large volumes of training data to perform effectively, which is not always available. To mitigate the shortage of labeled data, training neural IR models with weak supervision has been recently proposed and received considerable attention in the literature. In weak supervision, an existing model automatically generates labels for a large set of unlabeled data, and a machine learning model is further trained on the generated \"weak\" data. Surprisingly, it has been shown in prior art that the trained neural model can outperform the weak labeler by a significant margin. Although these obtained improvements have been intuitively justified in previous work, the literature still lacks theoretical justification for the observed empirical findings. In this paper, we provide a theoretical insight into weak supervision for information retrieval, focusing on learning to rank. We model the weak supervision signal as a noisy channel that introduces noise to the correct ranking. Based on the risk minimization framework, we prove that given some sufficient constraints on the loss function, weak supervision is equivalent to supervised learning under uniform noise. We also find an upper bound for the empirical risk of weak supervision in case of non-uniform noise. Following the recent work on using multiple weak supervision signals to learn more accurate models, we find an information theoretic lower bound on the number of weak supervision signals required to guarantee an upper bound for the pairwise error probability. We empirically verify a set of presented theoretical findings, using synthetic and real weak supervision data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Utilizing Knowledge Graphs for Text-Centric Information Retrieval\n",
            "Authors: Laura Dietz, Alexander Kotov, E. Meij\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The past decade has witnessed the emergence of several publicly available and proprietary knowledge graphs (KGs). The depth and breadth of content in these KGs made them not only rich sources of structured knowledge by themselves, but also valuable resources for search systems. A surge of recent developments in entity linking and entity retrieval methods gave rise to a new line of research that aims at utilizing KGs for text-centric retrieval applications. This tutorial is the first to summarize and disseminate the progress in this emerging area to industry practitioners and researchers.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval With Private Side Information Under Storage Constraints\n",
            "Authors: Yi-Peng Wei, S. Ulukus\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of private information retrieval (PIR) of a single message out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> replicated and non-colluding databases where a cache-enabled user (retriever) of cache-size <inline-formula> <tex-math notation=\"LaTeX\">$S$ </tex-math></inline-formula> possesses side information in the form of uncoded portions of the messages where the message identities are unknown to the databases. The identities of these side information messages need to be kept private from the databases, i.e., we consider PIR with private side information (PSI). We characterize the optimal normalized download cost for this PIR-PSI problem under the storage constraint <inline-formula> <tex-math notation=\"LaTeX\">$S$ </tex-math></inline-formula> as <inline-formula> <tex-math notation=\"LaTeX\">$D^{*}=1+\\frac {1}{N}+\\frac {1}{N^{2}}+ {\\dots }+\\frac {1}{N^{K-1-M}}+ \\frac {1-r_{M}}{N^{K-M}}+\\frac {1-r_{M-1}}{N^{K-M+1}}+ {\\dots }+\\frac {1-r_{1}}{N^{K-1}}$ </tex-math></inline-formula>, where <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> is the number of side information messages and <inline-formula> <tex-math notation=\"LaTeX\">$r_{i}$ </tex-math></inline-formula> is the portion of the <inline-formula> <tex-math notation=\"LaTeX\">$i$ </tex-math></inline-formula>th side information message that is cached with <inline-formula> <tex-math notation=\"LaTeX\">$\\sum _{i=1}^{M} r_{i}=S$ </tex-math></inline-formula>. Based on this capacity result, we prove two facts: First, for a fixed memory size <inline-formula> <tex-math notation=\"LaTeX\">$S$ </tex-math></inline-formula> and a fixed number of accessible messages <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula>, uniform caching achieves the lowest normalized download cost, i.e., <inline-formula> <tex-math notation=\"LaTeX\">$r_{i}=\\frac {S}{M}$ </tex-math></inline-formula>, for <inline-formula> <tex-math notation=\"LaTeX\">$i=1, {\\dots }, M$ </tex-math></inline-formula>, is optimum. Second, for a fixed memory size <inline-formula> <tex-math notation=\"LaTeX\">$S$ </tex-math></inline-formula>, among all possible <inline-formula> <tex-math notation=\"LaTeX\">$K-\\left \\lceil{ {S} }\\right \\rceil +1$ </tex-math></inline-formula> uniform caching schemes, the uniform caching scheme which caches <inline-formula> <tex-math notation=\"LaTeX\">$M=K$ </tex-math></inline-formula> messages achieves the lowest normalized download cost.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Intelligent ontology based semantic information retrieval using feature selection and classification\n",
            "Authors: B. Selvalakshmi, M. Subramaniam\n",
            "Year: 2018\n",
            "Venue: Cluster Computing\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A data-driven text mining and semantic network analysis for design information retrieval\n",
            "Authors: Feng Shi, Liuqing Chen, Ji Han, P. Childs\n",
            "Year: 2018\n",
            "Venue: \n",
            "Abstract: ..................................................................................................................... 2 Declaration ................................................................................................................. 3 List of Publications ..................................................................................................... 4 Table of\n",
            "\n",
            "---\n",
            "\n",
            "Title: Query Expansion Techniques for Information Retrieval: a Survey\n",
            "Authors: Dr. Hiteshwar Kumar Azad, A. Deepak\n",
            "Year: 2017\n",
            "Venue: Information Processing & Management\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private information retrieval schemes for codec data with arbitrary collusion patterns\n",
            "Authors: Razane Tajeddine, O. W. Gnilke, David A. Karpuk, Ragnar Freij, C. Hollanti, S. E. Rouayheb\n",
            "Year: 2017\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: In Private Information Retrieval (PIR), one wants to download a file from a database without revealing to the database which file is being downloaded. Much attention has been paid to the case of the database being encoded across several servers, subsets of which can collude to attempt to deduce the requested file. With the goal of studying the achievable PIR rates in realistic scenarios, we generalize results for coded data from the case of all subsets of servers of size t colluding, to arbitrary subsets of the servers. We investigate the effectiveness of previous strategies in this new scenario, and present new results in the case where the servers are partitioned into disjoint colluding groups.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Introduction to the special issue on bibliometric-enhanced information retrieval and natural language processing for digital libraries (BIRNDL)\n",
            "Authors: Philipp Mayr, Ingo Frommholz, G. Cabanac, Muthu Kumar Chandrasekaran, Kokil Jaidka, Min-Yen Kan, Dietmar Wolfram\n",
            "Year: 2018\n",
            "Venue: International Journal on Digital Libraries\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Using Word Embeddings for Information Retrieval: How Collection and Term Normalization Choices Affect Performance\n",
            "Authors: Dwaipayan Roy, Debasis Ganguly, S. Bhatia, Srikanta J. Bedathur, Mandar Mitra\n",
            "Year: 2018\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Neural word embedding approaches, due to their ability to capture semantic meanings of vocabulary terms, have recently gained attention of the information retrieval (IR) community and have shown promising results in improving ad hoc retrieval performance. It has been observed that these approaches are sensitive to various choices made during the learning of word embeddings and their usage, often leading to poor reproducibility. We study the effect of varying following two parameters, viz., i) the term normalization and ii) the choice of training collection, on ad hoc retrieval performance with word2vec and fastText embeddings. We present quantitative estimates of similarity of word vectors obtained under different settings, and use embeddings based query expansion task to understand the effects of these parameters on IR effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval with Private Side Information\n",
            "Authors: Zhen Chen, Zhiying Wang, S. Jafar\n",
            "Year: 2017\n",
            "Venue: arXiv.org\n",
            "Abstract: We consider the problem of $T$-Private Information Retrieval with private side information (TPIR-PSI). In this problem, $N$ replicated databases store $K$ independent messages, and a user, equipped with a local cache that holds $M$ messages as side information, wishes to retrieve one of the other $K-M$ messages. The desired message index and the side information must remain jointly private even if any $T$ of the $N$ databases collude. We show that the capacity of TPIR-PSI is $\\left(1+\\frac{T}{N}+\\cdots+\\left(\\frac{T}{N}\\right)^{K-M-1}\\right)^{-1}$. As a special case obtained by setting $T=1$, this result settles the capacity of PIR-PSI, an open problem previously noted by Kadhe et al. We also consider the problem of symmetric-TPIR with private side information (STPIR-PSI), where the answers from all $N$ databases reveal no information about any other message besides the desired message. We show that the capacity of STPIR-PSI is $1-\\frac{T}{N}$ if the databases have access to common randomness (not available to the user) that is independent of the messages, in an amount that is at least $\\frac{T}{N-T}$ bits per desired message bit. Otherwise, the capacity of STPIR-PSI is zero.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fundamental Limits of Cache-Aided Private Information Retrieval With Unknown and Uncoded Prefetching\n",
            "Authors: Yi-Peng Wei, Karim A. Banawan, S. Ulukus\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of private information retrieval (PIR) from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-colluding and replicated databases when the user is equipped with a cache that holds an uncoded fraction <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> from each of the <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> stored messages in the databases. We assume that the databases are unaware of the cache content. We investigate <inline-formula> <tex-math notation=\"LaTeX\">$D^{*}(r)$ </tex-math></inline-formula> the optimal download cost normalized with the message size as a function of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula>. For a fixed <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, we develop an inner bound (converse bound) for the <inline-formula> <tex-math notation=\"LaTeX\">$D^{*}(r)$ </tex-math></inline-formula> curve. The inner bound is a piece-wise linear function in <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> that consists of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> line segments. For the achievability, we develop explicit schemes that exploit the cached bits as side information to achieve <inline-formula> <tex-math notation=\"LaTeX\">$K-1$ </tex-math></inline-formula> non-degenerate corner points. These corner points differ in the number of cached bits that are used to generate the one-side information equation. We obtain an outer bound (achievability) for any caching ratio by memory sharing between these corner points. Thus, the outer bound is also a piece-wise linear function in <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> that consists of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> line segments. The inner and the outer bounds match in general for the cases of very low-caching ratio and very high-caching ratio. As a corollary, we fully characterize the optimal download cost caching ratio tradeoff for <inline-formula> <tex-math notation=\"LaTeX\">$K=3$ </tex-math></inline-formula>. For general <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula>, we show that the largest gap between the achievability and the converse bounds is 1/6. Our results show that the download cost can be reduced beyond memory sharing if the databases are unaware of the cached content.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural information retrieval: at the end of the early years\n",
            "Authors: Kezban Dilek Onal, Ye Zhang, I. S. Altingövde, Md. Mustafizur Rahman, Pinar Senkul, Alexander Braylan, B. Dang, Heng-Lu Chang, Henna Kim, Quinten McNamara, Aaron Angert, Edward Banner, Vivek Khetan, Tyler McDonnell, A. T. Nguyen, Dan Xu, Byron C. Wallace, M. de Rijke, Matthew Lease\n",
            "Year: 2017\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval From Coded Databases\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of private information retrieval (PIR) over a distributed storage system. The storage system consists of <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-colluding databases, each storing an MDS-coded version of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages. In the PIR problem, the user wishes to retrieve one of the available messages without revealing the message identity to any individual database. We derive the information-theoretic capacity of this problem, which is defined as the maximum number of bits of the desired message that can be privately retrieved per one bit of downloaded information. We show that the PIR capacity in this case is <inline-formula> <tex-math notation=\"LaTeX\">$C=(1+{K}/{N}+{K^{2}}/{N^{2}}+\\cdots +{K^{M-1}}/{N^{M-1}})^{-1}=(1+R_{c}+R_{c}^{2}+\\cdots +R_{c}^{M-1})^{-1}=({1-R_{c}})/({1-R_{c}^{M}})$ </tex-math></inline-formula>, where <inline-formula> <tex-math notation=\"LaTeX\">$R_{c}$ </tex-math></inline-formula> is the rate of the <inline-formula> <tex-math notation=\"LaTeX\">$(N,K)$ </tex-math></inline-formula> MDS code used. The capacity is a function of the code rate and the number of messages only regardless of the explicit structure of the storage code. The result implies a fundamental tradeoff between the optimal retrieval cost and the storage cost when the storage code is restricted to the class of MDS codes. The result generalizes the achievability and converse results for the classical PIR with replicated databases to the case of MDS-coded databases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval\n",
            "Authors: Hamid Palangi, L. Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, R. Ward\n",
            "Year: 2015\n",
            "Venue: IEEE/ACM Transactions on Audio Speech and Language Processing\n",
            "Abstract: This paper develops a model that addresses sentence embedding, a hot topic in current natural language processing research, using recurrent neural networks (RNN) with Long Short-Term Memory (LSTM) cells. The proposed LSTM-RNN model sequentially takes each word in a sentence, extracts its information, and embeds it into a semantic vector. Due to its ability to capture long term memory, the LSTM-RNN accumulates increasingly richer information as it goes through the sentence, and when it reaches the last word, the hidden layer of the network provides a semantic representation of the whole sentence. In this paper, the LSTM-RNN is trained in a weakly supervised manner on user click-through data logged by a commercial web search engine. Visualization and analysis are performed to understand how the embedding process works. The model is found to automatically attenuate the unimportant words and detect the salient keywords in the sentence. Furthermore, these detected keywords are found to automatically activate different cells of the LSTM-RNN, where words belonging to a similar topic activate the same cell. As a semantic representation of the sentence, the embedding vector can be used in many different applications. These automatic keyword detection and topic allocation abilities enabled by the LSTM-RNN allow the network to perform document retrieval, a difficult language processing task, where the similarity between the query and documents can be measured by the distance between their corresponding sentence embedding vectors computed by the LSTM-RNN. On a web search task, the LSTM-RNN embedding is shown to significantly outperform several existing state of the art methods. We emphasize that the proposed model generates sentence embedding vectors that are specially useful for web document retrieval tasks. A comparison with a well known general sentence embedding method, the Paragraph Vector, is performed. The results show that the proposed method in this paper significantly outperforms Paragraph Vector method for web document retrieval task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On the concept of relevance in legal information retrieval\n",
            "Authors: M. V. Opijnen, Cristiana Santos\n",
            "Year: 2017\n",
            "Venue: Artificial Intelligence and Law\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Tutorial on Deep Learning for Music Information Retrieval\n",
            "Authors: Keunwoo Choi, György Fazekas, Kyunghyun Cho, M. Sandler\n",
            "Year: 2017\n",
            "Venue: arXiv.org\n",
            "Abstract: Following their success in Computer Vision and other areas, deep learning techniques have recently become widely adopted in Music Information Retrieval (MIR) research. However, the majority of works aim to adopt and assess methods that have been shown to be effective in other domains, while there is still a great need for more original research focusing on music primarily and utilising musical knowledge and insight. The goal of this paper is to boost the interest of beginners by providing a comprehensive tutorial and reducing the barriers to entry into deep learning for MIR. We lay out the basic principles and review prominent works in this hard to navigate field. We then outline the network structures that have been successful in MIR problems and facilitate the selection of building blocks for the problems at hand. Finally, guidelines for new tasks and some advanced topics in deep learning are discussed to stimulate new research in this fascinating field.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval and Text Mining Technologies for Chemistry.\n",
            "Authors: Martin Krallinger, Obdulia Rabal, A. Lourenço, J. Oyarzábal, A. Valencia\n",
            "Year: 2017\n",
            "Venue: Chemical Reviews\n",
            "Abstract: Efficient access to chemical information contained in scientific literature, patents, technical reports, or the web is a pressing need shared by researchers and patent attorneys from different chemical disciplines. Retrieval of important chemical information in most cases starts with finding relevant documents for a particular chemical compound or family. Targeted retrieval of chemical documents is closely connected to the automatic recognition of chemical entities in the text, which commonly involves the extraction of the entire list of chemicals mentioned in a document, including any associated information. In this Review, we provide a comprehensive and in-depth description of fundamental concepts, technical implementations, and current technologies for meeting these information demands. A strong focus is placed on community challenges addressing systems performance, more particularly CHEMDNER and CHEMDNER patents tasks of BioCreative IV and V, respectively. Considering the growing interest in the construction of automatically annotated chemical knowledge bases that integrate chemical information and biological data, cheminformatics approaches for mapping the extracted chemical names into chemical structures and their subsequent annotation together with text mining applications for linking chemistry with biological information are also presented. Finally, future trends and current challenges are highlighted as a roadmap proposal for research in this emerging field.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On Crowdsourcing Relevance Magnitudes for Information Retrieval Evaluation\n",
            "Authors: Eddy Maddalena, Stefano Mizzaro, Falk Scholer, A. Turpin\n",
            "Year: 2017\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: Magnitude estimation is a psychophysical scaling technique for the measurement of sensation, where observers assign numbers to stimuli in response to their perceived intensity. We investigate the use of magnitude estimation for judging the relevance of documents for information retrieval evaluation, carrying out a large-scale user study across 18 TREC topics and collecting over 50,000 magnitude estimation judgments using crowdsourcing. Our analysis shows that magnitude estimation judgments can be reliably collected using crowdsourcing, are competitive in terms of assessor cost, and are, on average, rank-aligned with ordinal judgments made by expert relevance assessors. We explore the application of magnitude estimation for IR evaluation, calibrating two gain-based effectiveness metrics, nDCG and ERR, directly from user-reported perceptions of relevance. A comparison of TREC system effectiveness rankings based on binary, ordinal, and magnitude estimation relevance shows substantial variation; in particular, the top systems ranked using magnitude estimation and ordinal judgments differ substantially. Analysis of the magnitude estimation scores shows that this effect is due in part to varying perceptions of relevance: different users have different perceptions of the impact of relative differences in document relevance. These results have direct implications for IR evaluation, suggesting that current assumptions about a single view of relevance being sufficient to represent a population of users are unlikely to hold.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effects of Stop Words Elimination for Arabic Information Retrieval: A Comparative Study\n",
            "Authors: I. A. El-Khair\n",
            "Year: 2017\n",
            "Venue: arXiv.org\n",
            "Abstract: The effectiveness of three stop words lists for Arabic Information Retrieval---General Stoplist, Corpus- Based Stoplist, Combined Stoplist ---were investigated in this study. Three popular weighting schemes were examined: the inverse document frequency weight, probabilistic weighting, and statistical language modelling. The Idea is to combine the statistical approaches with linguistic approaches to reach an optimal performance, and compare their effect on retrieval. The LDC (Linguistic Data Consortium) Arabic Newswire data set was used with the Lemur Toolkit. The Best Match weighting scheme used in the Okapi retrieval system had the best overall performance of the three weighting algorithms used in the study, stoplists improved retrieval effectiveness especially when used with the BM25 weight. The overall performance of a general stoplist was better than the other two lists.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Automatic Test Smell Detection Using Information Retrieval Techniques\n",
            "Authors: Fabio Palomba, A. Zaidman, A. D. Lucia\n",
            "Year: 2018\n",
            "Venue: IEEE International Conference on Software Maintenance and Evolution\n",
            "Abstract: Software testing is a key activity to control the reliability of production code. Unfortunately, the effectiveness of test cases can be threatened by the presence of faults. Recent work showed that static indicators can be exploited to identify test-related issues. In particular test smells, i.e., sub-optimal design choices applied by developers when implementing test cases, have been shown to be related to test case effectiveness. While some approaches for the automatic detection of test smells have been proposed so far, they generally suffer of poor performance: as a consequence, current detectors cannot properly provide support to developers when diagnosing the quality of test cases. In this paper, we aim at making a step ahead toward the automated detection of test smells by devising a novel textual-based detector, coined TASTE (Textual AnalySis for Test smEll detection), with the aim of evaluating the usefulness of textual analysis for detecting three test smell types, General Fixture, Eager Test, and Lack of Cohesion of Methods. We evaluate TASTE in an empirical study that involves a manually-built dataset composed of 494 test smell instances belonging to 12 software projects, comparing the capabilities of our detector with those of two code metrics-based techniques proposed by Van Rompaey et al. and Greiler et al. Our results show that the structural-based detection applied by existing approaches cannot identify most of the test smells in our dataset, while TASTE is up to 44% more effective. Finally, we find that textual and structural approaches can identify different sets of test smells, thereby indicating complementarity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Noisy Private Information Retrieval: On Separability of Channel Coding and Information Retrieval\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of noisy private information retrieval (NPIR) from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating databases, each storing the same set of <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> messages. In this model, the answer strings are not returned through noiseless bit pipes, but rather through <italic>noisy</italic> memoryless channels. We aim at characterizing the PIR capacity for this model as a function of the statistical information measures of the noisy channels such as entropy and mutual information. We derive a general upper bound for the retrieval rate in the form of a max-min optimization. We use the achievable schemes for the PIR problem under asymmetric traffic constraints and random coding arguments to derive a general lower bound for the retrieval rate. The upper and lower bounds match for <inline-formula> <tex-math notation=\"LaTeX\">$M=2$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$M=3$ </tex-math></inline-formula>, for any <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, and any noisy channel. The lower and upper bounds show a separation between channel coding and retrieval scheme except for adapting the traffic ratio from the databases. We refer to this as <italic>almost separation</italic>. Next, we consider the private information retrieval problem from multiple access channels (MAC-PIR). In MAC-PIR, the database responses reach the user through a multiple access channel (MAC) that mixes the responses together in a stochastic way. We show that for the additive MAC and the conjunction/disjunction MAC, channel coding and retrieval scheme are <italic>inseparable</italic> unlike in NPIR. We show that the retrieval scheme depends on the properties of the MAC, in particular on the linearity aspect. For both cases, we provide schemes that achieve the full capacity without any loss due to the privacy constraint, which implies that the user can exploit the nature of the channel to improve privacy. Finally, we show that the full unconstrained capacity is not always attainable by determining the capacity of the selection channel.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval from Non-Replicated Databases\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2018\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We consider the problem of private information retrieval (PIR) of a single message out of K messages from N non-colluding and non-replicated databases. Different from the majority of the existing literature, here, we consider the case of non-replicated databases under a special non-replication structure where each database stores M out of K messages and each message is stored across R different databases. This generates an R-regular graph structure for the storage system where the vertices of the graph are the messages and the edges are the databases. We derive a general upper bound for M = 2 that depends on the graph structure. We then specialize the problem to storage systems described by two special types of graph structures: cyclic graphs and fully-connected graphs. We prove that the PIR capacity for the case of cyclic graphs is $\\frac{2}{{K + 1}}$, and the PIR capacity for the case of fully-connected graphs is $\\min \\left\\{ {\\frac{2}{K},\\;\\frac{1}{2}} \\right\\}$. In both cases, the results show severe degradation in PIR capacity due to non-replication.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fast and effective cluster-based information retrieval using frequent closed itemsets\n",
            "Authors: Y. Djenouri, Asma Belhadi, Philippe Fournier-Viger, Chun-Wei Lin\n",
            "Year: 2018\n",
            "Venue: Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fusion in Information Retrieval: SIGIR 2018 Half-Day Tutorial\n",
            "Authors: Oren Kurland, J. Culpepper\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Fusion is an important and central concept in Information Retrieval. The goal of fusion methods is to merge different sources of information so as to address a retrieval task. For example, in the adhoc retrieval setting, fusion methods have been applied to merge multiple document lists retrieved for a query. The lists could be retrieved using different query representations, document representations, ranking functions and corpora. The goal of this half day, intermediate-level, tutorial is to provide a methodological view of the theoretical foundations of fusion approaches, the numerous fusion methods that have been devised and a variety of applications for which fusion techniques have been applied.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Word-embedding-based pseudo-relevance feedback for Arabic information retrieval\n",
            "Authors: Abdelkader El Mahdaouy, Said Ouatik El Alaoui, Éric Gaussier\n",
            "Year: 2018\n",
            "Venue: Journal of information science\n",
            "Abstract: Pseudo-relevance feedback (PRF) is a very effective query expansion approach, which reformulates queries by selecting expansion terms from top k pseudo-relevant documents. Although standard PRF models have been proven effective to deal with vocabulary mismatch between users’ queries and relevant documents, expansion terms are selected without considering their similarity to the original query terms. In this article, we propose a method to incorporate word embedding (WE) similarity into PRF models for Arabic information retrieval (IR). The main idea is to select expansion terms using their distribution in the set of top pseudo-relevant documents along with their similarity to the original query terms. Experiments are conducted on the standard Arabic TREC 2001/2002 collection using three neural WE models. The obtained results show that our PRF extensions significantly outperform their baseline PRF models. Moreover, they enhanced the baseline IR model by 22% and 68% for the mean average precision (MAP) and the robustness index (RI), respectively.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Capacity of Single-Server Single-Message Private Information Retrieval with Coded Side Information\n",
            "Authors: A. Heidarzadeh, Fatemeh Kazemi, A. Sprintson\n",
            "Year: 2018\n",
            "Venue: Information Theory Workshop\n",
            "Abstract: This paper considers the problem of single-server single-message private information retrieval with coded side information (PIR-CSI). In this problem, there is a server storing a database, and a user which knows a linear combination of a subset of messages in the database as a side information. The number of messages contributing to the side information is known to the server, but the indices and the coefficients of these messages are unknown to the server. The user wishes to download a message from the server privately, i.e., without revealing which message it is requesting, while minimizing the download cost. In this work, we consider two different settings for the PIR-CSI problem depending on the demanded message being or not being one of the messages contributing to the side information. For each setting, we prove an upper bound on the maximum download rate as a function of the size of the database and the size of the side information, and propose a protocol that achieves the rate upper-bound.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Achieving Maximum Distance Separable Private Information Retrieval Capacity With Linear Codes\n",
            "Authors: Siddhartha Kumar, Hsuan-Yin Lin, E. Rosnes, A. Graell i Amat\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We propose three private information retrieval (PIR) protocols for distributed storage systems (DSSs), where data is stored using an arbitrary linear code. The first two protocols, named Protocol 1 and Protocol 2, achieve privacy for the scenario with noncolluding nodes. Protocol 1 requires a file size that is exponential in the number of files in the system, while Protocol 2 requires a file size that is independent of the number of files and is hence simpler. We prove that, for certain linear codes, Protocol 1 achieves the maximum distance separable (MDS) PIR capacity, i.e., the maximum PIR rate (the ratio of the amount of retrieved stored data per unit of downloaded data) for a DSS that uses an MDS code to store any given (finite and infinite) number of files, and Protocol 2 achieves the asymptotic MDS-PIR capacity (with infinitely large number of files in the DSS). In particular, we provide a necessary and a sufficient condition for a code to achieve the MDS-PIR capacity with Protocols 1 and 2 and prove that cyclic codes, Reed–Muller (RM) codes, and a class of distance-optimal local reconstruction codes achieve both the finite MDS-PIR capacity (i.e., with any given number of files) and the asymptotic MDS-PIR capacity with Protocols 1 and 2, respectively. Furthermore, we present a third protocol, Protocol 3, for the scenario with multiple colluding nodes, which can be seen as an improvement of a protocol recently introduced by Freij-Hollanti et al.. Similar to the noncolluding case, we provide a necessary and a sufficient condition to achieve the maximum possible PIR rate of Protocol 3. Moreover, we provide a particular class of codes that is suitable for this protocol and show that RM codes achieve the maximum possible PIR rate for the protocol. For all three protocols, we present an algorithm to optimize their PIR rates.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Secure symmetric private information retrieval from colluding databases with adversaries\n",
            "Authors: Qiwen Wang, M. Skoglund\n",
            "Year: 2017\n",
            "Venue: Allerton Conference on Communication, Control, and Computing\n",
            "Abstract: The problem of symmetric private information retrieval (SPIR) from replicated databases with colluding servers and adversaries is studied. Specifically, the database comprises K files, which are replicatively stored among N servers. A user wants to retrieve one file from the database by communicating with the N servers, without revealing the identity of the desired file to any server. Furthermore, the user shall learn nothing about the other K − 1 files in the database. Any T out of N servers may collude, that is, they may communicate their interactions with the user to guess the identity of the requested file. An adversary in the system can tap in on or even try to corrupt the communication. Three types of adversaries are considered: a Byzantine adversary who can overwrite the transmission of any B servers to the user; a passive eavesdropper who can tap in on the incoming and outgoing transmissions of any E servers; and a combination of both — an adversary who can tap in on a set of any E nodes, and overwrite the transmission of a set of any B nodes. The problems of SPIR with colluding servers and the three types of adversaries are named T-BSPIR, T-ESPIR and T-BESPIR respectively. The capacity of the problem is defined as the maximum number of information bits of the desired file retrieved per downloaded bit. We show that the information-theoretical capacity of the T-BSPIR problem equals 1 − 2B+T/N, if the servers share common randomness (unavailable at the user) with amount at least 2B+T/N−2B−T times the file size. Otherwise, the capacity equals zero. The information-theoretical capacity of the T-ESPIR problem is proved to equal 1 − max(T, E)/N if the servers share common randomness with amount at least max(T, E)/N − max(T, E) times the file size. Finally, for the problem of T-BESPIR, the capacity is proved to be 1 − 2B+max(T, E)/N where the common randomness shared by the servers should be at least 2B+max(T, E)/N−2B-max(T, E) times the file size. The results resemble those of secure network coding problems with adversaries and eavesdroppers.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy\n",
            "Authors: Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, Weizhu Chen\n",
            "Year: 2023\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Large language models are powerful text processors and reasoners, but are still subject to limitations including outdated knowledge and hallucinations, which necessitates connecting them to the world. Retrieval-augmented large language models have raised extensive attention for grounding model generation on external knowledge. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to improve retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner. A model output shows what might be needed to finish a task, and thus provides an informative context for retrieving more relevant knowledge which in turn helps generate a better output in the next iteration. Compared with recent work which interleaves retrieval with generation when producing an output, Iter-RetGen processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-RetGen on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fuzzy Rough Set Based Technique for User Specific Information Retrieval: A Case Study on Wikipedia Data\n",
            "Authors: Nidhika Yadav, N. Chatterjee\n",
            "Year: 2018\n",
            "Venue: Int. J. Rough Sets Data Anal.\n",
            "Abstract: Information retrieval is widely used due to extremely large volume of text and image data available on the web and consequently, efficient retrieval is required. Text information retrieval is a branch of information retrieval which deals with text documents. Another key factor is the concern for a retrieval engine, often referred to as user-specific information retrieval, which works according to a specific user. This article performs a preliminary investigation of the proposed fuzzy rough sets-based model for user-specific text information retrieval. The model improves on the computational time required to compute the approximations compared to classical fuzzy rough set model by using Wikipedia as the information source. The technique also improves on the accuracy of clustering obtained for user specified classes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bibliometric-enhanced Information Retrieval\n",
            "Authors: Philipp Mayr, A. Scharnhorst, Birger Larsen, Philipp Schaer, Peter Mutschke\n",
            "Year: 2018\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval in the workplace: A comparison of professional search practices\n",
            "Authors: Tony Russell-Rose, Jon Chamberlain, L. Azzopardi\n",
            "Year: 2018\n",
            "Venue: Information Processing & Management\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bug Localization with Combination of Deep Learning and Information Retrieval\n",
            "Authors: A. Lam, A. Nguyen, H. Nguyen, T. Nguyen\n",
            "Year: 2017\n",
            "Venue: IEEE International Conference on Program Comprehension\n",
            "Abstract: The automated task of locating the potential buggy files in a softwareproject given a bug report is called bug localization. Buglocalization helps developers focus on crucial files. However, theexisting automated bug localization approaches face a key challenge, called lexical mismatch. Specifically, the terms used in bug reportsto describe a bug are different from the terms and code tokens used insource files. To address that, we present a novel approach that usesdeep neural network (DNN) in combination with rVSM, an informationretrieval (IR) technique. rVSM collects the feature on the textualsimilarity between bug reports and source files. DNN is used to learnto relate the terms in bug reports to potentially different codetokens and terms in source files. Our empirical evaluation onreal-world bug reports in the open-source projects shows that DNN andIR complement well to each other to achieve higher bug localizationaccuracy than individual models. Importantly, our new model, DNNLOC, with a combination of the features built from DNN, rVSM, and project'sbug-fixing history, achieves higher accuracy than the state-of-the-artIR and machine learning techniques. In half of the cases, it iscorrect with just a single suggested file. In 66% of the time, acorrect buggy file is in the list of three suggested files. With 5suggested files, it is correct in almost 70% of the cases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Doubly Efficient Private Information Retrieval\n",
            "Authors: R. Canetti, Justin Holmgren, Silas Richelson\n",
            "Year: 2017\n",
            "Venue: Theory of Cryptography Conference\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval methodology for aiding scientific database search\n",
            "Authors: Samuel Marcos-Pablos, F. García-Peñalvo\n",
            "Year: 2018\n",
            "Venue: Soft Computing - A Fusion of Foundations, Methodologies and Applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private information retrieval from MDS coded data with colluding servers: Settling a conjecture by Freij-Hollanti et al\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2017\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: A (K, N, T, Kc) instance of the MDS-TPIR problem is comprised of K messages and N distributed servers. Each message is separately encoded through an (N, Kc) MDS storage code. A user wishes to retrieve one message, as efficiently as possible, while revealing no information about the desired message index to any colluding set of up to T servers. The fundamental limit on the efficiency of retrieval, i.e., the capacity of MDS-TPIR is known only at the extremes where either T or Kc belongs to {1, N}. The focus of this work is a recent conjecture by Freij-Hollanti, Gnilke, Hollanti and Karpuk which offers a general capacity expression for MDS-TPIR. We prove that the conjecture is false by presenting as a counterexample a PIR scheme for the setting (K, N, T, Kc) = (2,4, 2, 2), which achieves the rate 3/5, exceeding the conjectured capacity, 4/7.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural Text Embeddings for Information Retrieval\n",
            "Authors: Bhaskar Mitra, Nick Craswell\n",
            "Year: 2017\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: In the last few years, neural representation learning approaches have achieved very good performance on many natural language processing tasks, such as language modelling and machine translation. This suggests that neural models will also achieve good performance on information retrieval (IR) tasks, such as relevance ranking, addressing the query-document vocabulary mismatch problem by using a semantic rather than lexical matching. Although initial iterations of neural models do not outperform traditional lexical-matching baselines, the level of interest and effort in this area is increasing, potentially leading to a breakthrough. The popularity of the recent SIGIR 2016 workshop on Neural Information Retrieval provides evidence to the growing interest in neural models for IR. While recent tutorials have covered some aspects of deep learning for retrieval tasks, there is a significant scope for organizing a tutorial that focuses on the fundamentals of representation learning for text retrieval. The goal of this tutorial will be to introduce state-of-the-art neural embedding models and bridge the gap between these neural models with early representation learning approaches in IR (e.g., LSA). We will discuss some of the key challenges and insights in making these models work in practice, and demonstrate one of the toolsets available to researchers interested in this area.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval\n",
            "Authors: Wenxiao Zhang, Chunxia Xiao\n",
            "Year: 2019\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Point cloud based retrieval for place recognition is an emerging problem in vision field. The main challenge is how to find an efficient way to encode the local features into a discriminative global descriptor. In this paper, we propose a Point Contextual Attention Network (PCAN), which can predict the significance of each local point feature based on point context. Our network makes it possible to pay more attention to the task-relevent features when aggregating local features. Experiments on various benchmark datasets show that the proposed network can provide outperformance than current state-of-the-art approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Here and Now: Reality-Based Information Retrieval: Perspective Paper\n",
            "Authors: Wolfgang Büschel, A. Mitschick, Raimund Dachselt\n",
            "Year: 2018\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: Today, the widespread use of mobile devices allows users to search information \"on the go»», whenever and wherever they want, no longer confining Information Retrieval to classic desktop interfaces. We believe that technical advances in Augmented Reality will allow Information Retrieval to go even further, making use of both the users» surroundings and their abilities to interact with the physical world. In this paper, we present the fundamental concept of Reality-Based Information Retrieval, which combines the classic Information Retrieval process with Augmented Reality technologies to provide context-dependent search cues and situated visualizations of the query and the results. With information needs often stemming from real-world experiences, this novel combination has the potential to better support both Just-in-time Information Retrieval and serendipity. Based on extensive literature research, we propose a conceptual framework for Reality-Based Information Retrieval. We illustrate and discuss this framework and present two prototypical implementations, which we tested in small user studies. They demonstrate the feasibility of our concepts and inspired our discussion of notable challenges for further research in this novel and promising area.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cache-Aided Private Information Retrieval With Partially Known Uncoded Prefetching: Fundamental Limits\n",
            "Authors: Yi-Peng Wei, Karim A. Banawan, S. Ulukus\n",
            "Year: 2017\n",
            "Venue: IEEE Journal on Selected Areas in Communications\n",
            "Abstract: We consider the problem of private information retrieval from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-colluding and replicated databases, when the user is equipped with a cache that holds an uncoded fraction <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> of the symbols from each of the <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> stored messages in the databases. This model operates in a two-phase scheme, namely, the prefetching phase where the user acquires side information and the retrieval phase where the user privately downloads the desired message. In the prefetching phase, the user receives <inline-formula> <tex-math notation=\"LaTeX\">${r}/{N}$ </tex-math></inline-formula> uncoded fraction of each message from the <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>th database. This side information is known only to the <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>th database and unknown to the remaining databases, i.e., the user possesses <italic>partially known</italic> side information. We investigate the optimal normalized download cost <inline-formula> <tex-math notation=\"LaTeX\">$D^{*}(r)$ </tex-math></inline-formula> in the retrieval phase as a function of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula>. We develop lower and upper bounds for the optimal download cost. The bounds match in general for the cases of very low caching ratio and very high caching ratio. We fully characterize the optimal download cost caching ratio tradeoff for <inline-formula> <tex-math notation=\"LaTeX\">$K=3$ </tex-math></inline-formula>. For general <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> values, we show that the largest additive gap between the achievability and the converse bounds is 5/32.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval With Partially Known Private Side Information\n",
            "Authors: Yi-Peng Wei, Karim A. Banawan, S. Ulukus\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We consider the problem of private information retrieval (PIR) of a single message out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> replicated and non-colluding databases where a cache-enabled user (retriever) of cache-size <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula> possesses side information in the form of full messages that are partially known to the databases. In this model, the user and the databases engage in a two-phase scheme, namely, the prefetching phase where the user acquires side information and the retrieval phase where the user downloads desired information. In the prefetching phase, the user receives <inline-formula> <tex-math notation=\"LaTeX\">$m_{n}$ </tex-math></inline-formula> full messages from the <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula>th database, under the cache memory size constraint <inline-formula> <tex-math notation=\"LaTeX\">$\\sum _{n=1}^{N} m_{n} \\leq M$ </tex-math></inline-formula>. In the retrieval phase, the user wishes to retrieve a message (which is not present in its memory) such that no individual database learns anything about the identity of the desired message. In addition, the identities of the side information messages that the user did not prefetch from a database must remain private against that database. Since the side information provided by each database in the prefetching phase is known by the providing database and the side information must be kept private against the remaining databases, we coin this model as <italic>partially known private side information</italic>. We characterize the capacity of the PIR with partially known private side information to be <inline-formula> <tex-math notation=\"LaTeX\">$C=\\left ({1+\\frac {1}{N}+\\cdots +\\frac {1}{N^{K-M-1}}}\\right)^{-1}=\\frac {1-\\frac {1}{N}}{1-\\left({\\frac {1}{N}}\\right)^{K-M}}$ </tex-math></inline-formula>. Interestingly, this result is the same if none of the databases knows any of the prefetched side information, i.e., when the side information is obtained externally, a problem posed by Kadhe et al. and settled by Chen-Wang-Jafar recently. Thus, our result implies that there is no loss in using the same databases for both prefetching and retrieval phases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Staircase-PIR: Universally Robust Private Information Retrieval\n",
            "Authors: Rawad Bitar, S. E. Rouayheb\n",
            "Year: 2018\n",
            "Venue: Information Theory Workshop\n",
            "Abstract: We consider the problem of designing private information retrieval (PIR) schemes on data of m files replicated on n servers that can possibly collude. We focus on devising robust PIR schemes that can tolerate stragglers, i.e., slow or unresponsive servers. In many settings, the number of stragglers is not known a priori or may change with time. We define universally robust PIR as schemes that achieve PIR capacity asymptotically in m and simultaneously for any number of stragglers up to a given threshold. We introduce Staircase-PIR schemes and prove that they are universally robust. Towards that end, we establish an equivalence between robust PIR and communication efficient secret sharing.\n",
            "\n",
            "---\n",
            "\n",
            "Title: From Word Embeddings to Document Similarities for Improved Information Retrieval in Software Engineering\n",
            "Authors: Xin Ye, Hui Shen, Xiao Ma, Razvan C. Bunescu, Chang Liu\n",
            "Year: 2016\n",
            "Venue: International Conference on Software Engineering\n",
            "Abstract: The application of information retrieval techniques to search tasks in software engineering is made difficult by the lexical gap between search queries, usually expressed in natural language (e.g. English), and retrieved documents, usually expressed in code (e.g. programming languages). This is often the case in bug and feature location, community question answering, or more generally the communication between technical personnel and non-technical stake holders in a software project. In this paper, we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture, word embeddings are rst trained on API documents, tutorials, and reference documents, and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly de ned task of linking API documents to computer programming questions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An analysis of evaluation campaigns in ad-hoc medical information retrieval: CLEF eHealth 2013 and 2014\n",
            "Authors: Lorraine Goeuriot, G. Jones, Liadh Kelly, Johannes Leveling, M. Lupu, João Palotti, G. Zuccon\n",
            "Year: 2018\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: HINMINE: heterogeneous information network mining with information retrieval heuristics\n",
            "Authors: Jan Kralj, M. Robnik-Sikonja, N. Lavrač\n",
            "Year: 2018\n",
            "Venue: Journal of Intelligence and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Robust Private Information Retrieval With Colluding Databases\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: Private information retrieval (PIR) is the problem of retrieving as efficiently as possible, one out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating replicated databases (each holds all <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages) while keeping the identity of the desired message index a secret from each individual database. The information theoretic capacity of PIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-private PIR is a generalization of PIR to include the requirement that even if any <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula> of the <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> databases collude, the identity of the retrieved message remains completely unknown to them. Robust PIR is another generalization that refers to the scenario where we have <inline-formula> <tex-math notation=\"LaTeX\">$M \\geq N$ </tex-math></inline-formula> databases, out of which any <inline-formula> <tex-math notation=\"LaTeX\">$M - N$ </tex-math></inline-formula> may fail to respond. For <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages and <inline-formula> <tex-math notation=\"LaTeX\">$M\\geq N$ </tex-math></inline-formula> databases out of which at least some <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> must respond, we show that the capacity of <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-private and Robust PIR is <inline-formula> <tex-math notation=\"LaTeX\">$(1+T/N+T^{2}/N^{2}+\\cdots +T^{K-1}/N^{K-1})^{-1}$ </tex-math></inline-formula>. The result includes as special cases the capacity of PIR without robustness (<inline-formula> <tex-math notation=\"LaTeX\">$M=N$ </tex-math></inline-formula>) or <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-privacy constraints (<inline-formula> <tex-math notation=\"LaTeX\">$T=1$ </tex-math></inline-formula>).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Reproducibility Challenges in Information Retrieval Evaluation\n",
            "Authors: N. Ferro\n",
            "Year: 2017\n",
            "Venue: ACM Journal of Data and Information Quality\n",
            "Abstract: Information Retrieval (IR) is concerned with ranking information resources with respect to user information needs, delivering a wide range of key applications for industry and society, such as Web search engines [Croft et al. 2009], intellectual property, and patent search [Lupu and Hanbury 2013], and many others. The performance of IR systems is determined not only by their efficiency but also and most importantly by their effectiveness, that is, their ability to retrieve and better rank relevant information resources while at the same time suppressing the retrieval of not relevant ones. Due to the many sources of uncertainty, as for example vague user information needs, unstructured information sources, or subjective notion of relevance, experimental evaluation is the only mean to assess the performances of IR systems from the effectiveness point of view. Experimental evaluation relies on the Cranfield paradigm, which makes use of experimental collections, consisting of documents, sampled from a real domain of interest; topics, representing real user information needs in that domain; and relevance judgements, determining which documents are relevant to which topics [Harman 2011]. To share the effort and optimize the use of resources, experimental evaluation is usually carried out in publicly open and large-scale evaluation campaigns at the international level, like the Text REtrieval Conference (TREC)1 in the United States [Harman and Voorhees 2005], the Conference and Labs of the Evaluation Forum (CLEF)2 in Europe [Ferro 2014], the NII Testbeds and Community for Information access Research (NTCIR)3 in Japan and Asia, and the Forum for Information Retrieval Evaluation (FIRE)4 in India. These initiatives produce, every year, huge amounts of scientific data\n",
            "\n",
            "---\n",
            "\n",
            "Title: RETRIEVAL—An Online Performance Evaluation Tool for Information Retrieval Methods\n",
            "Authors: G. Ioannakis, A. Koutsoudis, I. Pratikakis, C. Chamzas\n",
            "Year: 2018\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Performance evaluation is one of the main research topics in information retrieval. Evaluation metrics are used to quantify various performance aspects of a retrieval method. These metrics assist in identifying the optimum method for a specific retrieval challenge but also to allow its parameters fine-tuning in order to achieve a robust operation for a given set of requirements specification. In this work, we present RETRIEVAL, a Web-based integrated information retrieval performance evaluation platform. It offers a number of metrics that are popular within the scientific community, so as to compose an efficient framework for implementing performance evaluation. We discuss the functionality of RETRIEVAL by citing important aspects such as the data input approaches, the user-level performance metrics parameterization, the evaluation scenarios, the interactive plots, and the performance reports repository that offers both archiving and download functionalities.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Information Retrieval Framework for Contextual Suggestion Based on Heterogeneous Information Network Embeddings\n",
            "Authors: Dominic Seyler, Praveen Chandar, Matthew Davis\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We present an Information Retrieval framework that leverages Heterogeneous Information Network (HIN) embeddings for contextual suggestion. Our method represents users, documents and other context-related documents as heterogeneous objects in a HIN. Using meta-paths, selected based on domain knowledge, we create graph embeddings from this network, thereby learning a representation of users and objects in the same semantic vector space. This allows inferences of user interest on unseen objects based on distance in the embedding space. These object distances are then incorporated as features in a well-established learning to rank (LTR) framework. We make use of the 2016 TREC Contextual Suggestion (TRECCS) dataset, which contains user profiles in the form of relevance-rated documents, and demonstrate the competitiveness of our approach by comparing our system to the best performing systems of the TRECCS task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Linear symmetric private information retrieval for MDS coded distributed storage with colluding servers\n",
            "Authors: Qiwen Wang, M. Skoglund\n",
            "Year: 2017\n",
            "Venue: Information Theory Workshop\n",
            "Abstract: The problem of symmetric private information retrieval (SPIR) from a coded database which is distributively stored among colluding servers is studied. Specifically, the database comprises K files, which are stored among N servers using an (N, M)-MDS storage code. A user wants to retrieve one file from the database by communicating with the N servers, without revealing the identity of the desired file to any server. Furthermore, the user shall learn nothing about the other K − 1 files in the database. In the T-colluding SPIR problem (hence called TSPIR), any T out of N servers may collude, that is, they may communicate their interactions with the user to guess the identity of the requested file. We show that for linear schemes, the information-theoretic capacity of the MDS-TSPIR problem, defined as the maximum number of information bits of the desired file retrieved per downloaded bit, equals 1 − M+T−1/N, if the servers share common randomness (unavailable at the user) with amount at least M+T−1/N−M−T+1 times the file size. Otherwise, the capacity equals zero.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ROSF: Leveraging Information Retrieval and Supervised Learning for Recommending Code Snippets\n",
            "Authors: He Jiang, Liming Nie, Zeyi Sun, Zhilei Ren, Weiqiang Kong, Zhang Tao, Xiapu Luo\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Services Computing\n",
            "Abstract: When implementing unfamiliar programming tasks, developers commonly search code examples and learn usage patterns of APIs from the code examples or reuse them by copy-pasting and modifying. For providing high-quality code examples, previous studies present several methods to recommend code snippets mainly based on information retrieval. In this paper, to provide better recommendation results, we propose ROSF, Recommending code Snippets with multi-aspect Features, a novel method combining both information retrieval and supervised learning. In our method, we recommend Top-K code snippets for a given free-form query based on two stages, i.e., coarse-grained searching and fine-grained re-ranking. First, we generate a code snippet candidate set by searching a code snippet corpus using an information retrieval method. Second, we predict probability values of the code snippets for different relevance scores in the candidate set by the learned prediction model from a training set, re-rank these candidate code snippets according to the probability values, and recommend the final results to developers. We conduct several experiments to evaluate our method in a large-scale corpus containing 921,713 real-world code snippets. The results show that ROSF is an effective method for code snippets recommendation and outperforms the-state-of-the-art methods by 20-41percent in Precision and 13-33 percent in NDCG.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Single-server Multi-user Private Information Retrieval with Side Information\n",
            "Authors: Su Li, M. Gastpar\n",
            "Year: 2018\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: In the problem of private information retrieval with side information, a single user wants to recover one of the $K$ independent messages which are stored at one or multiple servers. The user initially has a subset of messages as side information. The goal of the user is to retrieve the demand message by using minimum number of transmissions $(R^{\\ast})$ from the server(s) to the user under the condition that the index of the demand message should not be inferred by the server. We introduce the multi-user variant into this problem, where each user wants to retrieve one message and has a subset of messages as side information. In this paper, we study the special cases where all users want to retrieve one common message from a single server, but each user has different side information messages. We show that the optimal coding scheme can be constructed by first optimally partitioning the messages and then generating MDS codes separately in each subset of messages in the partition. We determine the $R^{\\ast}$, propose algorithms to compute $R^{\\ast}$, and construct optimal linear coding schemes with complexity polynomial in $K$ (but exponential in the number of side information messages).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Visualization for Interactive Information Retrieval\n",
            "Authors: O. Hoeber\n",
            "Year: 2018\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: As search tasks move beyond targeted search and into the domain of complex search, a substantial cognitive burden is placed on the searcher to craft and refine their queries, evaluate and explore among the search results, and ultimately make use of what is found. In such cases, information visualization techniques may be leveraged to enable searchers to perceive, interpret, and make sense of the information available throughout the search process. This tutorial will establish the fundamental principles and theories of information visualization, explain how information visualization can support interactive information retrieval, and survey search interfaces from my own research that leverage information visualization techniques. The goal of this tutorial will be to encourage researchers to make informed design decisions for how to integrate information visualization into their own interactive information retrieval projects.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval Over Random Linear Networks\n",
            "Authors: Razane Tajeddine, A. Wachter-Zeh, C. Hollanti\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: In this paper, the problem of providing privacy to users requesting data over a network from a distributed storage system (DSS) is considered. The DSS, which is considered as the multi-terminal destination of the network from the user’s perspective, is encoded by a maximum rank distance (MRD) code to store the data on these multiple servers. A private information retrieval (PIR) scheme ensures that a user can request a file without revealing any information on which file is being requested to any of the servers. In this paper, a novel PIR scheme is proposed, allowing the user to recover a file from a storage system with low communication cost, while allowing some servers in the system to collude in the quest of revealing the identity of the requested file. The network is modeled as a random linear network, i.e., all nodes of the network forward random (unknown) linear combinations of incoming packets. Both error-free and erroneous random linear networks are considered.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantically Enhanced Medical Information Retrieval System: A Tensor Factorization Based Approach\n",
            "Authors: Haolin Wang, Qingpeng Zhang, Jiahu Yuan\n",
            "Year: 2017\n",
            "Venue: IEEE Access\n",
            "Abstract: Medical information retrieval plays an increasingly important role to help physicians and domain experts to better access medical-related knowledge and information, and support decision making. Integrating the medical knowledge bases has the potential to improve the information retrieval performance through incorporating medical domain knowledge for relevance assessment. However, this is not a trivial task due to the challenges to effectively utilize the domain knowledge in the medical knowledge bases. In this paper, we proposed a novel medical information retrieval system with a two-stage query expansion strategy, which is able to effectively model and incorporate the latent semantic associations to improve the performance. This system consists of two parts. First, we applied a heuristic approach to enhance the widely used pseudo relevance feedback method for more effective query expansion, through iteratively expanding the queries to boost the similarity score between queries and documents. Second, to improve the retrieval performance with structured knowledge bases, we presented a latent semantic relevance model based on tensor factorization to identify semantic association patterns under sparse settings. These identified patterns are then used as inference paths to trigger knowledge-based query expansion in medical information retrieval. Experiments with the TREC CDS 2014 data set: 1) showed that the performance of the proposed system is significantly better than the baseline system and the systems reported in TREC CDS 2014 conference, and is comparable with the state-of-the-art systems and 2) demonstrated the capability of tensor-based semantic enrichment methods for medical information retrieval tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The role of emotional aspects in the information retrieval from the web\n",
            "Authors: M. Zanganeh, N. Hariri\n",
            "Year: 2018\n",
            "Venue: Online information review (Print)\n",
            "Abstract: \n",
            "Purpose\n",
            "The purpose of this paper is to identify the role of emotional aspects in information retrieval of PhD students from the web.\n",
            "\n",
            "\n",
            "Design/methodology/approach\n",
            "From the methodological perspective, the present study is experimental and the type of study is practical. The study population is PhD students of various fields of science. The study sample consists of 50 students as selected by the stratified purposive sampling method. The information aggregation is performed by observing the records of user’s facial expressions, log file by Morae software, as well as pre-search and post-search questionnaire. The data analysis is performed by canonical correlation analysis.\n",
            "\n",
            "\n",
            "Findings\n",
            "The findings showed that there was a significant relationship between emotional expressions and searchers’ individual characteristics. Searchers satisfaction of results, frequency internet search, experience of search, interest in the search task and familiarity with similar searches were correlated with the increased happy emotion. The examination of user’s emotions during searching performance showed that users with happiness emotion dedicated much time in searching and viewing of search solutions. More internet addresses with more queries were used by happy participants; on the other hand, users with anger and disgust emotions had the lowest attempt in search performance to complete search process.\n",
            "\n",
            "\n",
            "Practical implications\n",
            "The results imply that the information retrieval systems in the web should identify emotional expressions in a set of perceiving signs in human interaction with computer, similarity, face emotional states, searching and information retrieval from the web.\n",
            "\n",
            "\n",
            "Originality/value\n",
            "The results explicit in the automatic identification of users’ emotional expressions can enter new dimensions into their moderator and information retrieval systems on the web and can pave the way of design of emotional information retrieval systems for the successful retrieval of users of the network.\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-level Abstraction Convolutional Model with Weak Supervision for Information Retrieval\n",
            "Authors: Yifan Nie, Alessandro Sordoni, Jian-Yun Nie\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Recent neural models for IR have produced good retrieval effectiveness compared with traditional models. Yet all of them assume that a single matching function should be used for all queries. In practice, user's queries may be of various nature which might require different levels of matching, from low level word matching to high level conceptual matching. To cope with this problem, we propose a multi-level abstraction convolutional model (MACM) that generates and aggregates several levels of matching scores. Weak supervision is used to address the problem of large training data. Experimental results demonstrated the effectiveness of our proposed MACM model.\n",
            "\n",
            "---\n",
            "\n",
            "Title: $t$ -Private Information Retrieval Schemes Using Transitive Codes\n",
            "Authors: Ragnar Freij-Hollanti, O. W. Gnilke, C. Hollanti, Anna-Lena Horlemann-Trautmann, David A. Karpuk, Ivo Kubjas\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: Private information retrieval (PIR) schemes for coded storage with colluding servers are presented, which are not restricted to maximum distance separable (MDS) codes. PIR schemes for general linear codes are constructed, and the resulting PIR rate is calculated explicitly. It is shown that codes with transitive automorphism groups yield the highest possible rates obtainable with the proposed scheme. In the special case of no server collusion, this rate coincides with the known asymptotic PIR capacity for MDS-coded storage systems. While many PIR schemes in the literature require field sizes that grow with the number of servers and files in the system, we focus especially on the case of a binary base field, for which Reed–Muller codes serve as an important and explicit class of examples.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Using Replicates in Information Retrieval Evaluation\n",
            "Authors: E. Voorhees, D. Samarov, I. Soboroff\n",
            "Year: 2017\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: This article explores a method for more accurately estimating the main effect of the system in a typical test-collection-based evaluation of information retrieval systems, thus increasing the sensitivity of system comparisons. Randomly partitioning the test document collection allows for multiple tests of a given system and topic (replicates). Bootstrap ANOVA can use these replicates to extract system-topic interactions—something not possible without replicates—yielding a more precise value for the system effect and a narrower confidence interval around that value. Experiments using multiple TREC collections demonstrate that removing the topic-system interactions substantially reduces the confidence intervals around the system effect as well as increases the number of significant pairwise differences found. Further, the method is robust against small changes in the number of partitions used, against variability in the documents that constitute the partitions, and the measure of effectiveness used to quantify system effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Kurdish stemmer pre-processing steps for improving information retrieval\n",
            "Authors: A. Mustafa, Tarik A. Rashid\n",
            "Year: 2018\n",
            "Venue: Journal of information science\n",
            "Abstract: The rapid increase in the quantity of Kurdish documents over the last several years has created a need for improving information accuracy and precision in text classification and retrieval. Language stemming is an imperative pre-processing step for increasing the possibility of matching terms in a document in text classification tasks. Stemming helps reduce the total number of searchable terms within a document or query. This article proposes an active approach for stemming Kurdish Sorani texts to reduce variations of words to single terms or stems. The outcomes of the process, described in this article, demonstrate that decreasing the dimensionality of feature vectors in documents will increase the effectiveness of retrieval when the stemming process is used. This process applied for Kurdish Sorani can be adapted and applied in Kurdish Kurmanji as well for greater efficiency and effectiveness in digital text classification and applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Laboratory Experiments in Information Retrieval\n",
            "Authors: T. Sakai\n",
            "Year: 2018\n",
            "Venue: The Information Retrieval Series\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private information retrieval with side information: The single server case\n",
            "Authors: S. Kadhe, B. Garcia, A. Heidarzadeh, S. E. Rouayheb, A. Sprintson\n",
            "Year: 2017\n",
            "Venue: Allerton Conference on Communication, Control, and Computing\n",
            "Abstract: We study the problem of Private Information Retrieval (PIR) in the presence of prior side information. The problem setup includes a database of K independent messages possibly replicated on several servers, and a user that needs to retrieve one of these messages. In addition, the user has some prior side information in the form of a subset of M messages, not containing the desired message and unknown to the servers. This problem is motivated by practical settings in which the user can obtain side information opportunistically from other users or has previously downloaded some messages using classical PIR schemes. The objective of the user is to retrieve the required message without revealing its identity while minimizing the amount of data downloaded from the server. We focus on achieving information-theoretic privacy in two scenarios: (i) the user wants to protect jointly its demand and side information; (ii) the user wants to protect only the information about its demand, but not the side information. To highlight the role of side information, we focus on the case of a single server. We prove that, in the first scenario, the minimum download cost is K-M messages, and in the second scenario, it is ⌈K/M+1⌉ messages. This is a significant improvement compared to the minimum cost of K messages in the setting where the user has no side information. Our proof techniques use a reduction from the PIR with side information problem to an index coding problem. We leverage this reduction to prove converse results, as well as to design achievability schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: XPIR : Private Information Retrieval for Everyone\n",
            "Authors: C. A. Melchor, Joris Barrier, Laurent Fousse, M. Killijian\n",
            "Year: 2016\n",
            "Venue: Proceedings on Privacy Enhancing Technologies\n",
            "Abstract: Abstract A Private Information Retrieval (PIR) scheme is a protocol in which a user retrieves a record from a database while hiding which from the database administrators. PIR can be achieved using mutuallydistrustful replicated databases, trusted hardware, or cryptography. In this paper we focus on the later setting which is known as single-database computationally- Private Information Retrieval (cPIR). Classic cPIR protocols require that the database server executes an algorithm over all the database content at very low speeds which impairs their usage. In [1], given certain assumptions, realistic at the time, Sion and Carbunar showed that cPIR schemes were not practical and most likely would never be. To this day, this conclusion is widely accepted by researchers and practitioners. Using the paradigm shift introduced by lattice-based cryptography, we show that the conclusion of Sion and Carbunar is not valid anymore: cPIR is of practical value. This is achieved without compromising security, using standard crytosystems, and conservative parameter choices.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval\n",
            "Authors: Haitao Li, Qingyao Ai, Jia Chen, Qian Dong, Yueyue Wu, Y. Liu, C. Chen, Qi Tian\n",
            "Year: 2023\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Legal case retrieval, which aims to find relevant cases for a query case, plays a core role in the intelligent legal system. Despite the success that pre-training has achieved in ad-hoc retrieval tasks, effective pre-training strategies for legal case retrieval remain to be explored. Compared with general documents, legal case documents are typically long text sequences with intrinsic logical structures. However, most existing language models have difficulty understanding the long-distance dependencies between different structures. Moreover, in contrast to the general retrieval, the relevance in the legal domain is sensitive to key legal elements. Even subtle differences in key legal elements can significantly affect the judgement of relevance. However, existing pre-trained language models designed for general purposes have not been equipped to handle legal elements. To address these issues, in this paper, we propose SAILER, a new Structure-Aware pre-traIned language model for LEgal case Retrieval. It is highlighted in the following three aspects: (1) SAILER fully utilizes the structural information contained in legal case documents and pays more attention to key legal elements, similar to how legal experts browse legal case documents. (2) SAILER employs an asymmetric encoder-decoder architecture to integrate several different pre-training objectives. In this way, rich semantic information across tasks is encoded into dense vectors. (3) SAILER has powerful discriminative ability, even without any legal annotation data. It can distinguish legal cases with different charges accurately. Extensive experiments over publicly available legal benchmarks demonstrate that our approach can significantly outperform previous state-of-the-art methods in legal case retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluation in Contextual Information Retrieval\n",
            "Authors: L. Tamine, Mariam Daoud\n",
            "Year: 2018\n",
            "Venue: ACM Computing Surveys\n",
            "Abstract: Context such as the user’s search history, demographics, devices, and surroundings, has become prevalent in various domains of information seeking and retrieval such as mobile search, task-based search, and social search. While evaluation is central and has a long history in information retrieval, it faces the big challenge of designing an appropriate methodology that embeds the context into evaluation settings. In this article, we present a unified summary of a wide range of main and recent progress in contextual information retrieval evaluation that leverages diverse context dimensions and uses different principles, methodologies, and levels of measurements. More specifically, this survey article aims to fill two main gaps in the literature: First, it provides a critical summary and comparison of existing contextual information retrieval evaluation methodologies and metrics according to a simple stratification model; second, it points out the impact of context dynamicity and data privacy on the evaluation design. Finally, we recommend promising research directions for future investigations.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval From MDS Coded Data in Distributed Storage Systems\n",
            "Authors: Razane Tajeddine, O. W. Gnilke, Salim el Rouayheb\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: The problem of providing privacy, in the private information retrieval (PIR) sense, to users requesting data from a distributed storage system (DSS), is considered. The DSS is coded by an <inline-formula> <tex-math notation=\"LaTeX\">$(n,k,d)$ </tex-math></inline-formula> maximum distance separable code to store the data reliably on unreliable storage nodes. Some of these nodes can be spies which report to a third party, such as an oppressive regime, which data is being requested by the user. An information theoretic PIR scheme ensures that a user can satisfy its request while revealing no information on which data is being requested to the nodes. A user can trivially achieve PIR by downloading all the data in the DSS. However, this is not a feasible solution due to its high communication cost. We construct PIR schemes with low download communication cost. When there is <inline-formula> <tex-math notation=\"LaTeX\">$b=1$ </tex-math></inline-formula> spy node in the DSS, in other words, no collusion between the nodes, we construct PIR schemes with download cost <inline-formula> <tex-math notation=\"LaTeX\">$\\frac {1}{1-R}$ </tex-math></inline-formula> per unit of requested data (<inline-formula> <tex-math notation=\"LaTeX\">$R=k/n$ </tex-math></inline-formula> is the code rate), achieving the information theoretic limit for linear schemes. The proposed schemes are universal since they depend on the code rate, but not on the generator matrix of the code. Also, if <inline-formula> <tex-math notation=\"LaTeX\">$b\\leq n-\\delta k$ </tex-math></inline-formula> nodes collude, with <inline-formula> <tex-math notation=\"LaTeX\">$\\delta =\\lfloor {\\frac {n-b}{k}}\\rfloor $ </tex-math></inline-formula>, we construct linear PIR schemes with download cost <inline-formula> <tex-math notation=\"LaTeX\">$\\frac {b+\\delta k}{\\delta }$ </tex-math></inline-formula>.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Expert Search Strategies: The Information Retrieval Practices of Healthcare Information Professionals\n",
            "Authors: Tony Russell-Rose, Jon Chamberlain\n",
            "Year: 2017\n",
            "Venue: JMIR Medical Informatics\n",
            "Abstract: Background Healthcare information professionals play a key role in closing the knowledge gap between medical research and clinical practice. Their work involves meticulous searching of literature databases using complex search strategies that can consist of hundreds of keywords, operators, and ontology terms. This process is prone to error and can lead to inefficiency and bias if performed incorrectly. Objective The aim of this study was to investigate the search behavior of healthcare information professionals, uncovering their needs, goals, and requirements for information retrieval systems. Methods A survey was distributed to healthcare information professionals via professional association email discussion lists. It investigated the search tasks they undertake, their techniques for search strategy formulation, their approaches to evaluating search results, and their preferred functionality for searching library-style databases. The popular literature search system PubMed was then evaluated to determine the extent to which their needs were met. Results The 107 respondents indicated that their information retrieval process relied on the use of complex, repeatable, and transparent search strategies. On average it took 60 minutes to formulate a search strategy, with a search task taking 4 hours and consisting of 15 strategy lines. Respondents reviewed a median of 175 results per search task, far more than they would ideally like (100). The most desired features of a search system were merging search queries and combining search results. Conclusions Healthcare information professionals routinely address some of the most challenging information retrieval problems of any profession. However, their needs are not fully supported by current literature search systems and there is demand for improved functionality, in particular regarding the development and management of search strategies.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private Information Retrieval from Coded Databases with Colluding Servers\n",
            "Authors: Ragnar Freij, O. W. Gnilke, C. Hollanti, David A. Karpuk\n",
            "Year: 2016\n",
            "Venue: SIAM Journal on applied algebra and geometry\n",
            "Abstract: We present a general framework for Private Information Retrieval (PIR) from arbitrary coded databases, that allows one to adjust the rate of the scheme according to the suspected number of colluding servers. If the storage code is a generalized Reed-Solomon code of length n and dimension k, we design PIR schemes which simultaneously protect against t colluding servers and provide PIR rate 1-(k+t-1)/n, for all t between 1 and n-k. This interpolates between the previously studied cases of t=1 and k=1 and asymptotically achieves the known capacity bounds in both of these cases, as the size of the database grows.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval\n",
            "Authors: Xiaodong Liu, Jianfeng Gao, Xiaodong He, L. Deng, Kevin Duh, Ye-Yi Wang\n",
            "Year: 2015\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Methods of deep neural networks (DNNs) have recently demonstrated superior performance on a number of natural language processing tasks. However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data. We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains. Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LibGuides: Information Retrieval Guide: Efficient Information Retrieval\n",
            "Authors: Emilia Kurikkala\n",
            "Year: 2019\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Information Retrieval\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: In the private information retrieval (PIR) problem, a user wishes to retrieve, as efficiently as possible, one out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating databases (each holds all <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages and <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> databases, we show that the PIR capacity is <inline-formula> <tex-math notation=\"LaTeX\">$(1+1/N+1/N^{2}+\\cdots +1/N^{K-1})^{-1}$ </tex-math></inline-formula>. A remarkable feature of the capacity achieving scheme is that if we eliminate any subset of messages (by setting the message symbols to zero), the resulting scheme also achieves the PIR capacity for the remaining subset of messages.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of the FIRE 2017 IRLeD Track: Information Retrieval from Legal Documents\n",
            "Authors: A. Mandal, Kripabandhu Ghosh, Arnab Bhattacharya, Arindam Pal, Saptarshi Ghosh\n",
            "Year: 2017\n",
            "Venue: Fire\n",
            "Abstract: The FIRE 2017 IRLeD Track focused on creating a framework for evaluating different methods of Information Retrieval from legal documents. Therewere two tasks for this track: (i) Catchphrase Extraction task, and (ii) Precedence Retrieval task. In the catchphrase extraction task, the participants had to extract catchphrases (legal keywords) from Indian Supreme Court case documents. In the second task of Precedence Retrieval, the participants were to retrieve relevant or cite-able documents for particular Indian SupremeCourt cases from a set of prior case documents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Utilizing Knowledge Graphs in Text-centric Information Retrieval\n",
            "Authors: Laura Dietz, Alexander Kotov, E. Meij\n",
            "Year: 2017\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: The past decade has witnessed the emergence of several publicly available and proprietary knowledge graphs (KGs). The increasing depth and breadth of content in KGs makes them not only rich sources of structured knowledge by themselves but also valuable resources for search systems. A surge of recent developments in entity linking and retrieval methods gave rise to a new line of research that aims at utilizing KGs for text-centric retrieval applications, making this an ideal time to pause and report current findings to the community, summarizing successful approaches, and soliciting new ideas. This tutorial is the first to disseminate the progress in this emerging field to researchers and practitioners. All tutorial resources are available online at http://github.com/laura-dietz/tutorial-utilizing-kg\n",
            "\n",
            "---\n",
            "\n",
            "Title: How Does Generative Retrieval Scale to Millions of Passages?\n",
            "Authors: Ronak Pradeep, Kai Hui, Jai Gupta, Á. Lelkes, Honglei Zhuang, Jimmy J. Lin, Donald Metzler, Vinh Q. Tran\n",
            "Year: 2023\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Popularized by the Differentiable Search Index, the emerging paradigm of generative retrieval re-frames the classic information retrieval problem into a sequence-to-sequence modeling task, forgoing external indices and encoding an entire document corpus within a single Transformer. Although many different approaches have been proposed to improve the effectiveness of generative retrieval, they have only been evaluated on document corpora on the order of 100k in size. We conduct the first empirical study of generative retrieval techniques across various corpus scales, ultimately scaling up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages and evaluating model sizes up to 11B parameters. We uncover several findings about scaling generative retrieval to millions of passages; notably, the central importance of using synthetic queries as document representations during indexing, the ineffectiveness of existing proposed architecture modifications when accounting for compute cost, and the limits of naively scaling model parameters with respect to retrieval performance. While we find that generative retrieval is competitive with state-of-the-art dual encoders on small corpora, scaling to millions of passages remains an important and unsolved challenge. We believe these findings will be valuable for the community to clarify the current state of generative retrieval, highlight the unique challenges, and inspire new research directions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Knowledge based collection selection for distributed information retrieval\n",
            "Authors: Baoli Han, Ling Chen, X. Tian\n",
            "Year: 2018\n",
            "Venue: Information Processing & Management\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Understanding the topic evolution in a scientific domain: An exploratory study for the field of information retrieval\n",
            "Authors: Baitong Chen, Satoshi Tsutsui, Ying Ding, Feicheng Ma\n",
            "Year: 2017\n",
            "Venue: J. Informetrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Symmetric Private Information Retrieval\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: 2016 IEEE Globecom Workshops (GC Wkshps)\n",
            "Abstract: Private information retrieval (PIR) is the problem of retrieving as efficiently as possible, one out of K messages from N non- communicating replicated databases (each holds all K messages) while keeping the identity of the desired message index a secret from each individual database. Symmetric PIR (SPIR) is a generalization of PIR to include the requirement that beyond the desired message, the user learns nothing about the other K &#8722; 1 messages. The information theoretic capacity of SPIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. We show that the capacity of SPIR is 1&#8722;1/N regardless of the number of messages K, if the databases have access to common randomness (not available to the user) that is independent of the messages, in the amount that is at least 1/(N &#8722;1) bits per desired message bit, and zero otherwise.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluating sentence-level relevance feedback for high-recall information retrieval\n",
            "Authors: Haotian Zhang, G. Cormack, Maura R. Grossman, Mark D. Smucker\n",
            "Year: 2018\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Visual Re-Ranking for Multi-Aspect Information Retrieval\n",
            "Authors: Khalil Klouche, Tuukka Ruotsalo, L. Micallef, S. Andolina, Giulio Jacucci\n",
            "Year: 2017\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: We present visual re-ranking, an interactive visualization technique for multi-aspect information retrieval. In multi-aspect search, the information need of the user consists of more than one aspect or query simultaneously. While visualization and interactive search user interface techniques for improving user interpretation of search results have been proposed, the current research lacks understanding on how useful these are for the user: whether they lead to quantifiable benefits in perceiving the result space and allow faster, and more precise retrieval. Our technique visualizes relevance and document density on a two-dimensional map with respect to the query phrases. Pointing to a location on the map specifies a weight distribution of the relevance to each of the query phrases, according to which search results are re-ranked. User experiments compared our technique to a uni-dimensional search interface with typed query and ranked result list, in perception and retrieval tasks. Visual re-ranking yielded improved accuracy in perception, higher precision in retrieval and overall faster task execution. Our findings demonstrate the utility of visual re-ranking, and can help designing search user interfaces that support multi-aspect search.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey on Information Retrieval Models, Techniques and Applications\n",
            "Authors: Ndengabaganizi Tonny James, R. Kannan\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: It has been long time many people have realized the importance of archiving and finding information. With the advent of computers, it became possible to store large amounts of information; and finding useful information from such collections became a necessity. Over the last forty years, Information Retrieval (IR) has matured considerably. Several IR systems are used on an everyday basis by a wide variety of users. Information retrieval (IR) is generally concerned with the searching and retrieving of knowledge-based information from database. In this paper, we will discuss about the various models and techniques and for information retrieval. We are also providing the overview of traditional IR models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: How Does Execution Information Help with Information-Retrieval Based Bug Localization?\n",
            "Authors: Tung Dao, Lingming Zhang, Na Meng\n",
            "Year: 2017\n",
            "Venue: IEEE International Conference on Program Comprehension\n",
            "Abstract: Bug localization is challenging and time-consuming. Given a bug report, a developer may spend tremendous time comprehending the bug description together with code in order to locate bugs. To facilitate bug report comprehension, information retrieval (IR)-based bug localization techniques have been proposed to automatically search for and rank potential buggy code elements (i.e., classes or methods). However, these techniques do not leverage any dynamic execution information of buggy programs. In this paper, we perform the first systematic study on how dynamic execution information can help with static IR-based bug localization. More specifically, with the fixing patches and bug reports of 157 real bugs, we investigated the impact of various execution information (i.e. coverage, slicing, and spectrum) on three IR-based techniques: the baseline technique, BugLocator, and BLUiR. Our experiments demonstrate that both the coverage and slicing information of failed tests can effectively reduce the search space and improve IR-based techniques at both class and method levels. Using additional spectrum information can further improve bug localization at the method but not the class level. Some of our investigated ways of augmenting IR-based bug localization with execution information even outperform a state-of-the-art technique, which merges spectrum with an IR-based technique in a complicated way. Different from prior work, by investigating various easy-to-understand ways to combine execution information with IR-based techniques, this study shows for the first time that execution information can generally bring considerable improvement to IR-based bug localization.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Secure Private Information Retrieval from Colluding Databases with Eavesdroppers\n",
            "Authors: Qiwen Wang, M. Skoglund\n",
            "Year: 2017\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: The problem of private information retrieval (PIR) is to retrieve one message out of $K$ messages replicated at $N$ databases, without revealing the identity of the desired message to the databases. We consider the problem of PIR with colluding databases and eavesdroppers, named ETPIR. Specifically, any $T$ out of $N$ databases may collude, that is, they may communicate their interactions with the user to guess the identity of the requested message. An eavesdropper is curious to know the content of the messages and can tap in on the incoming and outgoing transmissions of any $E$ databases with the user. The databases share some common randomness unknown to the eavesdropper and the user, and use the common randomness to generate the answers, such that the eavesdropper can learn no information about the $K$ messages. The capacity is defined as the maximum retrieval rate, i.e. the number of information bits of the desired message retrieved per downloaded bit. In our previous work [1], we found that when $E\\geq T$, the capacity equals $1-\\frac{E}{N}$. In this work, we focus on the case when $E\\leq T$. We find an outer bound (converse bound) and an inner bound (achievability) on the optimal achievable rate. The gap between the derived inner and outer bounds vanishes as the number of messages $K$ tends to infinity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Query Auto Completion in Information Retrieval\n",
            "Authors: Fei Cai, M. de Rijke\n",
            "Year: 2016\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: In information retrieval, query auto completion (QAC), also known as type-ahead and auto-complete suggestion, refers to the following functionality: given a prex consisting of a number of characters entered into a search box, the user interface proposes alternative ways of extending the prex to a full query. QAC helps users to formulate their query when they have an intent in mind but not a clear way of expressing this in a query. It helps to avoid possible spelling mistakes, especially on devices with small screens. It saves keystrokes and cuts down the search duration of users which implies a lower load on the search engine, and results in savings in machine resources and maintenance. Because of the clear benets of QAC, a considerable number of algorithmic approaches to QAC have been proposed in the past few years. Query logs have proven to be a key asset underlying most of the recent research. This monograph surveys this research. It focuses on summarizing the literature on QAC and provides a general understanding of the wealth of QAC approaches that are currently available. A Survey of Query Auto Completion in Information Retrieval is an ideal reference on the topic. Its contributions can be summarized as follows: It provides researchers who are working on query auto completion or related problems in the eld of information retrieval with a good overview and analysis of state-of-the-art QAC approaches. In particular, for researchers new to the eld, the survey can serve as an introduction to the state-of-the-art. It also offers a comprehensive perspective on QAC approaches by presenting a taxonomy of existing solutions. In addition, it presents solutions for QAC under different conditions such as available high-resolution query logs, in-depth user interactions with QAC using eye-tracking, and elaborate user engagements in a QAC process. It also discusses practical issues related to QAC. Lastly, it presents a detailed discussion of core challenges and promising open directions in QAC.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Information Retrieval Experiment Framework for Domain Specific Applications\n",
            "Authors: Harrisen Scells, Daniel Locke, G. Zuccon\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We present a framework for constructing and executing information retrieval experiment pipelines. The framework as a whole is built primarily for domain specific applications such as medical literature search for systematic reviews, or finding factually or legally applicable case law in the legal domain; however it can also be used for more general tasks. There are a number of pre-implemented components that enable common information retrieval experiments such as ad-hoc retrieval or query analysis through query performance predictors. In addition, this collection of tools seeks to be user friendly, well documented, and easily extendible. Finally, the entire pipeline can be distributed as a single binary with no dependencies, ready to use with a simple domain specific language (DSL) for constructing pipelines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey of Web crawlers for information retrieval\n",
            "Authors: M.Anjan Kumar, R. Bhatia, D. Rattan\n",
            "Year: 2017\n",
            "Venue: WIREs Data Mining Knowl. Discov.\n",
            "Abstract: Performance of any search engine relies heavily on its Web crawler. Web crawlers are the programs that get webpages from the Web by following hyperlinks. These webpages are indexed by a search engine and can be retrieved by a user query. In the area of Web crawling, we still lack an exhaustive study that covers all crawling techniques. This study follows the guidelines of systematic literature review and applies it to the field of Web crawling. We used the standard procedure of carrying out a systematic literature review on 248 studies from a total of 1488 articles published in 12 leading journals and other premier conferences and workshops. Existing literature about the Web crawler is classified into different key subareas. Each subarea is further divided according to the techniques being used. We analyzed the distribution of various articles using multiple criteria and depicted conclusions. Various studies that use open source Web crawlers are also reported. We have highlighted future areas of research. We call for an increased awareness in various fields of the Web crawler and identify how techniques from other domains can be used for crawling the Web. Limitations and recommendations for future are also discussed. WIREs Data Mining Knowl Discov 2017, 7:e1218. doi: 10.1002/widm.1218\n",
            "\n",
            "---\n",
            "\n",
            "Title: Monolingual and Cross-Lingual Information Retrieval Models Based on (Bilingual) Word Embeddings\n",
            "Authors: Ivan Vulic, Marie-Francine Moens\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We propose a new unified framework for monolingual (MoIR) and cross-lingual information retrieval (CLIR) which relies on the induction of dense real-valued word vectors known as word embeddings (WE) from comparable data. To this end, we make several important contributions: (1) We present a novel word representation learning model called Bilingual Word Embeddings Skip-Gram (BWESG) which is the first model able to learn bilingual word embeddings solely on the basis of document-aligned comparable data; (2) We demonstrate a simple yet effective approach to building document embeddings from single word embeddings by utilizing models from compositional distributional semantics. BWESG induces a shared cross-lingual embedding vector space in which both words, queries, and documents may be presented as dense real-valued vectors; (3) We build novel ad-hoc MoIR and CLIR models which rely on the induced word and document embeddings and the shared cross-lingual embedding space; (4) Experiments for English and Dutch MoIR, as well as for English-to-Dutch and Dutch-to-English CLIR using benchmarking CLEF 2001-2003 collections and queries demonstrate the utility of our WE-based MoIR and CLIR models. The best results on the CLEF collections are obtained by the combination of the WE-based approach and a unigram language model. We also report on significant improvements in ad-hoc IR tasks of our WE-based framework over the state-of-the-art framework for learning text representations from comparable data based on latent Dirichlet allocation (LDA).\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Exploration of Serverless Architectures for Information Retrieval\n",
            "Authors: Matt Crane, Jimmy J. Lin\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Serverless architectures represent a new approach to designing applications in the cloud without having to explicitly provision or manage servers. The developer specifies functions with well-defined entry and exit points, and the cloud provider handles all other aspects of execution. In this paper, we explore a novel application of serverless architectures to information retrieval and describe a search engine built in this manner with Amazon Web Services: postings lists are stored in the DynamoDB NoSQL store and the postings traversal algorithm for query evaluation is implemented in the Lambda service. The result is a search engine that scales elastically with a pay-per-request model, in contrast to a server-based model that requires paying for running instances even if there are no requests. We empirically assess the performance and economics of our serverless architecture. While our implementation is currently too slow for interactive searching, analysis shows that the pay-per-request model is economically compelling, and future infrastructure improvements will increase the attractiveness of serverless designs over time.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Mobile Information Retrieval\n",
            "Authors: F. Crestani, Stefano Mizzaro, Ivan Scagnetto\n",
            "Year: 2017\n",
            "Venue: SpringerBriefs in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Active Sampling for Large-scale Information Retrieval Evaluation\n",
            "Authors: Dan Li, E. Kanoulas\n",
            "Year: 2017\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Evaluation is crucial in Information Retrieval. The development of models, tools and methods has significantly benefited from the availability of reusable test collections formed through a standardized and thoroughly tested methodology, known as the Cranfield paradigm. Constructing these collections requires obtaining relevance judgments for a pool of documents, retrieved by systems participating in an evaluation task; thus involves immense human labor. To alleviate this effort different methods for constructing collections have been proposed in the literature, falling under two broad categories: (a) sampling, and (b) active selection of documents. The former devises a smart sampling strategy by choosing only a subset of documents to be assessed and inferring evaluation measure on the basis of the obtained sample; the sampling distribution is being fixed at the beginning of the process. The latter recognizes that systems contributing documents to be judged vary in quality, and actively selects documents from good systems. The quality of systems is measured every time a new document is being judged. In this paper we seek to solve the problem of large-scale retrieval evaluation combining the two approaches. We devise an active sampling method that avoids the bias of the active selection methods towards good systems, and at the same time reduces the variance of the current sampling approaches by placing a distribution over systems, which varies as judgments become available. We validate the proposed method using TREC data and demonstrate the advantages of this new method compared to past approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval\n",
            "Authors: Yelong Shen, Xiaodong He, Jianfeng Gao, L. Deng, Grégoire Mesnil\n",
            "Year: 2014\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: In this paper, we propose a new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents. In order to capture the rich contextual structures in a query or a document, we start with each word within a temporal context window in a word sequence to directly capture contextual features at the word n-gram level. Next, the salient word n-gram features in the word sequence are discovered by the model and are then aggregated to form a sentence-level feature vector. Finally, a non-linear transformation is applied to extract high-level semantic information to generate a continuous vector representation for the full text string. The proposed convolutional latent semantic model (CLSM) is trained on clickthrough data and is evaluated on a Web document ranking task using a large-scale, real-world data set. Results show that the proposed model effectively captures salient semantic information in queries and documents for the task while significantly outperforming previous state-of-the-art semantic models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents\n",
            "Authors: Zhao Yan, Nan Duan, Junwei Bao, Peng Chen, M. Zhou, Zhoujun Li, Jianshe Zhou\n",
            "Year: 2016\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Most current chatbot engines are designed to reply to user utterances based on existing utterance-response (or Q-R) 1 pairs. In this paper, we present DocChat, a novel information retrieval approach for chat-bot engines that can leverage unstructured documents, instead of Q-R pairs, to respond to utterances. A learning to rank model with features designed at different levels of granularity is proposed to measure the relevance between utterances and responses directly. We evaluate our proposed approach in both English and Chinese: (i) For English, we evaluate Doc-Chat on WikiQA and QASent, two answer sentence selection tasks, and compare it with state-of-the-art methods. Reasonable improvements and good adaptability are observed. (ii) For Chinese, we compare DocChat with XiaoIce 2 , a famous chitchat engine in China, and side-by-side evaluation shows that DocChat is a perfect complement for chatbot engines using Q-R pairs as main source of responses.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A passage retrieval method based on probabilistic information retrieval model and UMLS concepts in biomedical question answering\n",
            "Authors: Mourad Sarrouti, Said Ouatik El Alaoui\n",
            "Year: 2017\n",
            "Venue: Journal of Biomedical Informatics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-message private information retrieval\n",
            "Authors: Karim A. Banawan, S. Ulukus\n",
            "Year: 2017\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We consider the problem of multi-message private information retrieval (MPIR) from N non-communicating replicated databases. In MPIR, the user is interested in retrieving P messages out of M stored messages without leaking the identity of the retrieved messages. The information-theoretic sum capacity of MPIR CP is the maximum number of desired message symbols that can be retrieved privately per downloaded symbol. For the case P ≥ M/2, we determine the exact sum capacity of MPIR as C<sup>P</sup><inf>s</inf>=1/1+M-P/PN For P≤M/2, we develop lower and upper bounds for all M, P, N. These bounds match if the number of messages M is an integer multiple of the number of desired messages P, in which case, C<sup>P</sup><inf>s</inf> = 1−1N/1−(1/N)<sup>M/P</sup>. Our results indicate that joint retrieval of desired messages is more efficient than successive use of single-message retrieval schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Combining Word Embedding with Information Retrieval to Recommend Similar Bug Reports\n",
            "Authors: Xinli Yang, D. Lo, Xin Xia, Lingfeng Bao, Jianling Sun\n",
            "Year: 2016\n",
            "Venue: IEEE International Symposium on Software Reliability Engineering\n",
            "Abstract: Similar bugs are bugs that require handling of many common code files. Developers can often fix similar bugs with a shorter time and a higher quality since they can focus on fewer code files. Therefore, similar bug recommendation is a meaningful task which can improve development efficiency. Rocha et al. propose the first similar bug recommendation system named NextBug. Although NextBug performs better than a start-of-the-art duplicated bug detection technique REP, its performance is not optimal and thus more work is needed to improve its effectiveness. Technically, it is also rather simple as it relies only upon a standard information retrieval technique, i.e., cosine similarity. In the paper, we propose a novel approach to recommend similar bugs. The approach combines a traditional information retrieval technique and a word embedding technique, and takes bug titles and descriptions as well as bug product and component information into consideration. To evaluate the approach, we use datasets from two popular open-source projects, i.e., Eclipse and Mozilla, each of which contains bug reports whose bug ids range from [1,400000]. The results show that our approach improves the performance of NextBug statistically significantly and substantially for both projects.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Language Models via Plug-and-Play Retrieval Feedback\n",
            "Authors: W. Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, Ashish Sabharwal\n",
            "Year: 2023\n",
            "Venue: arXiv.org\n",
            "Abstract: Large language models (LLMs) exhibit remarkable performance across various NLP tasks. However, they often generate incorrect or hallucinated information, which hinders their practical applicability in real-world scenarios. Human feedback has been shown to effectively enhance the factuality and quality of generated content, addressing some of these limitations. However, this approach is resource-intensive, involving manual input and supervision, which can be time-consuming and expensive. Moreover, it cannot be provided during inference, further limiting its practical utility in dynamic and interactive applications. In this paper, we introduce ReFeed, a novel pipeline designed to enhance LLMs by providing automatic retrieval feedback in a plug-and-play framework without the need for expensive fine-tuning. ReFeed first generates initial outputs, then utilizes a retrieval model to acquire relevant information from large document collections, and finally incorporates the retrieved information into the in-context demonstration for output refinement, thereby addressing the limitations of LLMs in a more efficient and cost-effective manner. Experiments on four knowledge-intensive benchmark datasets demonstrate our proposed ReFeed could improve over +6.0% under zero-shot setting and +2.5% under few-shot setting, compared to baselines without using retrieval feedback.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Optimal Download Cost of Private Information Retrieval for Arbitrary Message Length\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: A private information retrieval (PIR) scheme is a mechanism that allows a user to retrieve any one out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating replicated databases, each of which stores all <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages, without revealing anything (in the information theoretic sense) about the identity of the desired message index to any individual database. If the size of each message is <inline-formula> <tex-math notation=\"LaTeX\">$L$ </tex-math></inline-formula> bits and the total download required by a PIR scheme from all <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> databases is <inline-formula> <tex-math notation=\"LaTeX\">$D$ </tex-math></inline-formula> bits, then <inline-formula> <tex-math notation=\"LaTeX\">$D$ </tex-math></inline-formula> is called the download cost and the ratio <inline-formula> <tex-math notation=\"LaTeX\">$L/D$ </tex-math></inline-formula> is called an achievable rate. For fixed <inline-formula> <tex-math notation=\"LaTeX\">$K,N\\in \\mathbb {N}$ </tex-math></inline-formula>, the capacity of PIR, denoted by <inline-formula> <tex-math notation=\"LaTeX\">$C$ </tex-math></inline-formula>, is the supremum of achievable rates over all PIR schemes and over all message sizes, and was recently shown to be <inline-formula> <tex-math notation=\"LaTeX\">$C=(1+1/N+1/N^{2}+\\cdots +1/N^{K-1})^{-1}$ </tex-math></inline-formula>. In this paper, for arbitrary <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula>, we explore the minimum download cost <inline-formula> <tex-math notation=\"LaTeX\">$D_{L}$ </tex-math></inline-formula> across all PIR schemes (not restricted to linear schemes) for arbitrary message lengths <inline-formula> <tex-math notation=\"LaTeX\">$L$ </tex-math></inline-formula> under arbitrary choices of alphabet (not restricted to finite fields) for the message and download symbols. If the same <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula>-ary alphabet is used for the message and download symbols, then we show that the optimal download cost in <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula>-ary symbols is <inline-formula> <tex-math notation=\"LaTeX\">$D_{L}=\\lceil \\frac {L}{C}\\rceil$ </tex-math></inline-formula>. If the message symbols are in <inline-formula> <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula>-ary alphabet and the downloaded symbols are in <inline-formula> <tex-math notation=\"LaTeX\">$M'$ </tex-math></inline-formula>-ary alphabet, then we show that the optimal download cost in <inline-formula> <tex-math notation=\"LaTeX\">$M'$ </tex-math></inline-formula>-ary symbols, <inline-formula> <tex-math notation=\"LaTeX\">$D_{L}\\in \\{\\lceil ~({L'}/{C})\\rceil, \\lceil ~({L'}/{C}\\rceil -1,\\lceil ~({L'}/{C})\\rceil -2\\}$ </tex-math></inline-formula>, where <inline-formula> <tex-math notation=\"LaTeX\">$L'= \\lceil L \\log _{M'} M\\rceil$ </tex-math></inline-formula>, i.e., the optimal download cost is characterized to within two symbols.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval Meets Game Theory: The Ranking Competition Between Documents' Authors\n",
            "Authors: Nimrod Raifer, Fiana Raiber, Moshe Tennenholtz, Oren Kurland\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In competitive search settings as the Web, there is an ongoing ranking competition between document authors (publishers) for certain queries. The goal is to have documents highly ranked, and the means is document manipulation applied in response to rankings. Existing retrieval models, and their theoretical underpinnings (e.g., the probability ranking principle), do not account for post-ranking corpus dynamics driven by this strategic behavior of publishers. However, the dynamics has major effect on retrieval effectiveness since it affects content availability in the corpus. Furthermore, while manipulation strategies observed over the Web were reported in past literature, they were not analyzed as ongoing, and changing, post-ranking response strategies, nor were they connected to the foundations of classical ad hoc retrieval models (e.g., content-based document-query surface level similarities and document relevance priors). We present a novel theoretical and empirical analysis of the strategic behavior of publishers using these foundations. Empirical analysis of controlled ranking competitions that we organized reveals a key strategy of publishers: making their documents (gradually) become similar to documents ranked the highest in previous rankings. Our theoretical analysis of the ranking competition as a repeated game, and its minmax regret equilibrium, yields a result that supports the merits of this publishing strategy. We further show that it can be predicted with high accuracy, and without explicit knowledge of the ranking function, whether documents will be promoted to the highest rank in our competitions. The prediction utilizes very few features which quantify changes of documents, specifically with respect to those previously ranked the highest.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval as Statistical Translation\n",
            "Authors: A. Berger, J. Lafferty\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: We propose a new probabilistic approach to information retrieval based upon the ideas and methods of statistical machine translation. The central ingredient in this approach is a statistical model of how a user might distill or \"translate\" a given document into a query. To assess the relevance of a document to a user's query, we estimate the probability that the query would have been generated as a translation of the document, and factor in the user's general preferences in the form of a prior distribution over documents. We propose a simple, well motivated model of the document-to-query translation process, and describe an algorithm for learning the parameters of this model in an unsupervised manner from a collection of documents. As we show, one can view this approach as a generalization and justification of the \"language modeling\" strategy recently proposed by Ponte and Croft. In a series of experiments on TREC data, a simple translation-based retrieval system performs well in comparison to conventional retrieval techniques. This prototype system only begins to tap the full potential of translation-based retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval Implementing And Evaluating Search Engines\n",
            "Authors: N. Bauer\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Thank you for downloading information retrieval implementing and evaluating search engines. Maybe you have knowledge that, people have look hundreds times for their chosen novels like this information retrieval implementing and evaluating search engines, but end up in harmful downloads. Rather than enjoying a good book with a cup of coffee in the afternoon, instead they cope with some malicious virus inside their desktop computer.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Robust private information retrieval on coded data\n",
            "Authors: Razane Tajeddine, S. E. Rouayheb\n",
            "Year: 2017\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We consider the problem of designing PIR scheme on coded data when certain nodes are unresponsive. We provide the construction of ν-robust PIR schemes that can tolerate up to ν unresponsive nodes. These schemes are adaptive and universally optimal in the sense of achieving (asymptotically) optimal download cost for any number of unresponsive nodes up to ν.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Word Embedding based Generalized Language Model for Information Retrieval\n",
            "Authors: Debasis Ganguly, Dwaipayan Roy, Mandar Mitra, Gareth J.F. Jones\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Word2vec, a state-of-the-art word embedding technique has gained a lot of interest in the NLP community. The embedding of the word vectors helps to retrieve a list of words that are used in similar contexts with respect to a given word. In this paper, we focus on using the word embeddings for enhancing retrieval effectiveness. In particular, we construct a generalized language model, where the mutual independence between a pair of words (say t and t') no longer holds. Instead, we make use of the vector embeddings of the words to derive the transformation probabilities between words. Specifically, the event of observing a term t in the query from a document d is modeled by two distinct events, that of generating a different term t', either from the document itself or from the collection, respectively, and then eventually transforming it to the observed query term t. The first event of generating an intermediate term from the document intends to capture how well does a term contextually fit within a document, whereas the second one of generating it from the collection aims to address the vocabulary mismatch problem by taking into account other related terms in the collection. Our experiments, conducted on the standard TREC collection, show that our proposed method yields significant improvements over LM and LDA-smoothed LM baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Online Evaluation for Information Retrieval\n",
            "Authors: Katja Hofmann, Lihong Li, Filip Radlinski\n",
            "Year: 2016\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Online evaluation is one of the most common approaches to measure the effectiveness of an information retrieval system. It involves fielding the information retrieval system to real users, and observing these users' interactions in-situ while they engage with the system. This allows actual users with real world information needs to play an important part in assessing retrieval quality. As such, online evaluation complements the common alternative offline evaluation approaches which may provide more easily interpretable outcomes, yet are often less realistic when measuring of quality and actual user experience.In this survey, we provide an overview of online evaluation techniques for information retrieval. We show how online evaluation is used for controlled experiments, segmenting them into experiment designs that allow absolute or relative quality assessments. Our presentation of different metrics further partitions online evaluation based on different sized experimental units commonly of interest: documents, lists and sessions. Additionally, we include an extensive discussion of recent work on data re-use, and experiment estimation based on historical data.A substantial part of this work focuses on practical issues: How to run evaluations in practice, how to select experimental parameters, how to take into account ethical considerations inherent in online evaluations, and limitations that experimenters should be aware of. While most published work on online experimentation today is at large scale in systems with millions of users, we also emphasize that the same techniques can be applied at small scale. To this end, we emphasize recent work that makes it easier to use at smaller scales and encourage studying real-world information seeking in a wide range of scenarios. Finally, we present a summary of the most recent work in the area, and describe open problems, as well as postulating future directions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval\n",
            "Authors: R. Perego, F. Sebastiani, J. Aslam, I. Ruthven, J. Zobel\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Welcome to SIGIR 2016, the 39th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, the premier conference in the area. We are grateful to all those who chose to submit their research papers to SIGIR 2016 and gave the Program Committee an opportunity to evaluate their work for potential inclusion in the program. We are also grateful to the 61 Senior Program Committee Members, 244 Program Committee Members, and many additional reviewers for providing significant time and effort to selecting this year's conference program. This pool of committed SIGIR volunteers comes from 24 countries and over 180 institutions. \n",
            " \n",
            "The PC reviewed 341 papers for the full paper track, and accepted 62 with an acceptance rate of 18%. The top countries in terms of accepted papers (taking all author affiliations of each paper equally into account) were the U.S.A. (34%), and China (23%) with the most successful countries (as measured by how likely authors from that country were to have their papers accepted) were Russia (55% of authors had their paper accepted), Israel (50%), and Germany (45%). With 1236 authors overall, 313 were from the U.S.A and 283 from China; and 289 from the next six most represented countries combined. \n",
            " \n",
            "As has been customary for many years, SIGIR 2016 employed a two-tier double-blind review process. At least three reviewers reviewed each paper, and then the Primary Area Chair of the paper led a discussion, which was used as the basis of the meta-review. The Secondary Area Chair assigned to each paper double-checked the reviews and discussion and, in some cases, provided an additional review. The PC chairs carefully examined the reviews and associated discussion, asking for additional reviews where necessary to provide a fuller discussion or additional expert opinion. \n",
            " \n",
            "The SIGIR 2016 PC meeting operated as a virtual meeting, held over several days, in order tofacilitate the involvement of as many Senior PC members as possible. Prior to the PC meeting the PC chairs proposed a list of \"clear accepts\" and \"clear rejects\" where the meta-reviews and reviews clearly indicated a decision. Over the four days of the PC meeting, the chairs indicated which undecided papers were open for discussion, led the discussion on these papers, and made the final decision when discussions moved towards completion; overall nearly half of the submitted papers were reviewed by the chairs or at the meeting. We are grateful for the involvement of the Senior PC members in supporting this PC meeting, especially those very committed members who participated in almost every discussion. The virtual PC meeting was supplemented by a small physical meeting of the Senior PC members who attended the ECIR 2016 conference, which took place during the same week. \n",
            " \n",
            "The short paper track received 339 submissions and accepted 104 papers for what promises to be a strong short paper track. Thanks are due to Ben Carterette, Carlos Castillo, and Jaana Kekalainen, the track chairs, for arranging and managing a thorough review process for so many papers -- a huge effort for which we are very grateful. \n",
            " \n",
            "The tutorial track reviewed 20 submissions and accepted 2 full-day tutorials and 10 half-day tutorials. We are grateful to Evangelos Kanoulas and Tie-Yan Liu for leading the selection of a diverse and high quality tutorial program. \n",
            " \n",
            "The workshops track received 12 submissions and selected 7 workshop proposals. We thank Aristides Gionis and Edie Rasmussen for their efforts in producing a great set of workshops. \n",
            " \n",
            "The demos track received 35 submissions of which 21 were accepted. Many thanks are due to Craig Macdonald for chairing this track and providing us with an array of interesting demos. \n",
            " \n",
            "Brian D. Davison and Kira Radinsky organised the Doctoral Consortium, a vitally important part of the SIGIR program. Thanks to their efforts, the event received 23 submissions from doctoral students and accepted 15 of these for presentation and discussion at the consortium. \n",
            " \n",
            "This year's industry track is the SIGIR Symposium on IR in Practice (SIRIP 2016) co-chaired by Jussi Karlgren and Gilad Mishne. Their efforts in organizing SIRIP and producing an interesting set of speakers from diverse backgrounds are gratefully acknowledged.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Symmetric private information retrieval for MDS coded distributed storage\n",
            "Authors: Qiwen Wang, M. Skoglund\n",
            "Year: 2016\n",
            "Venue: 2017 IEEE International Conference on Communications (ICC)\n",
            "Abstract: A user wants to retrieve a file from a database without revealing the identity of the file retrieved at the database, which is known as the problem of private information retrieval (PIR). If it is further required that the user obtains no information about the database other than the desired file, the concept of symmetric private information retrieval (SPIR) is introduced to guarantee privacy for both parties. In this paper, the problem of SPIR is studied for a database stored among N nodes in a distributed way, by using an (N, M)-MDS storage code. The information-theoretic capacity of SPIR, defined as the maximum number of information bits of the desired file retrieved per downloaded bit, for the coded database is derived. It is shown that the SPIR capacity for coded database is 1-M/N, when the amount of the shared common randomness of distributed nodes (unavailable at the user) is at least M/N-M times the file size. Otherwise, the SPIR capacity for the coded database equals zero.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Full-Text Learning to Rank Dataset for Medical Information Retrieval\n",
            "Authors: V. Boteva, D. Ghalandari, Artem Sokolov, S. Riezler\n",
            "Year: 2016\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Combining Deep Learning with Information Retrieval to Localize Buggy Files for Bug Reports (N)\n",
            "Authors: A. Lam, A. Nguyen, H. Nguyen, T. Nguyen\n",
            "Year: 2015\n",
            "Venue: International Conference on Automated Software Engineering\n",
            "Abstract: Bug localization refers to the automated process of locating the potential buggy files for a given bug report. To help developers focus their attention to those files is crucial. Several existing automated approaches for bug localization from a bug report face a key challenge, called lexical mismatch, in which the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. This paper presents a novel approach that uses deep neural network (DNN) in combination with rVSM, an information retrieval (IR) technique. rVSM collects the feature on the textual similarity between bug reports and source files. DNN is used to learn to relate the terms in bug reports to potentially different code tokens and terms in source files and documentation if they appear frequently enough in the pairs of reports and buggy files. Our empirical evaluation on real-world projects shows that DNN and IR complement well to each other to achieve higher bug localization accuracy than individual models. Importantly, our new model, HyLoc, with a combination of the features built from DNN, rVSM, and project's bug-fixing history, achieves higher accuracy than the state-of-the-art IR and machine learning techniques. In half of the cases, it is correct with just a single suggested file. Two out of three cases, a correct buggy file is in the list of three suggested files.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Aggregation operators in Information Retrieval\n",
            "Authors: S. Marrara, G. Pasi, Marco Viviani\n",
            "Year: 2017\n",
            "Venue: Fuzzy Sets Syst.\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Promptagator: Few-shot Dense Retrieval From 8 Examples\n",
            "Authors: Zhuyun Dai, Vincent Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, A. Bakalov, Kelvin Guu, Keith B. Hall, Ming-Wei Chang\n",
            "Year: 2022\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Prompt-base Query Generation for Retriever (Promptagator), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, Promptagator makes it possible to create task-specific end-to-end retrievers solely based on a few examples {without} using Natural Questions or MS MARCO to train %question generators or dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2 by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bandit Algorithms in Interactive Information Retrieval\n",
            "Authors: D. Głowacka\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: The multi-armed bandit problem models an agent that simultaneously attempts to acquire new knowledge (exploration) and optimize his decisions based on existing knowledge (exploitation). The agent attempts to balance these competing tasks in order to maximize his total value over the period of time considered. There are many practical applications of the bandit model, such as clinical trials, adaptive routing or portfolio design. Over the last decade there has been an increased interest in developing bandit algorithms for specific problems in information, such as diverse document ranking, news recommendation or ranker evaluation. The aim of this tutorial is to provide an overview of the various applications of bandit algorithms in information retrieval as well as issues related to their practical deployment and performance in real-life systems/applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Axiomatic Thinking for Information Retrieval: And Related Tasks\n",
            "Authors: Enrique Amigó, Hui Fang, Stefano Mizzaro, ChengXiang Zhai\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This is the first workshop on the emerging interdisciplinary research area of applying axiomatic thinking to information retrieval (IR) and related tasks. The workshop aims to help foster collaboration of researchers working on different perspectives of axiomatic thinking and encourage discussion and research on general methodological issues related to applying axiomatic thinking to IR and related tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Integrating and Evaluating Neural Word Embeddings in Information Retrieval\n",
            "Authors: G. Zuccon, B. Koopman, P. Bruza, L. Azzopardi\n",
            "Year: 2015\n",
            "Venue: Australasian Document Computing Symposium\n",
            "Abstract: Recent advances in neural language models have contributed new methods for learning distributed vector representations of words (also called word embeddings). Two such methods are the continuous bag-of-words model and the skipgram model. These methods have been shown to produce embeddings that capture higher order relationships between words that are highly effective in natural language processing tasks involving the use of word similarity and word analogy. Despite these promising results, there has been little analysis of the use of these word embeddings for retrieval. Motivated by these observations, in this paper, we set out to determine how these word embeddings can be used within a retrieval model and what the benefit might be. To this aim, we use neural word embeddings within the well known translation language model for information retrieval. This language model captures implicit semantic relations between the words in queries and those in relevant documents, thus producing more accurate estimations of document relevance. The word embeddings used to estimate neural language models produce translations that differ from previous translation language model approaches; differences that deliver improvements in retrieval effectiveness. The models are robust to choices made in building word embeddings and, even more so, our results show that embeddings do not even need to be produced from the same corpus being used for retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Information Retrieval Approach for Regression Test Prioritization Based on Program Changes\n",
            "Authors: Ripon K. Saha, Lingming Zhang, S. Khurshid, D. Perry\n",
            "Year: 2015\n",
            "Venue: 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering\n",
            "Abstract: Regression testing is widely used in practice for validating program changes. However, running large regression suites can be costly. Researchers have developed several techniques for prioritizing tests such that the higher-priority tests have a higher likelihood of finding bugs. A vast majority of these techniques are based on dynamic analysis, which can be precise but can also have significant overhead (e.g., for program instrumentation and test-coverage collection). We introduce a new approach, REPiR, to address the problem of regression test prioritization by reducing it to a standard Information Retrieval problem such that the differences between two program versions form the query and the tests constitute the document collection. REPiR does not require any dynamic profiling or static program analysis. As an enabling technology we leverage the open-source IR toolkit Indri. An empirical evaluation using eight open-source Java projects shows that REPiR is computationally efficient and performs better than existing (dynamic or static) techniques for the majority of subject systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Tokenize for Generative Retrieval\n",
            "Authors: Weiwei Sun, Lingyong Yan, Zheng Chen, Shuaiqiang Wang, Haichao Zhu, Pengjie Ren, Zhumin Chen, Dawei Yin, M. de Rijke, Z. Ren\n",
            "Year: 2023\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Conventional document retrieval techniques are mainly based on the index-retrieve paradigm. It is challenging to optimize pipelines based on this paradigm in an end-to-end manner. As an alternative, generative retrieval represents documents as identifiers (docid) and retrieves documents by generating docids, enabling end-to-end modeling of document retrieval tasks. However, it is an open question how one should define the document identifiers. Current approaches to the task of defining document identifiers rely on fixed rule-based docids, such as the title of a document or the result of clustering BERT embeddings, which often fail to capture the complete semantic information of a document. We propose GenRet, a document tokenization learning method to address the challenge of defining document identifiers for generative retrieval. GenRet learns to tokenize documents into short discrete representations (i.e., docids) via a discrete auto-encoding approach. Three components are included in GenRet: (i) a tokenization model that produces docids for documents; (ii) a reconstruction model that learns to reconstruct a document based on a docid; and (iii) a sequence-to-sequence retrieval model that generates relevant document identifiers directly for a designated query. By using an auto-encoding framework, GenRet learns semantic docids in a fully end-to-end manner. We also develop a progressive training scheme to capture the autoregressive nature of docids and to stabilize training. We conduct experiments on the NQ320K, MS MARCO, and BEIR datasets to assess the effectiveness of GenRet. GenRet establishes the new state-of-the-art on the NQ320K dataset. Especially, compared to generative retrieval baselines, GenRet can achieve significant improvements on the unseen documents. GenRet also outperforms comparable baselines on MS MARCO and BEIR, demonstrating the method's generalizability.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval and spectrum based bug localization: better together\n",
            "Authors: Tien-Duy B. Le, R. J. Oentaryo, D. Lo\n",
            "Year: 2015\n",
            "Venue: ESEC/SIGSOFT FSE\n",
            "Abstract: Debugging often takes much effort and resources. To help developers debug, numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been proposed. IR-based techniques process textual information in bug reports, while spectrum-based techniques process program spectra (i.e., a record of which program elements are executed for each test case). Both eventually generate a ranked list of program elements that are likely to contain the bug. However, these techniques only consider one source of information, either bug reports or program spectra, which is not optimal. To deal with the limitation of existing techniques, in this work, we propose a new multi-modal technique that considers both bug reports and program spectra to localize bugs. Our approach adaptively creates a bug-specific model to map a particular bug to its possible location, and introduces a novel idea of suspicious words that are highly associated to a bug. We evaluate our approach on 157 real bugs from four software systems, and compare it with a state-of-the-art IR-based bug localization method, a state-of-the-art spectrum-based bug localization method, and three state-of-the-art multi-modal feature location methods that are adapted for bug localization. Experiments show that our approach can outperform the baselines by at least 47.62%, 31.48%, 27.78%, and 28.80% in terms of number of bugs successfully localized when a developer inspects 1, 5, and 10 program elements (i.e., Top 1, Top 5, and Top 10), and Mean Average Precision (MAP) respectively.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multiround Private Information Retrieval: Capacity and Storage Overhead\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: Private information retrieval (PIR) is the problem of retrieving one message out of <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> non-communicating replicated databases, where each database stores all <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> messages, in such a way that each database learns no information about which message is being retrieved. The capacity of PIR is the maximum number of bits of desired information per bit of downloaded information among all PIR schemes. The capacity has recently been characterized for PIR as well as several of its variants. In every case it is assumed that all the queries are generated by the user simultaneously. Here we consider multiround PIR, where the queries in each round are allowed to depend on the answers received in previous rounds. We show that the capacity of multiround PIR is the same as the capacity of single-round PIR. The result is generalized to also include <inline-formula> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula>-privacy constraints. Combined with previous results, this shows that there is no capacity advantage from multiround over single-round schemes, non-linear over linear schemes or from <inline-formula> <tex-math notation=\"LaTeX\">$\\epsilon $ </tex-math></inline-formula>-error over zero-error schemes. However, we show through an example that there is an advantage in terms of storage overhead. We provide an example of a multiround, non-linear, <inline-formula> <tex-math notation=\"LaTeX\">$\\epsilon $ </tex-math></inline-formula>-error PIR scheme that requires a strictly smaller storage overhead than the best possible with single-round, linear, zero-error PIR schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: APPLYING GENETIC ALGORITHMS TO INFORMATION RETRIEVAL USING VECTOR SPACE MODEL\n",
            "Authors: L. Abualigah, Essam Said Hanandeh\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: Genetic algorithms are usually used in information retrieval systems (IRs) to enhance the information retrieval process, and to increase the efficiency of the optimal information retrieval in order to meet the users' needs and help them find what they want exactly among the growing numbers of available information. The improvement of adaptive genetic algorithms helps to retrieve the information needed by the user accurately, reduces the retrieved relevant files and excludes irrelevant files. In this study, the researcher explored the problems embedded in this process, attempted to find solutions such as the way of choosing mutation probability and fitness function, and chose Cranfield English Corpus test collection on mathematics. Such collection was conducted by Cyrial Cleverdon and used at the University of Cranfield in 1960 containing 1400 documents, and 225 queries for simulation purposes. The researcher also used cosine similarity and jaccards to compute similarity between the query and documents, and used two proposed adaptive fitness function, mutation operators as well as adaptive crossover. The process aimed at evaluating the effectiveness of results according to the measures of precision and recall. Finally, the study concluded that we might have several improvements when using adaptive genetic algorithms. �\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic Matching by Non-Linear Word Transportation for Information Retrieval\n",
            "Authors: J. Guo, Yixing Fan, Qingyao Ai, W. Bruce Croft\n",
            "Year: 2016\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: A common limitation of many information retrieval (IR) models is that relevance scores are solely based on exact (i.e., syntactic) matching of words in queries and documents under the simple Bag-of-Words (BoW) representation. This not only leads to the well-known vocabulary mismatch problem, but also does not allow semantically related words to contribute to the relevance score. Recent advances in word embedding have shown that semantic representations for words can be efficiently learned by distributional models. A natural generalization is then to represent both queries and documents as Bag-of-Word-Embeddings (BoWE), which provides a better foundation for semantic matching than BoW. Based on this representation, we introduce a novel retrieval model by viewing the matching between queries and documents as a non-linear word transportation (NWT) problem. With this formulation, we define the capacity and profit of a transportation model designed for the IR task. We show that this transportation problem can be efficiently solved via pruning and indexing strategies. Experimental results on several representative benchmark datasets show that our model can outperform many state-of-the-art retrieval models as well as recently introduced word embedding-based models. We also conducted extensive experiments to analyze the effect of different settings on our semantic matching model.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval Model using Uncertain Confidence's Network\n",
            "Authors: F. Naouar, L. Hlaoua, Mohamed Nazih Omri\n",
            "Year: 2017\n",
            "Venue: International Journal of Information Retrieval Research\n",
            "Abstract: This paper proposes a new relevance feedback approach to collaborative information retrieval based on a confidence's network, which performs propagation relevance between annotations terms. The main contribution of our approach is to extract relevant terms to reformulate the initial user query considering the annotations as an information source. The proposed model introduces the concept of necessity that allows determining the terms that have strong association relationships. The authors estimated the association relationship to a measure of a confidence. Another contribution consists on determining the relevant annotations for a given evidence source. Since the user is over whelmed by a variety of contradictory annotations on even one which are far from the original subject, the authors' model proceed filtering these annotations to determine the relevant one and then it classify them by grouping those related semantically. The experimental study conducted on different queries gives promoters results. They show very encouraging results that could reach an improvement rate.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analysis of the Paragraph Vector Model for Information Retrieval\n",
            "Authors: Qingyao Ai, Liu Yang, Jiafeng Guo, W. Bruce Croft\n",
            "Year: 2016\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Previous studies have shown that semantically meaningful representations of words and text can be acquired through neural embedding models. In particular, paragraph vector (PV) models have shown impressive performance in some natural language processing tasks by estimating a document (topic) level language model. Integrating the PV models with traditional language model approaches to retrieval, however, produces unstable performance and limited improvements. In this paper, we formally discuss three intrinsic problems of the original PV model that restrict its performance in retrieval tasks. We also describe modifications to the model that make it more suitable for the IR task, and show their impact through experiments and case studies. The three issues we address are (1) the unregulated training process of PV is vulnerable to short document over-fitting that produces length bias in the final retrieval model; (2) the corpus-based negative sampling of PV leads to a weighting scheme for words that overly suppresses the importance of frequent words; and (3) the lack of word-context information makes PV unable to capture word substitution relationships.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey of tag-based information retrieval\n",
            "Authors: Sanghoon Lee, M. Masoud, Janani Balaji, S. Belkasim, Rajshekhar Sunderraman, Seung-Jin Moon\n",
            "Year: 2017\n",
            "Venue: International Journal of Multimedia Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval for biomedical datasets: the 2016 bioCADDIE dataset retrieval challenge\n",
            "Authors: Kirk Roberts, Anupama E. Gururaj, Xiaoling Chen, Saeid Pournejati, W. Hersh, Dina Demner-Fushman, L. Ohno-Machado, T. Cohen, Hua Xu\n",
            "Year: 2017\n",
            "Venue: Database J. Biol. Databases Curation\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs\n",
            "Authors: O. Ovadia, Menachem Brief, Moshik Mishaeli, Oren Elisha\n",
            "Year: 2023\n",
            "Venue: arXiv.org\n",
            "Abstract: Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing them to numerous variations of the same fact during training could alleviate this problem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Privacy-Preserving Framework for Large-Scale Content-Based Information Retrieval\n",
            "Authors: Li Weng, L. Amsaleg, April Morton, S. Marchand-Maillet\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: We propose a privacy protection framework for large-scale content-based information retrieval. It offers two layers of protection. First, robust hash values are used as queries to prevent revealing original content or features. Second, the client can choose to omit certain bits in a hash value to further increase the ambiguity for the server. Due to the reduced information, it is computationally difficult for the server to know the client's interest. The server has to return the hash values of all possible candidates to the client. The client performs a search within the candidate list to find the best match. Since only hash values are exchanged between the client and the server, the privacy of both parties is protected. We introduce the concept oftunable privacy, where the privacy protection level can be adjusted according to a policy. It is realized through hash-based piecewise inverted indexing. The idea is to divide a feature vector into pieces and index each piece with a subhash value. Each subhash value is associated with an inverted index list. The framework has been extensively tested using a large image database. We have evaluated both retrieval performance and privacy-preserving performance for a particular content identification application. Two different constructions of robust hash algorithms are used. One is based on random projections; the other is based on the discrete wavelet transform. Both algorithms exhibit satisfactory performance in comparison with state-of-the-art retrieval schemes. The results show that the privacy enhancement slightly improves the retrieval performance. We consider the majority voting attack for estimating the query category and identification. Experiment results show that this attack is a threat when there are near-duplicates, but the success rate decreases with the number of omitted bits and the number of distinct items.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval\n",
            "Authors: Gianni Amati\n",
            "Year: 2018\n",
            "Venue: Encyclopedia of Database Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A generic framework for ontology-based information retrieval and image retrieval in web data\n",
            "Authors: V. Vijayarajan, M. Dinakaran, Priyam Tejaswin, Mayank Lohani\n",
            "Year: 2016\n",
            "Venue: Human-Centric Computing and Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining\n",
            "Authors: ChengXiang Zhai, Sean Massung\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Recent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic. \n",
            " \n",
            "This book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Learning for Information Retrieval\n",
            "Authors: Hang Li, Zhengdong Lu\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Recent years have observed a significant progress in information retrieval and natural language processing with deep learning technologies being successfully applied into almost all of their major tasks. The key to the success of deep learning is its capability of accurately learning distributed representations (vector representations or structured arrangement of them) of natural language expressions such as sentences, and effectively utilizing the representations in the tasks. This tutorial aims at summarizing and introducing the results of recent research on deep learning for information retrieval, in order to stimulate and foster more significant research and development work on the topic in the future. The tutorial mainly consists of three parts. In the first part, we introduce the fundamental techniques of deep learning for natural language processing and information retrieval, such as word embedding, recurrent neural networks, and convolutional neural networks. In the second part, we explain how deep learning, particularly representation learning techniques, can be utilized in fundamental NLP and IR problems, including matching, translation, classification, and structured prediction. In the third part, we describe how deep learning can be used in specific application tasks in details. The tasks are search, question answering (from either documents, database, or knowledge base), and image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Sublinear Scaling for Multi-Client Private Information Retrieval\n",
            "Authors: W. Lueks, I. Goldberg\n",
            "Year: 2015\n",
            "Venue: Financial Cryptography\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Online Learning to Rank for Information Retrieval: SIGIR 2016 Tutorial\n",
            "Authors: A. Grotov, M. D. Rijke\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: During the past 10--15 years offline learning to rank has had a tremendous influence on information retrieval, both scientifically and in practice. Recently, as the limitations of offline learning to rank for information retrieval have become apparent, there is increased attention for online learning to rank methods for information retrieval in the community. Such methods learn from user interactions rather than from a set of labeled data that is fully available for training up front. Below we describe why we believe that the time is right for an intermediate-level tutorial on online learning to rank, the objectives of the proposed tutorial, its relevance, as well as more practical details, such as format, schedule and support materials.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Who Wrote the Web? Revisiting Influential Author Identification Research Applicable to Information Retrieval\n",
            "Authors: Martin Potthast, Sarah Braun, Tolga Buz, Fabian Duffhauss, Florian Friedrich, J. Gülzow, Jakob Köhler, Winfried Lötzsch, Fabian Müller, Maike Elisa Müller, Robert Passmann, Bernhard Reinke, Lucas Rettenmeier, T. Rometsch, T. Sommer, Michael Träger, Sebastian Wilhelm, Benno Stein, E. Stamatatos, Matthias Hagen\n",
            "Year: 2016\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval as semantic inference: a Graph Inference model applied to medical search\n",
            "Authors: B. Koopman, G. Zuccon, P. Bruza, Laurianne Sitbon, Michael Lawley\n",
            "Year: 2016\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Understandability Biased Evaluation for Information Retrieval\n",
            "Authors: G. Zuccon\n",
            "Year: 2016\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private information retrieval in distributed storage systems using an arbitrary linear code\n",
            "Authors: Siddhartha Kumar, E. Rosnes, A. G. Amat\n",
            "Year: 2016\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We propose an information-theoretic private information retrieval (PIR) scheme for distributed storage systems where data is stored using a linear systematic code of rate R> 1/2. The proposed scheme generalizes the PIR scheme for data stored using maximum distance separable codes recently proposed by Tajeddine and El Rouayheb for the scenario of a single spy node. We further propose an algorithm to optimize the communication price of privacy (cPoP) using the structure of the underlying linear code. As an example, we apply the proposed algorithm to several distributed storage codes, showing that the cPoP can be significantly reduced by exploiting the structure of the distributed storage code.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Power Law Distributions in Information Retrieval\n",
            "Authors: Casper Petersen, J. Simonsen, C. Lioma\n",
            "Year: 2016\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: Several properties of information retrieval (IR) data, such as query frequency or document length, are widely considered to be approximately distributed as a power law. This common assumption aims to focus on specific characteristics of the empirical probability distribution of such data (e.g., its scale-free nature or its long/fat tail). This assumption, however, may not be always true. Motivated by recent work in the statistical treatment of power law claims, we investigate two research questions: (i) To what extent do power law approximations hold for term frequency, document length, query frequency, query length, citation frequency, and syntactic unigram frequency? And (ii) what is the computational cost of replacing ad hoc power law approximations with more accurate distribution fitting? We study 23 TREC and 5 non-TREC datasets and compare the fit of power laws to 15 other standard probability distributions. We find that query frequency and 5 out of 24 term frequency distributions are best approximated by a power law. All remaining properties are better approximated by the Inverse Gaussian, Generalized Extreme Value, Negative Binomial, or Yule distribution. We also find the overhead of replacing power law approximations by more informed distribution fitting to be negligible, with potential gains to IR tasks like index compression or test collection generation for IR evaluation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Entropy Optimized Feature-Based Bag-of-Words Representation for Information Retrieval\n",
            "Authors: N. Passalis, A. Tefas\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Knowledge and Data Engineering\n",
            "Abstract: In this paper, we present a supervised dictionary learning method for optimizing the feature-based Bag-of-Words (BoW) representation towards Information Retrieval. Following the cluster hypothesis, which states that points in the same cluster are likely to fulfill the same information need, we propose the use of an entropy-based optimization criterion that is better suited for retrieval instead of classification. We demonstrate the ability of the proposed method, abbreviated as EO-BoW, to improve the retrieval performance by providing extensive experiments on two multi-class image datasets. The BoW model can be applied to other domains as well, so we also evaluate our approach using a collection of 45 time-series datasets, a text dataset, and a video dataset. The gains are three-fold since the EO-BoW can improve the mean Average Precision, while reducing the encoding time and the database storage requirements. Finally, we provide evidence that the EO-BoW maintains its representation ability even when used to retrieve objects from classes that were not seen during the training.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural Information Retrieval: A Literature Review\n",
            "Authors: Ye Zhang, Md. Mustafizur Rahman, Alexander Braylan, B. Dang, Heng-Lu Chang, Henna Kim, Quinten McNamara, Aaron Angert, Edward Banner, Vivek Khetan, Tyler McDonnell, A. T. Nguyen, Dan Xu, Byron C. Wallace, Matthew Lease\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: A recent \"third wave\" of Neural Network (NN) approaches now delivers state-of-the-art performance in many machine learning tasks, spanning speech recognition, computer vision, and natural language processing. Because these modern NNs often comprise multiple interconnected layers, this new NN research is often referred to as deep learning. Stemming from this tide of NN work, a number of researchers have recently begun to investigate NN approaches to Information Retrieval (IR). While deep NNs have yet to achieve the same level of success in IR as seen in other areas, the recent surge of interest and work in NNs for IR suggest that this state of affairs may be quickly changing. In this work, we survey the current landscape of Neural IR research, paying special attention to the use of learned representations of queries and documents (i.e., neural embeddings). We highlight the successes of neural IR thus far, catalog obstacles to its wider adoption, and suggest potentially promising directions for future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval with Verbose Queries\n",
            "Authors: Manish Gupta, Michael Bendersky\n",
            "Year: 2015\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Recently, the focus of many novel search applications shifted from short keyword queries to verbose natural language queries. Examples include question answering systems and dialogue systems, voice search on mobile devices and entity search engines like Facebook's Graph Search or Google's Knowledge Graph. However the performance of textbook information retrieval techniques for such verbose queries is not as good as that for their shorter counterparts. Thus, effective handling of verbose queries has become a critical factor for adoption of information retrieval techniques in this new breed of search applications. Over the past decade, the information retrieval community has deeply explored the problem of transforming natural language verbose queries using operations like reduction, weighting, expansion, reformulation and segmentation into more effective structural representations. However, thus far, there was not a coherent and organized tutorial on this topic. In this tutorial, we aim to put together various research pieces of the puzzle, provide a comprehensive and structured overview of various proposed methods, and also list various application scenarios where effective verbose query processing can make a significant difference.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Query auto completion in information retrieval\n",
            "Authors: Fei Cai\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Query auto completion is an important feature embedded into today's search engines. It can help users formulate queries which other people have searched for when he/she finishes typing the query prefix. Today's most sophisticated query auto completion approaches are based on the collected query logs to provide the best possible queries for each searcher's input. In this thesis, we develop new query auto completion methods for information retrieval. First, we consider the information of both time and user to propose a time-sensitive personalized query auto completion approach. In previous work, these two sources of information have been developed separately. We bring them together and pay special attention to long-tail prefixes. Second, based on a learning-to-rank framework, we propose to extract features originating from so-called homologous queries and from the semantic similarity of terms, which allow the contributions from similar queries and from semantic relatedness to be used for query auto completion. In addition, we study the problem of query auto completion diversification, where we aim to diversify aspect-level query intents of query completions. This task has not been studied before. Given that only a limited number of query completions can be returned to users of a search engine, it is important to remove redundant queries and improve user satisfaction by finding an acceptable query. Finally, we conduct an investigation on when to personalize query auto completion by proposing a selectively personalizing query auto completion approach, where the weight of personalization in a query auto completion model is selectively assigned based on the search context in session. The experimental results in this thesis indicate that our proposed query auto completion approaches can improve the ranking performance of query completions in terms of well-known metrics, like Mean Reciprocal Rank. The unique insights and interesting findings in this thesis may be used to help search engine designers to improve the satisfaction of search engine user by providing high quality query completions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private information retrieval from MDS coded data in distributed storage systems\n",
            "Authors: Razane Tajeddine, S. E. Rouayheb\n",
            "Year: 2016\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We consider the problem of providing privacy, in the private information retrieval (PIR) sense, to users requesting data from a distributed storage system (DSS). The DSS uses an (n, k) Maximum Distance Separable (MDS) code to store the data reliably on unreliable storage nodes. Some of these nodes can be spies which report to a third party, such as an oppressive regime, which data is being requested by the user. An information theoretic PIR scheme ensures that a user can satisfy its request while revealing, to the spy nodes, no information on which data is being requested. A user can achieve PIR by downloading all the data in the DSS. However, this is not a feasible solution due to its high communication cost. We construct PIR schemes with low download communication cost. When there is b = 1 spy node in the DSS, we construct PIR schemes with download cost 1/1-R per unit of requested data (R = k/n is the code rate), achieving the information theoretic limit for linear schemes. The proposed schemes are universal since they depend on the code rate, but not on the generator matrix of the code. When there are 2 ≤ b ≤ n - k spy nodes, we devise linear PIR schemes that have download cost equal to b + k per unit of requested data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of the Mixed Script Information Retrieval (MSIR) at FIRE-2016\n",
            "Authors: Somnath Banerjee, Kunal Chakma, S. Naskar, Amitava Das, Paolo Rosso, Sivaji Bandyopadhyay, M. Choudhury\n",
            "Year: 2016\n",
            "Venue: Fire\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Medical information retrieval: introduction to the special issue\n",
            "Authors: Lorraine Goeuriot, G. Jones, Liadh Kelly, H. Müller, J. Zobel\n",
            "Year: 2016\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Blind interference alignment for private information retrieval\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: Blind interference alignment (BIA) refers to interference alignment schemes that are designed only based on channel coherence pattern knowledge at the transmitters (the “blind” transmitters do not know the exact channel values). Private information retrieval (PIR) refers to the problem where a user retrieves one out of K messages from N non-communicating databases (each holds all K messages) without revealing anything about the identity of the desired message index to any individual database. In this paper, we identify an intriguing connection between PIR and BIA. Inspired by this connection, we characterize the information theoretic optimal download cost of PIR, when we have K = 2 messages and the number of databases, N, is arbitrary.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey of Stemming Algorithms for Information Retrieval\n",
            "Authors: Brajendra Singh Rajput, Dr. Nilay Khare\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: : Now a day’s text documents is advancing over internet, e-mails and web pages. As the use of internet is exponentially growing, the need of massive data storage is increasing. Normally many of the documents contain morphological variables, so stemming which is a preprocessing technique gives a mapping of different morphological variants of words into their base word called the stem. Stemming process is used in information retrieval as a way to improve retrieval performance based on the assumption that terms with the same stem usually have similar meaning. To do stemming operation on large data, we require normally more computation time and power, to cope up with the need to search for a particular word in the data. In this paper, various stemming algorithms are analyzed with the benefits and limitation of the recent stemming technique.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On Private Information Retrieval Array Codes\n",
            "Authors: Yiwei Zhang, Xin Wang, Hengjia Wei, G. Ge\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: Given a database, the private information retrieval (PIR) protocol allows a user to make queries to several servers and retrieve a certain item of the database via the feedbacks without revealing the identity of the specific item to any single server. Classic <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-server PIR protocols work on replicated databases, i.e., each of the <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula> servers stores a whole copy of the database. Recently, new PIR models were proposed with coding techniques arising from the distributed storage system. In these new models, each server only stores a fraction <inline-formula> <tex-math notation=\"LaTeX\">$1/s$ </tex-math></inline-formula> of the whole database, where <inline-formula> <tex-math notation=\"LaTeX\">$s>1$ </tex-math></inline-formula> is the given rational number. The PIR array codes are recently proposed by Fazeli, Vardy, and Yaakobi to characterize the new models. The central problem in designing a PIR array code with <inline-formula> <tex-math notation=\"LaTeX\">$m$ </tex-math></inline-formula> servers and the <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-PIR property (which indicates that these <inline-formula> <tex-math notation=\"LaTeX\">$m$ </tex-math></inline-formula> servers may emulate a classic <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-server PIR protocol) is to maximize <inline-formula> <tex-math notation=\"LaTeX\">$k/m$ </tex-math></inline-formula>, known as the virtual server rate. Our main contribution to this problem is twofold. First, for the case <inline-formula> <tex-math notation=\"LaTeX\">$1 < s\\le 2$ </tex-math></inline-formula>, although the PIR array codes with optimal rate have been constructed recently by Blackburn and Etzion, the number of servers in their construction is rather large. We determine the minimum number of servers admitting the existence of a PIR array code with an optimal rate for a certain range of parameters. Second, for the case <inline-formula> <tex-math notation=\"LaTeX\">$s>2$ </tex-math></inline-formula>, a new upper bound on the rate of a PIR array code is presented. Besides, we also have some discussions on an asymptotically optimal construction by Blackburn and Etzion.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neu-IR: The SIGIR 2016 Workshop on Neural Information Retrieval\n",
            "Authors: \n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In recent years, deep neural networks have yielded significant performance improvements on speech recognition and computer vision tasks, as well as led to exciting breakthroughs in novel application areas such as automatic voice translation, image captioning, and conversational agents. Despite demonstrating good performance on natural language processing (NLP) tasks (e.g., language modelling and machine translation, the performance of deep neural networks on information retrieval (IR) tasks has had relatively less scrutiny. Recent work in this area has mainly focused on word embeddings and neural models for short text similarity. The lack of many positive results in this area of information retrieval is partially due to the fact that IR tasks such as ranking are fundamentally different from NLP tasks, but also because the IR and neural network communities are only beginning to focus on the application of these techniques to core information retrieval problems. Given that deep learning has made such a big impact, first on speech processing and computer vision and now, increasingly, also on computational linguistics, it seems clear that deep learning will have a major impact on information retrieval and that this is an ideal time for a workshop in this area. Neu-IR (pronounced \"new IR\") will be a forum for new research relating to deep learning and other neural network based approaches to IR. The purpose is to provide an opportunity for people to present new work and early results, compare notes on neural network toolkits, share best practices, and discuss the main challenges facing this line of research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Introduction to Information Retrieval and Quantum Mechanics\n",
            "Authors: M. Melucci\n",
            "Year: 2015\n",
            "Venue: The Information Retrieval Series\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semi-Supervised Information Retrieval System for Clinical Decision Support\n",
            "Authors: H. Gurulingappa, L. Toldo, Claudia Schepers, Alexander Bauer, Gerard Megaro\n",
            "Year: 2016\n",
            "Venue: Text Retrieval Conference\n",
            "Abstract: This article summarizes the approach developed for TREC 2016 Clinical Decision Support Track. In order to address the daunting challenge of retrieval of biomedical articles for answering clinical questions, an information retrieval methodology was developed that combines pseudo-relevance feedback, semantic query expansion and document similarity measures based on unsupervised word embeddings. The individual relevance metrics were combined through a supervised learning-to-rank model based on gradient boosting to maximize the normalized discounted cumulative gain (nDCG). Experimental results show that document distance measures derived from unsupervised word embeddings contribute to significant ranking improvements when combined with traditional document retrieval approaches\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantification of Identifiers in Mathematics for Better Math Information Retrieval\n",
            "Authors: M. Schubotz, A. Grigorev, M. Leich, H. Cohl, Norman Meuschke, Bela Gipp, Abdou Youssef, V. Markl\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Mathematical formulae are essential in science, but face challenges of ambiguity, due to the use of a small number of identifiers to represent an immense number of concepts. Corresponding to word sense disambiguation in Natural Language Processing, we disambiguate mathematical identifiers. By regarding formulae and natural text as one monolithic information source, we are able to extract the semantics of identifiers in a process we term Mathematical Language Processing (MLP). As scientific communities tend to establish standard (identifier) notations, we use the document domain to infer the actual meaning of an identifier. Therefore, we adapt the software development concept of namespaces to mathematical notation. Thus, we learn namespace definitions by clustering the MLP results and mapping those clusters to subject classification schemata. In addition, this gives fundamental insights into the usage of mathematical notations in science, technology, engineering and mathematics. Our gold standard based evaluation shows that MLP extracts relevant identifier-definitions. Moreover, we discover that identifier namespaces improve the performance of automated identifier-definition extraction, and elevate it to a level that cannot be achieved within the document context alone.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Toward Word Embedding for Personalized Information Retrieval\n",
            "Authors: Nawal Ould Amer, P. Mulhem, M. Géry\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This paper presents preliminary works on using Word Embedding (word2vec) for query expansion in the context of Personalized Information Retrieval. Traditionally, word embeddings are learned on a general corpus, like Wikipedia. In this work we try to personalize the word embeddings learning, by achieving the learning on the user's profile. The word embeddings are then in the same context than the user interests. Our proposal is evaluated on the CLEF Social Book Search 2016 collection. The results obtained show that some efforts should be made in the way to apply Word Embedding in the context of Personalized Information Retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Comparison of Approaches to Timbre Descriptors in Music Information Retrieval and Music Psychology\n",
            "Authors: Kai Siedenburg, Ichiro Fujinaga, S. McAdams\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: A curious divide characterizes the usage of audio descriptors for timbre research in music information research (MIR) and music psychology. While MIR uses a multitude of audio descriptors for tasks such as automatic instrument classification, only a highly constrained set is used to describe the physical correlates of timbre perception in parts of music psychology. We argue that this gap is not coincidental and results from the differences in the two fields’ methodologies, their epistemic groundwork, and research goals. This paper lays out perspectives on the emergence of the divide and reviews studies in both fields with regards to divergences in research methods and goals. We discuss new representations for spectro-temporal modulations in MIR and psychology, and compare approaches to spectral envelope description in depth. Finally, we will propose that the interdisciplinary discourse on the computational modelling of music requires negotiations about the roles of scientific evaluation criteria.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction\n",
            "Authors: Keshav Santhanam, O. Khattab, Jon Saad-Falcon, Christopher Potts, M. Zaharia\n",
            "Year: 2021\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce Maize, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate Maize across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 6–10x.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction\n",
            "Authors: Keshav Santhanam, O. Khattab, Jon Saad-Falcon, Christopher Potts, M. Zaharia\n",
            "Year: 2021\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce Maize, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate Maize across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 6–10x.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Arabic Cross-Language Information Retrieval\n",
            "Authors: Bilel Elayeb, Ibrahim Bounhas\n",
            "Year: 2016\n",
            "Venue: ACM Trans. Asian Low Resour. Lang. Inf. Process.\n",
            "Abstract: Cross-language information retrieval (CLIR) deals with retrieving relevant documents in one language using queries expressed in another language. As CLIR tools rely on translation techniques, they are challenged by the properties of highly derivational and flexional languages like Arabic. Much work has been done on CLIR for different languages including Arabic. In this article, we introduce the reader to the motivations for solving some problems related to Arabic CLIR approaches. The evaluation of these approaches is discussed starting from the 2001 and 2002 TREC Arabic CLIR tracks, which aim to objectively evaluate CLIR systems. We also study many other research works to highlight the unresolved problems or those that require further investigation. These works are discussed in the light of a deep study of the specificities and the tasks of Arabic information retrieval (IR). Particular attention is given to translation techniques and CLIR resources, which are key issues challenging Arabic CLIR. To push research in this field, we discuss how a new standard collection can improve Arabic IR and CLIR tracks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LIRE: open source visual information retrieval\n",
            "Authors: M. Lux, M. Riegler, P. Halvorsen, Konstantin Pogorelov, N. Anagnostopoulos\n",
            "Year: 2016\n",
            "Venue: ACM SIGMM Conference on Multimedia Systems\n",
            "Abstract: With an annual growth rate of 16.2% of taken photos a year, researchers predict an almost unbelievable number of 4.9 trillion stored images in 2017. Nearly 80% of these photos in 2017 will be taken with mobile phones. To be able to cope with this immense amount of visual data in a fast and accurate way, a visual information retrieval systems are needed for various domains and applications. LIRE, short for Lucene Image Retrieval, is a light weight and easy to use Java library for visual information retrieval. It allows developers and researchers to integrate common content based image retrieval approaches in their applications and research projects. LIRE supports global and local image features and can cope with millions of images using approximate search and distributing indexes on the cloud. In this demo we present a novel tool called F-search that emphasize the core strengths of LIRE: lightness, speed and accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Efficient Private Information Retrieval Over Unsynchronized Databases\n",
            "Authors: G. Fanti, K. Ramchandran\n",
            "Year: 2015\n",
            "Venue: IEEE Journal on Selected Topics in Signal Processing\n",
            "Abstract: Web search histories can reveal detailed and sensitive information about people. Private information retrieval (PIR) tackles this potential privacy violation by allowing users to retrieve the wth record of a database without revealing w to the server. However, most known PIR schemes are either very inefficient (and therefore unlikely to gain traction in a practical sense) or reliant on some restrictive assumptions. In this paper, we consider an efficient class of schemes called multi-server PIR. Multi-server PIR assumes that the client communicates with multiple, non-colluding servers, each possessing an identical copy of the database. Significant prior work has gone towards relaxing the anti-collusion assumption, but the literature does not address the assumption that servers store perfectly-synchronized databases. This seems implausible, especially if servers are not meant to collude. We propose the first multi-server PIR scheme to return the desired record even when servers' databases are not perfectly synchronized. Our scheme asymptotically has the same computational and communication complexity as state-of-the-art PIR schemes for synchronized databases; this comes at the expense of probabilistic success and two rounds of communication (most existing schemes require only one). Additionally, this approach efficiently processes multiple concurrent PIR queries.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dynamic Information Retrieval Modeling\n",
            "Authors: G. Yang, Marc Sloan, Jun Wang\n",
            "Year: 2015\n",
            "Venue: Synthesis Lectures on Information Concepts Retrieval and Services\n",
            "Abstract: In Dynamic Information Retrieval modeling we model dynamic systems which change or adapt over time or a sequence of events using a range of techniques from artificial intelligence and reinforcement learning. Many of the open problems in current IR research can be described as dynamic systems, for instance, session search or computational advertising. State of the art research provides solutions to these problems that are responsive to a changing environment, learn from past interactions and predict future utility. Advances in IR interface, personalization and ad display demand models that can react to users in real time and in an intelligent, contextual way. The objective of this half-day tutorial is to provide a comprehensive and up-to-date introduction to Dynamic Information Retrieval Modeling. We motivate a conceptual model linking static, interactive and dynamic retrieval and use this to define dynamics within the context of IR. We then cover a number of algorithms and techniques from the artificial intelligence (AI) and online learning literature such as Markov Decision Processes (MDP), their partially observable variation (POMDP) and multi-armed bandits. Following this we describe how to identify dynamics in an IR problem and demonstrate how to model them using the described techniques. The remainder of the tutorial will then cover an array of state-of-the-art research on dynamic systems in IR and how they can be modeled using using dynamic IR. We use research on session search, multi-page search and online advertising as in-depth examples of such work. This tutorial is of relevance to IR practitioners and researchers, where we will present the merits of dynamic information retrieval modeling and introduce the relevant techniques. The content will be of particular interest to researchers working in the areas of statistical modeling, personalization and recommendation, and is also relevant to practitioners in Web search, online advertising and anyone who works with big data. After this tutorial, attendees will: Be able to identify the dynamics in an IR system; Be able to model these dynamics using techniques from AI and reinforcement learning; Have knowledge of the state-of-the-art research in dynamic information retrieval modeling.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Using knowledge-based relatedness for information retrieval\n",
            "Authors: Arantxa Otegi, Xabier Arregi, Olatz Ansa, Eneko Agirre\n",
            "Year: 2015\n",
            "Venue: Knowledge and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Optimal Rate Private Information Retrieval from Homomorphic Encryption\n",
            "Authors: A. Kiayias, Nikos Leonardos, H. Lipmaa, K. Pavlyk, Qiang Tang\n",
            "Year: 2015\n",
            "Venue: Proceedings on Privacy Enhancing Technologies\n",
            "Abstract: Abstract We consider the problem of minimizing the communication in single-database private information retrieval protocols in the case where the length of the data to be transmitted is large. We present first rate-optimal protocols for 1-out-of-n computationallyprivate information retrieval (CPIR), oblivious transfer (OT), and strong conditional oblivious transfer (SCOT). These protocols are based on a new optimalrate leveled homomorphic encryption scheme for large-output polynomial-size branching programs, that might be of independent interest. The analysis of the new scheme is intricate: the optimal rate is achieved if a certain parameter s is set equal to the only positive root of a degree-(m + 1) polynomial, where m is the length of the branching program. We show, by using Galois theory, that even when m = 4, this polynomial cannot be solved in radicals. We employ the Newton-Puiseux algorithm to find a Puiseux series for s, and based on this, propose a Θ (logm)-time algorithm to find an integer approximation to s.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Social networks and information retrieval, how are they converging? A survey, a taxonomy and an analysis of social information retrieval approaches and platforms\n",
            "Authors: Mohamed Reda Bouadjenek, Hakim Hacid, M. Bouzeghoub\n",
            "Year: 2016\n",
            "Venue: Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Credibility in Information Retrieval\n",
            "Authors: \n",
            "Year: 2015\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Credibility, as the general concept covering trustworthiness and expertise, but also quality and reliability, is strongly debated in philosophy, psychology, and sociology, and its adoption in computer science is therefore fraught with difficulties. Yet its importance has grown in the information access community because of two complementing factors: on one hand, it is relatively difficult to precisely point to the source of a piece of information, and on the other hand, complex algorithms, statistical machine learning, artificial intelligence, make decisions on behalf of the users, with little oversight from the users themselves.This survey presents a detailed analysis of existing credibility models from different information seeking research areas, with focus on the Web and its pervasive social component. It shows that there is a very rich body of work pertaining to different aspects and interpretations of credibility, particularly for different types of textual content e.g., Web sites, blogs, tweets, but also to other modalities videos, images, audio and topics e.g., health care. After an introduction placing credibility in the context of other sciences and relating it to trust, we argue for a quartic decomposition of credibility: expertise and trustworthiness, well documented in the literature and predominantly related to information source, and quality and reliability, raised to the status of equal partners because the source is often impossible to detect, and predominantly related to the content.The second half of the survey provides the reader with access points to the literature, grouped by research interests. Section 3 reviews general research directions: the factors that contribute to credibility assessment in human consumers of information; the models used to combine these factors; the methods to predict credibility. A smaller section is dedicated to informing users about the credibility learned from the data. Sections 4, 5, and 6 go further into details, with domain-specific credibility, social media credibility, and multimedia credibility, respectively. While each of them is best understood in the context of Sections 1 and 2, they can be read independently of each other.The last section of this survey addresses a topic not commonly considered under \"credibility\": the credibility of the system itself, independent of the data creators. This is a topic of particular importance in domains where the user is professionally motivated and where there are no concerns about the credibility of the data e.g. e-discovery and patent search. While there is little explicit work in this direction, we argue that this is an open research direction that is worthy of future exploration.Finally, as an additional help to the reader, an appendix lists the existing test collections that cater specifically to some aspect of credibility.Overall, this review will provide the reader with an organised and comprehensive reference guide to the state of the art and the problems at hand, rather than a final answer to the question of what credibility is for computer science. Even within the relatively limited scope of an exact science, such an answer is not possible for a concept that is itself widely debated in philosophy and social sciences.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval for ecological syntheses\n",
            "Authors: Helen R. Bayliss, F. Beyer\n",
            "Year: 2015\n",
            "Venue: Research Synthesis Methods\n",
            "Abstract: Research syntheses are increasingly being conducted within the fields of ecology and environmental management. Information retrieval is crucial in any synthesis in identifying data for inclusion whilst potentially reducing biases in the dataset gathered, yet the nature of ecological information provides several challenges when compared with medicine that should be considered when planning and undertaking searches. We present ten recommendations for anyone considering undertaking information retrieval for ecological research syntheses that highlight the main differences with medicine and, if adopted, may help reduce biases in the dataset retrieved, increase search efficiency and improve reporting standards. They are as follows: (1) plan for information retrieval at an early stage, (2) identify and use sources of help, (3) clearly define the question to be addressed, (4) ensure that provisions for managing, recording and reporting the search are in place, (5) select an appropriate search type, (6) identify sources to be used, (7) identify limitations of the sources, (8) ensure that the search vocabulary is appropriate, (9) identify limits and filters that can help direct the search, and (10) test the strategy to ensure that it is realistic and manageable. These recommendations may be of value for other disciplines where search infrastructures are not yet sufficiently well developed. Copyright © 2014 John Wiley & Sons, Ltd.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Music Imagery Information Retrieval: Introducing the OpenMIIR Dataset of EEG Recordings from Music Perception and Imagination\n",
            "Authors: Sebastian Stober, Avital Sternin, A. Owen, Jessica A. Grahn\n",
            "Year: 2015\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Music imagery information retrieval (MIIR) systems may one day be able to recognize a song from only our thoughts. As a step towards such technology, we are presenting a public domain dataset of electroencephalography (EEG) recordings taken during music perception and imagination. We acquired this data during an ongoing study that so far comprises 10 subjects listening to and imagining 12 short music fragments – each 7–16s long – taken from well-known pieces. These stimuli were selected from different genres and systematically vary along musical dimensions such as meter, tempo and the presence of lyrics. This way, various retrieval scenarios can be addressed and the success of classifying based on specific dimensions can be tested. The dataset is aimed to enable music information retrieval researchers interested in these new MIIR challenges to easily test and adapt their existing approaches for music analysis like fingerprinting, beat tracking, or tempo estimation on EEG data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The capacity of private information retrieval with colluding databases\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2016\n",
            "Venue: IEEE Global Conference on Signal and Information Processing\n",
            "Abstract: Private information retrieval (PIR) is the problem of retrieving as efficiently as possible, one out of K messages from N non-communicating replicated databases (each holds all K messages) while keeping the identity of the desired message index a secret from each individual database. T-private PIR is a generalization of PIR to include the requirement that even if any T of the N databases collude, the identity of the retrieved message remains completely unknown to them. The information theoretic capacity of T-private PIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. We show that the capacity of T-private PIR is (1 + T/N + T<sup>2</sup>/N<sup>2</sup> + … + T<sup>K-1</sup>/N<sup>K-1</sup>)<sup>−1</sup>.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Lower-Cost epsilon-Private Information Retrieval\n",
            "Authors: Raphael R. Toledo, G. Danezis, I. Goldberg\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: Private Information Retrieval (PIR), despite being well studied, is computationally costly and arduous to scale. We explore lower-cost relaxations of information-theoretic PIR, based on dummy queries, sparse vectors, and compositions with an anonymity system. We prove the security of each scheme using a flexible differentially private definition for private queries that can capture notions of imperfect privacy. We show that basic schemes are weak, but some of them can be made arbitrarily safe by composing them with large anonymity systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval as Card Playing: A Formal Model for Optimizing Interactive Retrieval Interface\n",
            "Authors: Yinan Zhang, ChengXiang Zhai\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We propose a novel formal model for optimizing interactive information retrieval interfaces. To model interactive retrieval in a general way, we frame the task of an interactive retrieval system as to choose a sequence of interface cards to present to the user. At each interaction lap, the system's goal is to choose an interface card that can maximize the expected gain of relevant information for the user while minimizing the effort of the user with consideration of the user's action model and any desired constraints on the interface card. We show that such a formal interface card model can not only cover the Probability Ranking Principle for Interactive Information Retrieval as a special case by making multiple simplification assumptions, but also be used to derive a novel formal interface model for adaptively optimizing navigational interfaces in a retrieval system. Experimental results show that the proposed model is effective in automatically generating adaptive navigational interfaces, which outperform the baseline pre-designed static interfaces.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Knowledge Extraction for Information Retrieval\n",
            "Authors: F. Corcoglioniti, M. Dragoni, M. Rospocher, Alessio Palmero Aprosio\n",
            "Year: 2016\n",
            "Venue: Extended Semantic Web Conference\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: IRAFCA: an O(n) information retrieval algorithm based on formal concept analysis\n",
            "Authors: Fethi Fkih, Mohamed Nazih Omri\n",
            "Year: 2016\n",
            "Venue: Knowledge and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: On Obtaining Effort Based Judgements for Information Retrieval\n",
            "Authors: Manisha Verma, Emine Yilmaz, Nick Craswell\n",
            "Year: 2016\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: Document relevance has been the primary focus in the design, optimization and evaluation of retrieval systems. Traditional testcollections are constructed by asking judges the relevance grade for a document with respect to an input query. Recent work of Yilmaz et al. found an evidence that effort is another important factor in determining document utility, suggesting that more thought should be given into incorporating effort into information retrieval. However, that work did not ask judges to directly assess the level of effort required to consume a document or analyse how effort judgements relate to traditional relevance judgements. In this work, focusing on three aspects associated with effort, we show that it is possible to get judgements of effort from the assessors. We further show that given documents of the same relevance grade, effort needed to find the portion of the document relevant to the query is a significant factor in determining user satisfaction as well as user preference between these documents. Our results suggest that if the end goal is to build retrieval systems that optimize user satisfaction, effort should be included as an additional factor to relevance in building and evaluating retrieval systems. We further show that new retrieval features are needed if the goal is to build retrieval systems that jointly optimize relevance and effort and propose a set of such features. Finally, we focus on the evaluation of retrieval systems and show that incorporating effort into retrieval evaluation could lead to significant differences regarding the performance of retrieval systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Simple Enhancement for Ad-hoc Information Retrieval via Topic Modelling\n",
            "Authors: Fanghong Jian, Xiangji Huang, Jiashu Zhao, Tingting He, P. Hu\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Traditional information retrieval (IR) models, in which a document is normally represented as a bag of words and their frequencies, capture the term-level and document-level information. Topic models, on the other hand, discover semantic topic-based information among words. In this paper, we consider term-based information and semantic information as two features of query terms and propose a simple enhancement for ad-hoc IR via topic modeling. In particular, three topic-based hybrid models, LDA-BM25, LDA-MATF and LDA-LM, are proposed. A series of experiments on eight standard datasets show that our proposed models can always outperform significantly the corresponding strong baselines over all datasets in terms of MAP and most of datasets in terms of P@5 and P@20. A direct comparison on eight standard datasets also indicates our proposed models are at least comparable to the state-of-the-art approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Automatic Text Classification in Information retrieval: A Survey\n",
            "Authors: S. Dwivedi, Chandrakala Arya\n",
            "Year: 2016\n",
            "Venue: Italian Conference on Theoretical Computer Science\n",
            "Abstract: Improvement in information retrieval performance relates to the accessibility, selection and management of large amounts of information on web that usually expressed as textual data and supervised machine learning approach is an important source of tool for automating information retrieval task. This paper provides a review of supervised machine learning approaches of text classification for information retrieval and present a comparative study of supervised machine learning algorithms namely Naïve Bayes (NB), Support vector machine (SVM), K- nearest neighbor (KNN) and decision tree (DT). We used WEKA (Weikato Environment for Knowledge Analysis) tool to evaluate these four algorithms through a series of experiments. In WEKA Sequential Minimum Optimization (SMO) represents Support vector machine (SVM) classifier, IBK represents K- nearest neighbour and J48 version of Decision Tree is used. The result concludes that the performance of the algorithms depends on the characteristics of the datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval in web crawling: A survey\n",
            "Authors: C. Saini, V. Arora\n",
            "Year: 2016\n",
            "Venue: International Conference on Advances in Computing, Communications and Informatics\n",
            "Abstract: In today's scenario, World Wide Web (WWW) is flooded with huge amount of information. Due to growing popularity of the internet, finding the meaningful information among billions of information resources on the WWW is a challenging task. The information retrieval (IR) provides documents to the end users which satisfy their need of information. Search engine is used to extract valuable information from the internet. Web crawler is the principal part of search engine; it is an automatic script or program which can browse the WWW in automatic manner. This process is known as web crawling. In this paper, review on strategies of information retrieval in web crawling has been presented that are classifying into four categories viz: focused, distributed, incremental and hidden web crawlers. Finally, on the basis of user customized parameters the comparative analysis of various IR strategies has been performed.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CMIR: A Corpus for Evaluation of Code Mixed Information Retrieval of Hindi-English Tweets\n",
            "Authors: Kunal Chakma, Amitava Das\n",
            "Year: 2016\n",
            "Venue: Journal of Computacion y Sistemas\n",
            "Abstract: Social media has become almost ubiquitous in present times. Such proliferation leads to automatic information processing need and has various challenges. The nature of social media content is mostly informal. Additionally while talking about Indian social media, users often prefer to use Roman transliterations of their native languages and English embedding. Therefore Information retrieval (IR) on such Indian social media data is a challenging and difficult task when the documents and the queries are a mixture of two or more languages written in either the native scripts and/or in the Roman transliterated form. Here in this paper we have emphasized issues related with Information Retrieval (IR) for Code-Mixed Indian social media texts, particularly texts from twitter. We describe a corpus collection process, reported limitations of available state-of-the-art IR systems on such data and formalize the problem of Code-Mixed Information Retrieval on informal texts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluation of information retrieval: precision and recall\n",
            "Authors: Monika Arora, U. Kanjilal, Dinesh Varshney\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: The information retrieval system evaluation revolves around the notion of relevant and non-relevant documents. The performance indicator such as precision and recall are used to determine how far the system satisfies the user requirements. The effectiveness of information retrieval systems is essentially measured by comparing performance, functionality and systematic approach on a common set of queries and documents. The significance tests are used to evaluate functional, performance (precession and recall), collection and interface evaluation. We must focus on the user satisfaction, which is the key parameter of performance evaluation. It identifies the collection of relevant documents under the retrieved set of collection in specific time interval. The recall and precision technique are used to evaluate the efficacy of information retrieval systems. The response time and the relevancy of the results are the significant factors in user satisfaction. The comparison of search engine Yahoo and Google based on precision and recall technique.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pooling-based continuous evaluation of information retrieval systems\n",
            "Authors: Alberto Tonon, Gianluca Demartini, P. Cudré-Mauroux\n",
            "Year: 2015\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond Relevance: Adapting Exploration/Exploitation in Information Retrieval\n",
            "Authors: Kumaripaba Athukorala, A. Medlar, Antti Oulasvirta, Giulio Jacucci, D. Głowacka\n",
            "Year: 2016\n",
            "Venue: International Conference on Intelligent User Interfaces\n",
            "Abstract: We present a novel adaptation technique for search engines to better support information-seeking activities that include both lookup and exploratory tasks. Building on previous findings, we describe (1) a classifier that recognizes task type (lookup vs. exploratory) as a user is searching and (2) a reinforcement learning based search engine that adapts accordingly the balance of exploration/exploitation in ranking the documents. This allows supporting both task types surreptitiously without changing the familiar list-based interface. Search results include more diverse results when users are exploring and more precise results for lookup tasks. Users found more useful results in exploratory tasks when compared to a base-line system, which is specifically tuned for lookup tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of FIRE-2015 Shared Task on Mixed Script Information Retrieval\n",
            "Authors: R. Sequiera, M. Choudhury, Parth Gupta, Paolo Rosso, Shubham Kumar, Somnath Banerjee, S. Naskar, Sivaji Bandyopadhyay, Gokul Chittaranjan, Amitava Das, Kunal Chakma\n",
            "Year: 2015\n",
            "Venue: Fire\n",
            "Abstract: The Transliterated Search track has been organized for the third year in FIRE-2015. The track had three subtasks. Subtask I was on language labeling of words in code-mixed text fragments; it was conducted for 8 Indian languages: Bangla, Gujarati, Hindi, Kannada, Malayalam, Marathi, Tamil, Telugu, mixed with English. Subtask II was on ad-hoc retrieval of Hindi film lyrics, movie reviews and astrology documents, where both the queries and documents were either in Hindi written in Devanagari or in Roman transliterated form. Subtask III was on transliterated question answering where the documents as well as questions were in Bangla script or Roman transliterated Bangla. A total of 24 runs were submitted by 10 teams, of which 14 runs were for subtask I and 10 runs for subtask II. There were no participation for Subtask III. The overview presents a comprehensive report of the subtasks, datasets, runs submitted and performances.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Project-based as-needed information retrieval from unstructured AEC documents\n",
            "Authors: H. Fan, Fan Xue, Heng Li\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: AbstractWith the increasing complexity of architecture, engineering, and construction (AEC) projects and fast track execution of project works, written documents are becoming more and more important for project coordination, communication, and works control. Finding all the relevant information from unstructured construction documents is critical to various management tasks such as work planning, progress control, and claims. A framework is proposed in this research to retrieve project-wide as-needed information from AEC documents. Through this framework, improvement in the levels of precision and recall in the information retrieval process can be made effective through the use of a project-specific term dictionary and dependency grammar parsing information of textual documents. Their effectiveness is demonstrated through a series of experimental tests conducted on a real life building redevelopment project with different information retrieval and ranking strategies. The results and findings are presented...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval Framework for Hazard Identification in Construction\n",
            "Authors: Hyunsoo Kim, Hyun-soo Lee, Moonseo Park, Booyoung Chung, Sungjoo Hwang\n",
            "Year: 2015\n",
            "Venue: Journal of computing in civil engineering\n",
            "Abstract: AbstractThe repetitive occurrence of similar accidents in construction is one of the most prevalent characteristics of construction accidents. Similar accident cases provide direct information for determining the risks of scheduled activities and for planning safety countermeasures. Moreover, understanding these cases gives laborers the chance to evade and prepare for an expected accident in their workspaces. Researchers have developed many systems in order to retrieve and use past accident cases. Although the developed systems have a clear and limited target (user), most of them were developed under retrieval methods based on ad hoc systems, which can cause inconvenience to users in using the retrieval system. To overcome these limitations, this study proposes an automated information (about past accident case) retrieval system that can automatically search for and provide (as a push system) similar accident cases. The retrieval system extracts building information modeling (BIM) objects and composes a q...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond information retrieval: information discovery and multimedia information retrieval\n",
            "Authors: Roberto Raieli\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: L’articolo discute a confronto le attuali metodologie per la ricerca e la scoperta dell’informazione e delle risorse informative: la ricerca di tipo terminologico e il linguaggio term-based, tipici dell’information retrieval (IR); la ricerca di tipo semantico e l’information discovery, in fase di sviluppo soprattutto tramite il linguaggio dei linked data; la ricerca di tipo semiotico e il linguaggio content-based, sperimentati dal multimedia information retrieval (MIR). E approfondita, quindi, la metodologia semiotica del MIR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Query Variations and their Effect on Comparing Information Retrieval Systems\n",
            "Authors: G. Zuccon, João Palotti, A. Hanbury\n",
            "Year: 2016\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: We explore the implications of using query variations for evaluating information retrieval systems and how these variations should be exploited to compare system effectiveness. Current evaluation approaches consider the availability of a set of topics (information needs), and only one expression of each topic in the form of a query is used for evaluation and system comparison. While there is strong evidence that considering query variations better models the usage of retrieval systems and accounts for the important user aspect of user variability, it is unclear how to best exploit query variations for evaluating and comparing information retrieval systems. We propose a framework for evaluating retrieval systems that explicitly takes into account query variations. The framework considers both the system mean effectiveness and its variance over query variations and topics, as opposed to current approaches that only consider the mean across topics or perform a topic-focused analysis of variance across systems. Furthermore, the framework extends current evaluation practice by encoding: (1) user tolerance to effectiveness variations, (2) the popularity of different query variations, and (3) the relative importance of individual topics. These extensions and our findings make information retrieval comparisons more aligned with user behaviour.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Optimizing Dense Retrieval Model Training with Hard Negatives\n",
            "Authors: Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, M. Zhang, Shaoping Ma\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Ranking has always been one of the top concerns in information retrieval researches. For decades, the lexical matching signal has dominated the ad-hoc retrieval process, but solely using this signal in retrieval may cause the vocabulary mismatch problem. In recent years, with the development of representation learning techniques, many researchers turn to Dense Retrieval (DR) models for better ranking performance. Although several existing DR models have already obtained promising results, their performance improvement heavily relies on the sampling of training examples. Many effective sampling strategies are not efficient enough for practical usage, and for most of them, there still lacks theoretical analysis in how and why performance improvement happens. To shed light on these research questions, we theoretically investigate different training strategies for DR models and try to explain why hard negative sampling performs better than random sampling. Through the analysis, we also find that there are many potential risks in static hard negative sampling, which is employed by many existing training methods. Therefore, we propose two training strategies named a Stable Training Algorithm for dense Retrieval (STAR) and a query-side training Algorithm for Directly Optimizing Ranking pErformance (ADORE), respectively. STAR improves the stability of DR training process by introducing random negatives. ADORE replaces the widely-adopted static hard negative sampling method with a dynamic one to directly optimize the ranking performance. Experimental results on two publicly available retrieval benchmark datasets show that either strategy gains significant improvements over existing competitive baselines and a combination of them leads to the best performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploring Peripheral Physiology as a Predictor of Perceived Relevance in Information Retrieval\n",
            "Authors: Oswald Barral, M. Eugster, Tuukka Ruotsalo, Michiel M. A. Spapé, Ilkka Kosunen, N. Ravaja, Samuel Kaski, Giulio Jacucci\n",
            "Year: 2015\n",
            "Venue: International Conference on Intelligent User Interfaces\n",
            "Abstract: Peripheral physiological signals, as obtained using electrodermal activity and facial electromyography over the corrugator supercilii muscle, are explored as indicators of perceived relevance in information retrieval tasks. An experiment with 40 participants is reported, in which these physiological signals are recorded while participants perform information retrieval tasks. Appropriate feature engineering is defined, and the feature space is explored. The results indicate that features in the window of 4 to 6 seconds after the relevance judgment for electrodermal activity, and from 1 second before to 2 seconds after the relevance judgment for corrugator supercilii activity, are associated with the users' perceived relevance of information items. A classifier verified the predictive power of the features and showed up to 14% improvement predicting relevance. Our research can help the design of intelligent user interfaces for information retrieval that can detect the user's perceived relevance from physiological signals and complement or replace conventional relevance feedback.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Formal Concept Analysis and Information Retrieval - A Survey\n",
            "Authors: Víctor Codocedo, A. Napoli\n",
            "Year: 2015\n",
            "Venue: International Conference on Formal Concept Analysis\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Advances in Information Retrieval\n",
            "Authors: Tuukka Ruotsalo, E. Hyvönen\n",
            "Year: 2015\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Review: Information Retrieval Techniques and Applications\n",
            "Authors: Akram Roshdi, Akram Roohparvar\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: For thousands of years people have realized the importance of archiving and finding information. With the advent of computers, it became possible to store large amounts of information; and finding useful information from such collections became a necessity. The field of Information Retrieval (IR) was born in the 1950s out of this necessity. Over the last forty years, the field has matured considerably. Several IR systems are used on an everyday basis by a wide variety of users. Information retrieval is become a important research area in the field of computer science. Information retrieval (IR) is generally concerned with the searching and retrieving of knowledge-based information from database. In this paper, we represent the various models and techniques for information retrieval. In this Review paper we are describing different indexing methods for reducing search space and different searching techniques for retrieving a information. We are also providing the overview of traditional IR models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: MULTIMEDIA INFORMATION RETRIEVAL BASED ON LATE SEMANTIC FUSION APPROACHES- EXPERIMENTS ON A WIKIPEDIA IMAGE COLLECTION\n",
            "Authors: S. Bhagyashri\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: This paper proposes an improved system using a textual pre-filtering combined with an image re-ranking in a Multimedia Information Retrieval task. Three different sub systems Text based subsystem, content based subsystem and fusion of both subsystems is used for multimedia information retrieval processes to overcome semantic gap in a given query. To get the accurate result we use Multimedia information retrieval on publicly available Image CLEF Wikipedia Collection. Keywords—Content-based information retrieval, multimedia information, multimedia retrieval, text-based image retrieval\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Benefits of Magnitude Estimation Relevance Assessments for Information Retrieval Evaluation\n",
            "Authors: A. Turpin, Falk Scholer, Stefano Mizzaro, Eddy Maddalena\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Magnitude estimation is a psychophysical scaling technique for the measurement of sensation, where observers assign numbers to stimuli in response to their perceived intensity. We investigate the use of magnitude estimation for judging the relevance of documents in the context of information retrieval evaluation, carrying out a large-scale user study across 18 TREC topics and collecting more than 50,000 magnitude estimation judgments. Our analysis shows that on average magnitude estimation judgments are rank-aligned with ordinal judgments made by expert relevance assessors. An advantage of magnitude estimation is that users can chose their own scale for judgments, allowing deeper investigations of user perceptions than when categorical scales are used. We explore the application of magnitude estimation for IR evaluation, calibrating two gain-based effectiveness metrics, nDCG and ERR, directly from user-reported perceptions of relevance. A comparison of TREC system effectiveness rankings based on binary, ordinal, and magnitude estimation relevance shows substantial variation; in particular, the top systems ranked using magnitude estimation and ordinal judgments differ substantially. Analysis of the magnitude estimation scores shows that this effect is due in part to varying perceptions of relevance, in terms of how impactful relative differences in document relevance are perceived to be. We further use magnitude estimation to investigate gain profiles, comparing the currently assumed linear and exponential approaches with actual user-reported relevance perceptions. This indicates that the currently used exponential gain profiles in nDCG and ERR are mismatched with an average user, but perhaps more importantly that individual perceptions are highly variable. These results have direct implications for IR evaluation, suggesting that current assumptions about a single view of relevance being sufficient to represent a population of users are unlikely to hold. Finally, we demonstrate that magnitude estimation judgments can be reliably collected using crowdsourcing, and are competitive in terms of assessor cost.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Reproducibility Study of Information Retrieval Models\n",
            "Authors: Peilin Yang, Hui Fang\n",
            "Year: 2016\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Developing effective information retrieval models has been a long standing challenge in Information Retrieval (IR), and significant progresses have been made over the years. With the increasing number of developed retrieval functions and the release of new data collections, it becomes more difficult, if not impossible, to compare a new retrieval function with all existing retrieval functions over all available data collections. To tackle thisproblem, this paper describes our efforts on constructing a platform that aims to improve the reproducibility of IR researchand facilitate the evaluation and comparison of retrieval functions. With the developed platform, more than 20 state of the art retrieval functions have been implemented and systematically evaluated over 16 standard TREC collections (including the newly released ClueWeb datasets). Our reproducibility study leads to several interesting observations. First, the performance difference between the reproduced results and those reported in the original papers is small for most retrieval functions. Second, the optimal performance of a few representative retrieval functions is still comparable over the new TREC ClueWeb collections. Finally, the developed platform (i.e., RISE) is made publicly available so that any IR researchers would be able to utilize it to evaluate other retrieval functions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Diagonalizing the Black Hole Information Retrieval Process\n",
            "Authors: G. Hooft\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: The mechanism by which black holes return the absorbed information to the outside world is reconsidered, and described in terms of a set of mutually non-interacting modes. Our mechanism is based on the mostly classical gravitational back-reaction. The diagonalized formalism is particularly useful for further studies of this process. Although no use is made of string theory, our analysis appears to point towards an ensuing string-like interaction. It is shown how black hole entropy can be traced down to classical gravitational back-reaction.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal medical information retrieval with unsupervised rank fusion\n",
            "Authors: André Mourão, Flávio Martins, João Magalhães\n",
            "Year: 2015\n",
            "Venue: Comput. Medical Imaging Graph.\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval evaluation using test collections\n",
            "Authors: Falk Scholer, D. Kelly, Ben Carterette\n",
            "Year: 2016\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploiting salient semantic analysis for information retrieval\n",
            "Authors: Jing Luo, Bo Meng, Changqin Quan, Xinhui Tu\n",
            "Year: 2016\n",
            "Venue: Enterprise Information Systems\n",
            "Abstract: ABSTRACT Recently, many Wikipedia-based methods have been proposed to improve the performance of different natural language processing (NLP) tasks, such as semantic relatedness computation, text classification and information retrieval. Among these methods, salient semantic analysis (SSA) has been proven to be an effective way to generate conceptual representation for words or documents. However, its feasibility and effectiveness in information retrieval is mostly unknown. In this paper, we study how to efficiently use SSA to improve the information retrieval performance, and propose a SSA-based retrieval method under the language model framework. First, SSA model is adopted to build conceptual representations for documents and queries. Then, these conceptual representations and the bag-of-words (BOW) representations can be used in combination to estimate the language models of queries and documents. The proposed method is evaluated on several standard text retrieval conference (TREC) collections. Experiment results on standard TREC collections show the proposed models consistently outperform the existing Wikipedia-based retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fairness in Information Retrieval\n",
            "Authors: Aldo Lipani\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The offline evaluation of Information Retrieval (IR) systems is performed through the use of test collections. A test collection, in its essence, is composed of: a collection of documents, a set of topics and, a set of relevance assessments for each topic, derived from the collection of documents. Ideally, for each topic, all the documents of the test collection should be judged, but due to the dimensions of the collections of documents, and their exponential growth over the years, this practice soon became impractical. Therefore, early in IR history, this problem has been addressed through the use of the pooling method. The pooling method consists of optimizing the relevance assessment process by pooling the documents retrieved by different search engines following a particular pooling strategy. The most common one consists on pooling the top d documents of each run. The pool is constructed from systems taking part in a challenge for which the collection was made, at a specific point in time, after which the collection is generally frozen in terms of relevance judgments. This method leads to a bias called pool bias, which is the effect that documents that were not selected in the pool created from the original runs will never be considered relevant. Thereby, this bias affects the evaluation of a system that has not been part of the pool, with any IR evaluation measures, making the comparison with pooled systems unfair. IR measures have evolved over the years and become more and more complex and difficult to interpret. Witnessing a need in industry for measures that 'make sense', I focus on the problematics of the two fundamental IR evaluation measures, Precision at cut-off P@n and Recall at cut-off $R@n$. There are two reasons to consider such 'simple' metrics: first, they are cornerstones for many other developed metrics and, second, they are easy to understand by all users. To the eyes of a practitioner, these two evaluation measures are interesting because they lead to more intuitive interpretations like, how much time people are reading useless documents (low precision), or how many relevant documents they are missing (low recall). But this last interpretation, due to the fact that recall is inversely proportional to the number of relevant documents per topic, is very difficult to be addressed if to be judged is just a portion of the collection of documents, as it is done when using the pooling method. To tackle this problem, another kind of evaluation has been developed, based on measuring how much an IR system makes documents accessible. Accessibility measures can be seen as a complementary evaluation to recall because they provide information on whether some relevant documents are not retrieved due to an unfairness in accessibility. The main goal of this Ph.D. is to increase the stability and reusability of existing test collections, when to be evaluated are systems in terms of precision, recall, and accessibility. The outcome will be: the development of a novel estimator to tackle the pool bias issue for P@n, and R@n, a comprehensive analysis of the effect of the estimator on varying pooling strategies, and finally, to support the evaluation of recall, an analytic approach to the evaluation of accessibility measures.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bayesian Inference for Information Retrieval Evaluation\n",
            "Authors: Ben Carterette\n",
            "Year: 2015\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: A key component of experimentation in IR is statistical hypothesis testing, which researchers and developers use to make inferences about the effectiveness of their system relative to others. A statistical hypothesis test can tell us the likelihood that small mean differences in effectiveness (on the order of 5%, say) is due to randomness or measurement error, and thus is critical for making progress in research. But the tests typically used in IR - the t-test, the Wilcoxon signed-rank test - are very general, not developed specifically for the problems we face in information retrieval evaluation. A better approach would take advantage of the fact that the atomic unit of measurement in IR is the relevance judgment rather than the effectiveness measure, and develop tests that model relevance directly. In this work we present such an approach, showing theoretically that modeling relevance in this way naturally gives rise to the effectiveness measures we care about. We demonstrate the usefulness of our model on both simulated data and a diverse set of runs from various TREC tracks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval\n",
            "Authors: Luyu Gao, Jamie Callan\n",
            "Year: 2021\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Recent research demonstrates the effectiveness of using fine-tuned language models (LM) for dense retrieval. However, dense retrievers are hard to train, typically requiring heavily engineered fine-tuning pipelines to realize their full potential. In this paper, we identify and address two underlying problems of dense retrievers: i) fragility to training data noise and ii) requiring large batches to robustly learn the embedding space. We use the recently proposed Condenser pre-training architecture, which learns to condense information into the dense vector through LM pre-training. On top of it, we propose coCondenser, which adds an unsupervised corpus-level contrastive loss to warm up the passage embedding space. Experiments on MS-MARCO, Natural Question, and Trivia QA datasets show that coCondenser removes the need for heavy data engineering such as augmentation, synthesis, or filtering, and the need for large batch training. It shows comparable performance to RocketQA, a state-of-the-art, heavily engineered system, using simple small batch fine-tuning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Using Term Location Information to Enhance Probabilistic Information Retrieval\n",
            "Authors: Baiyan Liu, X. An, Xiangji Huang\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Nouns are more important than other parts of speech in information retrieval and are more often found near the beginning or the end of sentences. In this paper, we investigate the effects of rewarding terms based on their location in sentences on information retrieval. Particularly, we propose a novel Term Location (TEL) retrieval model based on BM25 to enhance probabilistic information retrieval, where a kernel-based method is used to capture term placement patterns. Experiments on five TREC datasets of varied size and content indicate the proposed model significantly outperforms the optimized BM25 and DirichletLM in MAP over all datasets with all kernel functions, and excels the optimized BM25 and DirichletLM over most of the datasets in P@5 and P@20 with different kernel functions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Assessing the impact of Stemming Accuracy on Information Retrieval - A multilingual perspective\n",
            "Authors: Felipe N. Flores, V. Moreira\n",
            "Year: 2016\n",
            "Venue: Information Processing & Management\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multilingual information retrieval in the language modeling framework\n",
            "Authors: Razieh Rahimi, A. Shakery, Irwin King\n",
            "Year: 2015\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A new fuzzy logic based ranking function for efficient Information Retrieval system\n",
            "Authors: Yogesh Gupta, A. Saini, A. Saxena\n",
            "Year: 2015\n",
            "Venue: Expert systems with applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cyberbullying Detection and Classification Using Information Retrieval Algorithm\n",
            "Authors: B. Nandhini, J. I. Sheeba\n",
            "Year: 2015\n",
            "Venue: ICARCSET '15\n",
            "Abstract: Social networking site is being rapidly increased in recent years, which provides platform to connect people all over the world and share their interests. However, Social Networking Sites is providing opportunities for cyberbullying activities. Cyberbullying is harassing or insulting a person by sending messages of hurting or threatening nature using electronic communication. Cyberbullying poses significant threat to physical and mental health of the victims. Detection of cyberbullying and the provision of subsequent preventive measures are the main courses of action to combat cyberbullying. A cyberbully detection system to identify and classify cyberbullying activities such as Flaming, Harassment, Racism and Terrorism in Social network is proposed. Cyberbully detection is done using Levenshtein algorithm and classification of Cyberbully activity is carried out using Naïve Bayes classifier.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Constraining Word Embeddings by Prior Knowledge - Application to Medical Information Retrieval\n",
            "Authors: Xiaojie Liu, Jian-Yun Nie, Alessandro Sordoni\n",
            "Year: 2016\n",
            "Venue: Asia Information Retrieval Symposium\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Optically secured information retrieval using two authenticated phase-only masks\n",
            "Authors: Xiaogang Wang, Wen Chen, S. Mei, Xudong Chen\n",
            "Year: 2015\n",
            "Venue: Scientific Reports\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Temporal Information Retrieval\n",
            "Authors: Nattiya Kanhabua, Roi Blanco, K. Nørvåg\n",
            "Year: 2015\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: The study of temporal dynamics and its impact can be framed within the so-called temporal IR approaches, which explain how user behavior, document content and scale vary with time, and how we can use them in our favor in order to improve retrieval effectiveness. This half-day tutorial will outline research issues with respect to temporal dynamics, and provide a comprehensive overview of temporal IR approaches, essentially regarding processing dynamic content, temporal information extraction, temporal query analysis, and time-aware retrieval and ranking. The tutorial is structured into two sessions. During the first session, we will explain the general and wide aspects associated to temporal dynamics by focusing on the web domain, from content and structural changes to variations of user behavior and interactions. We will begin with temporal indexing and query processing. Next step, we will explain current approaches to time-aware retrieval and ranking, which can be classified into different types based on two main notions of relevance with respect to time, namely, recency-based ranking, and time-dependent ranking. In the latter session, we will describe research issues centered on determining the temporal intent of queries, and time-aware query enhancement, e.g., temporal relevance feedback, and time-aware query reformulation. In addition, we present applications in related research areas, e.g., exploration, summarization, and clustering of search results, as well as future event retrieval and prediction. To this end, we conclude our tutorial and outline future directions. This tutorial targets graduate students, researchers and practitioners in the field of information retrieval. The goal is to provide an overview as well as an important context that enables further research on and practical applications within this area.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation\n",
            "Authors: P. Galuscáková, Romain Deveaud, Gabriela González Sáez, P. Mulhem, Lorraine Goeuriot, Florina Piroi, M. Popel\n",
            "Year: 2023\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: LongEval-Retrieval is a Web document retrieval benchmark that focuses on continuous retrieval evaluation. This test collection is intended to be used to study the temporal persistence of Information Retrieval systems and will be used as the test collection in the Longitudinal Evaluation of Model Performance Track (LongEval) at CLEF 2023. This benchmark simulates an evolving information system environment - such as the one a Web search engine operates in - where the document collection, the query distribution, and relevance all move continuously, while following the Cranfield paradigm for offline evaluation. To do that, we introduce the concept of a dynamic test collection that is composed of successive sub-collections each representing the state of an information system at a given time step. In LongEval-Retrieval, each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models. The data comes from Qwant, a privacy-preserving Web search engine that primarily focuses on the French market. LongEval-Retrieval also provides a 'mirror' collection: it is initially constructed in the French language to benefit from the majority of Qwant's traffic, before being translated to English. This paper presents the creation process of LongEval-Retrieval and provides baseline runs and analysis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Algorithm for Information Retrieval optimization\n",
            "Authors: K. Agbele, E. F. Ayetiran, Kehinde D. Aruleba, Daniel O. Ekong\n",
            "Year: 2016\n",
            "Venue: IEEE Annual Information Technology, Electronics and Mobile Communication Conference\n",
            "Abstract: When using Information Retrieval (IR) systems, users often present search queries made of ad-hoc keywords. It is then up to the information retrieval systems (IRS) to obtain a precise representation of the user's information need and the context (preferences) of the information. To address this problem, we investigate optimization of IRS to individual information needs in order of relevance. The goal of this article is to develop algorithms that optimize the ranking of documents retrieved from IRS according to user search context. In particular, the ranking task that led the user to engage in information-seeking behaviour during search tasks. This article discusses and describes a Document Ranking Optimization (DROPT) algorithm for IR in an Internet-based or designated databases environment. Conversely, as the volume of information available online and in designated databases is growing continuously, ranking algorithms can play a major role in the context of search results. In this article, a DROPT technique for documents retrieved from a corpus is developed with respect to document index keywords and the query vectors. This is based on calculating the weight (wij) of keywords in the document index vector, calculated as a function of the frequency of a keyword kj across a document. The purpose of the DROPT technique is to reflect how human users can judge the context changes in IR result rankings according to information relevance. This article shows that it is possible for the DROPT technique to overcome some of the limitations of existing traditional (tf × idf) algorithms via adaptation. The empirical evaluation using metrics measures on the DROPT technique carried out through human user interaction shows improvement over the traditional relevance feedback technique to demonstrate improving IR effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Proactive Information Retrieval: Anticipating Users' Information Need\n",
            "Authors: S. Bhatia, Debapriyo Majumdar, Nitish Aggarwal\n",
            "Year: 2016\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content based image retrieval using image features information fusion\n",
            "Authors: Khawaja Tehseen Ahmed, Shahida Ummesafi, M. Iqbal\n",
            "Year: 2019\n",
            "Venue: Information Fusion\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Storage and Retrieval\n",
            "Authors: Edward A. Fox\n",
            "Year: 2020\n",
            "Venue: Definitions\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal Music Information Processing and Retrieval: Survey and Future Challenges\n",
            "Authors: Federico Simonetta, S. Ntalampiras, F. Avanzini\n",
            "Year: 2019\n",
            "Venue: 2019 International Workshop on Multilayer Music Representation and Processing (MMRP)\n",
            "Abstract: Towards improving the performance in various music information processing tasks, recent studies exploit different modalities able to capture diverse aspects of music. Such modalities include audio recordings, symbolic music scores, mid-level representations, motion and gestural data, video recordings, editorial or cultural tags, lyrics and album cover arts. This paper critically reviews the various approaches adopted in Music Information Processing and Retrieval, and highlights how multimodal algorithms can help Music Computing applications. First, we categorize the related literature based on the application they address. Subsequently, we analyze existing information fusion approaches, and we conclude with the set of challenges that Music Information Retrieval and Sound and Music Computing research communities should focus in the next years.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Accurate and effective latent concept modeling for ad hoc information retrieval\n",
            "Authors: Romain Deveaud, Eric SanJuan, P. Bellot\n",
            "Year: 2014\n",
            "Venue: Document Numérique\n",
            "Abstract: Une requete est la representation du besoin d’information d’un utilisateur, et est le resultat d’un processus cognitif complexe qui mene souvent a un mauvais choix de mots-cles. Nous proposons une methode non supervisee pour la modelisation de concepts implicites d’une requete, dans le but de recreer la representation conceptuelle du besoin d’information initial. Nous utilisons l’allocation de Dirichlet latente (LDA) pour detecter les concepts implicites de la requete en utilisant des documents pseudo-pertinents. Nous evaluons cette methode en profondeur en utilisant deux collections de test de TREC. Nous trouvons notamment que notre approche permet de modeliser precisement les concepts implicites de la requete, tout en obtenant de bonnes performances dans le cadre d’une recherche de documents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dynamic Information Retrieval: Theoretical Framework and Application\n",
            "Authors: Marc Sloan, Jun Wang\n",
            "Year: 2015\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Theoretical frameworks like the Probability Ranking Principle and its more recent Interactive Information Retrieval variant have guided the development of ranking and retrieval algorithms for decades, yet they are not capable of helping us model problems in Dynamic Information Retrieval which exhibit the following three properties; an observable user signal, retrieval over multiple stages and an overall search intent. In this paper a new theoretical framework for retrieval in these scenarios is proposed. We derive a general dynamic utility function for optimizing over these types of tasks, that takes into account the utility of each stage and the probability of observing user feedback. We apply our framework to experiments over TREC data in the dynamic multi page search scenario as a practical demonstration of its effectiveness and to frame the discussion of its use, its limitations and to compare it against the existing frameworks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Information Retrieval Approach to Short Text Conversation\n",
            "Authors: Zongcheng Ji, Zhengdong Lu, Hang Li\n",
            "Year: 2014\n",
            "Venue: arXiv.org\n",
            "Abstract: Human computer conversation is regarded as one of the most difficult problems in artificial intelligence. In this paper, we address one of its key sub-problems, referred to as short text conversation, in which given a message from human, the computer returns a reasonable response to the message. We leverage the vast amount of short conversation data available on social media to study the issue. We propose formalizing short text conversation as a search problem at the first step, and employing state-of-the-art information retrieval (IR) techniques to carry out the task. We investigate the significance as well as the limitation of the IR approach. Our experiments demonstrate that the retrieval-based model can make the system behave rather \"intelligently\", when combined with a huge repository of conversation data from social media.\n",
            "\n",
            "---\n",
            "\n",
            "Title: RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking\n",
            "Authors: Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-rong Wen\n",
            "Year: 2021\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: In various natural language processing tasks, passage retrieval and passage re-ranking are two key procedures in finding and ranking relevant information. Since both the two procedures contribute to the final performance, it is important to jointly optimize them in order to achieve mutual improvement. In this paper, we propose a novel joint training approach for dense passage retrieval and passage reranking. A major contribution is that we introduce the dynamic listwise distillation, where we design a unified listwise training approach for both the retriever and the re-ranker. During the dynamic distillation, the retriever and the re-ranker can be adaptively improved according to each other’s relevance information. We also propose a hybrid data augmentation strategy to construct diverse training instances for listwise training approach. Extensive experiments show the effectiveness of our approach on both MSMARCO and Natural Questions datasets. Our code is available at https://github.com/PaddlePaddle/RocketQA.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Music Information Retrieval: Recent Developments and Applications\n",
            "Authors: M. Schedl, E. Gómez, Julián Urbano\n",
            "Year: 2014\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: We provide a survey of the field of Music Information Retrieval (MIR), in particular paying attention to latest developments, such as semantic auto-tagging and user-centric retrieval and recommendation approaches. We first elaborate on well-established and proven methods for feature extraction and music indexing, from both the audio signal and contextual data sources about music items, such as web pages or collaborative tags. These in turn enable a wide variety of music retrieval tasks, such as semantic music search or music identification (\"query by example\"). Subsequently, we review current work on user analysis and modeling in the context of music recommendation and retrieval, addressing the recent trend towards user-centric and adaptive approaches and systems. A discussion follows about the important aspect of how various MIR approaches to different problems are evaluated and compared. Eventually, a discussion about the major open challenges concludes the survey.\n",
            "\n",
            "---\n",
            "\n",
            "Title: One extra bit of download ensures perfectly private information retrieval\n",
            "Authors: Nihar B. Shah, K. V. Rashmi, K. Ramchandran\n",
            "Year: 2014\n",
            "Venue: 2014 IEEE International Symposium on Information Theory\n",
            "Abstract: Private information retrieval (PIR) systems allow a user to retrieve a record from a public database without revealing to the server which record is being retrieved. The literature on PIR considers only replication-based systems, wherein each storage node stores a copy of the entire data. However, systems based on erasure codes are gaining increasing popularity due to a variety of reasons. This paper initiates an investigation into PIR in erasure-coded systems by establishing its capacity and designing explicit codes and algorithms. The notion of privacy considered here is information-theoretic, and the metric optimized is the amount of data downloaded by the user during PIR. In this paper, we present four main results. First, we design an explicit erasure code and PIR algorithm that requires only one extra bit of download to provide perfect privacy. In contrast, all existing PIR algorithms require a download of at least twice the size of the requisite data. Second, we derive lower bounds proving the necessity of downloading at least one additional bit. This establishes the precise capacity of PIR with respect to the metric of download. These results are also applicable to PIR in replication-based systems, which are a special case of erasure codes. Our third contribution is a negative result showing that capacity-achieving codes necessitate super-linear storage overheads. This motivates the fourth contribution of this paper: an erasure code and PIR algorithm that requires a linear storage overhead, provides high reliability to the data, and is a small factor away from the capacity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Survey of Temporal Information Retrieval and Related Applications\n",
            "Authors: Ricardo Campos, G. Dias, A. Jorge, A. Jatowt\n",
            "Year: 2014\n",
            "Venue: ACM Computing Surveys\n",
            "Abstract: Temporal information retrieval has been a topic of great interest in recent years. Its purpose is to improve the effectiveness of information retrieval methods by exploiting temporal information in documents and queries. In this article, we present a survey of the existing literature on temporal information retrieval. In addition to giving an overview of the field, we categorize the relevant research, describe the main contributions, and compare different approaches. We organize existing research to provide a coherent view, discuss several open issues, and point out some possible future research directions in this area. Despite significant advances, the area lacks a systematic arrangement of prior efforts and an overview of state-of-the-art approaches. Moreover, an effective end-to-end temporal retrieval system that exploits temporal information to improve the quality of the presented results remains undeveloped.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A geometric framework for data fusion in information retrieval\n",
            "Authors: Shengli Wu, F. Crestani\n",
            "Year: 2015\n",
            "Venue: Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private information retrieval for coded storage\n",
            "Authors: T. Chan, Siu-Wai Ho, Hirosuke Yamamoto\n",
            "Year: 2014\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: Private information retrieval scheme for coded data storage is considered in this paper. We focus on the case where the size of each data record is large and hence only the download cost (but not the upload cost for transmitting retrieval queries) is of interest. We prove that the tradeoff between storage cost and retrieval/download cost depends on the number of data records in the system. We propose a class of linear storage codes and retrieval schemes, and derive conditions under which our schemes are error-free and private. Tradeoffs between the storage cost and retrieval costs are also obtained.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval\n",
            "Authors: Jacques Savoy, Éric Gaussier\n",
            "Year: 2017\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval\n",
            "Authors: Jirong Wen, Jianyun Nie, Tong Ruan, Yiqun Liu, Tieyun Qian\n",
            "Year: 2017\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Re-Imagen: Retrieval-Augmented Text-to-Image Generator\n",
            "Authors: Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen\n",
            "Year: 2022\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Research on text-to-image generation has witnessed significant progress in generating diverse and photo-realistic images, driven by diffusion and auto-regressive models trained on large-scale image-text data. Though state-of-the-art models can generate high-quality images of common entities, they often have difficulty generating images of uncommon entities, such as `Chortai (dog)' or `Picarones (food)'. To tackle this issue, we present the Retrieval-Augmented Text-to-Image Generator (Re-Imagen), a generative model that uses retrieved information to produce high-fidelity and faithful images, even for rare or unseen entities. Given a text prompt, Re-Imagen accesses an external multi-modal knowledge base to retrieve relevant (image, text) pairs and uses them as references to generate the image. With this retrieval step, Re-Imagen is augmented with the knowledge of high-level semantics and low-level visual details of the mentioned entities, and thus improves its accuracy in generating the entities' visual appearances. We train Re-Imagen on a constructed dataset containing (image, text, retrieval) triples to teach the model to ground on both text prompt and retrieval. Furthermore, we develop a new sampling strategy to interleave the classifier-free guidance for text and retrieval conditions to balance the text and retrieval alignment. Re-Imagen achieves significant gain on FID score over COCO and WikiImage. To further evaluate the capabilities of the model, we introduce EntityDrawBench, a new benchmark that evaluates image generation for diverse entities, from frequent to rare, across multiple object categories including dogs, foods, landmarks, birds, and characters. Human evaluation on EntityDrawBench shows that Re-Imagen can significantly improve the fidelity of generated images, especially on less frequent entities.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic boolean arabic information retrieval\n",
            "Authors: Emad Elabd, Eissa Alshari, Hatem M. Abdelkader\n",
            "Year: 2015\n",
            "Venue: ˜The œinternational Arab journal of information technology\n",
            "Abstract: Arabic language is one of the most widely spoken languages. This language has a complex morphological structure and is considered as one of the most prolific languages in terms of article linguistic. Therefore, Arabic Information Retrieval (AIR) models need specific techniques to deal with this complex morphological structure. This paper aims to develop an integrate AIR frameworks. It lists and analysis the different Information Retrieval (IR) methods and techniques such as query processing, stemming and indexing which are used in AIR systems. We conclude that AIR frameworks have a weakness to deal with semantic in term of indexing, Boolean model, Latent Semantic Analysis (LSA), Latent Semantic Index (LSI) and semantic ranking. Therefore, semantic Boolean IR framework is proposed in this paper. This model is implemented and the precision, recall and run time are measured and compared with the traditional IR model.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Language Information Retrieval\n",
            "Authors: Jian-Yun Nie\n",
            "Year: 2014\n",
            "Venue: Encyclopedia of Machine Learning and Data Mining\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Simple Method to Determine if a Music Information Retrieval System is a “Horse”\n",
            "Authors: Bob L. Sturm\n",
            "Year: 2014\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: We propose and demonstrate a simple method to explain the figure of merit (FoM) of a music information retrieval (MIR) system evaluated in a dataset, specifically, whether the FoM comes from the system using characteristics confounded with the “ground truth” of the dataset. Akin to the controlled experiments designed to test the supposed mathematical ability of the famous horse “Clever Hans,” we perform two experiments to show how three state-of-the-art MIR systems produce excellent FoM in spite of not using musical knowledge. This provides avenues for improving MIR systems, as well as their evaluation. We make available a reproducible research package so that others can apply the same method to evaluating other MIR systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ShARe/CLEF eHealth Evaluation Lab 2014, Task 3: User-centred Health Information Retrieval\n",
            "Authors: Lorraine Goeuriot, Liadh Kelly, Wei Li, João Palotti, Pavel Pecina, G. Zuccon, A. Hanbury, G. Jones, H. Müller\n",
            "Year: 2014\n",
            "Venue: Conference and Labs of the Evaluation Forum\n",
            "Abstract: This paper presents the results of task 3 of the ShARe/CLEF eHealth Evaluation Lab 2014. This evaluation lab focuses on improving access to medical information on the web. The task objective was to investigate the eect of using additional information such as a related discharge summary and external resources such as medical ontologies on the eectiveness of information retrieval systems, in a monolingual (Task 3a) and in a multilingual (Task 3b) context. The participants were al- lowed to submit up to seven runs for each language (English, Czech, French, German), one mandatory run using no additional information or external resources, and three each using or not using discharge sum- maries.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Scientometrics and information retrieval: weak-links revitalized\n",
            "Authors: Philipp Mayr, A. Scharnhorst\n",
            "Year: 2014\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic Modelling with Long-Short-Term Memory for Information Retrieval\n",
            "Authors: Hamid Palangi, L. Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, R. Ward\n",
            "Year: 2014\n",
            "Venue: arXiv.org\n",
            "Abstract: In this paper we address the following problem in web document and information retrieval (IR): How can we use long-term context information to gain better IR performance? Unlike common IR methods that use bag of words representation for queries and documents, we treat them as a sequence of words and use long short term memory (LSTM) to capture contextual dependencies. To the best of our knowledge, this is the first time that LSTM is applied to information retrieval tasks. Unlike training traditional LSTMs, the training strategy is different due to the special nature of information retrieval problem. Experimental evaluation on an IR task derived from the Bing web search demonstrates the ability of the proposed method in addressing both lexical mismatch and long-term context modelling issues, thereby, significantly outperforming existing state of the art methods for web document retrieval task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Untangling search task complexity and difficulty in the context of interactive information retrieval studies\n",
            "Authors: B. Wildemuth, Luanne Freund, Elaine Toms\n",
            "Year: 2014\n",
            "Venue: J. Documentation\n",
            "Abstract: Purpose – One core element of interactive information retrieval (IIR) experiments is the assignment of search tasks. The purpose of this paper is to provide an analytical review of current practice in developing those search tasks to test, observe or control task complexity and difficulty. Design/methodology/approach – Over 100 prior studies of IIR were examined in terms of how each defined task complexity and/or difficulty (or related concepts) and subsequently interpreted those concepts in the development of the assigned search tasks. Findings – Search task complexity is found to include three dimensions: multiplicity of subtasks or steps, multiplicity of facets, and indeterminability. Search task difficulty is based on an interaction between the search task and the attributes of the searcher or the attributes of the search situation. The paper highlights the anomalies in our use of these two concepts, concluding with suggestions for future methodological research related to search task complexity and d...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Arabic Information Retrieval\n",
            "Authors: Kareem Darwish, Walid Magdy\n",
            "Year: 2014\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Arabic is ranked as the seventh largest language on the Internet but it has also been the fastest growing language in the last decade in terms of users. At this rate of growth, Arabic users should have the fourth largest user population on the Internet by 2020. Given these facts, it is not surprising that Arabic Information Retrieval (IR) has garnered significant attention. The main research interests have focused on retrieval of formal language, mostly in the news domain, with ad hoc retrieval, OCR document retrieval, and cross-language retrieval. The literature on other aspects of retrieval continues to be sparse or non-existent, though some of these aspects have been investigated by industry. Others aspects of Arabic retrieval that have received attention include document image retrieval, speech search, filtering, and social media and web search. However, efforts within different aspects of Arabic retrieval continue to be deficient and severely lacking behind efforts in other languages. Arabic Information Retrieval reviews Arabic IR including the nature of the Arabic language, the techniques used for pre-processing the language, the latest research in Arabic IR in different domains, and the open areas in Arabic IR. It covers general properties of the Arabic language, aspects of Arabic that affect retrieval, Arabic processing necessary for effective Arabic retrieval, Arabic retrieval in public IR evaluations, Arabic IR and NLP resources, and specialized retrieval problems such as Arabic-English CLIR, Arabic Document Image Retrieval, Arabic Social Search, Arabic Web Search, Question Answering, Image retrieval, and Arabic Speech Search. Lastly, it also discusses open IR problems that require further attention.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Image Features in Music Information Retrieval\n",
            "Authors: Grzegorz Gwardys, Daniel Grzywczak\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Applications of Convolutional Neural Networks ( CNNs ) to various problems have been the subject of a number of recent studiesranging from image classification and object detection to scene parsing, segmentation 3D volumetric images and action recognition in videos. In this study, the CNNs were applied to a Music Information Retrieval (MIR), in particular to musical genre recognition. The model was trained on ILSVRC-2012 (more than 1 million natural images) to perform image classification and was reused to perform genre classification using spectrograms images. Harmonic and percussion separation was applied, because it is characteristic formusical genre. At final stage, the evaluation of various strategies of merging Support Vector Machines (SVMs) was performed on well known in MIR community - GTZAN dataset. Even though, the model was trained on natural images, the results achieved in this studywere close to the state-of-the-art.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dense Text Retrieval Based on Pretrained Language Models: A Survey\n",
            "Authors: Wayne Xin Zhao, Jing Liu, Ruiyang Ren, Ji-rong Wen\n",
            "Year: 2022\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: Text retrieval is a long-standing research topic on information seeking, where a system is required to return relevant information resources to user’s queries in natural language. From heuristic-based retrieval methods to learning-based ranking functions, the underlying retrieval models have been continually evolved with the ever-lasting technical innovation. To design effective retrieval models, a key point lies in how to learn text representations and model the relevance matching. The recent success of pretrained language models (PLM) sheds light on developing more capable text-retrieval approaches by leveraging the excellent modeling capacity of PLMs. With powerful PLMs, we can effectively learn the semantic representations of queries and texts in the latent representation space, and further construct the semantic matching function between the dense vectors for relevance modeling. Such a retrieval approach is called dense retrieval, since it employs dense vectors to represent the texts. Considering the rapid progress on dense retrieval, this survey systematically reviews the recent progress on PLM-based dense retrieval. Different from previous surveys on dense retrieval, we take a new perspective to organize the related studies by four major aspects, including architecture, training, indexing and integration, and thoroughly summarize the mainstream techniques for each aspect. We extensively collect the recent advances on this topic, and include 300+ reference papers. To support our survey, we create a website for providing useful resources, and release a code repository for dense retrieval. This survey aims to provide a comprehensive, practical reference focused on the major progress for dense text retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond Part Models: Person Retrieval with Refined Part Pooling\n",
            "Authors: Yifan Sun, Liang Zheng, Yi Yang, Q. Tian, Shengjin Wang\n",
            "Year: 2017\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Condenser: a Pre-training Architecture for Dense Retrieval\n",
            "Authors: Luyu Gao, Jamie Callan\n",
            "Year: 2021\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Pre-trained Transformer language models (LM) have become go-to text representation encoders. Prior research fine-tunes deep LMs to encode text sequences such as sentences and passages into single dense vector representations for efficient text comparison and retrieval. However, dense encoders require a lot of data and sophisticated techniques to effectively train and suffer in low data situations. This paper finds a key reason is that standard LMs’ internal attention structure is not ready-to-use for dense encoders, which needs to aggregate text information into the dense representation. We propose to pre-train towards dense encoder with a novel Transformer architecture, Condenser, where LM prediction CONditions on DENSE Representation. Our experiments show Condenser improves over standard LM by large margins on various text retrieval and similarity tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Introduction to Formal Concept Analysis and Its Applications in Information Retrieval and Related Fields\n",
            "Authors: D. Ignatov\n",
            "Year: 2014\n",
            "Venue: Russian Summer School on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Novelty and diversity enhancement and evaluation in recommender systems and information retrieval\n",
            "Authors: S. Vargas\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The development and evaluation of Information Retrieval and Recommender Systems has traditionally focused on the relevance and accuracy of retrieved documents and recommendations, respectively. However, there is an increasing realization that accuracy alone might be a sub-optimal strategy for a successful user experience. Properties such as novelty and diversity have been explored in both fields for assessing and enhancing the usefulness of search results and recommendations. In this doctoral research we study the assessment and enhancement of both properties in the confluence of Information Retrieval and Recommender Systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Study of Query Expansion Techniques and Their Application in the Biomedical Information Retrieval\n",
            "Authors: A. Rivas, E. L. Iglesias, Mar´ıa Lourdes, Borrajo Diz\n",
            "Year: 2014\n",
            "Venue: TheScientificWorldJournal\n",
            "Abstract: Information Retrieval focuses on finding documents whose content matches with a user query from a large document collection. As formulating well-designed queries is difficult for most users, it is necessary to use query expansion to retrieve relevant information. Query expansion techniques are widely applied for improving the efficiency of the textual information retrieval systems. These techniques help to overcome vocabulary mismatch issues by expanding the original query with additional relevant terms and reweighting the terms in the expanded query. In this paper, different text preprocessing and query expansion approaches are combined to improve the documents initially retrieved by a query in a scientific documental database. A corpus belonging to MEDLINE, called Cystic Fibrosis, is used as a knowledge source. Experimental results show that the proposed combinations of techniques greatly enhance the efficiency obtained by traditional queries.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Modality Submodular Dictionary Learning for Information Retrieval\n",
            "Authors: Fan Zhu, Ling Shao, Mengyang Yu\n",
            "Year: 2014\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: This paper addresses the problem of joint modeling of multimedia components in different media forms. We consider the information retrieval task across both text and image documents, which includes retrieving relevant images that closely match the description in a text query and retrieving text documents that best explain the content of an image query. A greedy dictionary construction approach is introduced for learning an isomorphic feature space, to which cross-modality data can be adapted while data smoothness is guaranteed. The proposed objective function consists of two reconstruction error terms for both modalities and a Maximum Mean Discrepancy (MMD) term that measures the cross-modality discrepancy. Optimization of the reconstruction terms and the MMD term yields a compact and modality-adaptive dictionary pair. We formulate the joint combinatorial optimization problem by maximizing variance reduction over a candidate signal set while constraining the dictionary size and coefficients' sparsity. By exploiting the submodularity and the monotonicity property of the proposed objective function, the optimization problem can be solved by a highly efficient greedy algorithm, and is guaranteed to be at least a (e - 1)=/e≈0.632- approximation to the optimum. The proposed method achieves state-of-the-art performance on the Wikipedia dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bibliometrics-aided retrieval: where information retrieval meets scientometrics\n",
            "Authors: W. Glänzel\n",
            "Year: 2014\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Systematic Evaluation of the Bag-of-Frames Representation for Music Information Retrieval\n",
            "Authors: Li Su, Chin-Chia Michael Yeh, Jen-Yu Liu, Ju-Chiang Wang, Yi-Hsuan Yang\n",
            "Year: 2014\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: There has been an increasing attention on learning feature representations from the complex, high-dimensional audio data applied in various music information retrieval (MIR) problems. Unsupervised feature learning techniques, such as sparse coding and deep belief networks have been utilized to represent music information as a term-document structure comprising of elementary audio codewords. Despite the widespread use of such bag-of-frames (BoF) model, few attempts have been made to systematically compare different component settings. Moreover, whether techniques developed in the text retrieval community are applicable to audio codewords is poorly understood. To further our understanding of the BoF model, we present in this paper a comprehensive evaluation that compares a large number of BoF variants on three different MIR tasks, by considering different ways of low-level feature representation, codebook construction, codeword assignment, segment-level and song-level feature pooling, tf-idf term weighting, power normalization, and dimension reduction. Our evaluations lead to the following findings: 1) modeling music information by two levels of abstraction improves the result for difficult tasks such as predominant instrument recognition, 2) tf-idf weighting and power normalization improve system performance in general, 3) topic modeling methods such as latent Dirichlet allocation does not work for audio codewords.\n",
            "\n",
            "---\n",
            "\n",
            "Title: International Society for Music Information Retrieval\n",
            "Authors: \n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval Technology\n",
            "Authors: Rafael E. Banchs, F. Silvestri, Tie-Yan Liu, Min Zhang, Shenghao Gao, Jun Lang\n",
            "Year: 2014\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval\n",
            "Authors: Mustafa Jarrar\n",
            "Year: 2015\n",
            "Venue: Communications in Computer and Information Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A semantic approach to concept lattice-based information retrieval\n",
            "Authors: Víctor Codocedo, Ioanna Lykourentzou, A. Napoli\n",
            "Year: 2014\n",
            "Venue: Annals of Mathematics and Artificial Intelligence\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Query expansion for mixed-script information retrieval\n",
            "Authors: Parth Gupta, Kalika Bali, R. Banchs, M. Choudhury, Paolo Rosso\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: For many languages that use non-Roman based indigenous scripts (e.g., Arabic, Greek and Indic languages) one can often find a large amount of user generated transliterated content on the Web in the Roman script. Such content creates a monolingual or multi-lingual space with more than one script which we refer to as the Mixed-Script space. IR in the mixed-script space is challenging because queries written in either the native or the Roman script need to be matched to the documents written in both the scripts. Moreover, transliterated content features extensive spelling variations. In this paper, we formally introduce the concept of Mixed-Script IR, and through analysis of the query logs of Bing search engine, estimate the prevalence and thereby establish the importance of this problem. We also give a principled solution to handle the mixed-script term matching and spelling variation where the terms across the scripts are modelled jointly in a deep-learning architecture and can be compared in a low-dimensional abstract space. We present an extensive empirical analysis of the proposed method along with the evaluation results in an ad-hoc retrieval setting of mixed-script IR where the proposed method achieves significantly better results (12% increase in MRR and 29% increase in MAP) compared to other state-of-the-art baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modeling Term Associations for Probabilistic Information Retrieval\n",
            "Authors: Jiashu Zhao, Xiangji Huang, Zheng Ye\n",
            "Year: 2014\n",
            "Venue: TOIS\n",
            "Abstract: Traditionally, in many probabilistic retrieval models, query terms are assumed to be independent. Although such models can achieve reasonably good performance, associations can exist among terms from a human being’s point of view. There are some recent studies that investigate how to model term associations/dependencies by proximity measures. However, the modeling of term associations theoretically under the probabilistic retrieval framework is still largely unexplored. In this article, we introduce a new concept cross term, to model term proximity, with the aim of boosting retrieval performance. With cross terms, the association of multiple query terms can be modeled in the same way as a simple unigram term. In particular, an occurrence of a query term is assumed to have an impact on its neighboring text. The degree of the query-term impact gradually weakens with increasing distance from the place of occurrence. We use shape functions to characterize such impacts. Based on this assumption, we first propose a bigram CRoss TErm Retrieval (CRTER2) model as the basis model, and then recursively propose a generalized n-gram CRoss TErm Retrieval (CRTERn) model for n query terms, where n > 2. Specifically, a bigram cross term occurs when the corresponding query terms appear close to each other, and its impact can be modeled by the intersection of the respective shape functions of the query terms. For an n-gram cross term, we develop several distance metrics with different properties and employ them in the proposed models for ranking. We also show how to extend the language model using the newly proposed cross terms. Extensive experiments on a number of TREC collections demonstrate the effectiveness of our proposed models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval Augmented Classification for Long-Tail Visual Recognition\n",
            "Authors: Alex Long, Wei Yin, Thalaiyasingam Ajanthan, V. Nguyen, Pulak Purkait, Ravi Garg, Alan Blair, Chunhua Shen, A. Hengel\n",
            "Year: 2022\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: We introduce Retrieval Augmented Classification (RAC), a generic approach to augmenting standard image classification pipelines with an explicit retrieval module. RAC consists of a standard base image encoder fused with a parallel retrieval branch that queries a non-parametric external memory of pre-encoded images and associated text snippets. We apply RAC to the problem of long-tail classification and demonstrate a significant improvement over previous state-of-the-art on Places365-LT and iNaturalist-2018 (14.5% and 6.7% respectively), despite using only the training datasets themselves as the external information source. We demonstrate that RAC's retrieval module, without prompting, learns a high level of accuracy on tail classes. This, in turn, frees the base encoder to focus on common classes, and improve its performance thereon. RAC represents an alternative approach to utilizing large, pretrained models without requiring fine-tuning, as well as a first step towards more effectively making use of external memory within common computer vision architectures.\n",
            "\n",
            "---\n",
            "\n",
            "Title: AN EFFECTIVE TOKENIZATION ALGORITHM FOR INFORMATION RETRIEVAL SYSTEMS\n",
            "Authors: Vikram Singh, Balwinder Saini\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: In the web, amount of operational data has been increasing exponentially from past few decades, the expectations of data-user is changing proportionally as well. The data-user expects more deep, exact, and detailed results. Retrieval of relevant results is always affected by the pattern, how they are stored/ indexed. There are various techniques are designed to indexed the documents, which is done on the token’s identified with in documents. Tokenization process, primarily effective is to identifying the token and their count. In this paper, we have proposed an effective tokenization approach which is based on training vector and result shows that efficiency/ effectiveness of proposed algorithm.Tokenization of a given documents helps to satisfy user’s information need more precisely and reduced search sharply, is believed to be a part of information retrieval. Tokenization involves pre-processing of documents and generates its respective tokens which is the basis of these tokens probabilistic IR generate its scoring and gives reduced search space. No of Token generated is the parameters used for result analysis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: User-driven system-mediated collaborative information retrieval\n",
            "Authors: L. Soulier, C. Shah, L. Tamine\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Most of the previous approaches surrounding collaborative information retrieval (CIR) provide either a user-based mediation, in which the system only supports users' collaborative activities, or a system-based mediation, in which the system plays an active part in balancing user roles, re-ranking results, and distributing them to optimize overall retrieval performance. In this paper, we propose to combine both of these approaches by a role mining methodology that learns from users' actions about the retrieval strategy they adapt. This hybrid method aims at showing how users are different and how to use these differences for suggesting roles. The core of the method is expressed as an algorithm that (1) monitors users' actions in a CIR setting; (2) discovers differences among the collaborators along certain dimensions; and (3) suggests appropriate roles to make the most out of individual skills and optimize IR performance. Our approach is empirically evaluated and relies on two different laboratory studies involving 70 pairs of users. Our experiments show promising results that highlight how role mining could optimize the collaboration within a search session. The contributions of this work include a new algorithm for mining user roles in collaborative IR, an evaluation methodology, and a new approach to improve IR performance with the operationalization of user-driven system-mediated collaboration.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A nonparametric term weighting method for information retrieval based on measuring the divergence from independence\n",
            "Authors: I. Kocabas, Bekir Taner Dinçer, B. Karaoglan\n",
            "Year: 2014\n",
            "Venue: Information retrieval (Boston)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Aggregated search: A new information retrieval paradigm\n",
            "Authors: A. Kopliku, K. Pinel-Sauvagnat, M. Boughanem\n",
            "Year: 2014\n",
            "Venue: CSUR\n",
            "Abstract: Traditional search engines return ranked lists of search results. It is up to the user to scroll this list, scan within different documents, and assemble information that fulfill his/her information need. Aggregated search represents a new class of approaches where the information is not only retrieved but also assembled. This is the current evolution in Web search, where diverse content (images, videos, etc.) and relational content (similar entities, features) are included in search results.\n",
            " In this survey, we propose a simple analysis framework for aggregated search and an overview of existing work. We start with related work in related domains such as federated search, natural language generation, and question answering. Then we focus on more recent trends, namely cross vertical aggregated search and relational aggregated search, which are already present in current Web search.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Event graphs for information retrieval and multi-document summarization\n",
            "Authors: Goran Glavas, J. Šnajder\n",
            "Year: 2014\n",
            "Venue: Expert systems with applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Relevation!: An open source system for information retrieval relevance assessment\n",
            "Authors: B. Koopman, G. Zuccon\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Relevation! is a system for performing relevance judgements for information retrieval evaluation. Relevation! is web-based, fully configurable and expandable; it allows researchers to effectively collect assessments and additional qualitative data. The system is easily deployed allowing assessors to smoothly perform their relevance judging tasks, even remotely. Relevation! is available as an open source project at: http://ielab.github.io/relevation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-modal Transformer for Video Retrieval\n",
            "Authors: Valentin Gabeur, Chen Sun, Alahari Karteek, C. Schmid\n",
            "Year: 2020\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval for Children: Search Behavior and Solutions\n",
            "Authors: Sergio Duarte Torres\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Nowadays, children of very young ages and teenagers use the Internet extensively for entertainment and educational purposes. The number of active young users in the Internet is increasing everyday as the Internet is more accessible at home, schools and even on a mobile basis through cellphones and tablets. The most popular search engines are designed for adults and they do not provide customize tools for young users. Given that young and adult users have different interests and search strategies, research aimed at understanding the activities that young users carried out on the Internet, the way the search for information, and the difficulties that they encounter with state-of-the-art search engines, are urgently needed. The first contribution of this thesis addresses these research aims by providing a characterization, on a large scale, of the search behavior of young users. The problems they face when they search for information on the web, the topics they searched and the online activities that motivate search were explored in detail and contrasted against the search behavior of adult users. The results presented in this thesis have important implications for the development of search tools for young users and for the design of educational literacy. \n",
            " \n",
            "Two central problems were identified in the search process of young users: (1) difficulty representing the information needs with keyword queries, and (2) difficulty exploring the list of results. We found that focused queries are often required to access high quality content for young user with modern search engines. However, young users were found to submit queries that lack the specificity needed to retrieve content that is suitable for them, which leads to frustration during the search process. This observation motivates the second contribution of this thesis. We propose novel query recommendation methods to improve the chances of young users to find content that is suitable and on topic. Concretely, we present an effective biased random walk based on information gain metrics. This method is combined with topical and specialized features designed for the information domain of young users. We show that our query suggestions outperform by a larger margin not only related query recommendation methods but also the query suggestions offered by the search services available today. In respect to the second difficulty, it was found that young users have a strong click bias, in which results ranked at the bottom of the result list are rarely clicked. This behavior greatly hampers their navigational skills and exploration of results. It also reduces the chances of young users to find suitable information, since appropriate content for this audience is ranked, on average, at lower positions in the result list in comparison to the content aimed at the average web user. The third contribution of this thesis aims at helping young users to improve their chances to find appropriate content and to ease the exploration of results. For this purpose, we envisage an aggregated search system in which parents, teachers and young users add search services with content of interests for young audiences. We propose a test collection with a wide number of verticals with moderated content, a carefully selected set of search queries and vertical relevant judgments. We also provide novel methods of vertical selection in this information domain based on social media and based on the estimation of the amount of content that is appropriate for young users in each vertical. We show that our methods outperform state-of-the-art vertical selection methods in this information domain. We also show in a case study with children aged 9 to 10 years old that result pages derived from the collection proposed are preferred over the result pages provided by modern search engines. We provide evidence showing that the interaction and exploration of results are improved with result pages built using this collection, even if the users of this case study were unaware between the differences between the types of pages displayed to them. This thesis is concluded by providing concrete follow-up research directions and by suggesting other information domains that can potentially benefit from the methods proposed in the thesis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey of stemming algorithms in information retrieval\n",
            "Authors: C. Moral, Angélica de Antonio Jiménez, R. Imbert, J. Ramírez\n",
            "Year: 2014\n",
            "Venue: Information Research\n",
            "Abstract: Cristian Moral, Angelica de Antonio, Ricardo Imbert and JaimeRamirezEscuela Tecnica Superior de Ingenieros Informaticos, UniversidadPolitecnica de Madrid, SpainAbstractBackground. During the last fifty years, improved information retrieval techniques havebecome necessary because of the huge amount of information people have available, whichcontinues to increase rapidly due to the use of new technologies and the Internet.Stemming is one of the processes that can improve information retrieval in terms ofaccuracy and performance.Aim. This paper provides a detailed assessment of the current status of the stemmingprocess framed in an information retrieval application field by tracing its historical evolution.Method. Papers presenting the first approaches for stemming were reviewed to extracttheir main features, benefits and drawbacks. Additionally, papers dealing with stemmersfor non-English languages or with some more recent proposals were also consulted andcompiled. Finally, experimental papers defining the most well-known methods and metricsaimed at evaluating and classifying stemmers were also taken into account to expose theircontributions and results. Results. Even if not all researchers agree on the benefits and drawbacks of usingstemming in an information retrieval process in general terms, many of them agree on itsbenefits in specific contexts, such as when the language is highly inflective, when documentsare short or when there is limited space for storing data. Some researchers also state thatthe nature of the documents can influence the performance and the accuracy of thestemmer. Conclusions. Despite many researchers having investigated this field over many years,there are still some open questions, such as how to evaluate a stemmer independently ofthe information retrieval process, or how much a stemmer improves an information retrievalapplication in terms of speed. As a summary, some guidelines are also provided to help\n",
            "\n",
            "---\n",
            "\n",
            "Title: Care episode retrieval: distributional semantic models for information retrieval in the clinical domain\n",
            "Authors: Hans Moen, Filip Ginter, E. Marsi, Laura-Maria Peltonen, T. Salakoski, S. Salanterä\n",
            "Year: 2014\n",
            "Venue: BMC Medical Informatics and Decision Making\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving geographic information retrieval in spatial data infrastructures\n",
            "Authors: Fabio Gomes de Andrade, C. Baptista, C. Davis\n",
            "Year: 2014\n",
            "Venue: GeoInformatica\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: An architectural design for effective information retrieval in semantic web\n",
            "Authors: M. Thangaraj, G. Sujatha\n",
            "Year: 2014\n",
            "Venue: Expert systems with applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Statistical reform in information retrieval?\n",
            "Authors: T. Sakai\n",
            "Year: 2014\n",
            "Venue: SIGF\n",
            "Abstract: IR revolves around evaluation. Therefore, IR researchers should employ sound evaluation practices. Nowadays many of us know that statistical significance testing is not enough, but not all of us know exactly what to do about it. This paper provides suggestions on how to report effect sizes and confidence intervals along with p-values, in the context of comparing IR systems using test collections. Hopefully, these practices will make IR papers more informative, and help researchers form more reliable conclusions that \"add up.\" Finally, I pose a specific question for the IR community: should IR journal editors and SIGIR PC chairs require (rather than encourage) reporting of effect sizes and confidence intervals.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FashionVLP: Vision Language Transformer for Fashion Retrieval with Feedback\n",
            "Authors: Sonam Goenka, Zhao-Heng Zheng, Ayush Jaiswal, Rakesh Chada, Yuehua Wu, Varsha Hedau, P. Natarajan\n",
            "Year: 2022\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Fashion image retrieval based on a query pair of reference image and natural language feedback is a challenging task that requires models to assess fashion related information from visual and textual modalities simultaneously. We propose a new vision-language transformer based model, FashionVLP, that brings the prior knowledge contained in large image-text corpora to the domain of fashion image retrieval, and combines visual information from multiple levels of context to effectively capture fashion-related information. While queries are encoded through the transformer layers, our asymmetric design adopts a novel attention-based approach for fusing target image features without involving text or transformer layers in the process. Extensive results show that FashionVLP achieves the state-of-the-art performance on benchmark datasets, with a large 23% relative improvement on the challenging FashionIQ dataset, which contains complex natural language feedback.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancing learning and retrieval of new information: a review of the forward testing effect\n",
            "Authors: Chunliang Yang, R. Potts, D. Shanks\n",
            "Year: 2018\n",
            "Venue: npj Science of Learning\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ontology-based similarity for product information retrieval\n",
            "Authors: Suriati Akmal, L. Shih, Rafael Batres\n",
            "Year: 2014\n",
            "Venue: Computers in industry (Print)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information\n",
            "Authors: Richa Tanya Jeff Dennis A Colleen Evan Devon J Rodney St Agarwala Barrett Beck Benson Bollin Bolton Bourexi, R. Agarwala, T. Barrett, J. Beck, Dennis A. Benson, Colleen J. Bollin, Evan E. Bolton, Devon Bourexis, J. R. Brister, S. Bryant, Kathi Canese, Mark Cavanaugh, Chad Charowhas, Karen Clark, I. Dondoshansky, M. Feolo, Lawrence Fitzpatrick, Kathryn Funk, Lewis Y. Geer, V. Gorelenkov, Alan Graeff, W. Hlavina, Brad Holmes, Mark Johnson, B. Kattman, Viatcheslav Khotomlianski, Avi Kimchi, Michael Kimelman, Masato Kimura, P. Kitts, W. Klimke, A. Kotliarov, S. Krasnov, A. Kuznetsov, M. Landrum, D. Landsman, S. Lathrop, Jennifer M. Lee, Carl Leubsdorf, Zhiyong Lu, Thomas L. Madden, Aron Marchler-Bauer, Adriana Malheiro, Peter A. Meric, I. Karsch-Mizrachi, Anatoly Mnev, Terence D. Murphy, R. Orris, J. Ostell, Christopher O'Sullivan, Vasuki Palanigobu, A. Panchenko, Lon Phan, Borys Pierov, K. Pruitt, K. Rodarmer, E. Sayers, Valerie A. Schneider, C. Schoch, G. Schuler, S. Sherry, Karanjit Siyan, Alexandra Soboleva, Vladimir Soussov, G. Starchenko, T. Tatusova, F. Thibaud-Nissen, K. Todorov, B. Trawick, D. Vakatov, Minghong Ward, E. Yaschenko, A. Zasypkin, Kerry Zbicz\n",
            "Year: 2017\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: Abstract The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. The Entrez system provides search and retrieval operations for most of these data from 39 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. New resources released in the past year include PubMed Data Management, RefSeq Functional Elements, genome data download, variation services API, Magic-BLAST, QuickBLASTp, and Identical Protein Groups. Resources that were updated in the past year include the genome data viewer, a human genome resources page, Gene, virus variation, OSIRIS, and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Kurdish Information Retrieval\n",
            "Authors: K. S. Esmaili, Shahin Salavati, Anwitaman Datta\n",
            "Year: 2014\n",
            "Venue: ACM Transactions on Asian Language Information Processing\n",
            "Abstract: The Kurdish language is an Indo-European language spoken in Kurdistan, a large geographical region in the Middle East. Despite having a large number of speakers, Kurdish is among the less-resourced languages and has not seen much attention from the IR and NLP research communities. This article reports on the outcomes of a project aimed at providing essential resources for processing Kurdish texts. A principal output of this project is Pewan, the first standard Test Collection to evaluate Kurdish Information Retrieval systems. The other language resources that we have built include a lightweight stemmer and a list of stopwords. Our second principal contribution is using these newly-built resources to conduct a thorough experimental study on Kurdish documents. Our experimental results show that normalization, and to a lesser extent, stemming, can greatly improve the performance of Kurdish IR systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Latent Retrieval for Weakly Supervised Open Domain Question Answering\n",
            "Authors: Kenton Lee, Ming-Wei Chang, Kristina Toutanova\n",
            "Year: 2019\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Lightweight Multi-Scale Crossmodal Text-Image Retrieval Method in Remote Sensing\n",
            "Authors: Zhiqiang Yuan, Wenkai Zhang, Xuee Rong, Xuan Li, Jialiang Chen, Hongqi Wang, Kun Fu, Xian Sun\n",
            "Year: 2022\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: Remote sensing (RS) crossmodal text-image retrieval has become a research hotspot in recent years for its application in semantic localization. However, since multiple inferences on slices are demanded in semantic localization, designing a crossmodal retrieval model with less computation but well performance becomes an emergent and challenging task. In this article, considering the characteristics of multi-scale and target redundancy in RS, a concise but effective crossmodal retrieval model (LW-MCR) is designed. The proposed model incorporates multi-scale information and dynamically filters out redundant features when encoding RS image, while text features are obtained via lightweight group convolution. To improve the retrieval performance of LW-MCR, we come up with a novel hidden supervised optimization method based on knowledge distillation. This method enables the proposed model to acquire dark knowledge of the multi-level layers and representation layers in the teacher network, which significantly improves the accuracy of our lightweight model. Finally, on the basis of contrast learning, we present a method employing unlabeled data to boost the performance of RS retrieval model further. The experiment results on four RS image-text datasets demonstrate the efficiency of LW-MCR in RS crossmodal retrieval (RSCR) tasks. We have released some codes of the semantic localization and made it open to access at https://github.com/xiaoyuan1996/retrievalSystem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction\n",
            "Authors: Xinyu Ma, J. Guo, Ruqing Zhang, Yixing Fan, Xueqi Cheng\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Dense retrieval has shown promising results in many information retrieval (IR) related tasks, whose foundation is high-quality text representation learning for effective search. Some recent studies have shown that autoencoder-based language models are able to boost the dense retrieval performance using a weak decoder. However, we argue that 1) it is not discriminative to decode all the input texts and, 2) even a weak decoder has the bypass effect on the encoder. Therefore, in this work, we introduce a novel contrastive span prediction task to pre-train the encoder alone, but still retain the bottleneck ability of the autoencoder. In this way, we can 1) learn discriminative text representations efficiently with the group-wise contrastive learning over spans and, 2) avoid the bypass effect of the decoder thoroughly. Comprehensive experiments over publicly available retrieval benchmark datasets show that our approach can outperform existing pre-training methods for dense retrieval significantly.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Codes for Information Retrieval With Small Uncertainty\n",
            "Authors: Ville Junnila, T. Laihonen\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: In a recent paper by Yaakobi and Bruck, the problem of information retrieval in associative memories has been considered. In an associative memory, each memory entry is associated to the neighboring entries. When searching information, a fixed number of input clues are given and the output set is formed by the entries associated to all the input clues. The maximum size of an output set is called the uncertainty of the associative memory. In this paper, we study the problem of information retrieval in associative memories with small uncertainty. In particular, we concentrate on the cases where the memory entries and their associations form a binary Hamming space or an infinite square grid. Particularly, we focus on minimizing the number of input clues needed to retrieve information with small uncertainty and present good constructions some of which are optimal, i.e., use the smallest possible number of clues.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic information retrieval research based on co-occurrence analysis\n",
            "Authors: Wen-Heng Lou, Junping Qiu\n",
            "Year: 2014\n",
            "Venue: Online information review (Print)\n",
            "Abstract: Purpose – The paper aims to develop a new method for potential relations retrieval. It aims to find common aspects between co-occurrence analysis and ontology to build a model of semantic information retrieval based on co-occurrence analysis. Design/methodology/approach – This paper used a literature review, co-occurrence analysis, ontology build and other methods to design a model and process of semantic information retrieval based on co-occurrence analysis. Archaeological data from Wuhan University Library's bibliographic retrieval systems was used for experimental analysis. Findings – The literature review found that semantic information retrieval research mainly concentrates on ontology-based query techniques, semantic annotation and semantic relation retrieval. Moreover most recent systems can only achieve obvious relations retrieval. Ontology and co-occurrence analysis have strong similarities in theoretical ideas, data types, expressions, and applications. Research limitations/implications – The ex...\n",
            "\n",
            "---\n",
            "\n",
            "Title: VIRLab: a web-based virtual lab for learning and studying information retrieval models\n",
            "Authors: Hui Fang, Hao Wu, Peilin Yang, ChengXiang Zhai\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In this paper, we describe VIRLab, a novel web-based virtual laboratory for Information Retrieval (IR). Unlike existing command line based IR toolkits, the VIRLab system provides a more interactive tool that enables easy implementation of retrieval functions with only a few lines of codes, simplified evaluation process over multiple data sets and parameter settings and straightforward result analysis interface through operational search engines and pair-wise comparisons. These features make VIRLab a unique and novel tool that can help teaching IR models, improving the productivity for doing IR model research, as well as promoting controlled experimental study of IR models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Autoregressive Entity Retrieval\n",
            "Authors: Nicola De Cao, Gautier Izacard, Sebastian Riedel, F. Petroni\n",
            "Year: 2020\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Entities are at the center of how we represent and aggregate knowledge. For instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one per article). The ability to retrieve such entities given a query is fundamental for knowledge-intensive tasks such as entity linking and open-domain question answering. One way to understand current approaches is as classifiers among atomic labels, one for each entity. Their weight vectors are dense entity representations produced by encoding entity information such as descriptions. This approach leads to several shortcomings: i) context and entity affinity is mainly captured through a vector dot product, potentially missing fine-grained interactions between the two; ii) a large memory footprint is needed to store dense representations when considering large entity sets; iii) an appropriately hard set of negative data has to be subsampled at training time. We propose GENRE, the first system that retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion, and conditioned on the context. This enables to mitigate the aforementioned technical issues: i) the autoregressive formulation allows us to directly capture relations between context and entity name, effectively cross encoding both; ii) the memory footprint is greatly reduced because the parameters of our encoder-decoder architecture scale with vocabulary size, not entity count; iii) the exact softmax loss can be efficiently computed without the need to subsample negative data. We show the efficacy of the approach with more than 20 datasets on entity disambiguation, end-to-end entity linking and document retrieval tasks, achieving new SOTA, or very competitive results while using a tiny fraction of the memory of competing systems. Finally, we demonstrate that new entities can be added by simply specifying their unambiguous name.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Statistical Significance Testing in Information Retrieval: Theory and Practice\n",
            "Authors: Ben Carterette\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The past 20 years have seen a great improvement in the rigor of information retrieval experimentation, due primarily to two factors: high-quality, public, portable test collections such as those produced by TREC (the Text REtrieval Conference [28]), and the increased practice of sta- tistical hypothesis testing to determine whether measured improvements can be ascribed to something other than random chance. Together these create a very useful standard for reviewers, program committees, and journal editors; work in information retrieval (IR) increasingly cannot be published unless it has been evaluated using a well-constructed test collection and shown to produce a statistically significant improvement over a good baseline. But, as the saying goes, any tool sharp enough to be useful is also sharp enough to be dangerous. Statistical tests of significance are widely misunderstood. Most researchers and developers treat them as a \"black box\": evaluation results go in and a p-value comes out. But because significance is such an important factor in determining what research directions to explore and what is published, using p-values obtained without thought can have consequences for everyone doing research in IR. Ioannidis has argued that the main consequence in the biomedical sciences is that most published research findings are false [12]; could that be the case in IR as well?\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Use of Arabic WordNet in Arabic Information Retrieval\n",
            "Authors: Ahmed Abbache, F. Barigou, Fatma Zohra Belkredim, Ghalem Belalem\n",
            "Year: 2014\n",
            "Venue: International Journal of Information Retrieval Research\n",
            "Abstract: Research and experimentation using Arabic WordNet in the field of information retrieval are relatively new. It is limited compared to the research that has been done using Princeton WordNet. This work attempts to study the impact of Arabic WordNet on the performance of Arabic information retrieval. We extend Lucene with Arabic WordNet to expand user's queries. The major contribution of this study is to propose an interactive query expansion IQE methodology using the word's part-of-speech, according to the part it plays in a query. First, the user selects the appropriate part of speech for each term in the original query, and then he reselects the appropriate synonyms. Experimental results show that our IQE strategy produces a good Mean Average Precision MAP, it is able to improve MAP by 12.6%, but no variant of automatic query expansion AQE strategies did. Nevertheless, the experiments allow us to conclude that with an appropriate use of Arabic WordNet as a source of linguistic information for AQE can improve effectiveness for Arabic information retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation\n",
            "Authors: Sebastian Hofstätter, Jiecao Chen, K. Raman, Hamed Zamani\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Retrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. In this work, we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. Our FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. Our experiments on a diverse set of seven knowledge intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier between query latency and effectiveness. FiD-Light with source pointing sets substantial new state-of-the-art results on six KILT tasks for combined text generation and provenance retrieval evaluation, while maintaining high efficiency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An analysis of query difficulty for information retrieval in the medical domain\n",
            "Authors: Lorraine Goeuriot, Liadh Kelly, Johannes Leveling\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We present a post-hoc analysis of a benchmarking activity for information retrieval (IR) in the medical domain to determine if performance for queries with different levels of complexity can be associated with different IR methods or techniques. Our analysis is based on data and runs for Task 3 of the CLEF 2013 eHealth lab, which provided patient queries and a large medical document collection for patient centred medical information retrieval technique development. We categorise the queries based on their complexity, which is defined as the number of medical concepts they contain. We then show how query complexity affects performance of runs submitted to the lab, and provide suggestions for improving retrieval quality for this complex retrieval task and similar IR evaluation tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Flowchart recognition for non-textual information retrieval in patent search\n",
            "Authors: Marçal Rusiñol, Lluís-Pere de las Heras, O. R. Terrades\n",
            "Year: 2014\n",
            "Venue: Information retrieval (Boston)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Advances in Information Retrieval\n",
            "Authors: C. Wilkie, Leif Azzopardi\n",
            "Year: 2014\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Information Retrieval Ontology for Information Retrieval Nanopublications\n",
            "Authors: Aldo Lipani, Florina Piroi, Linda Andersson, A. Hanbury\n",
            "Year: 2014\n",
            "Venue: Conference and Labs of the Evaluation Forum\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Divergent Routing of Positive and Negative Information from the Amygdala during Memory Retrieval\n",
            "Authors: A. Beyeler, P. Namburi, Gordon F. Glober, Clémence Simonnet, G. G. Calhoon, Garrett F. Conyers, Robert Luck, Craig P. Wildes, K. Tye\n",
            "Year: 2016\n",
            "Venue: Neuron\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pre-training Tasks for Embedding-based Large-scale Retrieval\n",
            "Authors: Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar\n",
            "Year: 2020\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: We consider the large-scale query-document retrieval problem: given a query (e.g., a question), return the set of relevant documents (e.g., paragraphs containing the answer) from a large document corpus. This problem is often solved in two steps. The retrieval phase first reduces the solution space, returning a subset of candidate documents. The scoring phase then re-ranks the documents. Critically, the retrieval algorithm not only desires high recall but also requires to be highly efficient, returning candidates in time sublinear to the number of documents. Unlike the scoring phase witnessing significant advances recently due to the BERT-style pre-training tasks on cross-attention models, the retrieval phase remains less well studied. Most previous works rely on classic Information Retrieval (IR) methods such as BM-25 (token matching + TF-IDF weights). These models only accept sparse handcrafted features and can not be optimized for different downstream tasks of interest. In this paper, we conduct a comprehensive study on the embedding-based retrieval models. We show that the key ingredient of learning a strong embedding-based Transformer model is the set of pre-training tasks. With adequately designed paragraph-level pre-training tasks, the Transformer models can remarkably improve over the widely-used BM-25 as well as embedding models without Transformers. The paragraph-level pre-training tasks we studied are Inverse Cloze Task (ICT), Body First Selection (BFS), Wiki Link Prediction (WLP), and the combination of all three.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval\n",
            "Authors: Mengjun Cheng, Yipeng Sun, Long Wang, Xiongwei Zhu, Kun Yao, Jie Chen, Guoli Song, Junyu Han, Jingtuo Liu, Errui Ding, Jingdong Wang\n",
            "Year: 2022\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Visual appearance is considered to be the most important cue to understand images for cross-modal retrieval, while sometimes the scene text appearing in images can provide valuable information to understand the visual semantics. Most of existing cross-modal retrieval approaches ignore the usage of scene text information and directly adding this information may lead to performance degradation in scene text free scenarios. To address this issue, we propose a full transformer architecture to unify these cross-modal retrieval scenarios in a single Vision and Scene Text Aggregation framework (ViSTA). Specifically, ViSTA utilizes transformer blocks to directly encode image patches and fuse scene text embedding to learn an aggregated visual representation for cross-modal retrieval. To tackle the modality missing problem of scene text, we propose a novel fusion token based transformer aggregation approach to exchange the necessary scene text information only through the fusion token and concentrate on the most important features in each modality. To further strengthen the visual modality, we develop dual contrastive learning losses to embed both image-text pairs and fusion-text pairs into a common cross-modal space. Compared to existing methods, ViSTA enables to aggregate relevant scene text semantics with visual appearance, and hence improve results under both scene text free and scene text aware scenarios. Experimental results show that ViSTA outperforms other methods by at least 8.4% at Recall@ 1 for scene text aware retrieval task. Compared with state-of-the-art scene text free retrieval methods, ViSTA can achieve better accuracy on Flicker30K and MSCOCO while running at least three times faster during the inference stage, which validates the effectiveness of the proposed framework.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval-Enhanced Machine Learning\n",
            "Authors: Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, Michael Bendersky\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Although information access systems have long supportedpeople in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. In this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. We describe a generic retrieval-enhanced machine learning (REML) framework, which includes a number of existing models as special cases. REML challenges information retrieval conventions, presenting opportunities for novel advances in core areas, including optimization. The REML research agenda lays a foundation for a new style of information access research and paves a path towards advancing machine learning and artificial intelligence.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Metric Spaces for Temporal Information Retrieval\n",
            "Authors: Matteo Brucato, D. Montesi\n",
            "Year: 2014\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization\n",
            "Authors: Amin Abolghasemi, S. Verberne, L. Azzopardi\n",
            "Year: 2022\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Power of Noise: Redefining Retrieval for RAG Systems\n",
            "Authors: Florin Cuconasu, Giovanni Trappolini, F. Siciliano, Simone Filice, Cesare Campagnano, Y. Maarek, Nicola Tonellotto, Fabrizio Silvestri\n",
            "Year: 2024\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Transfer Learning Approaches for Building Cross-Language Dense Retrieval Models\n",
            "Authors: Suraj Nair, Eugene Yang, Dawn J Lawrie, Kevin Duh, Paul McNamee, Kenton Murray, J. Mayfield, Douglas W. Oard\n",
            "Year: 2022\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information fusion in content based image retrieval: A comprehensive overview\n",
            "Authors: Luca Piras, G. Giacinto\n",
            "Year: 2017\n",
            "Venue: Information Fusion\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Distributed retrieval practice promotes superior recall of anatomy information\n",
            "Authors: John L. Dobson, Jose Perez, Tracy Linderholm\n",
            "Year: 2017\n",
            "Venue: Anatomical Sciences Education\n",
            "Abstract: Effortful retrieval produces greater long‐term recall of information when compared to studying (i.e., reading), as do learning sessions that are distributed (i.e., spaced apart) when compared to those that are massed together. Although the retrieval and distributed practice effects are well‐established in the cognitive science literature, no studies have examined their additive effect with regard to learning anatomy information. The aim of this study was to determine how the benefits of retrieval practice vary with massed versus distributed learning. Participants used the following strategies to learn sets of skeletal muscle anatomy: (1) studying on three different days over a seven day period (SSSS7,2,0), (2) studying and retrieving on three different days over a seven day period (SRSR7,2,0), (3) studying on two different days over a two day period (SSSSSS2,0), (4) studying and retrieving on two separate days over a two day period (SRSRSR2,0), and (5) studying and retrieving on one day (SRx60). All strategies consisted of 12 learning phases and lasted exactly 24 minutes. Muscle information retention was assessed via free recall and using repeated measures ANOVAs. A week after learning, the recall scores were 24.72 ± 3.12, 33.88 ± 3.48, 15.51 ± 2.48, 20.72 ± 2.94, and 12.86 ± 2.05 for the SSSS7,2,0, SRSR7,2,0, SSSSSS2,0, STSTST2,0, and SRx60 strategies, respectively. In conclusion, the distributed strategies produced significantly better recall than the massed strategies, the retrieval‐based strategies produced significantly better recall than the studying strategies, and the combination of distributed and retrieval practice generated the greatest recall of anatomy information. Anat Sci Educ 10: 339–347. © 2016 American Association of Anatomists.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Where Does the Performance Improvement Come From?: - A Reproducibility Concern about Image-Text Retrieval\n",
            "Authors: Jun Rao, Fei Wang, Liang Ding, Shuhan Qi, Yibing Zhan, Weifeng Liu, D. Tao\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This article aims to provide the information retrieval community with some reflections on recent advances in retrieval learning by analyzing the reproducibility of image-text retrieval models. Due to the increase of multimodal data over the last decade, image-text retrieval has steadily become a major research direction in the field of information retrieval. Numerous researchers train and evaluate image-text retrieval algorithms using benchmark datasets such as MS-COCO and Flickr30k. Research in the past has mostly focused on performance, with multiple state-of-the-art methodologies being suggested in a variety of ways. According to their assertions, these techniques provide improved modality interactions and hence more precise multimodal representations. In contrast to previous works, we focus on the reproducibility of the approaches and the examination of the elements that lead to improved performance by pretrained and nonpretrained models in retrieving images and text. To be more specific, we first examine the related reproducibility concerns and explain why our focus is on image-text retrieval tasks. Second, we systematically summarize the current paradigm of image-text retrieval models and the stated contributions of those approaches. Third, we analyze various aspects of the reproduction of pretrained and nonpretrained retrieval models. To complete this, we conducted ablation experiments and obtained some influencing factors that affect retrieval recall more than the improvement claimed in the original paper. Finally, we present some reflections and challenges that the retrieval community should consider in the future. Our source code is publicly available at https://github.com/WangFei-2019/Image-text-Retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dynamic Modality Interaction Modeling for Image-Text Retrieval\n",
            "Authors: Leigang Qu, Meng Liu, Jianlong Wu, Zan Gao, Liqiang Nie\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Image-text retrieval is a fundamental and crucial branch in information retrieval. Although much progress has been made in bridging vision and language, it remains challenging because of the difficult intra-modal reasoning and cross-modal alignment. Existing modality interaction methods have achieved impressive results on public datasets. However, they heavily rely on expert experience and empirical feedback towards the design of interaction patterns, therefore, lacking flexibility. To address these issues, we develop a novel modality interaction modeling network based upon the routing mechanism, which is the first unified and dynamic multimodal interaction framework towards image-text retrieval. In particular, we first design four types of cells as basic units to explore different levels of modality interactions, and then connect them in a dense strategy to construct a routing space. To endow the model with the capability of path decision, we integrate a dynamic router in each cell for pattern exploration. As the routers are conditioned on inputs, our model can dynamically learn different activated paths for different data. Extensive experiments on two benchmark datasets, i.e., Flickr30K and MS-COCO, verify the superiority of our model compared with several state-of-the-art baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DSSL: Deep Surroundings-person Separation Learning for Text-based Person Retrieval\n",
            "Authors: A. Zhu, Zijie Wang, Yifeng Li, Xili Wan, Jing Jin, Tian Wang, Fangqiang Hu, G. Hua\n",
            "Year: 2021\n",
            "Venue: ACM Multimedia\n",
            "Abstract: Many previous methods on text-based person retrieval tasks are devoted to learning a latent common space mapping, with the purpose of extracting modality-invariant features from both visual and textual modality. Nevertheless, due to the complexity of high-dimensional data, the unconstrained mapping paradigms are not able to properly catch discriminative clues about the corresponding person while drop the misaligned information. Intuitively, the information contained in visual data can be divided into person information (PI) and surroundings information (SI), which are mutually exclusive from each other. To this end, we propose a novel Deep Surroundings-person Separation Learning (DSSL) model in this paper to effectively extract and match person information, and hence achieve a superior retrieval accuracy. A surroundings-person separation and fusion mechanism plays the key role to realize an accurate and effective surroundings-person separation under a mutually exclusion constraint. In order to adequately utilize multi-modal and multi-granular information for a higher retrieval accuracy, five diverse alignment paradigms are adopted. Extensive experiments are carried out to evaluate the proposed DSSL on CUHK-PEDES, which is currently the only accessible dataset for text-base person retrieval task. DSSL achieves the state-of-the-art performance on CUHK-PEDES. To properly evaluate our proposed DSSL in the real scenarios, a Real Scenarios Text-based Person Reidentification (RSTPReid) dataset is constructed to benefit future research on text-based person retrieval, which will be publicly available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval-based Neural Source Code Summarization\n",
            "Authors: Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Xudong Liu\n",
            "Year: 2020\n",
            "Venue: International Conference on Software Engineering\n",
            "Abstract: Source code summarization aims to automatically generate concise summaries of source code in natural language texts, in order to help developers better understand and maintain source code. Traditional work generates a source code summary by utilizing information retrieval techniques, which select terms from original source code or adapt summaries of similar code snippets. Recent studies adopt Neural Machine Translation techniques and generate summaries from code snippets using encoder-decoder neural networks. The neural-based approaches prefer the high-frequency words in the corpus and have trouble with the low-frequency ones. In this paper, we propose a retrieval-based neural source code summarization approach where we enhance the neural model with the most similar code snippets retrieved from the training set. Our approach can take advantages of both neural and retrieval-based techniques. Specifically, we first train an attentional encoder-decoder model based on the code snippets and the summaries in the training set; Second, given one input code snippet for testing, we retrieve its two most similar code snippets in the training set from the aspects of syntax and semantics, respectively; Third, we encode the input and two retrieved code snippets, and predict the summary by fusing them during decoding. We conduct extensive experiments to evaluate our approach and the experimental results show that our proposed approach can improve the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Use What You Have: Video retrieval using representations from collaborative experts\n",
            "Authors: Yang Liu, Samuel Albanie, Arsha Nagrani, Andrew Zisserman\n",
            "Year: 2019\n",
            "Venue: British Machine Vision Conference\n",
            "Abstract: The rapid growth of video on the internet has made searching for video content using natural language queries a significant challenge. Human-generated queries for video datasets `in the wild' vary a lot in terms of degree of specificity, with some queries describing specific details such as the names of famous identities, content from speech, or text available on the screen. Our goal is to condense the multi-modal, extremely high dimensional information from videos into a single, compact video representation for the task of video retrieval using free-form text queries, where the degree of specificity is open-ended. \n",
            "For this we exploit existing knowledge in the form of pre-trained semantic embeddings which include 'general' features such as motion, appearance, and scene features from visual content. We also explore the use of more 'specific' cues from ASR and OCR which are intermittently available for videos and find that these signals remain challenging to use effectively for retrieval. We propose a collaborative experts model to aggregate information from these different pre-trained experts and assess our approach empirically on five retrieval benchmarks: MSR-VTT, LSMDC, MSVD, DiDeMo, and ActivityNet. Code and data can be found at this http URL. This paper contains a correction to results reported in the previous version.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Multi-View Enhancement Hashing for Image Retrieval\n",
            "Authors: C. Yan, Biao Gong, Yuxuan Wei, Yue Gao\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "Abstract: Hashing is an efficient method for nearest neighbor search in large-scale data space by embedding high-dimensional feature descriptors into a similarity preserving Hamming space with a low dimension. However, large-scale high-speed retrieval through binary code has a certain degree of reduction in retrieval accuracy compared to traditional retrieval methods. We have noticed that multi-view methods can well preserve the diverse characteristics of data. Therefore, we try to introduce the multi-view deep neural network into the hash learning field, and design an efficient and innovative retrieval model, which has achieved a significant improvement in retrieval performance. In this paper, we propose a supervised multi-view hash model which can enhance the multi-view information through neural networks. This is a completely new hash learning method that combines multi-view and deep learning methods. The proposed method utilizes an effective view stability evaluation method to actively explore the relationship among views, which will affect the optimization direction of the entire network. We have also designed a variety of multi-data fusion methods in the Hamming space to preserve the advantages of both convolution and multi-view. In order to avoid excessive computing resources on the enhancement procedure during retrieval, we set up a separate structure called memory network which participates in training together. The proposed method is systematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and the results show that our method significantly outperforms the state-of-the-art single-view and multi-view hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Episodic Memory Retrieval Functionally Relies on Very Rapid Reactivation of Sensory Information\n",
            "Authors: G. Waldhauser, Verena Braun, S. Hanslmayr\n",
            "Year: 2016\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Episodic memory retrieval is assumed to rely on the rapid reactivation of sensory information that was present during encoding, a process termed “ecphory.” We investigated the functional relevance of this scarcely understood process in two experiments in human participants. We presented stimuli to the left or right of fixation at encoding, followed by an episodic memory test with centrally presented retrieval cues. This allowed us to track the reactivation of lateralized sensory memory traces during retrieval. Successful episodic retrieval led to a very early (∼100–200 ms) reactivation of lateralized alpha/beta (10–25 Hz) electroencephalographic (EEG) power decreases in the visual cortex contralateral to the visual field at encoding. Applying rhythmic transcranial magnetic stimulation to interfere with early retrieval processing in the visual cortex led to decreased episodic memory performance specifically for items encoded in the visual field contralateral to the site of stimulation. These results demonstrate, for the first time, that episodic memory functionally relies on very rapid reactivation of sensory information. SIGNIFICANCE STATEMENT Remembering personal experiences requires a “mental time travel” to revisit sensory information perceived in the past. This process is typically described as a controlled, relatively slow process. However, by using electroencephalography to measure neural activity with a high time resolution, we show that such episodic retrieval entails a very rapid reactivation of sensory brain areas. Using transcranial magnetic stimulation to alter brain function during retrieval revealed that this early sensory reactivation is causally relevant for conscious remembering. These results give first neural evidence for a functional, preconscious component of episodic remembering. This provides new insight into the nature of human memory and may help in the understanding of psychiatric conditions that involve the automatic intrusion of unwanted memories.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LibGuides: Guide to information retrieval: Executing information retrieval\n",
            "Authors: Harri Maikola\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval\n",
            "Authors: Lawrence Herbert Berul\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Identifying and exploiting target entity type information for ad hoc entity retrieval\n",
            "Authors: Darío Garigliotti, Faegheh Hasibi, K. Balog\n",
            "Year: 2018\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploring User-Specific Information in Music Retrieval\n",
            "Authors: Zhiyong Cheng, Jialie Shen, Liqiang Nie, Tat-Seng Chua, M. Kankanhalli\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: With the advancement of mobile computing technology and cloud-based streaming music service, user-centered music retrieval has become increasingly important. User-specific information has a fundamental impact on personal music preferences and interests. However, existing research pays little attention to the modeling and integration of user-specific information in music retrieval algorithms/models to facilitate music search. In this paper, we propose a novel model, named User-Information-Aware Music Interest Topic (UIA-MIT) model. The model is able to effectively capture the influence of user-specific information on music preferences, and further associate users' music preferences and search terms under the same latent space. Based on this model, a user information aware retrieval system is developed, which can search and re-rank the results based on age- and/or gender-specific music preferences. A comprehensive experimental study demonstrates that our methods can significantly improve the search accuracy over existing text-based music retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Large-Scale Retrieval for Reinforcement Learning\n",
            "Authors: P. Humphreys, A. Guez, O. Tieleman, L. Sifre, T. Weber, T. Lillicrap\n",
            "Year: 2022\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Effective decision making involves flexibly relating past experiences and relevant contextual information to a novel situation. In deep reinforcement learning (RL), the dominant paradigm is for an agent to amortise information that helps decision making into its network weights via gradient descent on training losses. Here, we pursue an alternative approach in which agents can utilise large-scale context sensitive database lookups to support their parametric computations. This allows agents to directly learn in an end-to-end manner to utilise relevant information to inform their outputs. In addition, new information can be attended to by the agent, without retraining, by simply augmenting the retrieval dataset. We study this approach for offline RL in 9x9 Go, a challenging game for which the vast combinatorial state space privileges generalisation over direct matching to past experiences. We leverage fast, approximate nearest neighbor techniques in order to retrieve relevant data from a set of tens of millions of expert demonstration states. Attending to this information provides a significant boost to prediction accuracy and game-play performance over simply using these demonstrations as training trajectories, providing a compelling demonstration of the value of large-scale retrieval in offline RL agents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Particular object retrieval with integral max-pooling of CNN activations\n",
            "Authors: Giorgos Tolias, R. Sicre, H. Jégou\n",
            "Year: 2015\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Recently, image representation built upon Convolutional Neural Network (CNN) has been shown to provide effective descriptors for image search, outperforming pre-CNN features as short-vector representations. Yet such models are not compatible with geometry-aware re-ranking methods and still outperformed, on some particular object retrieval benchmarks, by traditional image search systems relying on precise descriptor matching, geometric re-ranking, or query expansion. This work revisits both retrieval stages, namely initial search and re-ranking, by employing the same primitive information derived from the CNN. We build compact feature vectors that encode several image regions without the need to feed multiple inputs to the network. Furthermore, we extend integral images to handle max-pooling on convolutional layer activations, allowing us to efficiently localize matching objects. The resulting bounding box is finally used for image re-ranking. As a result, this paper significantly improves existing CNN-based recognition pipeline: We report for the first time results competing with traditional methods on the challenging Oxford5k and Paris6k datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval\n",
            "Authors: Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, Barlas Oğuz\n",
            "Year: 2020\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CoSMo: Content-Style Modulation for Image Retrieval with Text Feedback\n",
            "Authors: Seung-Min Lee, Dongwan Kim, Bohyung Han\n",
            "Year: 2021\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: We tackle the task of image retrieval with text feedback, where a reference image and modifier text are combined to identify the desired target image. We focus on designing an image-text compositor, i.e., integrating multi-modal inputs to produce a representation similar to that of the target image. In our algorithm, Content-Style Modulation (CoSMo), we approach this challenge by introducing two modules based on deep neural networks: the content and style modulators. The content modulator performs local updates to the reference image feature after normalizing the style of the image, where a disentangled multi-modal non-local block is employed to achieve the desired content modifications. Then, the style modulator reintroduces global style information to the updated feature. We provide an in-depth view of our algorithm and its design choices, and show that it accomplishes outstanding performance on multiple image-text retrieval benchmarks. Our code can be found at: https://github.com/postBG/CosMo.pytorch\n",
            "\n",
            "---\n",
            "\n",
            "Title: Case Retrieval in Medical Databases by Fusing Heterogeneous Information\n",
            "Authors: G. Quellec, M. Lamard, G. Cazuguel, C. Roux, B. Cochener\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Medical Imaging\n",
            "Abstract: A novel content-based heterogeneous information retrieval framework, particularly well suited to browse medical databases and support new generation computer aided diagnosis (CADx) systems, is presented in this paper. It was designed to retrieve possibly incomplete documents, consisting of several images and semantic information, from a database; more complex data types such as videos can also be included in the framework. The proposed retrieval method relies on image processing, in order to characterize each individual image in a document by their digital content, and information fusion. Once the available images in a query document are characterized, a degree of match, between the query document and each reference document stored in the database, is defined for each attribute (an image feature or a metadata). A Bayesian network is used to recover missing information if need be. Finally, two novel information fusion methods are proposed to combine these degrees of match, in order to rank the reference documents by decreasing relevance for the query. In the first method, the degrees of match are fused by the Bayesian network itself. In the second method, they are fused by the Dezert-Smarandache theory: the second approach lets us model our confidence in each source of information (i.e., each attribute) and take it into account in the fusion process for a better retrieval performance. The proposed methods were applied to two heterogeneous medical databases, a diabetic retinopathy database and a mammography screening database, for computer aided diagnosis. Precisions at five of 0.809 ± 0.158 and 0.821 ± 0.177, respectively, were obtained for these two databases, which is very promising.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Lucene for Information Access and Retrieval Research (LIARR) Workshop at SIGIR 2017\n",
            "Authors: L. Azzopardi, Matt Crane, Hui Fang, Grant Ingersoll, Jimmy J. Lin, Yashar Moshfeghi, Harrisen Scells, Peilin Yang, G. Zuccon\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: As an empirical discipline, information access and retrieval research requires substantial software infrastructure to index and search large collections. This workshop is motivated by the desire to better align information retrieval research with the practice of building search applications from the perspective of open-source information retrieval systems. Our goal is to promote the use of Lucene for information access and retrieval research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PyTerrier: Declarative Experimentation in Python from BM25 to Dense Retrieval\n",
            "Authors: Craig Macdonald, N. Tonellotto, Sean MacAvaney, I. Ounis\n",
            "Year: 2021\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: PyTerrier is a Python-based retrieval framework for expressing simple and complex information retrieval (IR) pipelines in a declarative manner. While making use of the long-established Terrier IR platform for basic text indexing and retrieval, its salient utility comes from its expressive Python operators, which allow for individual IR operations to be pipelined and combined in different flexible manners as requested by the search application. Each operation applies a transformation upon a dataframe, while operators are defined with clear semantics in relational algebra. Going further, we have recently expanded the PyTerrier framework to include additional support for state-of-the-art BERT-based text re-rankers (such as EPIC) and dense retrieval implementations (such as ANCE and ColBERT). Transformer pipelines can be tuned and evaluated in a declarative manner. To increase the reusability of this framework as a resource for the IR community, PyTerrier provides easy access to a variety of standard benchmark datasets, including pre-built indices. Finally, we highlight the advantages of such a framework for information retrieval researchers and educators.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase Retrieval from Incomplete Magnitude Information via Total Variation Regularization\n",
            "Authors: Huibin Chang, Y. Lou, M. Ng, T. Zeng\n",
            "Year: 2016\n",
            "Venue: SIAM Journal on Scientific Computing\n",
            "Abstract: The phase retrieval problem has drawn considerable attention, as many optical detection devices can only measure magnitudes of the Fourier transform of the underlying object (signal or image). This paper addresses the phase retrieval problem from incomplete data, where only partial magnitudes of Fourier transform are obtained. In particular, we consider structured illuminated patterns in holography and find that noninteger values used in designing such patterns often yield better reconstruction than the conventional integer-valued ones. Furthermore, we demonstrate theoretically and numerically that three diffracted sets of (complete) magnitude data are sufficient to recover the object. To compensate for incomplete information, we incorporate a total variation regularization a priori to guarantee that the reconstructed image satisfies some desirable properties. The proposed model can be solved efficiently by an alternative directional multiplier method with provable convergence. Numerical experiments valid...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval of ice cloud properties using an optimal estimation algorithm and MODIS infrared observations: 1. Forward model, error analysis, and information content\n",
            "Authors: Chenxi Wang, S. Platnick, Zhibo Zhang, K. Meyer, P. Yang\n",
            "Year: 2016\n",
            "Venue: Journal of Geophysical Research - Atmospheres\n",
            "Abstract: An optimal estimation (OE) retrieval method is developed to infer three ice cloud properties simultaneously: optical thickness (τ), effective radius (reff), and cloud top height (h). This method is based on a fast radiative transfer (RT) model and infrared (IR) observations from the MODerate resolution Imaging Spectroradiometer (MODIS). This study conducts thorough error and information content analyses to understand the error propagation and performance of retrievals from various MODIS band combinations under different cloud/atmosphere states. Specifically, the algorithm takes into account four error sources: measurement uncertainty, fast RT model uncertainty, uncertainties in ancillary data sets (e.g., atmospheric state), and assumed ice crystal habit uncertainties. It is found that the ancillary and ice crystal habit error sources dominate the MODIS IR retrieval uncertainty and cannot be ignored. The information content analysis shows that for a given ice cloud, the use of four MODIS IR observations is sufficient to retrieve the three cloud properties. However, the selection of MODIS IR bands that provide the most information and their order of importance varies with both the ice cloud properties and the ambient atmospheric and the surface states. As a result, this study suggests the inclusion of all MODIS IR bands in practice since little a priori information is available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Video Corpus Moment Retrieval with Contrastive Learning\n",
            "Authors: Hao Zhang, Aixin Sun, Wei Jing, Guoshun Nan, Liangli Zhen, Joey Tianyi Zhou, R. Goh\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Given a collection of untrimmed and unsegmented videos, video corpus moment retrieval (VCMR) is to retrieve a temporal moment (i.e., a fraction of a video) that semantically corresponds to a given text query. As video and text are from two distinct feature spaces, there are two general approaches to address VCMR: (i) to separately encode each modality representations, then align the two modality representations for query processing, and (ii) to adopt fine-grained cross-modal interaction to learn multi-modal representations for query processing. While the second approach often leads to better retrieval accuracy, the first approach is far more efficient. In this paper, we propose a Retrieval and Localization Network with Contrastive Learning (ReLoCLNet) for VCMR. We adopt the first approach and introduce two contrastive learning objectives to refine video encoder and text encoder to learn video and text representations separately but with better alignment for VCMR. The video contrastive learning (VideoCL) is to maximize mutual information between query and candidate video at video-level. The frame contrastive learning (FrameCL) aims to highlight the moment region corresponds to the query at frame-level, within a video. Experimental results show that, although ReLoCLNet encodes text and video separately for efficiency, its retrieval accuracy is comparable with baselines adopting cross-modal interaction learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries\n",
            "Authors: Carl N. Edwards, Chengxiang Zhai, Heng Ji\n",
            "Year: 2021\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We propose a new task, Text2Mol, to retrieve molecules using natural language descriptions as queries. Natural language and molecules encode information in very different ways, which leads to the exciting but challenging problem of integrating these two very different modalities. Although some work has been done on text-based retrieval and structure-based retrieval, this new task requires integrating molecules and natural language more directly. Moreover, this can be viewed as an especially challenging cross-lingual retrieval problem by considering the molecules as a language with a very unique grammar. We construct a paired dataset of molecules and their corresponding text descriptions, which we use to learn an aligned common semantic embedding space for retrieval. We extend this to create a cross-modal attention-based model for explainability and reranking by interpreting the attentions as association rules. We also employ an ensemble approach to integrate our different architectures, which significantly improves results from 0.372 to 0.499 MRR. This new multimodal approach opens a new perspective on solving problems in chemistry literature understanding and molecular machine learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LeCaRD: A Legal Case Retrieval Dataset for Chinese Law System\n",
            "Authors: Yixiao Ma, Yunqiu Shao, Yueyue Wu, Yiqun Liu, Ruizhe Zhang, M. Zhang, Shaoping Ma\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Legal case retrieval is of vital importance for ensuring justice in different kinds of law systems and has recently received increasing attention in information retrieval (IR) research. However, the relevance judgment criteria of previous retrieval datasets are either not applicable to non-cited relationship cases or not instructive enough for future datasets to follow. Besides, most existing benchmark datasets do not focus on the selection of queries. In this paper, we construct the Chinese Legal Case Retrieval Dataset (LeCaRD), which contains 107 query cases and over 43,000 candidate cases. Queries and results are adopted from criminal cases published by the Supreme People's Court of China. In particular, to address the difficulty in relevance definition, we propose a series of relevance judgment criteria designed by our legal team and corresponding candidate case annotations are conducted by legal experts. Also, we develop a novel query sampling strategy that takes both query difficulty and diversity into consideration. For dataset evaluation, we implemented several existing retrieval models on LeCaRD as baselines. The dataset is now available to the public together with the complete data processing details.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text\n",
            "Authors: Haitian Sun, Tania Bedrax-Weiss, William W. Cohen\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We consider open-domain question answering (QA) where answers are drawn from either a corpus, a knowledge base (KB), or a combination of both of these. We focus on a setting in which a corpus is supplemented with a large but incomplete KB, and on questions that require non-trivial (e.g., “multi-hop”) reasoning. We describe PullNet, an integrated framework for (1) learning what to retrieve and (2) reasoning with this heterogeneous information to find the best answer. PullNet uses an iterative process to construct a question-specific subgraph that contains information relevant to the question. In each iteration, a graph convolutional network (graph CNN) is used to identify subgraph nodes that should be expanded using retrieval (or “pull”) operations on the corpus and/or KB. After the subgraph is complete, another graph CNN is used to extract the answer from the subgraph. This retrieve-and-reason process allows us to answer multi-hop questions using large KBs and corpora. PullNet is weakly supervised, requiring question-answer pairs but not gold inference paths. Experimentally PullNet improves over the prior state-of-the art, and in the setting where a corpus is used with incomplete KB these improvements are often dramatic. PullNet is also often superior to prior systems in a KB-only setting or a text-only setting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features\n",
            "Authors: Min Yang, Dongliang He, M. Fan, Baorong Shi, Xuetong Xue, Fu Li, Errui Ding, Jizhou Huang\n",
            "Year: 2021\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Image Retrieval is a fundamental task of obtaining images similar to the query one from a database. A common image retrieval practice is to firstly retrieve candidate images via similarity search using global image features and then re-rank the candidates by leveraging their local features. Previous learning-based studies mainly focus on either global or local image representation learning to tackle the retrieval task. In this paper, we abandon the two-stage paradigm and seek to design an effective single-stage solution by integrating local and global information inside images into compact image representations. Specifically, we propose a Deep Orthogonal Local and Global (DOLG) information fusion framework for end-to-end image retrieval. It attentively extracts representative local information with multi-atrous convolutions and self-attention at first. Components orthogonal to the global image representation are then extracted from the local information. At last, the orthogonal components are concatenated with the global representation as a complementary, and then aggregation is performed to generate the final representation. The whole framework is end-to-end differentiable and can be trained with image-level labels. Extensive experimental results validate the effectiveness of our solution and show that our model achieves state-of-the-art image retrieval performances on Revisited Oxford and Paris datasets. 1\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase Retrieval via Wirtinger Flow: Theory and Algorithms\n",
            "Authors: E. Candès, Xiaodong Li, M. Soltanolkotabi\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We study the problem of recovering the phase from magnitude measurements; specifically, we wish to reconstruct a complex-valued signal x ∈ ℂn about which we have phaseless samples of the form yr = |〈ar, x〉|2, r = 1, ..., m (knowledge of the phase of these samples would yield a linear system). This paper develops a nonconvex formulation of the phase retrieval problem as well as a concrete solution algorithm. In a nutshell, this algorithm starts with a careful initialization obtained by means of a spectral method, and then refines this initial estimate by iteratively applying novel update rules, which have low computational complexity, much like in a gradient descent scheme. The main contribution is that this algorithm is shown to rigorously allow the exact retrieval of phase information from a nearly minimal number of random measurements. Indeed, the sequence of successive iterates provably converges to the solution at a geometric rate so that the proposed scheme is efficient both in terms of computational and data resources. In theory, a variation on this scheme leads to a near-linear time algorithm for a physically realizable model based on coded diffraction patterns. We illustrate the effectiveness of our methods with various experiments on image data. Underlying our analysis are insights for the analysis of nonconvex optimization schemes that may have implications for computational problems beyond phase retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Image retrieval by addition of spatial information based on histograms of triangular regions\n",
            "Authors: N. Ali, Khalid Bashir Bajwa, Robert Sablatnig, Zahid Mehmood\n",
            "Year: 2016\n",
            "Venue: Computers & electrical engineering\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Open-Retrieval Conversational Question Answering\n",
            "Authors: Chen Qu, Liu Yang, Cen Chen, Minghui Qiu, W. Bruce Croft, Mohit Iyyer\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Conversational search is one of the ultimate goals of information retrieval. Recent research approaches conversational search by simplified settings of response ranking and conversational question answering, where an answer is either selected from a given candidate set or extracted from a given passage. These simplifications neglect the fundamental role of retrieval in conversational search. To address this limitation, we introduce an open-retrieval conversational question answering (ORConvQA) setting, where we learn to retrieve evidence from a large collection before extracting answers, as a further step towards building functional conversational search systems. We create a dataset, OR-QuAC, to facilitate research on ORConvQA. We build an end-to-end system for ORConvQA, featuring a retriever, a reranker, and a reader that are all based on Transformers. Our extensive experiments on OR-QuAC demonstrate that a learnable retriever is crucial for ORConvQA. We further show that our system can make a substantial improvement when we enable history modeling in all system components. Moreover, we show that the reranker component contributes to the model performance by providing a regularization effect. Finally, further in-depth analyses are performed to provide new insights into ORConvQA.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Key-Value Retrieval Networks for Task-Oriented Dialogue\n",
            "Authors: Mihail Eric, Lakshmi. Krishnan, F. Charette, Christopher D. Manning\n",
            "Year: 2017\n",
            "Venue: SIGDIAL Conference\n",
            "Abstract: Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The model is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation. Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Domain-matched Pre-training Tasks for Dense Retrieval\n",
            "Authors: Barlas Oğuz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Wen-tau Yih, Sonal Gupta, Yashar Mehdad\n",
            "Year: 2021\n",
            "Venue: NAACL-HLT\n",
            "Abstract: Pre-training on larger datasets with ever increasing model size is now a proven recipe for increased performance across almost all NLP tasks. A notable exception is information retrieval, where additional pre-training has so far failed to produce convincing results. We show that, with the right pre-training setup, this barrier can be overcome. We demonstrate this by pre-training large bi-encoder models on 1) a recently released set of 65 million synthetically generated questions, and 2) 200 million post-comment pairs from a preexisting dataset of Reddit conversations made available by pushshift.io. We evaluate on a set of information retrieval and dialogue retrieval benchmarks, showing substantial improvements over supervised baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Jointly Optimizing Query Encoder and Product Quantization to Improve Retrieval Performance\n",
            "Authors: Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, M. Zhang, Shaoping Ma\n",
            "Year: 2021\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Recently, Information Retrieval community has witnessed fast-paced advances in Dense Retrieval (DR), which performs first-stage retrieval with embedding-based search. Despite the impressive ranking performance, previous studies usually adopt brute-force search to acquire candidates, which is prohibitive in practical Web search scenarios due to its tremendous memory usage and time cost. To overcome these problems, vector compression methods have been adopted in many practical embedding-based retrieval applications. One of the most popular methods is Product Quantization (PQ). However, although existing vector compression methods including PQ can help improve the efficiency of DR, they incur severely decayed retrieval performance due to the separation between encoding and compression. To tackle this problem, we present JPQ, which stands for Joint optimization of query encoding and Product Quantization. It trains the query encoder and PQ index jointly in an end-to-end manner based on three optimization strategies, namely ranking-oriented loss, PQ centroid optimization, and end-to-end negative sampling. We evaluate JPQ on two publicly available retrieval benchmarks. Experimental results show that JPQ significantly outperforms popular vector compression methods. Compared with previous DR models that use brute-force search, JPQ almost matches the best retrieval performance with 30x compression on index size. The compressed index further brings 10x speedup on CPU and 2x speedup on GPU in query latency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval\n",
            "Authors: Xiao Wang, Craig Macdonald, N. Tonellotto, I. Ounis\n",
            "Year: 2021\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Pseudo-relevance feedback mechanisms, from Rocchio to the relevance models, have shown the usefulness of expanding and reweighting the users' initial queries using information occurring in an initial set of retrieved documents, known as the pseudo-relevant set. Recently, dense retrieval -- through the use of neural contextual language models such as BERT for analysing the documents' and queries' contents and computing their relevance scores -- has shown a promising performance on several information retrieval tasks still relying on the traditional inverted index for identifying documents relevant to a query. Two different dense retrieval families have emerged: the use of single embedded representations for each passage and query (e.g. using BERT's [CLS] token), or via multiple representations (e.g. using an embedding for each token of the query and document). In this work, we conduct the first study into the potential for multiple representation dense retrieval to be enhanced using pseudo-relevance feedback. In particular, based on the pseudo-relevant set of documents identified using a first-pass dense retrieval, we extract representative feedback embeddings (using KMeans clustering) -- while ensuring that these embeddings discriminate among passages (based on IDF) -- which are then added to the query representation. These additional feedback embeddings are shown to both enhance the effectiveness of a reranking as well as an additional dense retrieval operation. Indeed, experiments on the MSMARCO passage ranking dataset show that MAP can be improved by upto 26% on the TREC 2019 query set and 10% on the TREC 2020 query set by the application of our proposed ColBERT-PRF method on a ColBERT dense retrieval approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: B-PROP: Bootstrapped Pre-training with Representative Words Prediction for Ad-hoc Retrieval\n",
            "Authors: Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Yingyan Li, Xueqi Cheng\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Pre-training and fine-tuning have achieved remarkable success in many downstream natural language processing (NLP) tasks. Recently, pre-training methods tailored for information retrieval (IR) have also been explored, and the latest success is the PROP method which has reached new SOTA on a variety of ad-hoc retrieval benchmarks. The basic idea of PROP is to construct therepresentative words prediction (ROP) task for pre-training inspired by the query likelihood model. Despite its exciting performance, the effectiveness of PROP might be bounded by the classical unigram language model adopted in the ROP task construction process. To tackle this problem, we propose a bootstrapped pre-training method (namely B-PROP) based on BERT for ad-hoc retrieval. The key idea is to use the powerful contextual language model BERT to replace the classical unigram language model for the ROP task construction, and re-train BERT itself towards the tailored objective for IR. Specifically, we introduce a novel contrastive method, inspired by the divergence-from-randomness idea, to leverage BERT's self-attention mechanism to sample representative words from the document. By further fine-tuning on downstream ad-hoc retrieval tasks, our method achieves significant improvements over PROP and other baselines, and further pushes forward the SOTA on a variety of ad-hoc retrieval tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term Importance Estimation and Neural Query Rewriting\n",
            "Authors: Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai, Chuan-Ju Wang, Jimmy J. Lin\n",
            "Year: 2021\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: Conversational search plays a vital role in conversational information seeking. As queries in information seeking dialogues are ambiguous for traditional ad hoc information retrieval (IR) systems due to the coreference and omission resolution problems inherent in natural language dialogue, resolving these ambiguities is crucial. In this article, we tackle conversational passage retrieval, an important component of conversational search, by addressing query ambiguities with query reformulation integrated into a multi-stage ad hoc IR system. Specifically, we propose two conversational query reformulation (CQR) methods: (1) term importance estimation and (2) neural query rewriting. For the former, we expand conversational queries using important terms extracted from the conversational context with frequency-based signals. For the latter, we reformulate conversational queries into natural, stand-alone, human-understandable queries with a pretrained sequence-to-sequence model. Detailed analyses of the two CQR methods are provided quantitatively and qualitatively, explaining their advantages, disadvantages, and distinct behaviors. Moreover, to leverage the strengths of both CQR methods, we propose combining their output with reciprocal rank fusion, yielding state-of-the-art retrieval effectiveness, 30% improvement in terms of NDCG@3 compared to the best submission of Text REtrieval Conference (TREC) Conversational Assistant Track (CAsT) 2019.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content Based Lecture Video Retrieval Using Speech and Video Text Information\n",
            "Authors: Haojin Yang, C. Meinel\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Learning Technologies\n",
            "Abstract: In the last decade e-lecturing has become more and more popular. The amount of lecture video data on the World Wide Web (WWW) is growing rapidly. Therefore, a more efficient method for video retrieval in WWW or within large lecture video archives is urgently needed. This paper presents an approach for automated video indexing and video search in large lecture video archives. First of all, we apply automatic video segmentation and key-frame detection to offer a visual guideline for the video content navigation. Subsequently, we extract textual metadata by applying video Optical Character Recognition (OCR) technology on key-frames and Automatic Speech Recognition (ASR) on lecture audio tracks. The OCR and ASR transcript as well as detected slide text line types are adopted for keyword extraction, by which both video- and segment-level keywords are extracted for content-based video browsing and search. The performance and the effectiveness of proposed indexing functionalities is proven by evaluation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Not All Relevance Scores are Equal: Efficient Uncertainty and Calibration Modeling for Deep Retrieval Models\n",
            "Authors: Daniel Cohen, Bhaskar Mitra, Oleg Lesota, Navid Rekabsaz, Carsten Eickhoff\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In any ranking system, the retrieval model outputs a single score for a document based on its belief on how relevant it is to a given search query. While retrieval models have continued to improve with the introduction of increasingly complex architectures, few works have investigated a retrieval model's belief in the score beyond the scope of a single value. We argue that capturing the model's uncertainty with respect to its own scoring of a document is a critical aspect of retrieval that allows for greater use of current models across new document distributions, collections, or even improving effectiveness for down-stream tasks. In this paper, we address this problem via an efficient Bayesian framework for retrieval models which captures the model's belief in the relevance score through a stochastic process while adding only negligible computational overhead. We evaluate this belief via a ranking based calibration metric showing that our approximate Bayesian framework significantly improves a retrieval model's ranking effectiveness through a risk aware reranking as well as its confidence calibration. Lastly, we demonstrate that this additional uncertainty information is actionable and reliable on down-stream tasks represented via cutoff prediction.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots\n",
            "Authors: Jia-Chen Gu, Tianda Li, Quan Liu, Xiao-Dan Zhu, Zhenhua Ling, Zhiming Su, Si Wei\n",
            "Year: 2020\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: In this paper, we study the problem of employing pre-trained language models for multi-turn response selection in retrieval-based chatbots. A new model, named Speaker-Aware BERT (SA-BERT), is proposed in order to make the model aware of the speaker change information, which is an important and intrinsic property of multi-turn dialogues. Furthermore, a speaker-aware disentanglement strategy is proposed to tackle the entangled dialogues. This strategy selects a small number of most important utterances as the filtered context according to the speakers' information in them. Finally, domain adaptation is performed to incorporate the in-domain knowledge into pre-trained language models. Experiments on five public datasets show that our proposed model outperforms the present models on all metrics by large margins and achieves new state-of-the-art performances for multi-turn response selection.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback\n",
            "Authors: HongChien Yu, Chenyan Xiong, Jamie Callan\n",
            "Year: 2021\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Dense retrieval systems conduct first-stage retrieval using embedded representations and simple similarity metrics to match a query to documents. Its effectiveness depends on encoded embeddings to capture the semantics of queries and documents, a challenging task due to the shortness and ambiguity of search queries. This paper proposes ANCE-PRF, a new query encoder that uses pseudo relevance feedback (PRF) to improve query representations for dense retrieval. ANCE-PRF uses a BERT encoder that consumes the query and the top retrieved documents from a dense retrieval model, ANCE, and it learns to produce better query embeddings directly from relevance labels. It also keeps the document index unchanged to reduce overhead. ANCE-PRF significantly outperforms ANCE and other recent dense retrieval systems on several datasets. Analysis shows that the PRF encoder effectively captures the relevant and complementary information from PRF documents, while ignoring the noise with its learned attention mechanism.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TRECVID 2020: A comprehensive campaign for evaluating video retrieval tasks across multiple application domains\n",
            "Authors: G. Awad, A. Butt, Keith Curtis, Jonathan G. Fiscus, A. Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas L. Diduch, Jeffrey Liu, A. Smeaton, Yvette Graham, Gareth J.F. Jones, Wessel Kraaij, G. Quénot\n",
            "Year: 2021\n",
            "Venue: TREC Video Retrieval Evaluation\n",
            "Abstract: The TREC Video Retrieval Evaluation (TRECVID) is a TREC-style video analysis and retrieval evaluation with the goal of promoting progress in research and development of content-based exploitation and retrieval of information from digital video via open, metrics-based evaluation. Over the last twenty years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID has been funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addition, many organizations and individuals worldwide contribute significant time and effort. TRECVID 2020 represented a continuation of four tasks and the addition of two new tasks. In total, 29 teams from various research organizations worldwide completed one or more of the following six tasks: 1. Ad-hoc Video Search (AVS), 2. Instance Search (INS), 3. Disaster Scene Description and Indexing (DSDI), 4. Video to Text Description (VTT), 5. Activities in Extended Video (ActEV), 6. Video Summarization (VSUM). This paper is an introduction to the evaluation framework, tasks, data, and measures used in the evaluation campaign.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Supervised Hashing for Image Retrieval via Image Representation Learning\n",
            "Authors: Rongkai Xia, Yan Pan, Hanjiang Lai, Cong Liu, Shuicheng Yan\n",
            "Year: 2014\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " Hashing is a popular approximate nearest neighbor search approach for large-scale image retrieval. Supervised hashing, which incorporates similarity/dissimilarity information on entity pairs to improve the quality of hashing function learning, has recently received increasing attention. However, in the existing supervised hashing methods for images, an input image is usually encoded by a vector of hand-crafted visual features. Such hand-crafted feature vectors do not necessarily preserve the accurate semantic similarities of images pairs, which may often degrade the performance of hashing function learning. In this paper, we propose a supervised hashing method for image retrieval, in which we automatically learn a good image representation tailored to hashing as well as a set of hash functions. The proposed method has two stages. In the first stage, given the pairwise similarity matrix $S$ over training images, we propose a scalable coordinate descent method to decompose $S$ into a product of $HH^T$ where $H$ is a matrix with each of its rows being the approximate hash code associated to a training image. In the second stage, we propose to simultaneously learn a good feature representation for the input images as well as a set of hash functions, via a deep convolutional network tailored to the learned hash codes in $H$ and optionally the discrete class labels of the images. Extensive empirical evaluations on three benchmark datasets with different kinds of images show that the proposed method has superior performance gains over several state-of-the-art supervised and unsupervised hashing methods.\n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots\n",
            "Authors: Yu Wu, Wei Yu Wu, Ming Zhou, Zhoujun Li\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: We study response selection for multi-turn conversation in retrieval based chatbots. Existing works either ignores relationships among utterances, or misses important information in context when matching a response with a highly abstract context vector finally. We propose a new session based matching model to address both problems. The model first matches a response with each utterance on multiple granularities, and distills important matching information from each pair as a vector with convolution and pooling operations. The vectors are then accumulated in a chronological order through a recurrent neural network (RNN) which models the relationships among the utterances. The final matching score is calculated with the hidden states of the RNN. Empirical study on two public data sets shows that our model can significantly outperform the state-of-the-art methods for response selection in multi-turn conversation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Transfer Hashing for Image Retrieval\n",
            "Authors: Hongjia Zhai, Shenqi Lai, Hanyang Jin, Xueming Qian, Tao Mei\n",
            "Year: 2021\n",
            "Venue: IEEE transactions on circuits and systems for video technology (Print)\n",
            "Abstract: Deep supervised hashing has emerged as an influential solution to large-scale semantic image retrieval problems in computer vision. In the light of recent progress, image label is the common way to define whether two images belong to the same category, but it contains little supervised information. The one-hot label can’t accurately define the similarity of two images, which is important for image retrieval. In this paper, we propose an effective method, Deep Transfer Hashing(DTH) which uses the knowledge from teacher model as the supervised information. Inspired by knowledge distillation for model compression and deep hashing for fast image retrieval, we transfer the knowledge from a complex convolutional neural network(teacher) to a small neural network(student) which is used for fast image retrieval. The distance of the knowledge from teacher model can indicate the similarity of images. By minimizing the hashing codes distribution between the hashing layers of teacher model and student model, we can improve the retrieval performance. And we also evaluate the performance of the compressed model at inference stage. We test our method on widely used datasets CIFAR-10 and NUS-WIDE and we compare our method with other state-of-the-art methods in image retrieval domain. The experimental results show that our method can improve the image retrieval baseline by a large margin and better than other methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\n",
            "Authors: Zihao Wang, Xihui Liu, Hongsheng Li, Lu Sheng, Junjie Yan, Xiaogang Wang, Jing Shao\n",
            "Year: 2019\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Text-image cross-modal retrieval is a challenging task in the field of language and vision. Most previous approaches independently embed images and sentences into a joint embedding space and compare their similarities. However, previous approaches rarely explore the interactions between images and sentences before calculating similarities in the joint space. Intuitively, when matching between images and sentences, human beings would alternatively attend to regions in images and words in sentences, and select the most salient information considering the interaction between both modalities. In this paper, we propose Cross-modal Adaptive Message Passing (CAMP), which adaptively controls the information flow for message passing across modalities. Our approach not only takes comprehensive and fine-grained cross-modal interactions into account, but also properly handles negative pairs and irrelevant information with an adaptive gating scheme. Moreover, instead of conventional joint embedding approaches for text-image matching, we infer the matching score based on the fused features, and propose a hardest negative binary cross-entropy loss for training. Results on COCO and Flickr30k significantly surpass state-of-the-art methods, demonstrating the effectiveness of our approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: XOR QA: Cross-lingual Open-Retrieval Question Answering\n",
            "Authors: Akari Asai, Jungo Kasai, J. Clark, Kenton Lee, Eunsol Choi, Hannaneh Hajishirzi\n",
            "Year: 2020\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Multilingual question answering tasks typically assume that answers exist in the same language as the question. Yet in practice, many languages face both information scarcity—where languages have few reference articles—and information asymmetry—where questions reference concepts from other cultures. This work extends open-retrieval question answering to a cross-lingual setting enabling questions from one language to be answered via answer content from another language. We construct a large-scale dataset built on 40K information-seeking questions across 7 diverse non-English languages that TyDi QA could not find same-language answers for. Based on this dataset, we introduce a task framework, called Cross-lingual Open-Retrieval Question Answering (XOR QA), that consists of three new tasks involving cross-lingual document retrieval from multilingual and English resources. We establish baselines with state-of-the-art machine translation systems and cross-lingual pretrained models. Experimental results suggest that XOR QA is a challenging task that will facilitate the development of novel techniques for multilingual question answering. Our data and code are available at https://nlp.cs.washington.edu/xorqa/.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Hierarchical Cross-Modal Graph Consistency Learning for Video-Text Retrieval\n",
            "Authors: Weike Jin, Zhou Zhao, Pengcheng Zhang, Jieming Zhu, Xiuqiang He, Yueting Zhuang\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Due to the popularity of video contents on the Internet, the information retrieval between videos and texts has attracted broad interest from researchers, which is a challenging cross-modal retrieval task. A common solution is to learn a joint embedding space to measure the cross-modal similarity. However, many existing approaches either pay more attention to textual information, video information, or cross-modal matching methods, but less to all three. We believe that a good video-text retrieval system should take into account all three points, fully exploiting the semantic information of both modalities and considering a comprehensive match. In this paper, we propose a Hierarchical Cross-Modal Graph Consistency Learning Network (HCGC) for video-text retrieval task, which considers multi-level graph consistency for video-text matching. Specifically, we first construct a hierarchical graph representation for the video, which includes three levels from global to local: video, clips and objects. Similarly, the corresponding text graph is constructed according to the semantic relationships among sentence, actions and entities. Then, in order to learn a better match between the video and text graph, we design three types of graph consistency (both direct and indirect): inter-graph parallel consistency, inter-graph cross consistency and intra-graph cross consistency. Extensive experimental results on different video-text datasets demonstrate the effectiveness of our approach on both text-to-video and video-to-text retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluating the Robustness of Retrieval Pipelines with Query Variation Generators\n",
            "Authors: Gustavo Penha, A. Câmara, C. Hauff\n",
            "Year: 2021\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fine-Grained Visual Textual Alignment for Cross-Modal Retrieval Using Transformer Encoders\n",
            "Authors: Nicola Messina, G. Amato, Andrea Esuli, F. Falchi, C. Gennaro, S. Marchand-Maillet\n",
            "Year: 2020\n",
            "Venue: ACM Trans. Multim. Comput. Commun. Appl.\n",
            "Abstract: Despite the evolution of deep-learning-based visual-textual processing systems, precise multi-modal matching remains a challenging task. In this work, we tackle the task of cross-modal retrieval through image-sentence matching based on word-region alignments, using supervision only at the global image-sentence level. Specifically, we present a novel approach called Transformer Encoder Reasoning and Alignment Network (TERAN). TERAN enforces a fine-grained match between the underlying components of images and sentences (i.e., image regions and words, respectively) to preserve the informative richness of both modalities. TERAN obtains state-of-the-art results on the image retrieval task on both MS-COCO and Flickr30k datasets. Moreover, on MS-COCO, it also outperforms current approaches on the sentence retrieval task. Focusing on scalable cross-modal information retrieval, TERAN is designed to keep the visual and textual data pipelines well separated. Cross-attention links invalidate any chance to separately extract visual and textual features needed for the online search and the offline indexing steps in large-scale retrieval systems. In this respect, TERAN merges the information from the two domains only during the final alignment phase, immediately before the loss computation. We argue that the fine-grained alignments produced by TERAN pave the way toward the research for effective and efficient methods for large-scale cross-modal information retrieval. We compare the effectiveness of our approach against relevant state-of-the-art methods. On the MS-COCO 1K test set, we obtain an improvement of 5.7% and 3.5% respectively on the image and the sentence retrieval tasks on the Recall@1 metric. The code used for the experiments is publicly available on GitHub at https://github.com/mesnico/TERAN.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep semantic ranking based hashing for multi-label image retrieval\n",
            "Authors: F. Zhao, Yongzhen Huang, Liang Wang, T. Tan\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: With the rapid growth of web images, hashing has received increasing interests in large scale image retrieval. Research efforts have been devoted to learning compact binary codes that preserve semantic similarity based on labels. However, most of these hashing methods are designed to handle simple binary similarity. The complex multi-level semantic structure of images associated with multiple labels have not yet been well explored. Here we propose a deep semantic ranking based method for learning hash functions that preserve multilevel semantic similarity between multi-label images. In our approach, deep convolutional neural network is incorporated into hash functions to jointly learn feature representations and mappings from them to hash codes, which avoids the limitation of semantic representation power of hand-crafted features. Meanwhile, a ranking list that encodes the multilevel similarity information is employed to guide the learning of such deep hash functions. An effective scheme based on surrogate loss is used to solve the intractable optimization problem of nonsmooth and multivariate ranking measures involved in the learning procedure. Experimental results show the superiority of our proposed approach over several state-of-the-art hashing methods in term of ranking evaluation metrics when tested on multi-label image datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval\n",
            "Authors: O. Khattab, Christopher Potts, M. Zaharia\n",
            "Year: 2021\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Multi-hop reasoning (i.e., reasoning across two or more documents) is a key ingredient for NLP models that leverage large corpora to exhibit broad knowledge. To retrieve evidence passages, multi-hop models must contend with a fast-growing search space across the hops, represent complex queries that combine multiple information needs, and resolve ambiguity about the best order in which to hop between training passages. We tackle these problems via Baleen, a system that improves the accuracy of multi-hop retrieval while learning robustly from weak training signals in the many-hop setting. To tame the search space, we propose condensed retrieval, a pipeline that summarizes the retrieved passages after each hop into a single compact context. To model complex queries, we introduce a focused late interaction retriever that allows different parts of the same query representation to match disparate relevant passages. Lastly, to infer the hopping dependencies among unordered training passages, we devise latent hop ordering, a weak-supervision strategy in which the trained retriever itself selects the sequence of hops. We evaluate Baleen on retrieval for two-hop question answering and many-hop claim verification, establishing state-of-the-art performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: More Robust Dense Retrieval with Contrastive Dual Learning\n",
            "Authors: Yizhi Li, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu\n",
            "Year: 2021\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Dense retrieval conducts text retrieval in the embedding space and has shown many advantages compared to sparse retrieval. Existing dense retrievers optimize representations of queries and documents with contrastive training and map them to the embedding space. The embedding space is optimized by aligning the matched query-document pairs and pushing the negative documents away from the query. However, in such training paradigm, the queries are only optimized to align to the documents and are coarsely positioned, leading to an anisotropic query embedding space. In this paper, we analyze the embedding space distributions and propose an effective training paradigm, Contrastive Dual Learning for Approximate Nearest Neighbor (DANCE) to learn fine-grained query representations for dense retrieval. DANCE incorporates an additional dual training object of query retrieval, inspired by the classic information retrieval training axiom, query likelihood. With contrastive learning, the dual training object of DANCE learns more tailored representations for queries and documents to keep the embedding space smooth and uniform, thriving on the ranking performance of DANCE on the MS MARCO document retrieval task. Different from ANCE that only optimized with the document retrieval task, DANCE concentrates the query embeddings closer to document representations while making the document distribution more discriminative. Such concentrated query embedding distribution assigns more uniform negative sampling probabilities to queries and helps to sufficiently optimize query representations in the query retrieval task. Our codes are released at https://github.com/thunlp/DANCE.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DoSSIER@COLIEE 2021: Leveraging dense retrieval and summarization-based re-ranking for case law retrieval\n",
            "Authors: Sophia Althammer, Arian Askari, S. Verberne, A. Hanbury\n",
            "Year: 2021\n",
            "Venue: arXiv.org\n",
            "Abstract: In this paper, we present our approaches for the case law retrieval and the legal case entailment task in the Competition on Legal Information Extraction/Entailment (COLIEE) 2021. As first stage retrieval methods combined with neural re-ranking methods using contextualized language models like BERT achieved great performance improvements for information retrieval in the web and news domain, we evaluate these methods for the legal domain. A distinct characteristic of legal case retrieval is that the query case and case description in the corpus tend to be long documents and therefore exceed the input length of BERT. We address this challenge by combining lexical and dense retrieval methods on the paragraph-level of the cases for the first stage retrieval. Here we demonstrate that the retrieval on the paragraph-level outperforms the retrieval on the document-level. Furthermore the experiments suggest that dense retrieval methods outperform lexical retrieval. For re-ranking we address the problem of long documents by summarizing the cases and fine-tuning a BERT-based re-ranker with the summaries. Overall, our best results were obtained with a combination of BM25 and dense passage retrieval using domain-specific embeddings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Passage Retrieval for Outside-Knowledge Visual Question Answering\n",
            "Authors: Chen Qu, Hamed Zamani, Liu Yang, W. Bruce Croft, E. Learned-Miller\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In this work, we address multi-modal information needs that contain text questions and images by focusing on passage retrieval for outside-knowledge visual question answering. This task requires access to outside knowledge, which in our case we define to be a large unstructured passage collection. We first conduct sparse retrieval with BM25 and study expanding the question with object names and image captions. We verify that visual clues play an important role and captions tend to be more informative than object names in sparse retrieval. We then construct a dual-encoder dense retriever, with the query encoder being LXMERT, a multi-modal pre-trained transformer. We further show that dense retrieval significantly outperforms sparse retrieval that uses object expansion. Moreover, dense retrieval matches the performance of sparse retrieval that leverages human-generated captions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Natural Language Object Retrieval\n",
            "Authors: Ronghang Hu, Huazhe Xu, Marcus Rohrbach, Jiashi Feng, Kate Saenko, Trevor Darrell\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: In this paper, we address the task of natural language object retrieval, to localize a target object within a given image based on a natural language query of the object. Natural language object retrieval differs from text-based image retrieval task as it involves spatial information about objects within the scene and global scene context. To address this issue, we propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate boxes for object retrieval, integrating spatial configurations and global scene-level contextual information into the network. Our model processes query text, local image descriptors, spatial configurations and global context features through a recurrent network, outputs the probability of the query text conditioned on each candidate box as a score for the box, and can transfer visual-linguistic knowledge from image captioning domain to our task. Experimental results demonstrate that our method effectively utilizes both local and global information, outperforming previous baseline methods significantly on different datasets and scenarios, and can exploit large scale vision and language datasets for knowledge transfer.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Conversational Fashion Image Retrieval via Multiturn Natural Language Feedback\n",
            "Authors: Yifei Yuan, W. Lam\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We study the task of conversational fashion image retrieval via multiturn natural language feedback. Most previous studies are based on single-turn settings. Existing models on multiturn conversational fashion image retrieval have limitations, such as employing traditional models, and leading to ineffective performance. We propose a novel framework that can effectively handle conversational fashion image retrieval with multiturn natural language feedback texts. One characteristic of the framework is that it searches for candidate images based on exploitation of the encoded reference image and feedback text information together with the conversation history. Furthermore, the image fashion attribute information is leveraged via a mutual attention strategy. Since there is no existing fashion dataset suitable for the multiturn setting of our task, we derive a large-scale multiturn fashion dataset via additional manual annotation efforts on an existing single-turn dataset. The experiments show that our proposed model significantly outperforms existing state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Tip of the Tongue Known-Item Retrieval: A Case Study in Movie Identification\n",
            "Authors: Jaime Arguello, Adam Ferguson, Emery Fine, Bhaskar Mitra, Hamed Zamani, Fernando Diaz\n",
            "Year: 2021\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: While current information retrieval systems are effective for known-item retrieval where the searcher provides a precise name or identifier for the item being sought, systems tend to be much less effective for cases where the searcher is unable to express a precise name or identifier. We refer to this as tip of the tongue (TOT) known-item retrieval, named after the cognitive state of not being able to retrieve an item from memory. Using movie search as a case study, we explore the characteristics of questions posed by searchers in TOT states in a community question answering website. We analyze how searchers express their information needs during TOT states in the movie domain. Specifically, what information do searchers remember about the item being sought and how do they convey this information? Our results suggest that searchers use a combination of information about: (1) the content of the item sought, (2) the context in which they previously engaged with the item, and (3) previous attempts to find the item using other resources (e.g., search engines). Additionally, searchers convey information by sometimes expressing uncertainty (i.e., hedging), opinions, emotions, and by performing relative (vs. absolute) comparisons with attributes of the item. As a result of our analysis, we believe that searchers in TOT states may require specialized query understanding methods or document representations. Finally, our preliminary retrieval experiments show the impact of each information type presented in information requests on retrieval performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Privacy-Preserving and Copy-Deterrence Content-Based Image Retrieval Scheme in Cloud Computing\n",
            "Authors: Zhihua Xia, Xinhui Wang, Liangao Zhang, Zhan Qin, Xingming Sun, K. Ren\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: With the increasing importance of images in people's daily life, content-based image retrieval (CBIR) has been widely studied. Compared with text documents, images consume much more storage space. Hence, its maintenance is considered to be a typical example for cloud storage outsourcing. For privacy-preserving purposes, sensitive images, such as medical and personal images, need to be encrypted before outsourcing, which makes the CBIR technologies in plaintext domain to be unusable. In this paper, we propose a scheme that supports CBIR over encrypted images without leaking the sensitive information to the cloud server. First, feature vectors are extracted to represent the corresponding images. After that, the pre-filter tables are constructed by locality-sensitive hashing to increase search efficiency. Moreover, the feature vectors are protected by the secure kNN algorithm, and image pixels are encrypted by a standard stream cipher. In addition, considering the case that the authorized query users may illegally copy and distribute the retrieved images to someone unauthorized, we propose a watermark-based protocol to deter such illegal distributions. In our watermark-based protocol, a unique watermark is directly embedded into the encrypted images by the cloud server before images are sent to the query user. Hence, when image copy is found, the unlawful query user who distributed the image can be traced by the watermark extraction. The security analysis and the experiments show the security and efficiency of the proposed scheme.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval\n",
            "Authors: Chao Li, Cheng Deng, Ning Li, W. Liu, Xinbo Gao, D. Tao\n",
            "Year: 2018\n",
            "Venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: Thanks to the success of deep learning, cross-modal retrieval has made significant progress recently. However, there still remains a crucial bottleneck: how to bridge the modality gap to further enhance the retrieval accuracy. In this paper, we propose a self-supervised adversarial hashing (SSAH) approach, which lies among the early attempts to incorporate adversarial learning into cross-modal hashing in a self-supervised fashion. The primary contribution of this work is that two adversarial networks are leveraged to maximize the semantic correlation and consistency of the representations between different modalities. In addition, we harness a self-supervised semantic network to discover high-level semantic information in the form of multi-label annotations. Such information guides the feature learning process and preserves the modality relationships in both the common semantic space and the Hamming space. Extensive experiments carried out on three benchmark datasets validate that the proposed SSAH surpasses the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effects of load and maintenance duration on the time course of information encoding and retrieval in working memory: from perceptual analysis to post-categorization processes\n",
            "Authors: D. Pinal, M. Zurrón, F. Díaz\n",
            "Year: 2014\n",
            "Venue: Frontiers in Human Neuroscience\n",
            "Abstract: Working memory (WM) involves three cognitive events: information encoding, maintenance, and retrieval; these are supported by brain activity in a network of frontal, parietal and temporal regions. Manipulation of WM load and duration of the maintenance period can modulate this activity. Although such modulations have been widely studied using the event-related potentials (ERP) technique, a precise description of the time course of brain activity during encoding and retrieval is still required. Here, we used this technique and principal component analysis to assess the time course of brain activity during encoding and retrieval in a delayed match to sample task. We also investigated the effects of memory load and duration of the maintenance period on ERP activity. Brain activity was similar during information encoding and retrieval and comprised six temporal factors, which closely matched the latency and scalp distribution of some ERP components: P1, N1, P2, N2, P300, and a slow wave. Changes in memory load modulated task performance and yielded variations in frontal lobe activation. Moreover, the P300 amplitude was smaller in the high than in the low load condition during encoding and retrieval. Conversely, the slow wave amplitude was higher in the high than in the low load condition during encoding, and the same was true for the N2 amplitude during retrieval. Thus, during encoding, memory load appears to modulate the processing resources for context updating and post-categorization processes, and during retrieval it modulates resources for stimulus classification and context updating. Besides, despite the lack of differences in task performance related to duration of the maintenance period, larger N2 amplitude and stronger activation of the left temporal lobe after long than after short maintenance periods were found during information retrieval. Thus, results regarding the duration of maintenance period were complex, and future work is required to test the time-based decay theory predictions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN\n",
            "Authors: Shangqing Liu, Yu Chen, Xiaofei Xie, J. Siow, Yang Liu\n",
            "Year: 2020\n",
            "Venue: \n",
            "Abstract: Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural ranking models for document retrieval\n",
            "Authors: M. Trabelsi, Zhiyu Chen, Brian D. Davison, J. Heflin\n",
            "Year: 2021\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: When textual and visual information join forces for multimedia retrieval\n",
            "Authors: Bahjat Safadi, Mathilde Sahuguet, B. Huet\n",
            "Year: 2014\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Currently, popular search engines retrieve documents on the basis of text information. However, integrating the visual information with the text-based search for video and image retrieval is still a hot research topic. In this paper, we propose and evaluate a video search framework based on using visual information to enrich the classic text-based search for video retrieval. The framework extends conventional text-based search by fusing together text and visual scores, obtained from video subtitles (or automatic speech recognition) and visual concept detectors respectively. We attempt to overcome the so called problem of semantic gap by automatically mapping query text to semantic concepts. With the proposed framework, we endeavor to show experimentally, on a set of real world scenarios, that visual cues can effectively contribute to the quality improvement of video retrieval. Experimental results show that mapping text-based queries to visual concepts improves the performance of the search system. Moreover, when appropriately selecting the relevant visual concepts for a query, a very significant improvement of the system's performance is achieved.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PROP: Pre-training with Representative Words Prediction for Ad-hoc Retrieval\n",
            "Authors: Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Xiang Ji, Xueqi Cheng\n",
            "Year: 2020\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: Recently pre-trained language representation models such as BERT have shown great success when fine-tuned on downstream tasks including information retrieval (IR). However, pre-training objectives tailored for ad-hoc retrieval have not been well explored. In this paper, we propose Pre-training with Representative wOrds Prediction (PROP) for ad-hoc retrieval. PROP is inspired by the classical statistical language model for IR, specifically the query likelihood model, which assumes that the query is generated as the piece of text representative of the \"ideal\" document. Based on this idea, we construct the representative words prediction (ROP) task for pre-training. Given an input document, we sample a pair of word sets according to the document language model, where the set with higher likelihood is deemed as more representative of the document. We then pre-train the Transformer model to predict the pairwise preference between the two word sets, jointly with the Masked Language Model (MLM) objective. By further fine-tuning on a variety of representative downstream ad-hoc retrieval tasks, PROP achieves significant improvements over baselines without pre-training or with other pre-training methods. We also show that PROP can achieve exciting performance under both the zero- and low-resource IR settings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval\n",
            "Authors: Wenhao Lu, Jian Jiao, Ruofei Zhang\n",
            "Year: 2020\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Pre-trained language models have achieved great success in a wide variety of natural language processing (NLP) tasks, while the superior performance comes with high demand in computational resources, which hinders the application in low-latency information retrieval (IR) systems. To address the problem, we present TwinBERT model, which has two improvements: 1) represent query and document separately using twin-structured encoders and 2) each encoder is a highly compressed BERT-like model with less than one third of the parameters. The former allows document embeddings to be pre-computed offline and cached in memory, which is different from BERT, where the two input sentences are concatenated and encoded together. The change saves large amount of computation time, however, it is still not sufficient for real-time retrieval considering the complexity of BERT model itself. To further reduce computational cost, a compressed multi-layer transformer encoder is proposed with special training strategies as a substitution of the original complex BERT encoder. Lastly, two versions of TwinBERT are developed to combine the query and keyword embeddings for retrieval and relevance tasks correspondingly. Both of them have met the real-time latency requirement and achieve close or on-par performance to BERT-Base model. The models were trained following the teacher-student framework and evaluated with data from one of the major search engines. Experimental results showed that the inference time was significantly reduced and was for the first time controlled within 20ms on CPUs while at the same time the performance gain from fine-tuned BERT-Base model was mostly retained. Integration of the models in production systems also demonstrated remarkable improvements on relevance metrics with negligible influence on latency. The models were released in 2019 with significant production impacts.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Local Self-Attention over Long Text for Efficient Document Retrieval\n",
            "Authors: Sebastian Hofstätter, Hamed Zamani, Bhaskar Mitra, Nick Craswell, A. Hanbury\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Neural networks, particularly Transformer-based architectures, have achieved significant performance improvements on several retrieval benchmarks. When the items being retrieved are documents, the time and memory cost of employing Transformers over a full sequence of document terms can be prohibitive. A popular strategy involves considering only the first n terms of the document. This can, however, result in a biased system that under retrieves longer documents. In this work, we propose a local self-attention which considers a moving window over the document terms and for each term attends only to other terms in the same window. This local attention incurs a fraction of the compute and memory cost of attention over the whole document. The windowed approach also leads to more compact packing of padded documents in minibatches resulting in additional savings. We also employ a learned saturation function and a two-staged pooling strategy to identify relevant regions of the document. The Transformer-Kernel pooling model with these changes can efficiently elicit relevance information from documents with thousands of tokens. We benchmark our proposed modifications on the document ranking task from the TREC 2019 Deep Learning track and observe significant improvements in retrieval quality as well as increased retrieval of longer documents at moderate increase in compute and memory costs.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Attentive Moment Retrieval in Videos\n",
            "Authors: Meng Liu, Xiang Wang, Liqiang Nie, Xiangnan He, Baoquan Chen, Tat-Seng Chua\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In the past few years, language-based video retrieval has attracted a lot of attention. However, as a natural extension, localizing the specific video moments within a video given a description query is seldom explored. Although these two tasks look similar, the latter is more challenging due to two main reasons: 1) The former task only needs to judge whether the query occurs in a video and returns an entire video, but the latter is expected to judge which moment within a video matches the query and accurately returns the start and end points of the moment. Due to the fact that different moments in a video have varying durations and diverse spatial-temporal characteristics, uncovering the underlying moments is highly challenging. 2) As for the key component of relevance estimation, the former usually embeds a video and the query into a common space to compute the relevance score. However, the later task concerns moment localization where not only the features of a specific moment matter, but the context information of the moment also contributes a lot. For example, the query may contain temporal constraint words, such as \"first'', therefore need temporal context to properly comprehend them. To address these issues, we develop an Attentive Cross-Modal Retrieval Network. In particular, we design a memory attention mechanism to emphasize the visual features mentioned in the query and simultaneously incorporate their context. In the light of this, we obtain the augmented moment representation. Meanwhile, a cross-modal fusion sub-network learns both the intra-modality and inter-modality dynamics, which can enhance the learning of moment-query representation. We evaluate our method on two datasets: DiDeMo and TACoS. Extensive experiments show the effectiveness of our model as compared to the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SOLAR: Second-Order Loss and Attention for Image Retrieval\n",
            "Authors: Tony Ng, Vassileios Balntas, Yurun Tian, K. Mikolajczyk\n",
            "Year: 2020\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information in 2023\n",
            "Authors: E. Sayers, Evan E. Bolton, J. R. Brister, Kathi Canese, Jessica Chan, Donald C. Comeau, C. Farrell, M. Feldgarden, Anna M. Fine, Kathryn Funk, Eneida L. Hatcher, S. Kannan, Christopher Kelly, Sunghwan Kim, W. Klimke, M. Landrum, S. Lathrop, Zhiyong Lu, Thomas L. Madden, A. Malheiro, Aron Marchler-Bauer, Terence D. Murphy, Lon Phan, S. Pujar, S. Rangwala, Valerie A. Schneider, Tony Tse, Jiyao Wang, Jian Ye, B. Trawick, K. Pruitt, S. Sherry\n",
            "Year: 2022\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides online information resources for biology, including the GenBank® nucleic acid sequence database and the PubMed® database of citations and abstracts published in life science journals. NCBI provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for most of these databases. New resources include the Comparative Genome Resource (CGR) and the BLAST ClusteredNR database. Resources receiving significant updates in the past year include PubMed, PMC, Bookshelf, IgBLAST, GDV, RefSeq, NCBI Virus, GenBank type assemblies, iCn3D, ClinVar, GTR, dbGaP, ALFA, ClinicalTrials.gov, Pathogen Detection, antimicrobial resistance resources, and PubChem. These resources can be accessed through the NCBI home page at https://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Complementing Lexical Retrieval with Semantic Residual Embedding\n",
            "Authors: Luyu Gao, Zhuyun Dai, Zhenhua Fan, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: arXiv.org\n",
            "Abstract: Information retrieval traditionally has relied on lexical matching signals, but lexical matching cannot handle vocabulary mismatch or topic-level matching. Neural embedding based retrieval models can match queries and documents in a latent semantic space, but they lose token-level matching information that is critical to IR. This paper presents CLEAR, a deep retrieval model that seeks to complement lexical retrieval with semantic embedding retrieval. Importantly, CLEAR uses a residual-based embedding learning framework, which focuses the embedding on the deep language structures and semantics that the lexical retrieval fails to capture. Empirical evaluation demonstrates the advantages of CLEAR over classic bag-of-words retrieval models, recent BERT-enhanced lexical retrieval models, as well as a BERT-based embedding retrieval. A full-collection retrieval with CLEAR can be as effective as a BERT-based reranking system, substantially narrowing the gap between full-collection retrieval and cost-prohibitive reranking systems\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancing Sketch-Based Image Retrieval by CNN Semantic Re-ranking\n",
            "Authors: Luo Wang, Xueming Qian, Yuting Zhang, Jialie Shen, Xiaochun Cao\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Cybernetics\n",
            "Abstract: This paper introduces a convolutional neural network (CNN) semantic re-ranking system to enhance the performance of sketch-based image retrieval (SBIR). Distinguished from the existing approaches, the proposed system can leverage category information brought by CNNs to support effective similarity measurement between the images. To achieve effective classification of query sketches and high-quality initial retrieval results, one CNN model is trained for classification of sketches, another for that of natural images. Through training dual CNN models, the semantic information of both the sketches and natural images is captured by deep learning. In order to measure the category similarity between images, a category similarity measurement method is proposed. Category information is then used for re-ranking. Re-ranking operation first infers the retrieval category of the query sketch and then uses the category similarity measurement to measure the category similarity between the query sketch and each initial retrieval result. Finally, the initial retrieval results are re-ranked. The experiments on different types of SBIR datasets demonstrate the effectiveness of the proposed re-ranking method. Comparisons with other re-ranking algorithms are also given to show the proposed method’s superiority. Further, compared to the baseline systems, the proposed re-ranking approach achieves significantly higher precision in the top ten different SBIR methods and datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Revealing the Importance of Semantic Retrieval for Machine Reading at Scale\n",
            "Authors: Yixin Nie, Songhe Wang, Mohit Bansal\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Machine Reading at Scale (MRS) is a challenging task in which a system is given an input query and is asked to produce a precise output by “reading” information from a large knowledge base. The task has gained popularity with its natural combination of information retrieval (IR) and machine comprehension (MC). Advancements in representation learning have led to separated progress in both IR and MC; however, very few studies have examined the relationship and combined design of retrieval and comprehension at different levels of granularity, for development of MRS systems. In this work, we give general guidelines on system design for MRS by proposing a simple yet effective pipeline system with special consideration on hierarchical semantic retrieval at both paragraph and sentence level, and their potential effects on the downstream task. The system is evaluated on both fact verification and open-domain multihop QA, achieving state-of-the-art results on the leaderboard test sets of both FEVER and HOTPOTQA. To further demonstrate the importance of semantic retrieval, we present ablation and analysis studies to quantify the contribution of neural retrieval modules at both paragraph-level and sentence-level, and illustrate that intermediate semantic retrieval modules are vital for not only effectively filtering upstream information and thus saving downstream computation, but also for shaping upstream data distribution and providing better data for downstream modeling.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Wafer Map Defect Pattern Classification and Image Retrieval Using Convolutional Neural Network\n",
            "Authors: Takeshi Nakazawa, Deepak V. Kulkarni\n",
            "Year: 2018\n",
            "Venue: IEEE transactions on semiconductor manufacturing\n",
            "Abstract: Wafer maps provide important information for engineers in identifying root causes of die failures during semiconductor manufacturing processes. We present a method for wafer map defect pattern classification and image retrieval using convolutional neural networks (CNNs). Twenty eight thousand six hundred synthetic wafer maps for 22 defect classes are generated theoretically and used for CNN training, validation, and testing. The overall classification accuracy for the 6600 test dataset is 98.2%. One thousand one hundred and ninety one real wafer maps are used for CNN performance evaluation for the same model trained by synthetic wafer maps. We demonstrate that by using only synthetic data for network training, real wafer maps can be classified with high accuracy. For image retrieval, a binary code for each wafer map is generated from an output of a fully connected layer with sigmoid activation. A retrieval error rate is 0.36% for the test dataset and 3.7% for the real wafers. Image retrieval takes 0.13 s per wafer map from the 18 000 wafer map library.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase Retrieval Under a Generative Prior\n",
            "Authors: Paul Hand, Oscar Leong, V. Voroninski\n",
            "Year: 2018\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: The phase retrieval problem asks to recover a natural signal $y_0 \\in \\mathbb{R}^n$ from $m$ quadratic observations, where $m$ is to be minimized. As is common in many imaging problems, natural signals are considered sparse with respect to a known basis, and the generic sparsity prior is enforced via $\\ell_1$ regularization. While successful in the realm of linear inverse problems, such $\\ell_1$ methods have encountered possibly fundamental limitations, as no computationally efficient algorithm for phase retrieval of a $k$-sparse signal has been proven to succeed with fewer than $O(k^2\\log n)$ generic measurements, exceeding the theoretical optimum of $O(k \\log n)$. In this paper, we propose a novel framework for phase retrieval by 1) modeling natural signals as being in the range of a deep generative neural network $G : \\mathbb{R}^k \\rightarrow \\mathbb{R}^n$ and 2) enforcing this prior directly by optimizing an empirical risk objective over the domain of the generator. Our formulation has provably favorable global geometry for gradient methods, as soon as $m = O(kd^2\\log n)$, where $d$ is the depth of the network. Specifically, when suitable deterministic conditions on the generator and measurement matrix are met, we construct a descent direction for any point outside of a small neighborhood around the unique global minimizer and its negative multiple, and show that such conditions hold with high probability under Gaussian ensembles of multilayer fully-connected generator networks and measurement matrices. This formulation for structured phase retrieval thus has two advantages over sparsity based methods: 1) deep generative priors can more tightly represent natural signals and 2) information theoretically optimal sample complexity. We corroborate these results with experiments showing that exploiting generative models in phase retrieval tasks outperforms sparse phase retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the national center for biotechnology information\n",
            "Authors: E. Sayers, Evan E. Bolton, J. R. Brister, Kathi Canese, Jessica Chan, Donald C. Comeau, Ryan Connor, Kathryn Funk, Christopher Kelly, Sunghwan Kim, T. Madej, Aron Marchler-Bauer, C. Lanczycki, S. Lathrop, Zhiyong Lu, F. Thibaud-Nissen, Terence D. Murphy, Lon Phan, Yuri Skripchenko, Tony Tse, Jiyao Wang, Rebecca J Williams, B. Trawick, K. Pruitt, S. Sherry\n",
            "Year: 2021\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) produces a variety of online information resources for biology, including the GenBank® nucleic acid sequence database and the PubMed® database of citations and abstracts published in life science journals. NCBI provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the most of these databases. Resources receiving significant updates in the past year include PubMed, PMC, Bookshelf, RefSeq, SRA, Virus, dbSNP, dbVar, ClinicalTrials.gov, MMDB, iCn3D and PubChem. These resources can be accessed through the NCBI home page at https://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analysis of CYGNSS Data for Soil Moisture Retrieval\n",
            "Authors: M. Clarizia, N. Pierdicca, Fabiano Costantini, N. Floury\n",
            "Year: 2019\n",
            "Venue: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n",
            "Abstract: Data from the CYGNSS mission, originally conceived to monitor tropical cyclones, are being investigated here for land applications as well. In this paper, a methodology for soil moisture (SM) retrieval from CYGNSS data is presented. The approach derives Level 3 gridded daily SM estimations, over the latitudinal band covered by CYGNSS, at a resolution of 36 km × 36 km, using the CYGNSS reflectivity over land, coupled with ancillary vegetation and roughness information from the SMAP mission. The results are compared globally with SM measurements from SMAP, which are assumed to be ground truth, showing a good agreement, and a global root-mean-square difference of 0.07 cm3/cm3. A more extensive comparison is performed over two test regions—Texas in the United States and New South Wales in Australia—where reference data from SMAP are complemented with measurements from the SMOS mission. The results over both regions are generally consistent with the global results, and a good agreement is observed between CYGNSS and reference SM measurements from SMAP and SMOS. The study demonstrates that SM can be successfully retrieved from the CYGNSS mission on a global scale and using ancillary information about the overlying vegetation and the characteristics of the soil. The results open up further future perspectives for global, high-resolution SM products from spaceborne Global Navigation Satellite System-Reflectometry data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-Based Brain Tumor Retrieval for MR Images Using Transfer Learning\n",
            "Authors: Zar Nawab Khan Swati, Qinghua Zhao, Muhammad Kabir, Farman Ali, Zakir Ali, Saeed Ahmed, Jianfeng Lu\n",
            "Year: 2019\n",
            "Venue: IEEE Access\n",
            "Abstract: This paper presents an automatic content-based image retrieval (CBIR) system for brain tumors on T1-weighted contrast-enhanced magnetic resonance images (CE-MRI). The key challenge in CBIR systems for MR images is the semantic gap between the low-level visual information captured by the MRI machine and the high-level information perceived by the human evaluator. The traditional feature extraction methods focus only on low-level or high-level features and use some handcrafted features to reduce this gap. It is necessary to design a feature extraction framework to reduce this gap without using handcrafted features by encoding/combining low-level and high-level features. Deep learning is very powerful for feature representation that can depict low-level and high-level information completely and embed the phase of feature extraction in self-learning. Therefore, we propose a deep convolutional neural network VGG19-based novel feature extraction framework and apply closed-form metric learning to measure the similarity between the query image and database images. Furthermore, we adopt transfer learning and propose a block-wise fine-tuning strategy to enhance the retrieval performance. The extensive experiments are performed on a publicly available CE-MRI dataset that consists of three types of brain tumors (i.e., glioma, meningioma, and pituitary tumor) collected from 233 patients with a total of 3064 images across the axial, coronal, and sagittal views. Our method is more generic, as we do not use any handcrafted features; it requires minimal preprocessing, tested as robust on fivefold cross-validation, can achieve a fivefold mean average precision of 96.13%, and outperforms the state-of-the-art CBIR systems on the CE-MRI dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Multi-View Representation With LSTM for 3-D Shape Recognition and Retrieval\n",
            "Authors: Chao Ma, Yulan Guo, Jungang Yang, W. An\n",
            "Year: 2019\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Shape representation for 3-D models is an important topic in computer vision, multimedia analysis, and computer graphics. Recent multiview-based methods demonstrate promising performance for 3-D shape recognition and retrieval. However, most multiview-based methods ignore the correlations of multiple views or suffer from high computional cost. In this paper, we propose a novel multiview-based network architecture for 3-D shape recognition and retrieval. Our network combines convolutional neural networks (CNNs) with long short-term memory (LSTM) to exploit the correlative information from multiple views. Well-pretrained CNNs with residual connections are first used to extract a low-level feature of each view image rendered from a 3-D shape. Then, a LSTM and a sequence voting layer are employed to aggregate these features into a shape descriptor. The highway network and a three-step training strategy are also adopted to boost the optimization of the deep network. Experimental results on two public datasets demonstrate that the proposed method achieves promising performance for 3-D shape recognition and the state-of-the-art performance for the 3-D shape retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval\n",
            "Authors: Anjan Dutta, Zeynep Akata\n",
            "Year: 2019\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Zero-shot sketch-based image retrieval (SBIR) is an emerging task in computer vision, allowing to retrieve natural images relevant to sketch queries that might not been seen in the training phase. Existing works either require aligned sketch-image pairs or inefficient memory fusion layer for mapping the visual information to a semantic space. In this work, we propose a semantically aligned paired cycle-consistent generative (SEM-PCYC) model for zero-shot SBIR, where each branch maps the visual information to a common semantic space via an adversarial training. Each of these branches maintains a cycle consistency that only requires supervision at category levels, and avoids the need of highly-priced aligned sketch-image pairs. A classification criteria on the generators' outputs ensures the visual to semantic space mapping to be discriminating. Furthermore, we propose to combine textual and hierarchical side information via a feature selection auto-encoder that selects discriminating side information within a same end-to-end model. Our results demonstrate a significant boost in zero-shot SBIR performance over the state-of-the-art on the challenging Sketchy and TU-Berlin datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Respond with Deep Neural Networks for Retrieval-Based Human-Computer Conversation System\n",
            "Authors: Rui Yan, Yiping Song, Hua Wu\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: To establish an automatic conversation system between humans and computers is regarded as one of the most hardcore problems in computer science, which involves interdisciplinary techniques in information retrieval, natural language processing, artificial intelligence, etc. The challenges lie in how to respond so as to maintain a relevant and continuous conversation with humans. Along with the prosperity of Web 2.0, we are now able to collect extremely massive conversational data, which are publicly available. It casts a great opportunity to launch automatic conversation systems. Owing to the diversity of Web resources, a retrieval-based conversation system will be able to find at least some responses from the massive repository for any user inputs. Given a human issued message, i.e., query, our system would provide a reply after adequate training and learning of how to respond. In this paper, we propose a retrieval-based conversation system with the deep learning-to-respond schema through a deep neural network framework driven by web data. The proposed model is general and unified for different conversation scenarios in open domain. We incorporate the impact of multiple data inputs, and formulate various features and factors with optimization into the deep learning framework. In the experiments, we investigate the effectiveness of the proposed deep neural network structures with better combinations of all different evidence. We demonstrate significant performance improvement against a series of standard and state-of-art baselines in terms of p@1, MAP, nDCG, and MRR for conversational purposes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-based image retrieval using high-dimensional information geometry\n",
            "Authors: Wenming Cao, Ning Liu, Qicong Kong, H. Feng\n",
            "Year: 2014\n",
            "Venue: Science China Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\n",
            "Authors: Zhijie Lin, Zhou Zhao, Zhu Zhang, Qi Wang, Huasheng Liu\n",
            "Year: 2019\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: Video moment retrieval is to search the moment that is most relevant to the given natural language query. Existing methods are mostly trained in a fully-supervised setting, which requires the full annotations of temporal boundary for each query. However, manually labeling the annotations is actually time-consuming and expensive. In this paper, we propose a novel weakly-supervised moment retrieval framework requiring only coarse video-level annotations for training. Specifically, we devise a proposal generation module that aggregates the context information to generate and score all candidate proposals in one single pass. We then devise an algorithm that considers both exploitation and exploration to select top-K proposals. Next, we build a semantic completion module to measure the semantic similarity between the selected proposals and query, compute reward and provide feedbacks to the proposal generation module for scoring refinement. Experiments on the ActivityCaptions and Charades-STA demonstrate the effectiveness of our proposed method.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Semantic-Alignment Hashing for Unsupervised Cross-Modal Retrieval\n",
            "Authors: Dejie Yang, Dayan Wu, Wanqian Zhang, Haisu Zhang, Bo Li, Weiping Wang\n",
            "Year: 2020\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Deep hashing methods have achieved tremendous success in cross-modal retrieval, due to its low storage consumption and fast retrieval speed. In real cross-modal retrieval applications, it's hard to obtain label information. Recently, increasing attention has been paid to unsupervised cross-modal hashing. However, existing methods fail to exploit the intrinsic connections between images and their corresponding descriptions or tags (text modality). In this paper, we propose a novel Deep Semantic-Alignment Hashing (DSAH) for unsupervised cross-modal retrieval, which sufficiently utilizes the co-occurred image-text pairs. DSAH explores the similarity information of different modalities and we elaborately design a semantic-alignment loss function, which elegantly aligns the similarities between features with those between hash codes. Moreover, to further bridge the modality gap, we innovatively propose to reconstruct features of one modality with hash codes of the other one. Extensive experiments on three cross-modal retrieval datasets demonstrate that DSAH achieves the state-of-the-art performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Level Correlation Adversarial Hashing for Cross-Modal Retrieval\n",
            "Authors: Xinhong Ma, Tianzhu Zhang, Changsheng Xu\n",
            "Year: 2020\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Cross-modal hashing (CMH) has been widely used for similarity search in multimedia retrieval applications, thanks to low storage cost and fast query speed. However, preserving the content similarities in finite-length hash codes between different data modalities is still challenging due to the existing heterogeneity gap. To further address the crucial bottleneck, we propose a Multi-Level Correlation Adversarial Hashing (MLCAH) algorithm to integrate the multi-level correlation information into hash codes. The proposed MLCAH model enjoys several merits. First, to the best of our knowledge, it is the early attempt of leveraging the multi-level correlation information for cross-modal hashing retrieval. Second, we propose global and local semantic alignment mechanisms, which can effectively encode multi-level correlation information, including global information, local information, and label information into hash codes. Third, a label-consistency attention mechanism with adversarial training is designed for exploiting the local cross-modality similarity from multi-modality data. Extensive evaluations on four benchmarks demonstrate that the proposed model brings significant improvements over several state-of-the-art cross-modal hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FAQ Retrieval using Query-Question Similarity and BERT-Based Query-Answer Relevance\n",
            "Authors: Wataru Sakata, Tomohide Shibata, Ribeka Tanaka, S. Kurohashi\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Frequently Asked Question (FAQ) retrieval is an important task where the objective is to retrieve an appropriate Question-Answer (QA) pair from a database based on a user's query. We propose a FAQ retrieval system that considers the similarity between a user's query and a question as well as the relevance between the query and an answer. Although a common approach to FAQ retrieval is to construct labeled data for training, it takes annotation costs. Therefore, we use a traditional unsupervised information retrieval system to calculate the similarity between the query and question. On the other hand, the relevance between the query and answer can be learned by using QA pairs in a FAQ database. The recently-proposed BERT model is used for the relevance calculation. Since the number of QA pairs in FAQ page is not enough to train a model, we cope with this issue by leveraging FAQ sets that are similar to the one in question. We evaluate our approach on two datasets. The first one is localgovFAQ, a dataset we construct in a Japanese administrative municipality domain. The second is StackExchange dataset, which is the public dataset in English. We demonstrate that our proposed method outperforms baseline methods on these datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Applying BERT to Document Retrieval with Birch\n",
            "Authors: Zeynep Akkalyoncu Yilmaz, Shengjin Wang, Wei Yang, Haotian Zhang, Jimmy J. Lin\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We present Birch, a system that applies BERT to document retrieval via integration with the open-source Anserini information retrieval toolkit to demonstrate end-to-end search over large document collections. Birch implements simple ranking models that achieve state-of-the-art effectiveness on standard TREC newswire and social media test collections. This demonstration focuses on technical challenges in the integration of NLP and IR capabilities, along with the design rationale behind our approach to tightly-coupled integration between Python (to support neural networks) and the Java Virtual Machine (to support document retrieval using the open-source Lucene search library). We demonstrate integration of Birch with an existing search interface as well as interactive notebooks that highlight its capabilities in an easy-to-understand manner.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantics-preserving hashing for cross-view retrieval\n",
            "Authors: Zijia Lin, Guiguang Ding, Mingqing Hu, Jianmin Wang\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: With benefits of low storage costs and high query speeds, hashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts. In this paper, we study the problem of cross-view retrieval and propose an effective Semantics-Preserving Hashing method, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them into a probability distribution and approximates it with to-be-learnt hash codes in Hamming space via minimizing the Kullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt hash codes. And for any unseen instance, predicted hash codes and their corresponding output probabilities from observed views are utilized to determine its unified hash code, using a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval on source code: a neural code search\n",
            "Authors: Saksham Sachdev, Hongyu Li, Sifei Luan, Seohyun Kim, Koushik Sen, S. Chandra\n",
            "Year: 2018\n",
            "Venue: MAPL@PLDI\n",
            "Abstract: Searching over large code corpora can be a powerful productivity tool for both beginner and experienced developers because it helps them quickly find examples of code related to their intent. Code search becomes even more attractive if developers could express their intent in natural language, similar to the interaction that Stack Overflow supports. In this paper, we investigate the use of natural language processing and information retrieval techniques to carry out natural language search directly over source code, i.e. without having a curated Q&A forum such as Stack Overflow at hand. Our experiments using a benchmark suite derived from Stack Overflow and GitHub repositories show promising results. We find that while a basic word–embedding based search procedure works acceptably, better results can be obtained by adding a layer of supervision, as well as by a customized ranking strategy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Time-Series Retrieval of Soil Moisture Using CYGNSS\n",
            "Authors: Mohammad M. Al-Khaldi, J. Johnson, A. O'Brien, A. Balenzano, F. Mattia\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: Time-series retrievals of soil moisture obtained from the Cyclone Global Navigation Satellite System (CYGNSS) constellation are presented. The retrieval approach assumes that vegetation and roughness changes occur on timescales longer than those associated with soil moisture changes to allow soil moisture sensing in the presence of vegetation and surface roughness contributions as well as the varying incidence angles associated with spaceborne Global Navigation Satellite System-Reflectometry (GNSS-R) systems. The approach is focused on incoherent scattering from land surfaces due to the expectation that coherent land surface returns arise primarily from inland water body contributions that are not directly representative of soil moisture. An approach for discarding coherent CYGNSS measurements is therefore developed and described. Because the approach requires the retrieval of  $N$  temporal soil moisture samples at a given location but uses only  $N-1$  ratios of CYGNSS measured quantities, ancillary information is incorporated in the retrieval through the use of maximum and minimum monthly soil moisture maps obtained from the Soil Moisture Active Passive (SMAP) mission. Retrieved soil moistures are presented for the 6-month period December 2017–May 2018 and are compared against values reported by the SMAP mission. The comparisons suggest that there exists the potential for using spaceborne GNSS-R systems for global soil moisture retrievals with an rms error on the order of 0.04 cm3/cm3 over varied terrain.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval\n",
            "Authors: Lin Wu, Yang Wang, Ling Shao\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: In this paper, we propose a novel deep generative approach to cross-modal retrieval to learn hash functions in the absence of paired training samples through the cycle consistency loss. Our proposed approach employs adversarial training scheme to learn a couple of hash functions enabling translation between modalities while assuming the underlying semantic relationship. To induce the hash codes with semantics to the input-output pair, cycle consistency loss is further delved into the adversarial training to strengthen the correlation between the inputs and corresponding outputs. Our approach is generative to learn hash functions, such that the learned hash codes can maximally correlate each input–output correspondence and also regenerate the inputs so as to minimize the information loss. The learning to hash embedding is thus performed to jointly optimize the parameters of the hash functions across modalities as well as the associated generative models. Extensive experiments on a variety of large-scale cross-modal data sets demonstrate that our proposed method outperforms the state of the arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Cross-Modal Image–Voice Retrieval in Remote Sensing\n",
            "Authors: Yaxiong Chen, Xiaoqiang Lu, Shuai Wang\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: With the rapid progress of satellite and aircraft technologies, cross-modal remote sensing image–voice retrieval has been studied in geography recently. However, there still exist some bottlenecks: how to consider the characteristics of remote sensing data adequately and how to reduce the memory and improve the retrieval efficiency in large-scale remote sensing data. In this article, we propose a novel deep cross-modal remote sensing image–voice retrieval approach, namely, deep image–voice retrieval (DIVR), to capture more information of remote sensing data to generate hash codes with low memory and fast retrieval properties. Especially, the DIVR approach proposes inception dilated convolution module to capture multiscale contextual information of remote sensing images and voices. Moreover, in order to enhance cross-modal similarity, the deep features’ similarity term is designed to make paired similar deep features as close as possible and paired dissimilar deep features as mutually far as possible. In addition, the quantization error term is designed to drive hash-like codes to approximate hash codes, which can effectively reduce the quantization error for hash codes’ learning. Extensive experimental results on three remote sensing image–voice data sets show that the proposed DIVR approach can outperform other cross-modal retrieval approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bilinear Attention Networks for Person Retrieval\n",
            "Authors: Pengfei Fang, Jieming Zhou, S. Roy, L. Petersson, M. Harandi\n",
            "Year: 2019\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: This paper investigates a novel Bilinear attention (Bi-attention) block, which discovers and uses second order statistical information in an input feature map, for the purpose of person retrieval. The Bi-attention block uses bilinear pooling to model the local pairwise feature interactions along each channel, while preserving the spatial structural information. We propose an Attention in Attention (AiA) mechanism to build inter-dependency among the second order local and global features with the intent to make better use of, or pay more attention to, such higher order statistical relationships. The proposed network, equipped with the proposed Bi-attention is referred to as Bilinear ATtention network (BAT-net). Our approach outperforms current state-of-the-art by a considerable margin across the standard benchmark datasets (e.g., CUHK03, Market-1501, DukeMTMC-reID and MSMT17).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Memory retrieval by activating engram cells in mouse models of early Alzheimer’s disease\n",
            "Authors: Dheeraj S. Roy, Autumn L Arons, Teryn Mitchell, Michele Pignatelli, T. Ryan, S. Tonegawa\n",
            "Year: 2016\n",
            "Venue: Nature\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Privacy-Preserving Image Retrieval for Medical IoT Systems: A Blockchain-Based Approach\n",
            "Authors: Meng Shen, Yawen Deng, Liehuang Zhu, Xiaojiang Du, Nadra Guizani\n",
            "Year: 2019\n",
            "Venue: IEEE Network\n",
            "Abstract: With the advent of medical IoT devices, the types and volumes of medical images have significantly increased. Retrieving of medical images is of great importance to facilitate disease diagnosis and improve treatment efficiency. However, it may raise privacy concerns from individuals, since medical images contain patients' sensitive and private information. Existing studies on retrieval of medical data either fail to protect sensitive information of medical images or are limited to a single image data provider. In this article, we propose a blockchain-based system for medical image retrieval with privacy protection. We first describe the typical scenarios of medical image retrieval and summarize the corresponding requirements in system design. Using the emerging blockchain techniques, we present the layered architecture and threat model of the proposed system. In order to accommodate large-size images with storage-constrained blocks, we capture a carefully selected feature vector from each medical image and design a customized transaction structure, which protects the privacy of medical images and image features. We also discuss the challenges and opportunities of future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FUNDAMENTALS OF CONTENT-BASED IMAGE RETRIEVAL\n",
            "Authors: S. V. Sakhare, V. G. Nasre, Fuhui Long, Hongjiang Zhang, David Dagan Feng, A. Khaparde, B.L.Deekshatulu, M. Madhavilath, Zakira Farheen, S. Kumari, Guoping Qiu, Sudeep D. Thepade, S. Rajala\n",
            "Year: 2020\n",
            "Venue: \n",
            "Abstract: Advances in data storage and image acquisition technologies have enabled the creation of large image datasets. In this scenario, it is necessary to develop appropriate information systems to efficiently manage these collections. The most common approaches use Content-Based Image Retrieval (CBIR).The goal of such CBIR systems is to support image retrieval based on content e.g., shape, color, texture. Retrieval of images based on visual features such as color, texture and shape have proven to have its own set of limitations under different conditions. In this paper we propose a novel method with highly accurate and retrieval efficient approach which will work on large image database with varied contents and background.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Coupled CycleGAN: Unsupervised Hashing Network for Cross-Modal Retrieval\n",
            "Authors: Chao Li, Cheng Deng, Lei Wang, De Xie, Xianglong Liu\n",
            "Year: 2019\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: In recent years, hashing has attracted more and more attention owing to its superior capacity of low storage cost and high query efficiency in large-scale cross-modal retrieval. Benefiting from deep leaning, continuously compelling results in cross-modal retrieval community have been achieved. However, existing deep cross-modal hashing methods either rely on amounts of labeled information or have no ability to learn an accuracy correlation between different modalities. In this paper, we proposed Unsupervised coupled Cycle generative adversarial Hashing networks (UCH), for cross-modal retrieval, where outer-cycle network is used to learn powerful common representation, and inner-cycle network is explained to generate reliable hash codes. Specifically, our proposed UCH seamlessly couples these two networks with generative adversarial mechanism, which can be optimized simultaneously to learn representation and hash codes. Extensive experiments on three popular benchmark datasets show that the proposed UCH outperforms the state-of-the-art unsupervised cross-modal hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Graph Convolutional Network Hashing for Cross-Modal Retrieval\n",
            "Authors: Ruiqing Xu, Chao Li, Junchi Yan, Cheng Deng, Xianglong Liu\n",
            "Year: 2019\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract: Deep network based cross-modal retrieval has recently made significant progress. However, bridging modality gap to further enhance the retrieval accuracy still remains a crucial bottleneck. In this paper, we propose a Graph Convolutional Hashing (GCH) approach, which learns modality-unified binary codes via an affinity graph. An end-to-end deep architecture is constructed with three main components: a semantic encoder module, two feature encoding networks, and a graph convolutional network (GCN). We design a semantic encoder as a teacher module to guide the feature encoding process, a.k.a. student module, for semantic information exploiting. Furthermore, GCN is utilized to explore the inherent similarity structure among data points, which will help to generate discriminative hash codes. Extensive experiments on three benchmark datasets demonstrate that the proposed GCH outperforms the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information\n",
            "Authors: E. Sayers, J. Beck, Evan E. Bolton, Devon Bourexis, J. R. Brister, Kathi Canese, Donald C. Comeau, Kathryn Funk, Sunghwan Kim, W. Klimke, Aron Marchler-Bauer, M. Landrum, S. Lathrop, Zhiyong Lu, Thomas L. Madden, N. O'Leary, Lon Phan, S. Rangwala, Valerie A. Schneider, Yuri Skripchenko, Jiyao Wang, Jian Ye, B. Trawick, K. Pruitt, S. Sherry\n",
            "Year: 2020\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed® database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 34 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface and NCBI datasets. Additional resources that were updated in the past year include PMC, Bookshelf, Genome Data Viewer, SRA, ClinVar, dbSNP, dbVar, Pathogen Detection, BLAST, Primer-BLAST, IgBLAST, iCn3D and PubChem. All of these resources can be accessed through the NCBI home page at https://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-modal Retrieval with Correspondence Autoencoder\n",
            "Authors: Fangxiang Feng, Xiaojie Wang, Ruifan Li\n",
            "Year: 2014\n",
            "Venue: ACM Multimedia\n",
            "Abstract: The problem of cross-modal retrieval, e.g., using a text query to search for images and vice-versa, is considered in this paper. A novel model involving correspondence autoencoder (Corr-AE) is proposed here for solving this problem. The model is constructed by correlating hidden representations of two uni-modal autoencoders. A novel optimal objective, which minimizes a linear combination of representation learning errors for each modality and correlation learning error between hidden representations of two modalities, is used to train the model as a whole. Minimization of correlation learning error forces the model to learn hidden representations with only common information in different modalities, while minimization of representation learning error makes hidden representations are good enough to reconstruct input of each modality. A parameter $\\alpha$ is used to balance the representation learning error and the correlation learning error. Based on two different multi-modal autoencoders, Corr-AE is extended to other two correspondence models, here we called Corr-Cross-AE and Corr-Full-AE. The proposed models are evaluated on three publicly available data sets from real scenes. We demonstrate that the three correspondence autoencoders perform significantly better than three canonical correlation analysis based models and two popular multi-modal deep models on cross-modal retrieval tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Adaptive Semi-Supervised Feature Selection for Cross-Modal Retrieval\n",
            "Authors: En Yu, Jiande Sun, Jing Li, Xiaojun Chang, Xianhua Han, Alexander Hauptmann\n",
            "Year: 2019\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: In order to exploit the abundant potential information of the unlabeled data and contribute to analyzing the correlation among heterogeneous data, we propose the semi-supervised model named adaptive semi-supervised feature selection for cross-modal retrieval. First, we utilize the semantic regression to strengthen the neighboring relationship between the data with the same semantic. And the correlation between heterogeneous data can be optimized via keeping the pairwise closeness when learning the common latent space. Second, we adopt the graph-based constraint to predict accurate labels for unlabeled data, and it can also keep the geometric structure consistency between the label space and the feature space of heterogeneous data in the common latent space. Finally, an efficient joint optimization algorithm is proposed to update the mapping matrices and the label matrix for unlabeled data simultaneously and iteratively. It makes samples from different classes to be far apart, while the samples from same class lie as close as possible. Meanwhile, the ${l_{2,1}}$-norm constraint is used for feature selection and outlier reduction when the mapping matrices are learned. In addition, we propose learning different mapping matrices corresponding to different sub-tasks to emphasize the semantic and structural information of query data. Experiment results on three datasets demonstrate that our method performs better than the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Spatial-Semantic Attention for Fine-Grained Sketch-Based Image Retrieval\n",
            "Authors: Jifei Song, Qian Yu, Yi-Zhe Song, T. Xiang, Timothy M. Hospedales\n",
            "Year: 2017\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Human sketches are unique in being able to capture both the spatial topology of a visual object, as well as its subtle appearance details. Fine-grained sketch-based image retrieval (FG-SBIR) importantly leverages on such fine-grained characteristics of sketches to conduct instance-level retrieval of photos. Nevertheless, human sketches are often highly abstract and iconic, resulting in severe misalignments with candidate photos which in turn make subtle visual detail matching difficult. Existing FG-SBIR approaches focus only on coarse holistic matching via deep cross-domain representation learning, yet ignore explicitly accounting for fine-grained details and their spatial context. In this paper, a novel deep FG-SBIR model is proposed which differs significantly from the existing models in that: (1) It is spatially aware, achieved by introducing an attention module that is sensitive to the spatial position of visual details: (2) It combines coarse and fine semantic information via a shortcut connection fusion block: and (3) It models feature correlation and is robust to misalignments between the extracted features across the two domains by introducing a novel higher-order learnable energy function (HOLEF) based loss. Extensive experiments show that the proposed deep spatial-semantic attention model significantly outperforms the state-of-the-art.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Privacy-Preserving Content-Based Image Retrieval in Cloud Computing\n",
            "Authors: Zhihua Xia, Yi Zhu, Xingming Sun, Zhan Qin, K. Ren\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Cloud Computing\n",
            "Abstract: Content-based image retrieval (CBIR) applications have been rapidly developed along with the increase in the quantity, availability and importance of images in our daily life. However, the wide deployment of CBIR scheme has been limited by its the severe computation and storage requirement. In this paper, we propose a privacy-preserving content-based image retrieval scheme, which allows the data owner to outsource the image database and CBIR service to the cloud, without revealing the actual content of the database to the cloud server. Local features are utilized to represent the images, and earth mover's distance (EMD) is employed to evaluate the similarity of images. The EMD computation is essentially a linear programming (LP) problem. The proposed scheme transforms the EMD problem in such a way that the cloud server can solve it without learning the sensitive information. In addition, local sensitive hash (LSH) is utilized to improve the search efficiency. The security analysis and experiments show the security and efficiency of the proposed scheme.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Practicing Retrieval Facilitates Learning.\n",
            "Authors: K. McDermott\n",
            "Year: 2020\n",
            "Venue: Annual Review of Psychology\n",
            "Abstract: How do we go about learning new information? This article reviews the importance of practicing retrieval of newly experienced information if one wants to be able to retrieve it again in the future. Specifically, practicing retrieval shortly after learning can slow the forgetting process. This benefit can be seen across various material types, and it seems prevalent in all ages and learner abilities and on all types of test. It can also be used to enhance student learning in a classroom setting. I review theoretical understanding of this phenomenon (sometimes referred to as the testing effect or as retrieval-based learning) and consider directions for future research. Expected final online publication date for the Annual Review of Psychology, Volume 72 is January 5, 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Diagnosing BERT with Retrieval Heuristics\n",
            "Authors: A. Câmara, C. Hauff\n",
            "Year: 2020\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Modal Video Moment Retrieval with Spatial and Language-Temporal Attention\n",
            "Authors: Bin Jiang, Xin Huang, Chao Yang, Junsong Yuan\n",
            "Year: 2019\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Given an untrimmed video and a description query, temporal moment retrieval aims to localize the temporal segment within the video that best describes the textual query. Existing studies predominantly employ coarse frame-level features as the visual representation, obfuscating the specific details which may provide critical cues for localizing the desired moment. We propose a SLTA (short for \"Spatial and Language-Temporal Attention\") method to address the detail missing issue. Specifically, the SLTA method takes advantage of object-level local features and attends to the most relevant local features (e.g., the local features \"girl\", \"cup\") by spatial attention. Then we encode the sequence of local features on consecutive frames to capture the interaction information among these objects (e.g., the interaction \"pour\" involving these two objects). Meanwhile, a language-temporal attention is utilized to emphasize the keywords based on moment context information. Therefore, our proposed two attention sub-networks can recognize the most relevant objects and interactions in the video, and simultaneously highlight the keywords in the query. Extensive experiments on TACOS, Charades-STA and DiDeMo datasets demonstrate the effectiveness of our model as compared to state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Nanophotonic rare-earth quantum memory with optically controlled retrieval\n",
            "Authors: T. Zhong, J. Kindem, J. Bartholomew, Jake Rochman, I. Craiciu, Evan Miyazono, M. Bettinelli, E. Cavalli, V. Verma, S. Nam, F. Marsili, M. Shaw, A. Beyer, A. Faraon\n",
            "Year: 2017\n",
            "Venue: Science\n",
            "Abstract: A rare-earth quantum memory The development of global quantum networks will require chip-scale optically addressable quantum memories for quantum state storage, manipulation, and state swapping. Zhong et al. fabricated a nanostructured photonic crystal cavity in a rare-earth-doped material to form a high-fidelity quantum memory (see the Perspective by Waks and Goldschmidt). The cavity enhanced the light-matter interaction, allowing quantum states to be stored and retrieved from the memory on demand. The high fidelity and small footprint of the device offer a powerful building block for a quantum information platform. Science, this issue p. 1392; see also p. 1354 Rare-earth atoms in a nanophotonic crystal provide a scalable platform for quantum memories. Optical quantum memories are essential elements in quantum networks for long-distance distribution of quantum entanglement. Scalable development of quantum network nodes requires on-chip qubit storage functionality with control of the readout time. We demonstrate a high-fidelity nanophotonic quantum memory based on a mesoscopic neodymium ensemble coupled to a photonic crystal cavity. The nanocavity enables >95% spin polarization for efficient initialization of the atomic frequency comb memory and time bin–selective readout through an enhanced optical Stark shift of the comb frequencies. Our solid-state memory is integrable with other chip-scale photon source and detector devices for multiplexed quantum and classical information processing at the network nodes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: End-to-End Retrieval in Continuous Space\n",
            "Authors: D. Gillick, Alessandro Presta, Gaurav Singh Tomar\n",
            "Year: 2018\n",
            "Venue: arXiv.org\n",
            "Abstract: Most text-based information retrieval (IR) systems index objects by words or phrases. These discrete systems have been augmented by models that use embeddings to measure similarity in continuous space. But continuous-space models are typically used just to re-rank the top candidates. We consider the problem of end-to-end continuous retrieval, where standard approximate nearest neighbor (ANN) search replaces the usual discrete inverted index, and rely entirely on distances between learned embeddings. By training simple models specifically for retrieval, with an appropriate model architecture, we improve on a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval tasks. We also discuss the problem of evaluation for retrieval systems, and show how to modify existing pairwise similarity datasets for this purpose.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Night-Time Pedestrian Retrieval With Distribution Alignment and Contextual Distance\n",
            "Authors: Mang Ye, Yi Cheng, X. Lan, Hongyuan Zhu\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Industrial Informatics\n",
            "Abstract: Night-time pedestrian retrieval is a cross-modality retrieval task of retrieving person images between day-time visible images and night-time thermal images. It is a very challenging problem due to modality difference, camera variations, and person variations, but it plays an important role in night-time video surveillance. The existing cross-modality retrieval usually focuses on learning modality sharable feature representations to bridge the modality gap. In this article, we propose to utilize auxiliary information to improve the retrieval performance, which consistently improves the performance with different baseline loss functions. Our auxiliary information contains two major parts: cross-modality feature distribution and contextual information. The former aligns the cross-modality feature distributions between two modalities to improve the performance, and the latter optimizes the cross-modality distance measurement with the contextual information. We also demonstrate that abundant annotated visible pedestrian images, which are easily accessible, help to improve the cross-modality pedestrian retrieval as well. The proposed method is featured in two aspects: the auxiliary information does not need additional human intervention or annotation; it learns discriminative feature representations in an end-to-end deep learning manner. Extensive experiments on two cross-modality pedestrian retrieval datasets demonstrate the superiority of the proposed method, achieving much better performance than the state-of-the-arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information.\n",
            "Authors: E. Sayers, J. Beck, J. R. Brister, Evan E. Bolton, Kathi Canese, Donald C. Comeau, Kathryn Funk, A. Ketter, Sunghwan Kim, Avi Kimchi, P. Kitts, A. Kuznetsov, S. Lathrop, Zhiyong Lu, Kelly M. McGarvey, Thomas L. Madden, Terence D. Murphy, N. O'Leary, Lon Phan, Valerie A. Schneider, F. Thibaud-Nissen, B. Trawick, K. Pruitt, J. Ostell\n",
            "Year: 2019\n",
            "Venue: Nucleic Acids Research\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface, a sequence database search and a gene orthologs page. Additional resources that were updated in the past year include PMC, Bookshelf, My Bibliography, Assembly, RefSeq, viral genomes, the prokaryotic genome annotation pipeline, Genome Workbench, dbSNP, BLAST, Primer-BLAST, IgBLAST and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ReQA: An Evaluation for End-to-End Answer Retrieval Models\n",
            "Authors: Amin Ahmad, Noah Constant, Yinfei Yang, Daniel Matthew Cer\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Popular QA benchmarks like SQuAD have driven progress on the task of identifying answer spans within a specific passage, with models now surpassing human performance. However, retrieving relevant answers from a huge corpus of documents is still a challenging problem, and places different requirements on the model architecture. There is growing interest in developing scalable answer retrieval models trained end-to-end, bypassing the typical document retrieval step. In this paper, we introduce Retrieval Question-Answering (ReQA), a benchmark for evaluating large-scale sentence-level answer retrieval models. We establish baselines using both neural encoding models as well as classical information retrieval techniques. We release our evaluation code to encourage further work on this challenging task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Rank Using User Clicks and Visual Features for Image Retrieval\n",
            "Authors: Jun Yu, D. Tao, Meng Wang, Y. Rui\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Cybernetics\n",
            "Abstract: The inconsistency between textual features and visual contents can cause poor image search results. To solve this problem, click features, which are more reliable than textual information in justifying the relevance between a query and clicked images, are adopted in image ranking model. However, the existing ranking model cannot integrate visual features, which are efficient in refining the click-based search results. In this paper, we propose a novel ranking model based on the learning to rank framework. Visual features and click features are simultaneously utilized to obtain the ranking model. Specifically, the proposed approach is based on large margin structured output learning and the visual consistency is integrated with the click features through a hypergraph regularizer term. In accordance with the fast alternating linearization method, we design a novel algorithm to optimize the objective function. This algorithm alternately minimizes two different approximations of the original objective function by keeping one function unchanged and linearizing the other. We conduct experiments on a large-scale dataset collected from the Microsoft Bing image search engine, and the results demonstrate that the proposed learning to rank models based on visual features and user clicks outperforms state-of-the-art algorithms.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ad Hoc Table Retrieval using Semantic Similarity\n",
            "Authors: Shuo Zhang, K. Balog\n",
            "Year: 2018\n",
            "Venue: The Web Conference\n",
            "Abstract: We introduce and address the problem of ad hoc table retrieval: answering a keyword query with a ranked list of tables. This task is not only interesting on its own account, but is also being used as a core component in many other table-based information access scenarios, such as table completion or table mining. The main novel contribution of this work is a method for performing semantic matching between queries and tables. Specifically, we (i) represent queries and tables in multiple semantic spaces (both discrete sparse and continuous dense vector representations) and (ii) introduce various similarity measures for matching those semantic representations. We consider all possible combinations of semantic representations and similarity measures and use these as features in a supervised learning model. Using a purpose-built test collection based on Wikipedia tables, we demonstrate significant and substantial improvements over a state-of-the-art baseline.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Distilling Knowledge for Fast Retrieval-based Chat-bots\n",
            "Authors: Amir Vakili Tahami, Kamyar Ghajar, A. Shakery\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Response retrieval is a subset of neural ranking in which a model selects a suitable response from a set of candidates given a conversation history. Retrieval-based chat-bots are typically employed in information seeking conversational systems such as customer support agents. To make pairwise comparisons between a conversation history and a candidate response, two approaches are common: cross-encoders performing full self-attention over the pair and bi-encoders encoding the pair separately. The former gives better prediction quality but is too slow for practical use. In this paper, we propose a new cross-encoder architecture and transfer knowledge from this model to a bi-encoder model using distillation. This effectively boosts bi-encoder performance at no cost during inference time. We perform a detailed analysis of this approach on three response retrieval datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural Embedding-Based Metrics for Pre-retrieval Query Performance Prediction\n",
            "Authors: Negar Arabzadeh, Fattane Zarrinkalam, J. Jovanović, E. Bagheri\n",
            "Year: 2020\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: TRECVID 2019: An evaluation campaign to benchmark Video Activity Detection, Video Captioning and Matching, and Video Search & retrieval\n",
            "Authors: G. Awad, A. Butt, Keith Curtis, Yooyoung Lee, Jonathan G. Fiscus, A. Godil, Andrew Delgado, Jesse Zhang, Eliot Godard, Lukas L. Diduch, A. Smeaton, Yyette Graham, Wessel Kraaij, G. Quénot\n",
            "Year: 2019\n",
            "Venue: TREC Video Retrieval Evaluation\n",
            "Abstract: The TREC Video Retrieval Evaluation (TRECVID) 2019 was a TREC-style video analysis and retrieval evaluation, the goal of which remains to promote progress in research and development of content-based exploitation and retrieval of information from digital video via open, metrics-based evaluation. Over the last nineteen years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID has been funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addition, many organizations and individuals worldwide contribute significant time and effort. TRECVID 2019 represented a continuation of four tasks from TRECVID 2018. In total, 27 teams from various research organizations worldwide completed one or more of the following four tasks: 1. Ad-hoc Video Search (AVS) 2. Instance Search (INS) 3. Activities in Extended Video (ActEV) 4. Video to Text Description (VTT) This paper is an introduction to the evaluation framework, tasks, data, and measures used in the workshop.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Quantum Interference Inspired Neural Matching Model for Ad-hoc Retrieval\n",
            "Authors: Yongyu Jiang, Peng Zhang, Hui Gao, D. Song\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: An essential task of information retrieval (IR) is to compute the probability of relevance of a document given a query. If we regard a query term or n-gram fragment as a relevance matching unit, most retrieval models firstly calculate the relevance evidence between the given query and the candidate document separately, and then accumulate these evidences as the final document relevance prediction. This kind of approach obeys the the classical probability, which is not fully consistent with human cognitive rules in the actual retrieval process, due to the possible existence of interference effect between relevance matching units. In our work, we propose a Quantum Interference inspired Neural Matching model (QINM), which can apply the interference effects to guide the construction of additional evidence generated by the interaction between matching units in the retrieval process. Experimental results on two benchmark collections demonstrate that our approach outperforms the quantum-inspired retrieval models, and some well-known neural retrieval models in the ad-hoc retrieval task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Web Table Extraction, Retrieval and Augmentation\n",
            "Authors: Shuo Zhang, K. Balog\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This tutorial synthesizes and presents research on web tables over the past two decades. We group the tasks into six main categories of information access tasks: (i) table extraction, (ii) table interpretation, (iii) table search, (iv) question answering on tables, (v) knowledge base augmentation, and (vi) table completion. For each category, we identify and introduce seminal approaches, present relevant resources, and point out interdependencies among the different tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Triplet Neural Networks with Cluster-CCA for Audio-Visual Cross-Modal Retrieval\n",
            "Authors: Donghuo Zeng, Yi Yu, K. Oyama\n",
            "Year: 2019\n",
            "Venue: ACM Trans. Multim. Comput. Commun. Appl.\n",
            "Abstract: Cross-modal retrieval aims to retrieve data in one modality by a query in another modality, which has been a very interesting research issue in the field of multimedia, information retrieval, and computer vision, and database. Most existing works focus on cross-modal retrieval between text-image, text-video, and lyrics-audio. Little research addresses cross-modal retrieval between audio and video due to limited audio-video paired datasets and semantic information. The main challenge of the audio-visual cross-modal retrieval task focuses on learning joint embeddings from a shared subspace for computing the similarity across different modalities, where generating new representations is to maximize the correlation between audio and visual modalities space. In this work, we propose TNN-C-CCA, a novel deep triplet neural network with cluster canonical correlation analysis, which is an end-to-end supervised learning architecture with an audio branch and a video branch. We not only consider the matching pairs in the common space but also compute the mismatching pairs when maximizing the correlation. In particular, two significant contributions are made. First, a better representation by constructing a deep triplet neural network with triplet loss for optimal projections can be generated to maximize correlation in the shared subspace. Second, positive examples and negative examples are used in the learning stage to improve the capability of embedding learning between audio and video. Our experiment is run over fivefold cross validation, where average performance is applied to demonstrate the performance of audio-video cross-modal retrieval. The experimental results achieved on two different audio-visual datasets show that the proposed learning architecture with two branches outperforms existing six canonical correlation analysis–based methods and four state-of-the-art-based cross-modal retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory\n",
            "Authors: Deng Cai, Yan Wang, Victoria Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam, Shuming Shi\n",
            "Year: 2018\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Traditional generative dialogue models generate responses solely from input queries. Such information is insufficient for generating a specific response since a certain query could be answered in multiple ways. Recently, researchers have attempted to fill the information gap by exploiting information retrieval techniques. For a given query, similar dialogues are retrieved from the entire training data and considered as an additional knowledge source. While the use of retrieval may harvest extensive information, the generative models could be overwhelmed, leading to unsatisfactory performance. In this paper, we propose a new framework which exploits retrieval results via a skeleton-to-response paradigm. At first, a skeleton is extracted from the retrieved dialogues. Then, both the generated skeleton and the original query are used for response generation via a novel response generator. Experimental results show that our approach significantly improves the informativeness of the generated responses\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems\n",
            "Authors: Yiping Song, Cheng-te Li, Jian-Yun Nie, Ming Zhang, Dongyan Zhao, Rui Yan\n",
            "Year: 2018\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract:  Human-computer conversation systems have attracted much attention in Natural Language Processing. Conversation systems can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (namely a query ) in a large conversational repository and return a reply that best matches the query. Generative approaches synthesize new replies. Both ways have certain advantages but suffer from their own disadvantages. We propose a novel ensemble of retrieval-based and generation-based conversation system. The retrieved candidates, in addition to the original query, are fed to a reply generator via a neural network, so that the model is aware of more information. The generated reply together with the retrieved ones then participates in a re-ranking process to find the final reply to output. Experimental results show that such an ensemble system outperforms each single module by a large margin.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modeling Diverse Relevance Patterns in Ad-hoc Retrieval\n",
            "Authors: Yixing Fan, J. Guo, Yanyan Lan, Jun Xu, ChengXiang Zhai, Xueqi Cheng\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Assessing relevance between a query and a document is challenging in ad-hoc retrieval due to its diverse patterns, i.e., a document could be relevant to a query as a whole or partially as long as it provides sufficient information for users' need. Such diverse relevance patterns require an ideal retrieval model to be able to assess relevance in the right granularity adaptively. Unfortunately, most existing retrieval models compute relevance at a single granularity, either document-wide or passage-level, or use fixed combination strategy, restricting their ability in capturing diverse relevance patterns. In this work, we propose a data-driven method to allow relevance signals at different granularities to compete with each other for final relevance assessment. Specifically, we propose a HIerarchical Neural maTching model (HiNT) which consists of two stacked components, namely local matching layer and global decision layer. The local matching layer focuses on producing a set of local relevance signals by modeling the semantic matching between a query and each passage of a document. The global decision layer accumulates local signals into different granularities and allows them to compete with each other to decide the final relevance score.Experimental results demonstrate that our HiNT model outperforms existing state-of-the-art retrieval models significantly on benchmark ad-hoc retrieval datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The LFM-1b Dataset for Music Retrieval and Recommendation\n",
            "Authors: M. Schedl\n",
            "Year: 2016\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: We present the LFM-1b dataset of more than one billion music listening events created by more than 120,000 users of Last.fm. Each listening event is characterized by artist, album, and track name, and further includes a timestamp. On the (anonymous) user level, basic demographics and a selection of more elaborate user descriptors are included. The dataset is foremost intended for benchmarking in music information retrieval and recommendation. To facilitate experimentation in a straightforward manner, it also includes a precomputed user-item-playcount matrix. In addition, sample Python scripts showing how to load the data and perform efficient computations are provided. An implementation of a simple collaborative filtering recommender rounds off the code package. We discuss in detail the LFM-1b dataset's acquisition, availability, statistics, and content, and place it in the context of existing datasets. We also showcase its usage in a simple artist recommendation task, whose results are intended to serve as baseline against which more elaborate techniques can be assessed. The two unique features of the dataset in comparison to existing ones are (i) its substantial size and (ii) a wide range of additional user descriptors that reflect their music taste and consumption behavior.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effective Multi-Query Expansions: Collaborative Deep Networks for Robust Landmark Retrieval\n",
            "Authors: Yang Wang, Xuemin Lin, Lin Wu, W. Zhang\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Given a query photo issued by a user (q-user), the landmark retrieval is to return a set of photos with their landmarks similar to those of the query, while the existing studies on the landmark retrieval focus on exploiting geometries of landmarks for similarity matches between candidate photos and a query photo. We observe that the same landmarks provided by different users over social media community may convey different geometry information depending on the viewpoints and/or angles, and may, subsequently, yield very different results. In fact, dealing with the landmarks with low quality shapes caused by the photography of q-users is often nontrivial and has seldom been studied. In this paper, we propose a novel framework, namely, multi-query expansions, to retrieve semantically robust landmarks by two steps. First, we identify the top- $k$  photos regarding the latent topics of a query landmark to construct multi-query set so as to remedy its possible low quality shape. For this purpose, we significantly extend the techniques of Latent Dirichlet Allocation. Then, motivated by the typical collaborative filtering methods, we propose to learn a collaborative deep networks-based semantically, nonlinear, and high-level features over the latent factor for landmark photo as the training set, which is formed by matrix factorization over collaborative user-photo matrix regarding the multi-query set. The learned deep network is further applied to generate the features for all the other photos, meanwhile resulting into a compact multi-query set within such space. Then, the final ranking scores are calculated over the high-level feature space between the multi-query set and all other photos, which are ranked to serve as the final ranking list of landmark retrieval. Extensive experiments are conducted on real-world social media data with both landmark photos together with their user information to show the superior performance over the existing methods, especially our recently proposed multi-query based mid-level pattern representation method [1].\n",
            "\n",
            "---\n",
            "\n",
            "Title: Guided Similarity Separation for Image Retrieval\n",
            "Authors: Chundi Liu, Guangwei Yu, M. Volkovs, Cheng Chang, Himanshu Rai, Junwei Ma, S. Gorti\n",
            "Year: 2019\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Despite recent progress in computer vision, image retrieval remains a challenging open problem. Numerous variations such as view angle, lighting and occlusion make it difficult to design models that are both robust and efficient. Many leading methods traverse the nearest neighbor graph to exploit higher order neighbor information and uncover the highly complex underlying manifold. In this work we propose a different approach where we leverage graph convolutional networks to directly encode neighbor information into image descriptors. We further leverage ideas from clustering and manifold learning, and introduce an unsupervised loss based on pairwise separation of image similarities. Empirically, we demonstrate that our model is able to successfully learn a new descriptor space that significantly improves retrieval accuracy, while still allowing efficient inner product inference. Experiments on five public benchmarks show highly competitive performance with up to 24\\% relative improvement in mAP over leading baselines. Full code for this work is available here: https://github.com/layer6ai-labs/GSS.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Use of Ontology in Retrieval: A Study on Textual, Multilingual, and Multimedia Retrieval\n",
            "Authors: M. Asim, Muhammad Wasim, M. U. Ghani Khan, Nasir Mahmood, Waqar Mahmood\n",
            "Year: 2019\n",
            "Venue: IEEE Access\n",
            "Abstract: Web contains a vast amount of data, which are accumulated, studied, and utilized by a huge number of users on a daily basis. A substantial amount of data on the Web is available in an unstructured format, such as Web pages, books, journals, and files. Acquiring appropriate information from such humongous data has become quite challenging and a time-consuming task. Trivial keyword-based information retrieval systems highly depend on the statistics of data, thus facing word mismatch problem due to inevitable semantic and context variations of a certain word. Therefore, this marks the desperate need to organize such massive data into a structured format so that information can be easily processed in a large context by taking data semantics into account. Ontologies are not only being extensively employed in the semantic Web to store unstructured information in an organized and structured way but it has also raised the performance of diverse information retrieval approaches to a great extent. Ontological information retrieval systems retrieve data based on the similarity of semantics between the user query and the indexed data. This paper reviews modern ontology-based information retrieval methods for textual, multimedia, and cross-lingual data types. Furthermore, we compare and categorize the most recent approaches used in the above-mentioned information retrieval methods along with their major drawbacks and advantages.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information\n",
            "Authors: David L. Wheeler, T. Barrett, Dennis A. Benson, Stephen H. Bryant, Kathi Canese, V. Chetvernin, Deanna M. Church, Michael DiCuccio, Ron Edgar, S. Federhen, Lewis Y. Geer, Wolfgang Helmberg, Yuri Kapustin, D. L. Kenton, Oleg Khovayko, D. Lipman, Thomas L. Madden, D. Maglott, J. Ostell, K. Pruitt, Gregory D. Schuler, L. M. Schriml, Edwin Sequeira, Stephen T. Sherry, K. Sirotkin, A. Souvorov, G. Starchenko, Tugba Onal Suzek, R. Tatusov, T. Tatusova, Lukas Wagner, E. Yaschenko\n",
            "Year: 2014\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. Additional NCBI resources focus on literature (Bookshelf, PubMed Central (PMC) and PubReader); medical genetics (ClinVar, dbMHC, the Genetic Testing Registry, HIV-1/Human Protein Interaction Database and MedGen); genes and genomics (BioProject, BioSample, dbSNP, dbVar, Epigenomics, Gene, Gene Expression Omnibus (GEO), Genome, HomoloGene, the Map Viewer, Nucleotide, PopSet, Probe, RefSeq, Sequence Read Archive, the Taxonomy Browser, Trace Archive and UniGene); and proteins and chemicals (Biosystems, COBALT, the Conserved Domain Database (CDD), the Conserved Domain Architecture Retrieval Tool (CDART), the Molecular Modeling Database (MMDB), Protein Clusters, Protein and the PubChem suite of small molecule databases). The Entrez system provides search and retrieval operations for many of these databases. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. All of these resources can be accessed through the NCBI home page at http://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Supervised Matrix Factorization Hashing for Cross-Modal Retrieval\n",
            "Authors: Jun Tang, Ke Wang, Ling Shao\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: The target of cross-modal hashing is to embed heterogeneous multimedia data into a common low-dimensional Hamming space, which plays a pivotal part in multimedia retrieval due to the emergence of big multimodal data. Recently, matrix factorization has achieved great success in cross-modal hashing. However, how to effectively use label information and local geometric structure is still a challenging problem for these approaches. To address this issue, we propose a cross-modal hashing method based on collective matrix factorization, which considers both the label consistency across different modalities and the local geometric consistency in each modality. These two elements are formulated as a graph Laplacian term in the objective function, leading to a substantial improvement on the discriminative power of latent semantic features obtained by collective matrix factorization. Moreover, the proposed method learns unified hash codes for different modalities of an instance to facilitate cross-modal search, and the objective function is solved using an iterative strategy. The experimental results on two benchmark data sets show the effectiveness of the proposed method and its superiority over state-of-the-art cross-modal hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Visual-Semantic Quantization for Efficient Image Retrieval\n",
            "Authors: Yue Cao, Mingsheng Long, Jianmin Wang, Shichen Liu\n",
            "Year: 2017\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Compact coding has been widely applied to approximate nearest neighbor search for large-scale image retrieval, due to its computation efficiency and retrieval quality. This paper presents a compact coding solution with a focus on the deep learning to quantization approach, which improves retrieval quality by end-to-end representation learning and compact encoding and has already shown the superior performance over the hashing solutions for similarity retrieval. We propose Deep Visual-Semantic Quantization (DVSQ), which is the first approach to learning deep quantization models from labeled image data as well as the semantic information underlying general text domains. The main contribution lies in jointly learning deep visual-semantic embeddings and visual-semantic quantizers using carefully-designed hybrid networks and well-specified loss functions. DVSQ enables efficient and effective image retrieval by supporting maximum inner-product search, which is computed based on learned codebooks with fast distance table lookup. Comprehensive empirical evidence shows that DVSQ can generate compact binary codes and yield state-of-the-art similarity retrieval performance on standard benchmarks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: BioWordVec, improving biomedical word embeddings with subword information and MeSH\n",
            "Authors: Yijia Zhang, Qingyu Chen, Zhihao Yang, Hongfei Lin, Zhiyong Lu\n",
            "Year: 2019\n",
            "Venue: Scientific Data\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Hierarchical Attention Retrieval Model for Healthcare Question Answering\n",
            "Authors: Ming Zhu, Aman Ahuja, Wei Wei, Chandan K. Reddy\n",
            "Year: 2019\n",
            "Venue: The Web Conference\n",
            "Abstract: The growth of the Web in recent years has resulted in the development of various online platforms that provide healthcare information services. These platforms contain an enormous amount of information, which could be beneficial for a large number of people. However, navigating through such knowledgebases to answer specific queries of healthcare consumers is a challenging task. A majority of such queries might be non-factoid in nature, and hence, traditional keyword-based retrieval models do not work well for such cases. Furthermore, in many scenarios, it might be desirable to get a short answer that sufficiently answers the query, instead of a long document with only a small amount of useful information. In this paper, we propose a neural network model for ranking documents for question answering in the healthcare domain. The proposed model uses a deep attention mechanism at word, sentence, and document levels, for efficient retrieval for both factoid and non-factoid queries, on documents of varied lengths. Specifically, the word-level cross-attention allows the model to identify words that might be most relevant for a query, and the hierarchical attention at sentence and document levels allows it to do effective retrieval on both long and short documents. We also construct a new large-scale healthcare question-answering dataset, which we use to evaluate our model. Experimental evaluation results against several state-of-the-art baselines show that our model outperforms the existing retrieval techniques.\n",
            "\n",
            "---\n",
            "\n",
            "Title: WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval\n",
            "Authors: Daniel Cohen, Liu Yang, W. Bruce Croft\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: With the rise in mobile and voice search, answer passage retrieval acts as a critical component of an effective information retrieval system for open domain question answering. Currently, there are no comparable collections that address non-factoid question answering within larger documents while simultaneously providing enough examples sufficient to train a deep neural network. In this paper, we introduce a new Wikipedia based collection specific for non-factoid answer passage retrieval containing thousands of questions with annotated answers and show benchmark results on a variety of state of the art neural architectures and retrieval models. The experimental results demonstrate the unique challenges presented by answer passage retrieval within topically relevant documents for future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fairness and Discrimination in Retrieval and Recommendation\n",
            "Authors: Michael D. Ekstrand, R. Burke, Fernando Diaz\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Fairness and related concerns have become of increasing importance in a variety of AI and machine learning contexts. They are also highly relevant to information retrieval and related problems such as recommendation, as evidenced by the growing literature in SIGIR, FAT*, RecSys, and special sessions such as the FATREC workshop and the Fairness track at TREC 2019; however, translating algorithmic fairness constructs from classification, scoring, and even many ranking settings into information retrieval and recommendation scenarios is not a straightforward task. This tutorial will help to orient IR researchers to algorithmic fairness, understand how concepts do and do not translate from other settings, and provide an introduction to the growing literature on this topic.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-label Cross-Modal Retrieval\n",
            "Authors: Viresh Ranjan, Nikhil Rasiwasia, C. V. Jawahar\n",
            "Year: 2015\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: In this work, we address the problem of cross-modal retrieval in presence of multi-label annotations. In particular, we introduce multi-label Canonical Correlation Analysis (ml-CCA), an extension of CCA, for learning shared subspaces taking into account high level semantic information in the form of multi-label annotations. Unlike CCA, ml-CCA does not rely on explicit pairing between modalities, instead it uses the multi-label information to establish correspondences. This results in a discriminative subspace which is better suited for cross-modal retrieval tasks. We also present Fast ml-CCA, a computationally efficient version of ml-CCA, which is able to handle large scale datasets. We show the efficacy of our approach by conducting extensive cross-modal retrieval experiments on three standard benchmark datasets. The results show that the proposed approach achieves state of the art retrieval performance on the three datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The operational cloud retrieval algorithms from TROPOMI on board Sentinel-5 Precursor\n",
            "Authors: D. Loyola, S. G. García, R. Lutz, A. Argyrouli, F. Romahn, R. Spurr, Mattia Pedergnana, A. Doicu, V. M. García, Olena Schüssler\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: Abstract. This paper presents the operational cloud retrieval algorithms for\n",
            "the TROPOspheric Monitoring Instrument (TROPOMI) on board the European Space\n",
            "Agency Sentinel-5 Precursor (S5P) mission scheduled for launch in 2017. Two algorithms working in tandem are used for retrieving cloud properties:\n",
            "OCRA (Optical Cloud Recognition Algorithm) and ROCINN (Retrieval of Cloud\n",
            "Information using Neural Networks). OCRA retrieves the cloud fraction using\n",
            "TROPOMI measurements in the ultraviolet (UV) and visible (VIS) spectral regions, and ROCINN retrieves the\n",
            "cloud top height (pressure) and optical thickness (albedo) using TROPOMI\n",
            "measurements in and around the oxygen A -band in the near infrared (NIR). Cloud parameters from TROPOMI/S5P will be used not only for enhancing the\n",
            "accuracy of trace gas retrievals but also for extending the satellite data\n",
            "record of cloud information derived from oxygen A -band measurements, a record\n",
            "initiated with the Global Ozone Monitoring Experiment (GOME) on board the second European Remote-Sensing Satellite (ERS-2) over 20 years ago. The OCRA and ROCINN algorithms are integrated in the S5P operational\n",
            "processor UPAS (Universal Processor for UV/VIS/NIR Atmospheric\n",
            "Spectrometers), and we present here UPAS cloud results using the Ozone Monitoring Instrument (OMI) and GOME-2\n",
            "measurements. In addition, we examine anticipated challenges for the\n",
            "TROPOMI/S5P cloud retrieval algorithms, and we discuss the future validation\n",
            "needs for OCRA and ROCINN.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploiting Deep Features for Remote Sensing Image Retrieval: A Systematic Investigation\n",
            "Authors: Gui-Song Xia, Xin-Yi Tong, Fan Hu, Yanfei Zhong, M. Datcu, Liangpei Zhang\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Big Data\n",
            "Abstract: Remote sensing (RS) image retrieval is of great significant for geological information mining. Over the past two decades, a large amount of research on this task has been carried out, which mainly focuses on the following three core issues: feature extraction, similarity metric, and relevance feedback. Due to the complexity and multiformity of ground objects in high-resolution remote sensing (HRRS) images, there is still room for improvement in the current retrieval approaches. In this article, we analyze the three core issues of RS image retrieval and provide a comprehensive review on existing methods. Furthermore, for the goal to advance the state-of-the-art in HRRS image retrieval, we focus on the feature extraction issue and delve how to use powerful deep representations to address this task. We conduct systematic investigation on evaluating correlative factors that may affect the performance of deep features. By optimizing each factor, we acquire remarkable retrieval results on publicly available HRRS datasets. Finally, we explain the experimental phenomenon in detail and draw conclusions according to our analysis. Our work can serve as a guiding role for the research of content-based RS image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Legal Document Retrieval using Document Vector Embeddings and Deep Learning\n",
            "Authors: Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, A. Perera, Vindula Jayawardana, Dimuthu Lakmal, M. Perera\n",
            "Year: 2018\n",
            "Venue: Advances in Intelligent Systems and Computing\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Privacy-Preserving Smart Parking Navigation Supporting Efficient Driving Guidance Retrieval\n",
            "Authors: Jianbing Ni, Kuan Zhang, Yong Yu, Xiaodong Lin, X. Shen\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Vehicular Technology\n",
            "Abstract: It is frustrating and time consuming for drivers to find an available parking spot in a congested area, such as downtown and shopping malls, especially in peak hours. Thus, it is very helpful for drivers to have real-time parking information to assist them in finding vacant parking spots timely. Unfortunately, to acquire needed parking information, the drivers have to submit personal queries for the availability of parking spaces in their destinations, and this could result in privacy violation if the queries are not protected. To reduce drivers’ hassle and preserve drivers’ privacy, we propose a privacy-preserving smart parking navigation system (P-SPAN) with efficient navigation result retrieval for drivers using Bloom filters. P-SPAN enables a cloud to guide vehicles to vacant parking spaces in the destinations based on real-time parking information without disclosing any personal information about drivers. Specifically, an efficient data retrieval mechanism is developed based on Bloom filters to support navigation result retrieval for querying vehicles. The drivers can anonymously query accessible parking spots to the cloud, and efficiently retrieve the encrypted navigation results from the passing-by roadside units. Therefore, it is unnecessary for a vehicle to keep connected with the queried roadside unit for acquiring the navigation result. Performance evaluation demonstrates that P-SPAN can provide effective parking navigation with high navigation result retrieving probability and low computational and communication overhead.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Large-Scale Histopathological Image Analysis: Hashing-Based Image Retrieval\n",
            "Authors: Xiaofan Zhang, W. Liu, Murat Dundar, S. Badve, Shaoting Zhang\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Medical Imaging\n",
            "Abstract: Automatic analysis of histopathological images has been widely utilized leveraging computational image-processing methods and modern machine learning techniques. Both computer-aided diagnosis (CAD) and content-based image-retrieval (CBIR) systems have been successfully developed for diagnosis, disease detection, and decision support in this area. Recently, with the ever-increasing amount of annotated medical data, large-scale and data-driven methods have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing scalable image-retrieval techniques to cope intelligently with massive histopathological images. Specifically, we present a supervised kernel hashing technique which leverages a small amount of supervised information in learning to compress a 10 \\thinspace000-dimensional image feature vector into only tens of binary bits with the informative signatures preserved. These binary codes are then indexed into a hash table that enables real-time retrieval of images in a large database. Critically, the supervised information is employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build a scalable image-retrieval framework based on the supervised hashing technique and validate its performance on several thousand histopathological images acquired from breast microscopic tissues. Extensive evaluations are carried out in terms of image classification (i.e., benign versus actionable categorization) and retrieval tests. Our framework achieves about 88.1% classification accuracy as well as promising time efficiency. For example, the framework can execute around 800 queries in only 0.01 s, comparing favorably with other commonly used dimensionality reduction and feature selection methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A surface reflectance scheme for retrieving aerosol optical depth over urbansurfaces in MODIS Dark Target retrieval algorithm\n",
            "Authors: Pawan Gupta, R. Levy, S. Mattoo, L. Remer, L. Munchak\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Abstract. The MODerate resolution Imaging Spectroradiometer (MODIS) instruments, aboard the two Earth Observing System (EOS) satellites Terra and Aqua, provide aerosol information with nearly daily global coverage at moderate spatial resolution (10 and 3 km). Almost 15 years of aerosol data records are now available from MODIS that can be used for various climate and air-quality applications. However, the application of MODIS aerosol products for air-quality concerns is limited by a reduction in retrieval accuracy over urban surfaces. This is largely because the urban surface reflectance behaves differently than that assumed for natural surfaces. In this study, we address the inaccuracies produced by the MODIS Dark Target (MDT) algorithm aerosol optical depth (AOD) retrievals over urban areas and suggest improvements by modifying the surface reflectance scheme in the algorithm. By integrating MODIS Land Surface Reflectance and Land Cover Type information into the aerosol surface parameterization scheme for urban areas, much of the issues associated with the standard algorithm have been mitigated for our test region, the continental United States (CONUS). The new surface scheme takes into account the change in underlying surface type and is only applied for MODIS pixels with urban percentage (UP) larger than 20 %. Over the urban areas where the new scheme has been applied (UP > 20 %), the number of AOD retrievals falling within expected error (EE %) has increased by 20 %, and the strong positive bias against ground-based sun photometry has been eliminated. However, we note that the new retrieval introduces a small negative bias for AOD values less than 0.1 due to the ultra-sensitivity of the AOD retrieval to the surface parameterization under low atmospheric aerosol loadings. Global application of the new urban surface parameterization appears promising, but further research and analysis are required before global implementation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions\n",
            "Authors: Peter Clark, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter D. Turney, Daniel Khashabi\n",
            "Year: 2016\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " What capabilities are required for an AI system to pass standard 4th Grade Science Tests? Previous work has examined the use of Markov Logic Networks (MLNs) to represent the requisite background knowledge and interpret test questions, but did not improve upon an information retrieval (IR) baseline. In this paper, we describe an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base, to achieve substantially improved results. We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions), and show that our overall system’s score is 71.3%, an improvement of 23.8% (absolute) over the MLN-based method described in previous work. We conclude with a detailed analysis, illustrating the complementary strengths of each method in the ensemble. Our datasets are being released to enable further research.\n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Parietal Representations of Stimulus Features Are Amplified during Memory Retrieval and Flexibly Aligned with Top-Down Goals\n",
            "Authors: Serra E. Favila, Rosalie Samide, Sarah C. Sweigart, Brice A. Kuhl\n",
            "Year: 2018\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: In studies of human episodic memory, the phenomenon of reactivation has traditionally been observed in regions of occipitotemporal cortex (OTC) involved in visual perception. However, reactivation also occurs in lateral parietal cortex (LPC), and recent evidence suggests that stimulus-specific reactivation may be stronger in LPC than in OTC. These observations raise important questions about the nature of memory representations in LPC and their relationship to representations in OTC. Here, we report two fMRI experiments that quantified stimulus feature information (color and object category) within LPC and OTC, separately during perception and memory retrieval, in male and female human subjects. Across both experiments, we observed a clear dissociation between OTC and LPC: while feature information in OTC was relatively stronger during perception than memory, feature information in LPC was relatively stronger during memory than perception. Thus, while OTC and LPC represented common stimulus features in our experiments, they preferentially represented this information during different stages. In LPC, this bias toward mnemonic information co-occurred with stimulus-level reinstatement during memory retrieval. In Experiment 2, we considered whether mnemonic feature information in LPC was flexibly and dynamically shaped by top-down retrieval goals. Indeed, we found that dorsal LPC preferentially represented retrieved feature information that addressed the current goal. In contrast, ventral LPC represented retrieved features independent of the current goal. Collectively, these findings provide insight into the nature and significance of mnemonic representations in LPC and constitute an important bridge between putative mnemonic and control functions of parietal cortex. SIGNIFICANCE STATEMENT When humans remember an event from the past, patterns of sensory activity that were present during the initial event are thought to be reactivated. Here, we investigated the role of lateral parietal cortex (LPC), a high-level region of association cortex, in representing prior visual experiences. We find that LPC contained stronger information about stimulus features during memory retrieval than during perception. We also found that current task goals influenced the strength of stimulus feature information in LPC during memory. These findings suggest that, in addition to early sensory areas, high-level areas of cortex, such as LPC, represent visual information during memory retrieval, and that these areas may play a special role in flexibly aligning memories with current goals.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Idea Grou p Inc . Copy right Idea Grou p Inc . Copy right Idea Grou p Inc . Copy right Idea Grou p Inc . Chapter II Bridging the Semantic Gap in Image Retrieval\n",
            "Authors: R. Zhao, W. Grosky\n",
            "Year: 2018\n",
            "Venue: \n",
            "Abstract: INTRODUCTION The emergence of multimedia technology and the rapidly expanding image and video collections on the Internet have attracted significant research efforts in providing tools for effective retrieval and management of visual data. Image retrieval is based on the availability of a representation scheme of image content. Image content descriptors may be visual features such as color, texture, shape, and spatial relationships, or semantic primitives. Conventional information retrieval was based solely on text, and those approaches to textual information retrieval have been transplanted into image retrieval in a variety of ways. However, a picture is worth a thousand words. Image content is much more versatile compared with text, and the amount of visual data is already enormous and still expanding very rapidly. Hoping to cope with these special characteristics of visual data, content-based image retrieval methods have been introduced. It has been widely recognized that the family of image retrieval techniques should become an integration of both low-level visual features addressing the more detailed perceptual aspects and high-level semantic features underlying the more general conceptual aspects of visual data. Neither of these two types of features is sufficient to retrieve or manage visual data in an effective or efficient way (Smeulders, et al., 2000). Although efforts have been devoted to combining these two aspects of visual data, the gap between them is still a huge barrier in front of researchers. Intuitive and heuristic approaches do not provide us with satisfactory performance. Therefore, there is an urgent need of finding the latent correlation between low-level features and high-level concepts and merging them from a different perspective. How to find this new perspective and bridge the gap between visual features and semantic features has been a major challenge in this research field. Our chapter addresses these issues.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Storage and retrieval of vector beams of light in a multiple-degree-of-freedom quantum memory\n",
            "Authors: V. Parigi, V. D’Ambrosio, C. Arnold, L. Marrucci, F. Sciarrino, J. Laurat\n",
            "Year: 2015\n",
            "Venue: Nature Communications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic Topic Multimodal Hashing for Cross-Media Retrieval\n",
            "Authors: Di Wang, Xinbo Gao, Xiumei Wang, Lihuo He\n",
            "Year: 2015\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract: Multimodal hashing is essential to cross-media similarity search for its low storage cost and fast query speed. Most existing multimodal hashing methods embedded heterogeneous data into a common low-dimensional Hamming space, and then rounded the continuous embeddings to obtain the binary codes. Yet they usually neglect the inherent discrete nature of hashing for relaxing the discrete constraints, which will cause degraded retrieval performance especially for long codes. For this purpose, a novel Semantic Topic Multimodal Hashing (STMH) is developed by considering latent semantic information in coding procedure. It first discovers clustering patterns of texts and robust factorizes the matrix of images to obtain multiple semantic topics of texts and concepts of images. Then the learned multimodal semantic features are transformed into a common subspace by their correlations. Finally, each bit of unified hash code can be generated directly by figuring out whether a topic or concept is contained in a text or an image. Therefore, the obtained model by STMH is more suitable for hashing scheme as it directly learns discrete hash codes in the coding process. Experimental results demonstrate that the proposed method outperforms several state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Healthcare information on YouTube: A systematic review\n",
            "Authors: K. Madathil, A Joy Rivera-Rodriguez, J. Greenstein, A. Gramopadhye\n",
            "Year: 2015\n",
            "Venue: Health Informatics Journal\n",
            "Abstract: This article reviews the peer-reviewed literature addressing the healthcare information available on YouTube. Inclusion and exclusion criteria were determined, and the online databases PubMed and Web of Knowledge were searched using the search phrases: (1) YouTube* AND Health* and (2) YouTube* AND Healthcare*. In all, 18 articles were reviewed, with the results suggesting that (1) YouTube is increasingly being used as a platform for disseminating health information; (2) content and frame analysis were the primary techniques employed by researchers to analyze the characteristics of this information; (3) YouTube contains misleading information, primarily anecdotal, that contradicts the reference standards and the probability of a lay user finding such content is relatively high; (4) the retrieval of relevant videos is dependent on the search term used; and (5) videos from government organizations and professional associations contained trustworthy and high-quality information. YouTube is used as a medium for promoting unscientific therapies and drugs that are yet to be approved by the appropriate agencies and has the potential to change the beliefs of patients concerning controversial topics such as vaccinations. This review recognizes the need to design interventions to enable consumers to critically assimilate the information posted on YouTube with more authoritative information sources to make effective healthcare decisions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Continuous Word Embedding with Metadata for Question Retrieval in Community Question Answering\n",
            "Authors: Guangyou Zhou, Tingting He, Jun Zhao, P. Hu\n",
            "Year: 2015\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Community question answering (cQA) has become an important issue due to the popularity of cQA archives on the web. This paper is concerned with the problem of question retrieval. Question retrieval in cQA archives aims to find the existing questions that are semantically equivalent or relevant to the queried questions. However, the lexical gap problem brings about new challenge for question retrieval in cQA. In this paper, we propose to learn continuous word embeddings with metadata of category information within cQA pages for question retrieval. To deal with the variable size of word embedding vectors, we employ the framework of fisher kernel to aggregated them into the fixedlength vectors. Experimental results on large-scale real world cQA data set show that our approach can significantly outperform state-of-the-art translation models and topic-based models for question re-\n",
            "\n",
            "---\n",
            "\n",
            "Title: Teaching a New Dog Old Tricks: Resurrecting Multilingual Retrieval Using Zero-Shot Learning\n",
            "Authors: Sean MacAvaney, Luca Soldaini, Nazli Goharian\n",
            "Year: 2019\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal Feature Integration in the Angular Gyrus during Episodic and Semantic Retrieval\n",
            "Authors: Heidi M. Bonnici, Franziska R. Richter, Yasemin Yazar, J. Simons\n",
            "Year: 2016\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Much evidence from distinct lines of investigation indicates the involvement of angular gyrus (AnG) in the retrieval of both episodic and semantic information, but the region's precise function and whether that function differs across episodic and semantic retrieval have yet to be determined. We used univariate and multivariate fMRI analysis methods to examine the role of AnG in multimodal feature integration during episodic and semantic retrieval. Human participants completed episodic and semantic memory tasks involving unimodal (auditory or visual) and multimodal (audio-visual) stimuli. Univariate analyses revealed the recruitment of functionally distinct AnG subregions during the retrieval of episodic and semantic information. Consistent with a role in multimodal feature integration during episodic retrieval, significantly greater AnG activity was observed during retrieval of integrated multimodal episodic memories compared with unimodal episodic memories. Multivariate classification analyses revealed that individual multimodal episodic memories could be differentiated in AnG, with classification accuracy tracking the vividness of participants' reported recollections, whereas distinct unimodal memories were represented in sensory association areas only. In contrast to episodic retrieval, AnG was engaged to a statistically equivalent degree during retrieval of unimodal and multimodal semantic memories, suggesting a distinct role for AnG during semantic retrieval. Modality-specific sensory association areas exhibited corresponding activity during both episodic and semantic retrieval, which mirrored the functional specialization of these regions during perception. The results offer new insights into the integrative processes subserved by AnG and its contribution to our subjective experience of remembering. SIGNIFICANCE STATEMENT Using univariate and multivariate fMRI analyses, we provide evidence that functionally distinct subregions of angular gyrus (AnG) contribute to the retrieval of episodic and semantic memories. Our multivariate pattern classifier could distinguish episodic memory representations in AnG according to whether they were multimodal (audio-visual) or unimodal (auditory or visual) in nature, whereas statistically equivalent AnG activity was observed during retrieval of unimodal and multimodal semantic memories. Classification accuracy during episodic retrieval scaled with the trial-by-trial vividness with which participants experienced their recollections. Therefore, the findings offer new insights into the integrative processes subserved by AnG and how its function may contribute to our subjective experience of remembering.\n",
            "\n",
            "---\n",
            "\n",
            "Title: GEO matching regions: multiple regions of interests using content based image retrieval based on relative locations\n",
            "Authors: Muhammad Hammad Memon, Jianping Li, I. Memon, Q. Arain\n",
            "Year: 2017\n",
            "Venue: Multimedia tools and applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: ContextNet: representation and exploration for painting classification and retrieval in context\n",
            "Authors: Noa García, B. Renoust, Yuta Nakashima\n",
            "Year: 2019\n",
            "Venue: International Journal of Multimedia Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Feature extraction and image retrieval based on AlexNet\n",
            "Authors: Zhe Yuan, Jun Zhang\n",
            "Year: 2016\n",
            "Venue: International Conference on Digital Image Processing\n",
            "Abstract: Convolutional Neural Network is a hot research topic in image recognition. The latest research shows that Deep CNN model is good at extracting features and representing images. This capacity is applied to image retrieval in this paper. We study on the significance of each layer and do image retrieval experiments on the fusion features. Caffe framework and AlexNet model were used to extract the feature information about images. Two public image datasets, Inria Holidays and Oxford Buildings, were used in our experiment to search for the influence of different datasets. The results showed the fusion feature of Deep CNN model can improve the result of image retrieval and should apply different weights for different datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond Instance-Level Image Retrieval: Leveraging Captions to Learn a Global Visual Representation for Semantic Retrieval\n",
            "Authors: Albert Gordo, Diane Larlus\n",
            "Year: 2017\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Querying with an example image is a simple and intuitive interface to retrieve information from a visual database. Most of the research in image retrieval has focused on the task of instance-level image retrieval, where the goal is to retrieve images that contain the same object instance as the query image. In this work we move beyond instance-level retrieval and consider the task of semantic image retrieval in complex scenes, where the goal is to retrieve images that share the same semantics as the query image. We show that, despite its subjective nature, the task of semantically ranking visual scenes is consistently implemented across a pool of human annotators. We also show that a similarity based on human-annotated region-level captions is highly correlated with the human ranking and constitutes a good computable surrogate. Following this observation, we learn a visual embedding of the images where the similarity in the visual space is correlated with their semantic similarity surrogate. We further extend our model to learn a joint embedding of visual and textual cues that allows one to query the database using a text modifier in addition to the query image, adapting the results to the modifier. Finally, our model can ground the ranking decisions by showing regions that contributed the most to the similarity between pairs of images, providing a visual explanation of the similarity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Patent retrieval: a literature review\n",
            "Authors: W. Shalaby, Wlodek Zadrozny\n",
            "Year: 2017\n",
            "Venue: Knowledge and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Stochastic Multiview Hashing for Large-Scale Near-Duplicate Video Retrieval\n",
            "Authors: Y. Hao, Tingting Mu, Richang Hong, Meng Wang, Ning An, J. Y. Goulermas\n",
            "Year: 2017\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Near-duplicate video retrieval (NDVR) has been a significant research task in multimedia given its high impact in applications, such as video search, recommendation, and copyright protection. In addition to accurate retrieval performance, the exponential growth of online videos has imposed heavy demands on the efficiency and scalability of the existing systems. Aiming at improving both the retrieval accuracy and speed, we propose a novel stochastic multiview hashing algorithm to facilitate the construction of a large-scale NDVR system. Reliable mapping functions, which convert multiple types of keyframe features, enhanced by auxiliary information such as video-keyframe association and ground truth relevance to binary hash code strings, are learned by maximizing a mixture of the generalized retrieval precision and recall scores. A composite Kullback-Leibler divergence measure is used to approximate the retrieval scores, which aligns stochastically the neighborhood structures between the original feature and the relaxed hash code spaces. The efficiency and effectiveness of the proposed method are examined using two public near-duplicate video collections and are compared against various classical and state-of-the-art NDVR systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal Multimedia Retrieval with vitrivr\n",
            "Authors: Ralph Gasser, Luca Rossetto, H. Schuldt\n",
            "Year: 2019\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: The steady growth of multimedia collections - both in terms of size and heterogeneity - necessitates systems that are able to conjointly deal with several types of media as well as large volumes of data. This is especially true when it comes to satisfying a particular information need, i.e., retrieving a particular object of interest from a large collection. Nevertheless, existing multimedia management and retrieval systems are mostly organized in silos and treat different media types separately. Hence, they are limited when it comes to crossing these silos for accessing objects. In this paper, we present vitrivr, a general-purpose content-based multimedia retrieval stack. In addition to the keyword search provided by most media management systems, vitrivr also exploits the object's content in order to facilitate different types of similarity search. This can be done within and, most importantly, across different media types giving rise to new, interesting use cases. To the best of our knowledge, the full vitrivr stack is unique in that it seamlessly integrates support for four different types of media, namely images, audio, videos, and 3D models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval Algorithms Optimized for Human Learning\n",
            "Authors: Rohail Syed, Kevyn Collins-Thompson\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: While search technology is widely used for learning-oriented information needs, the results provided by popular services such as Web search engines are optimized primarily for generic relevance, not effective learning outcomes. As a result, the typical information trail that a user must follow while searching to achieve a learning goal may be an inefficient one involving unnecessarily easy or difficult content, or material that is irrelevant to actual learning progress relative to a user's existing knowledge. We address this problem by introducing a novel theoretical framework, algorithms, and empirical analysis of an information retrieval model that is optimized for learning outcomes instead of generic relevance. We do this by formulating an optimization problem that incorporates a cognitive learning model into a retrieval objective, and then give an algorithm for an efficient approximate solution to find the search results that represent the best 'training set' for a human learner. Our model can personalize results for an individual user's learning goals, as well as account for the effort required to achieve those goals for a given set of retrieval results. We investigate the effectiveness and efficiency of our retrieval framework relative to a commercial search engine baseline ('Google') through a crowdsourced user study involving a vocabulary learning task, and demonstrate the effectiveness of personalized results from our model on word learning outcomes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Searching Data: A Review of Observational Data Retrieval Practices in Selected Disciplines\n",
            "Authors: Kathleen Gregory, Paul T. Groth, Helena Cousijn, A. Scharnhorst, S. Wyatt\n",
            "Year: 2017\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: A cross‐disciplinary examination of the user behaviors involved in seeking and evaluating data is surprisingly absent from the research data discussion. This review explores the data retrieval literature to identify commonalities in how users search for and evaluate observational research data in selected disciplines. Two analytical frameworks, rooted in information retrieval and science and technology studies, are used to identify key similarities in practices as a first step toward developing a model describing data retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A System for Efficient High-Recall Retrieval\n",
            "Authors: Mustafa Abualsaud, Nimesh Ghelani, Haotian Zhang, Mark D. Smucker, G. Cormack, Maura R. Grossman\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The goal of high-recall information retrieval (HRIR) is to find all or nearly all relevant documents for a search topic. In this paper, we present the design of our system that affords efficient high-recall retrieval. HRIR systems commonly rely on iterative relevance feedback. Our system uses a state-of-the-art implementation of continuous active learning (CAL), and is designed to allow other feedback systems to be attached with little work. Our system allows users to judge documents as fast as possible with no perceptible interface lag. We also support the integration of a search engine for users who would like to interactively search and judge documents. In addition to detailing the design of our system, we report on user feedback collected as part of a 50 participants user study. While we have found that users find the most relevant documents when we restrict user interaction, a majority of participants prefer having flexibility in user interaction. Our work has implications on how to build effective assessment systems and what features of the system are believed to be useful by users.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Minimum Information about a Biosynthetic Gene cluster.\n",
            "Authors: M. Medema, R. Kottmann, Pelin Yilmaz, M. Cummings, J. Biggins, K. Blin, I. de Bruijn, Y. Chooi, Jan Claesen, R. Coates, Pablo Cruz-Morales, Srikanth Duddela, Stephanie Düsterhus, D. J. Edwards, D. Fewer, Neha Garg, Christoph Geiger, J. Gomez-Escribano, Anja Greule, Michalis Hadjithomas, A. Haines, Eric J. N. Helfrich, Matthew L. Hillwig, K. Ishida, Adam C. Jones, Carla S. Jones, K. Jungmann, Carsten Kegler, H. Kim, P. Kötter, D. Krug, J. Masschelein, A. Melnik, S. M. Mantovani, Emily A. Monroe, M. Moore, N. Moss, Hans-Wilhelm Nützmann, Guohui Pan, Amrita Pati, D. Petráš, F. Reen, Federico Rosconi, Z. Rui, Zhenhua Tian, Nicholas J. Tobias, Y. Tsunematsu, Philipp Wiemann, E. Wyckoff, Xiaohui Yan, Grace Yim, F. Yu, Yunchang Xie, B. Aigle, A. Apel, C. Balibar, E. Balskus, F. Barona-Gómez, A. Bechthold, H. Bode, R. Borriss, S. Brady, A. Brakhage, P. Caffrey, Yi-Qiang Cheng, J. Clardy, Russell John Cox, R. De Mot, S. Donadio, M. Donia, W. A. van der Donk, P. Dorrestein, S. Doyle, A. Driessen, M. Ehling-Schulz, K. Entian, M. Fischbach, L. Gerwick, W. Gerwick, H. Gross, B. Gust, C. Hertweck, M. Höfte, S. Jensen, J. Ju, L. Katz, Leonard Kaysser, J. Klassen, N. Keller, J. Kormanec, O. Kuipers, T. Kuzuyama, N. Kyrpides, H. Kwon, S. Lautru, R. Lavigne, Chia Y. Lee, B. Linquan, Xinyu Liu, Wen Liu, A. Luzhetskyy, T. Mahmud, Yvonne Mast, C. Méndez, M. Metsä‐Ketelä, Jason Micklefield, D. Mitchell, B. Moore, L. M. Moreira, R. Müller, B. Neilan, M. Nett, J. Nielsen, F. O'Gara, H. Oikawa, A. Osbourn, M. Osburne, B. Ostash, Shelley M. Payne, J. Pernodet, M. Petříček, J. Piel, O. Ploux, J. Raaijmakers, J. Salas, E. Schmitt, B. Scott, R. Seipke, B. Shen, D. Sherman, K. Sivonen, M. Smanski, M. Sosio, E. Stegmann, R. Süssmuth, K. Tahlan, Christopher M Thomas, Yi Tang, A. Truman, M. Viaud, J. Walton, C. Walsh, T. Weber, G. V. van Wezel, B. Wilkinson, J. Willey, W. Wohlleben, Gerard D. Wright, N. Ziemert, Changsheng Zhang, S. Zotchev, R. Breitling, E. Takano, F. Glöckner\n",
            "Year: 2015\n",
            "Venue: Nature Chemical Biology\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Healthy ageing reduces the precision of episodic memory retrieval\n",
            "Authors: Saana M. Korkki, Franziska R. Richter, Priyanga Jeyarathnarajah, J. Simons\n",
            "Year: 2018\n",
            "Venue: bioRxiv\n",
            "Abstract: Episodic memory declines with older age, but it is unresolved whether this decline reflects reduced probability of successfully retrieving information from memory, or decreased precision of the retrieved information. Here, we used continuous measures of episodic memory retrieval in combination with computational modelling of participants’ retrieval errors to distinguish between these two potential accounts of age-related memory deficits. In three experiments, young and older participants encoded stimuli displays consisting of everyday objects varying along different perceptual features (e.g., location, colour and orientation) in a circular space. At test, participants recreated the features of studied objects using a continuous response dial. Across all three experiments, we observed age-related declines in the precision of episodic memory retrieval, whereas age differences in retrieval success were limited to the most challenging task condition. Reductions in mnemonic precision were evident for retrieval of both item-based and contextual information, and persisted after controlling for age-related decreases in the fidelity of perception and working memory. The findings highlight impoverished precision of memory representations as one factor contributing to age-related episodic memory loss, and suggest that the cognitive and neural changes associated with older age can differentially affect distinct aspects of episodic retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Weakly Supervised Deep Metric Learning for Community-Contributed Image Retrieval\n",
            "Authors: Zechao Li, Jinhui Tang\n",
            "Year: 2015\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Recent years have witnessed the explosive growth of community-contributed images with rich context information, which is beneficial to the task of image retrieval. It can help us to learn a suitable metric to alleviate the semantic gap. In this paper, we propose a new distance metric learning algorithm, namely weakly-supervised deep metric learning (WDML), under the deep learning framework. It utilizes a progressive learning manner to discover knowledge by jointly exploiting the heterogeneous data structures from visual contents and user-provided tags of social images. The semantic structure in the textual space is expected to be well preserved while the problem of the noisy, incomplete or subjective tags is addressed by leveraging the visual structure in the original visual space. Besides, a sparse model with the l2,1 mixed norm is imposed on the transformation matrix of the first layer in the deep architecture to compress the noisy or redundant visual features. The proposed problem is formulated as an optimization problem with a well-defined objective function and a simple yet efficient iterative algorithm is proposed to solve it. Extensive experiments on real-world social image datasets are conducted to verify the effectiveness of the proposed method for image retrieval. Encouraging experimental results are achieved compared with several representative metric learning methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Biomartr: genomic data retrieval with R\n",
            "Authors: Hajk-Georg Drost, J. Paszkowski\n",
            "Year: 2017\n",
            "Venue: Bioinform.\n",
            "Abstract: Motivation: Retrieval and reproducible functional annotation of genomic data are crucial in biology. However, the current poor usability and transparency of retrieval methods hinders reproducibility. Here we present an open source R package, biomartr, which provides a comprehensive easy‐to‐use framework for automating data retrieval and functional annotation for meta‐genomic approaches. The functions of biomartr achieve a high degree of clarity, transparency and reproducibility of analyses. Results: The biomartr package implements straightforward functions for bulk retrieval of all genomic data or data for selected genomes, proteomes, coding sequences and annotation files present in databases hosted by the National Center for Biotechnology Information (NCBI) and European Bioinformatics Institute (EMBL‐EBI). In addition, biomartr communicates with the BioMart database for functional annotation of retrieved sequences. Comprehensive documentation of biomartr functions and five tutorial vignettes provide step‐by‐step instructions on how to use the package in a reproducible manner. Availability and Implementation: The open source biomartr package is available at https://github.com/HajkD/biomartr and https://cran.r‐project.org/web/packages/biomartr/index.html. Contact: hgd23@cam.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Web Forum Retrieval and Text Analytics: A Survey\n",
            "Authors: Doris Hoogeveen, Li Wang, Timothy Baldwin, Karin M. Verspoor\n",
            "Year: 2018\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: This survey presents an overview of information retrieval, natural languageprocessing and machine learning research that makes use of forumdata, including both discussion forums and community questionansweringcQA archives. The focus is on automated analysis, withthe goal of gaining a better understanding of the data and its users.We discuss the different strategies used for both retrieval taskspost retrieval, question retrieval, and answer retrieval and classificationtasks post type classification, question classification, post qualityassessment, subjectivity, and viewpoint classification at the postlevel, as well as at the thread level thread retrieval, solvedness andtask orientation, discourse structure recovery and dialogue act tagging,QA-pair extraction, and thread summarisation. We also review workon forum users, including user satisfaction, expert finding, questionrecommendation and routing, and community analysis.The survey includes a brief history of forums, an overview of thedifferent kinds of forums, a summary of publicly available datasets forforum research, and a short discussion on the evaluation of retrievaltasks using forum data.The aim is to give a broad overview of the different kinds of forumresearch, a summary of the methods that have been applied, some insightsinto successful strategies, and potential areas for future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fairness in Information Access Systems\n",
            "Authors: Michael D. Ekstrand, Anubrata Das, R. Burke, Fernando Diaz\n",
            "Year: 2021\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Recommendation, information retrieval, and other information access systems pose unique challenges for investigating and applying the fairness and non-discrimination concepts that have been developed for studying other machine learning systems. While fair information access shares many commonalities with fair classification, the multistakeholder nature of information access applications, the rank-based problem setting, the centrality of personalization in many cases, and the role of user response complicate the problem of identifying precisely what types and operationalizations of fairness may be relevant, let alone measuring or promoting them. In this monograph, we present a taxonomy of the various dimensions of fair information access and survey the literature to date on this new and rapidly-growing topic. We preface this with brief introductions to information access and algorithmic fairness, to facilitate use of this work by scholars with experience in one (or neither) of these fields who wish to learn about their intersection. We conclude with several open problems in fair information access, along with some suggestions for how to approach research in this space.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Local Wavelet Pattern: A New Feature Descriptor for Image Retrieval in Medical CT Databases\n",
            "Authors: S. Dubey, S. Singh, R. Singh\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: A new image feature description based on the local wavelet pattern (LWP) is proposed in this paper to characterize the medical computer tomography (CT) images for content-based CT image retrieval. In the proposed work, the LWP is derived for each pixel of the CT image by utilizing the relationship of center pixel with the local neighboring information. In contrast to the local binary pattern that only considers the relationship between a center pixel and its neighboring pixels, the presented approach first utilizes the relationship among the neighboring pixels using local wavelet decomposition, and finally considers its relationship with the center pixel. A center pixel transformation scheme is introduced to match the range of center value with the range of local wavelet decomposed values. Moreover, the introduced local wavelet decomposition scheme is centrally symmetric and suitable for CT images. The novelty of this paper lies in the following two ways: 1) encoding local neighboring information with local wavelet decomposition and 2) computing LWP using local wavelet decomposed values and transformed center pixel values. We tested the performance of our method over three CT image databases in terms of the precision and recall. We also compared the proposed LWP descriptor with the other state-of-the-art local image descriptors, and the experimental results suggest that the proposed method outperforms other methods for CT image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Local Wavelet Pattern: A New Feature Descriptor for Image Retrieval in Medical CT Databases\n",
            "Authors: S. Dubey, S. Singh, R. Singh\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: A new image feature description based on the local wavelet pattern (LWP) is proposed in this paper to characterize the medical computer tomography (CT) images for content-based CT image retrieval. In the proposed work, the LWP is derived for each pixel of the CT image by utilizing the relationship of center pixel with the local neighboring information. In contrast to the local binary pattern that only considers the relationship between a center pixel and its neighboring pixels, the presented approach first utilizes the relationship among the neighboring pixels using local wavelet decomposition, and finally considers its relationship with the center pixel. A center pixel transformation scheme is introduced to match the range of center value with the range of local wavelet decomposed values. Moreover, the introduced local wavelet decomposition scheme is centrally symmetric and suitable for CT images. The novelty of this paper lies in the following two ways: 1) encoding local neighboring information with local wavelet decomposition and 2) computing LWP using local wavelet decomposed values and transformed center pixel values. We tested the performance of our method over three CT image databases in terms of the precision and recall. We also compared the proposed LWP descriptor with the other state-of-the-art local image descriptors, and the experimental results suggest that the proposed method outperforms other methods for CT image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Test Collection for Interactive Lifelog Retrieval\n",
            "Authors: C. Gurrin, Klaus Schöffmann, Hideo Joho, Bernd Münzer, Rami Albatal, F. Hopfgartner, Liting Zhou, Duc-Tien Dang-Nguyen\n",
            "Year: 2018\n",
            "Venue: Conference on Multimedia Modeling\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Natural‐Language‐Based Approach to Intelligent Data Retrieval and Representation for Cloud BIM\n",
            "Authors: Jia-Rui Lin, Zhen-Zhong Hu, Jianping Zhang, F. Yu\n",
            "Year: 2016\n",
            "Venue: Comput. Aided Civ. Infrastructure Eng.\n",
            "Abstract: As the information from diverse disciplines continues to integrate during the whole life cycle of an Architecture, Engineering, and Construction (AEC) project, the BIM (Building Information Model/Modeling) becomes increasingly large. This condition will cause users difficulty in acquiring the information they truly desire on a mobile device with limited space for interaction. The situation will be even worse for personnel without extensive knowledge of Industry Foundation Classes (IFC) or for nonexperts of the BIM software. To improve the value of the big data of BIM, an approach to intelligent data retrieval and representation for cloud BIM applications based on natural language processing was proposed. First, strategies for data storage and query acceleration based on the popular cloud‐based database were explored to handle the large amount of BIM data. Then, the concepts “keyword” and “constraint” were proposed to capture the key objects and their specifications in a natural‐language‐based sentence that expresses the requirements of the user. Keywords and constraints can be mapped to IFC entities or properties through the International Framework for Dictionaries (IFD). The relationship between the user's requirement and the IFC‐based data model was established by path finding in a graph generated from the IFC schema, enabling data retrieval and analysis. Finally, the analyzed and summarized results of BIM data were represented based on the structure of the retrieved data. A prototype application was developed to validate the proposed approach on the data collected during the construction of the terminal of Kunming Airport, the largest single building in China. The case study illustrated the following: (1) relationships between the user requirements and the data users concerned are established, (2) user‐concerned data can be automatically retrieved and aggregated based on the cloud for BIM, and (3) the data are represented in a proper form for a visual view and a comprehensive report. With this approach, users can significantly benefit from requesting for information and the value of BIM will be enhanced.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private function retrieval\n",
            "Authors: Mahtab Mirmohseni, M. Maddah-ali\n",
            "Year: 2017\n",
            "Venue: Iran Workshop on Communication and Information Theory\n",
            "Abstract: The widespread use of cloud computing services raises the question of how one can delegate the processing tasks to the untrusted distributed parties without breaching the privacy of its data and algorithms. Motivated by the algorithm privacy concerns in a distributed computing system, in this paper, we introduce the private function retrieval (PFR) problem, where a user wishes to efficiently retrieve a linear function of K messages from N non-communicating replicated servers while keeping the function hidden from each individual server. The goal is to find a scheme with minimum communication cost. To characterize the fundamental limits of the communication cost, we define the capacity of PFR problem as the maximum size of the message that can be privately retrieved (which is the size of one file) normalized to the required downloaded information bits. We first show that for the PFR problem with K messages, N = 2 servers and a linear function with binary coefficients the capacity is C = 1/2 (1-1/2K)−1. Interestingly, this is the capacity of retrieving one of K messages from N = 2 servers while keeping the index of the requested message hidden from each individual server, the problem known as private information retrieval (PIR). Then, we extend the proposed achievable scheme to the case of arbitrary number of servers and coefficients in the field GF (q) with arbitrary q and obtain an achievable rate R = (1-1/N)(1+1/N-1/(qK-1/q-1)N-1.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Document Retrieval Model Through Semantic Linking\n",
            "Authors: F. Ensan, E. Bagheri\n",
            "Year: 2017\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: This paper addresses the task of document retrieval based on the degree of document relatedness to the meanings of a query by presenting a semantic-enabled language model. Our model relies on the use of semantic linking systems for forming a graph representation of documents and queries, where nodes represent concepts extracted from documents and edges represent semantic relatedness between concepts. Based on this graph, our model adopts a probabilistic reasoning model for calculating the conditional probability of a query concept given values assigned to document concepts. We present an integration framework for interpolating other retrieval systems with the presented model in this paper. Our empirical experiments on a number of TREC collections show that the semantic retrieval has a synergetic impact on the results obtained through state of the art keyword-based approaches, and the consideration of semantic information obtained from entity linking on queries and documents can complement and enhance the performance of other retrieval models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effective deep learning-based multi-modal retrieval\n",
            "Authors: Wei Wang, Xiaoyan Yang, B. Ooi, Dongxiang Zhang, Yueting Zhuang\n",
            "Year: 2015\n",
            "Venue: The VLDB journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neighborhood Discriminant Hashing for Large-Scale Image Retrieval\n",
            "Authors: Jinhui Tang, Zechao Li, Meng Wang, Ruizhen Zhao\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: With the proliferation of large-scale community-contributed images, hashing-based approximate nearest neighbor search in huge databases has aroused considerable interest from the fields of computer vision and multimedia in recent years because of its computational and memory efficiency. In this paper, we propose a novel hashing method named neighborhood discriminant hashing (NDH) (for short) to implement approximate similarity search. Different from the previous work, we propose to learn a discriminant hashing function by exploiting local discriminative information, i.e., the labels of a sample can be inherited from the neighbor samples it selects. The hashing function is expected to be orthogonal to avoid redundancy in the learned hashing bits as much as possible, while an information theoretic regularization is jointly exploited using maximum entropy principle. As a consequence, the learned hashing function is compact and nonredundant among bits, while each bit is highly informative. Extensive experiments are carried out on four publicly available data sets and the comparison results demonstrate the outperforming performance of the proposed NDH method over state-of-the-art hashing techniques.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval\n",
            "Authors: Anan Liu, Weizhi Nie, Yue Gao, Yuting Su\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Multi-view matching is an important but a challenging task in view-based 3D model retrieval. To address this challenge, we propose an original multi-modal clique graph (MCG) matching method in this paper. We systematically present a method for MCG generation that is composed of cliques, which consist of neighbor nodes in multi-modal feature space and hyper-edges that link pairwise cliques. Moreover, we propose an image set-based clique/edgewise similarity measure to address the issue of the set-to-set distance measure, which is the core problem in MCG matching. The proposed MCG provides the following benefits: 1) preserves the local and global attributes of a graph with the designed structure; 2) eliminates redundant and noisy information by strengthening inliers while suppressing outliers; and 3) avoids the difficulty of defining high-order attributes and solving hyper-graph matching. We validate the MCG-based 3D model retrieval using three popular single-modal data sets and one novel multi-modal data set. Extensive experiments show the superiority of the proposed method through comparisons. Moreover, we contribute a novel real-world 3D object data set, the multi-view RGB-D object data set. To the best of our knowledge, it is the largest real-world 3D object data set containing multi-modal and multi-view information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SHREC’16 Track Large-Scale 3D Shape Retrieval from ShapeNet Core55\n",
            "Authors: M. Savva, F. Yu, Hao Su, M. Aono, B. Chen, D. Cohen-Or, W. Deng, Hang Su, S. Bai, X. Bai, N. Fish, J. Han, E. Kalogerakis, E. Learned-Miller, Y. Li, M. Liao, S. Maji, A. Tatsuma, Y. Wang, N. Zhang, Z. Zhou\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: With the advent of commodity 3D capturing devices and better 3D modeling tools, 3D shape content is becoming increasingly prevalent. Therefore, the need for shape retrieval algorithms to handle large-scale shape repositories is more and more important. This track aims to provide a benchmark to evaluate large-scale shape retrieval based on the ShapeNet dataset. We use ShapeNet Core55, which provides more than 50 thousands models over 55 common categories in total for training and evaluating several algorithms. Five participating teams have submitted a variety of retrieval methods which were evaluated on several standard information retrieval performance metrics. We ﬁnd the submitted methods work reasonably well on the track benchmark, but we also see signiﬁcant space for improvement by future algorithms. We release all the data, results, and evaluation code for the beneﬁt of the community.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Computer-Aided Diagnosis of Mammographic Masses Using Scalable Image Retrieval\n",
            "Authors: Menglin Jiang, Shaoting Zhang, Hongsheng Li, Dimitris N. Metaxas\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Biomedical Engineering\n",
            "Abstract: Computer-aided diagnosis of masses in mammograms is important to the prevention of breast cancer. Many approaches tackle this problem through content-based image retrieval techniques. However, most of them fall short of scalability in the retrieval stage, and their diagnostic accuracy is, therefore, restricted. To overcome this drawback, we propose a scalable method for retrieval and diagnosis of mammographic masses. Specifically, for a query mammographic region of interest (ROI), scale-invariant feature transform (SIFT) features are extracted and searched in a vocabulary tree, which stores all the quantized features of previously diagnosed mammographic ROIs. In addition, to fully exert the discriminative power of SIFT features, contextual information in the vocabulary tree is employed to refine the weights of tree nodes. The retrieved ROIs are then used to determine whether the query ROI contains a mass. The presented method has excellent scalability due to the low spatial-temporal cost of vocabulary tree. Extensive experiments are conducted on a large dataset of 11 553 ROIs extracted from the digital database for screening mammography, which demonstrate the accuracy and scalability of our approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dynamic neural architecture for social knowledge retrieval\n",
            "Authors: Y. Wang, Jessica A. Collins, Jessica E Koski, T. Nugiel, Athanasia Metoki, I. Olson\n",
            "Year: 2017\n",
            "Venue: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Abstract: Significance Knowledge about other people is critical for group survival and may have unique cognitive processing demands. Here, we investigate how person knowledge is represented, organized, and retrieved in the brain. We show that the anterior temporal lobe (ATL) stores abstract person identity representation that is commonly embedded in multiple sources (e.g. face, name, scene, and personal object). We also found the ATL serves as a “neural switchboard,” coordinating with a network of other brain regions in a rapid and need-specific way to retrieve different aspects of biographical information (e.g., occupation and personality traits). Our findings endorse the ATL as a central hub for representing and retrieving person knowledge. Social behavior is often shaped by the rich storehouse of biographical information that we hold for other people. In our daily life, we rapidly and flexibly retrieve a host of biographical details about individuals in our social network, which often guide our decisions as we navigate complex social interactions. Even abstract traits associated with an individual, such as their political affiliation, can cue a rich cascade of person-specific knowledge. Here, we asked whether the anterior temporal lobe (ATL) serves as a hub for a distributed neural circuit that represents person knowledge. Fifty participants across two studies learned biographical information about fictitious people in a 2-d training paradigm. On day 3, they retrieved this biographical information while undergoing an fMRI scan. A series of multivariate and connectivity analyses suggest that the ATL stores abstract person identity representations. Moreover, this region coordinates interactions with a distributed network to support the flexible retrieval of person attributes. Together, our results suggest that the ATL is a central hub for representing and retrieving person knowledge.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Planning Education for Long-Term Retention: The Cognitive Science and Implementation of Retrieval Practice\n",
            "Authors: Douglas P. Larsen\n",
            "Year: 2018\n",
            "Venue: Seminars in neurology\n",
            "Abstract: Abstract Educational systems are rarely designed for long-term retention of information. Strong evidence has emerged from cognitive psychology and applied education studies that repeated retrieval of information significantly improves retention compared to repeated studying. This effect likely emerges from the processes of memory consolidation and reconsolidation. Consolidation and reconsolidation are the means by which memories are organized into associational networks or schemas that are created and recreated as memories are formed and recalled. As educators implement retrieval practice, they should consider how various test formats lead to different degrees of schema activation. Repeated acts of retrieval provide opportunities for schemas to be updated and strengthened. Spacing of retrieval allows more consolidated schemas to be reactivated. Feedback provides metacognitive monitoring to ensure retrieval accuracy and can lead to shifts from ineffective to effective retrieval strategies. By using the principles of retrieval practice, educators can improve the likelihood that learners will retain information for longer periods of time.\n",
            "\n",
            "---\n",
            "\n",
            "Title: State-of-the-art in biomedical literature retrieval for clinical cases: a survey of the TREC 2014 CDS track\n",
            "Authors: Kirk Roberts, Matthew S. Simpson, Dina Demner-Fushman, E. Voorhees, W. Hersh\n",
            "Year: 2016\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Delay-dependent contributions of medial temporal lobe regions to episodic memory retrieval\n",
            "Authors: Maureen Ritchey, Maria E. Montchal, A. Yonelinas, C. Ranganath\n",
            "Year: 2015\n",
            "Venue: eLife\n",
            "Abstract: The medial temporal lobes play an important role in episodic memory, but over time, hippocampal contributions to retrieval may be diminished. However, it is unclear whether such changes are related to the ability to retrieve contextual information, and whether they are common across all medial temporal regions. Here, we used functional neuroimaging to compare neural responses during immediate and delayed recognition. Results showed that recollection-related activity in the posterior hippocampus declined after a 1-day delay. In contrast, activity was relatively stable in the anterior hippocampus and in neocortical areas. Multi-voxel pattern similarity analyses also revealed that anterior hippocampal patterns contained information about context during item recognition, and after a delay, context coding in this region was related to successful retention of context information. Together, these findings suggest that the anterior and posterior hippocampus have different contributions to memory over time and that neurobiological models of memory must account for these differences. DOI: http://dx.doi.org/10.7554/eLife.05025.001\n",
            "\n",
            "---\n",
            "\n",
            "Title: Benchmark for Complex Answer Retrieval\n",
            "Authors: F. Nanni, Bhaskar Mitra, Matthew Magnusson, Laura Dietz\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Providing answers to complex information needs is a challenging task. The new TREC Complex Answer Retrieval (TREC CAR) track introduces a large-scale dataset where paragraphs are to be retrieved in response to outlines of Wikipedia articles representing complex information needs. We present early results from a variety of approaches -- from standard information retrieval methods (e.g., TF-IDF) to complex systems that adopt query expansion, knowledge bases and deep neural networks. The goal is to offer an overview of some promising approaches to tackle this problem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Asking Clarifying Questions in Open-Domain Information-Seeking Conversations\n",
            "Authors: Mohammad Aliannejadi, Hamed Zamani, F. Crestani, W. Bruce Croft\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Users often fail to formulate their complex information needs in a single query. As a consequence, they may need to scan multiple result pages or reformulate their queries, which may be a frustrating experience. Alternatively, systems can improve user satisfaction by proactively asking questions of the users to clarify their information needs. Asking clarifying questions is especially important in conversational systems since they can only return a limited number of (often only one) result(s). In this paper, we formulate the task of asking clarifying questions in open-domain information-seeking conversational systems. To this end, we propose an offline evaluation methodology for the task and collect a dataset, called Qulac, through crowdsourcing. Our dataset is built on top of the TREC Web Track 2009-2012 data and consists of over 10K question-answer pairs for 198 TREC topics with 762 facets. Our experiments on an oracle model demonstrate that asking only one good question leads to over 170% retrieval performance improvement in terms of P@1, which clearly demonstrates the potential impact of the task. We further propose a retrieval framework consisting of three components: question retrieval, question selection, and document retrieval. In particular, our question selection model takes into account the original query and previous question-answer interactions while selecting the next question. Our model significantly outperforms competitive baselines. To foster research in this area, we have made Qulac publicly available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discrete Multi-view Hashing for Effective Image Retrieval\n",
            "Authors: Rui Yang, Yuliang Shi, Xin-Shun Xu\n",
            "Year: 2017\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Recently, hashing techniques have witnessed an increase in popularity due to their low storage cost and high query speed for large scale data retrieval task, e.g., image retrieval. Many methods have been proposed; however, most existing hashing techniques focus on single view data. In many scenarios, there are multiple views in data samples. Thus, those methods working on single view can not make full use of rich information contained in multi-view data. Although some methods have been proposed for multi-view data; they usually relax binary constraints or separate the process of learning hash functions and binary codes into two independent stages to bypass the obstacle of handling the discrete constraints on binary codes for optimization, which may generate large quantization error. To consider these problems, in this paper, we propose a novel hashing method, i.e., Discrete Multi-view Hashing (DMVH), which can work on multi-view data directly and make full use of rich information in multi-view data. Moreover, in DMVH, we optimize discrete codes directly instead of relaxing the binary constraints so that we could obtain high-quality hash codes. Simultaneously, we present a novel approach to construct similarity matrix, which can not only preserve local similarity structure, but also keep semantic similarity between data points. To solve the optimization problem in DMVH, we further propose an alternate algorithm. We test the proposed model on three large scale data sets. Experimental results show that it outperforms or is comparable to several state-of-the-arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval Consistency in the Presence of Query Variations\n",
            "Authors: P. Bailey, Alistair Moffat, Falk Scholer, Paul Thomas\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: A search engine that can return the ideal results for a person's information need, independent of the specific query that is used to express that need, would be preferable to one that is overly swayed by the individual terms used; search engines should be consistent in the presence of syntactic query variations responding to the same information need. In this paper we examine the retrieval consistency of a set of five systems responding to syntactic query variations over one hundred topics, working with the UQV100 test collection, and using Rank-Biased Overlap (RBO) relative to a centroid ranking over the query variations per topic as a measure of consistency. We also introduce a new data fusion algorithm, Rank-Biased Centroid (RBC), for constructing a centroid ranking over a set of rankings from query variations for a topic. RBC is compared with alternative data fusion algorithms. Our results indicate that consistency is positively correlated to a moderate degree with \"deep'' relevance measures. However, it is only weakly correlated with \"shallow'' relevance measures, as well as measures of topic complexity and variety in query expression. These findings support the notion that consistency is an independent property of a search engine's retrieval effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: on Information and Communication Technologies\n",
            "Authors: Sharmila Kumari, Li Sun, Guizhong Liu, Huan Wang, Rui Su, quot\n",
            "Year: 2020\n",
            "Venue: \n",
            "Abstract: Video text information plays an important role in semantic-based video analysis, indexing and retrieval. It is observed that the detection of texts in video remains as a challenging task due to its complex varying conditions. In this paper, we present a study on local features based text detection in document images and more focus is provided for text detection based on Laplacian method. The document image is convolved with Laplacian operator to filter the document image. Then the maximum gradient difference value is computed for each pixel to generate threshold. Based on the computed threshold, a binarized frame is obtained which highlights the text block. The candidate text block regions are further verified and refined that is, the\n",
            "\n",
            "---\n",
            "\n",
            "Title: Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems\n",
            "Authors: Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, Ming Zhang\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: Open-domain human-computer conversation has attracted much attention in the field of NLP. Contrary to rule- or template-based domain-specific dialog systems, open-domain conversation usually requires data-driven approaches, which can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (called a query) in a large database, and return a reply that best matches the query. Generative approaches, typically based on recurrent neural networks (RNNs), can synthesize new replies, but they suffer from the problem of generating short, meaningless utterances. In this paper, we propose a novel ensemble of retrieval-based and generation-based dialog systems in the open domain. In our approach, the retrieved candidate, in addition to the original query, is fed to an RNN-based reply generator, so that the neural model is aware of more information. The generated reply is then fed back as a new candidate for post-reranking. Experimental results show that such ensemble outperforms each single part of it by a large margin.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Packing and Padding: Coupled Multi-index for Accurate Image Retrieval\n",
            "Authors: Liang Zheng, Shengjin Wang, Ziqiong Liu, Q. Tian\n",
            "Year: 2014\n",
            "Venue: 2014 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: In Bag-of-Words (BoW) based image retrieval, the SIFT visual word has a low discriminative power, so false positive matches occur prevalently. Apart from the information loss during quantization, another cause is that the SIFT feature only describes the local gradient distribution. To address this problem, this paper proposes a coupled Multi-Index (c-MI) framework to perform feature fusion at indexing level. Basically, complementary features are coupled into a multi-dimensional inverted index. Each dimension of c-MI corresponds to one kind of feature, and the retrieval process votes for images similar in both SIFT and other feature spaces. Specifically, we exploit the fusion of local color feature into c-MI. While the precision of visual match is greatly enhanced, we adopt Multiple Assignment to improve recall. The joint cooperation of SIFT and color features significantly reduces the impact of false positive matches. Extensive experiments on several benchmark datasets demonstrate that c-MI improves the retrieval accuracy significantly, while consuming only half of the query time compared to the baseline. Importantly, we show that c-MI is well complementary to many prior techniques. Assembling these methods, we have obtained an mAP of 85.8% and N-S score of 3.85 on Holidays and Ukbench datasets, respectively, which compare favorably with the state-of-the-arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Novel Image Retrieval Based on Visual Words Integration of SIFT and SURF\n",
            "Authors: N. Ali, Khalid Bashir Bajwa, Robert Sablatnig, S. Chatzichristofis, Zeshan Iqbal, Muhammad Rashid, H. A. Habib\n",
            "Year: 2016\n",
            "Venue: PLoS ONE\n",
            "Abstract: With the recent evolution of technology, the number of image archives has increased exponentially. In Content-Based Image Retrieval (CBIR), high-level visual information is represented in the form of low-level features. The semantic gap between the low-level features and the high-level image concepts is an open research problem. In this paper, we present a novel visual words integration of Scale Invariant Feature Transform (SIFT) and Speeded-Up Robust Features (SURF). The two local features representations are selected for image retrieval because SIFT is more robust to the change in scale and rotation, while SURF is robust to changes in illumination. The visual words integration of SIFT and SURF adds the robustness of both features to image retrieval. The qualitative and quantitative comparisons conducted on Corel-1000, Corel-1500, Corel-2000, Oliva and Torralba and Ground Truth image benchmarks demonstrate the effectiveness of the proposed visual words integration.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancement of encoding and retrieval functions through theta phase-specific manipulation of hippocampus\n",
            "Authors: J. Siegle, M. Wilson\n",
            "Year: 2014\n",
            "Venue: eLife\n",
            "Abstract: Assessing the behavioral relevance of the hippocampal theta rhythm has proven difficult, due to a shortage of experiments that selectively manipulate phase-specific information processing. Using closed-loop stimulation, we triggered inhibition of dorsal CA1 at specific phases of the endogenous theta rhythm in freely behaving mice. This intervention enhanced performance on a spatial navigation task that requires the encoding and retrieval of information related to reward location on every trial. In agreement with prior models of hippocampal function, the behavioral effects depended on both the phase of theta and the task segment at which we stimulated. Stimulation in the encoding segment enhanced performance when inhibition was triggered by the peak of theta. Conversely, stimulation in the retrieval segment enhanced performance when inhibition was triggered by the trough of theta. These results suggest that processes related to the encoding and retrieval of task-relevant information are preferentially active at distinct phases of theta. DOI: http://dx.doi.org/10.7554/eLife.03061.001\n",
            "\n",
            "---\n",
            "\n",
            "Title: Look Here, Eye Movements Play a Functional Role in Memory Retrieval\n",
            "Authors: R. Johansson, M. Johansson\n",
            "Year: 2014\n",
            "Venue: Psychology Science\n",
            "Abstract: Research on episodic memory has established that spontaneous eye movements occur to spaces associated with retrieved information even if those spaces are blank at the time of retrieval. Although it has been claimed that such looks to “nothing” can function as facilitatory retrieval cues, there is currently no conclusive evidence for such an effect. In the present study, we addressed this fundamental issue using four direct eye manipulations in the retrieval phase of an episodic memory task: (a) free viewing on a blank screen, (b) maintaining central fixation, (c) looking inside a square congruent with the location of the to-be-recalled objects, and (d) looking inside a square incongruent with the location of the to-be-recalled objects. Our results provide novel evidence of an active and facilitatory role of gaze position during memory retrieval and demonstrate that memory for the spatial relationship between objects is more readily affected than memory for intrinsic object features.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Breast Histopathological Image Retrieval Based on Latent Dirichlet Allocation\n",
            "Authors: Yibing Ma, Zhi-guo Jiang, Haopeng Zhang, Feng-ying Xie, Yushan Zheng, Huaqiang Shi, Yu Zhao\n",
            "Year: 2017\n",
            "Venue: IEEE journal of biomedical and health informatics\n",
            "Abstract: In the field of pathology, whole slide image (WSI) has become the major carrier of visual and diagnostic information. Content-based image retrieval among WSIs can aid the diagnosis of an unknown pathological image by finding its similar regions in WSIs with diagnostic information. However, the huge size and complex content of WSI pose several challenges for retrieval. In this paper, we propose an unsupervised, accurate, and fast retrieval method for a breast histopathological image. Specifically, the method presents a local statistical feature of nuclei for morphology and distribution of nuclei, and employs the Gabor feature to describe the texture information. The latent Dirichlet allocation model is utilized for high-level semantic mining. Locality-sensitive hashing is used to speed up the search. Experiments on a WSI database with more than 8000 images from 15 types of breast histopathology demonstrate that our method achieves about 0.9 retrieval precision as well as promising efficiency. Based on the proposed framework, we are developing a search engine for an online digital slide browsing and retrieval platform, which can be applied in computer-aided diagnosis, pathology education, and WSI archiving and management.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Achievable Rate of Private Function Retrieval from MDS Coded Databases\n",
            "Authors: Sarah A. Obead, J. Kliewer\n",
            "Year: 2018\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We study the problem of private function retrieval (PFR) in a distributed storage system. In PFR the user wishes to retrieve a linear combination of $M$ messages stored in non-colluding (N, K) MDS coded databases while revealing no information about the coefficients of the intended linear combination to any of the individual databases. We present an achievable scheme for MDS coded PFR with a rate that matches the capacity for coded private information retrieval derived recently, $R= (1+R_{c}+R_{c}^{2}+\\cdots +R_{c}^{M-1})^{-1}=\\frac{1-R_{c}}{1-R_{c}^{M}}$, where $R_{c}=\\frac{K}{N}$ is the rate of the MDS code.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Data Collection for Evaluating the Retrieval of Related Tweets to News Articles\n",
            "Authors: Axel Suarez, M. Albakour, D. Corney, Miguel Martinez-Alvarez, José Esquivel\n",
            "Year: 2018\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: EMR: A Scalable Graph-Based Ranking Model for Content-Based Image Retrieval\n",
            "Authors: Bin Xu, Jiajun Bu, Chun Chen, C. Wang, Deng Cai, Xiaofei He\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Knowledge and Data Engineering\n",
            "Abstract: Graph-based ranking models have been widely applied in information retrieval area. In this paper, we focus on a well known graph-based model - the Ranking on Data Manifold model, or Manifold Ranking (MR). Particularly, it has been successfully applied to content-based image retrieval, because of its outstanding ability to discover underlying geometrical structure of the given image database. However, manifold ranking is computationally very expensive, which significantly limits its applicability to large databases especially for the cases that the queries are out of the database (new samples). We propose a novel scalable graph-based ranking model called Efficient Manifold Ranking (EMR), trying to address the shortcomings of MR from two main perspectives: scalable graph construction and efficient ranking computation. Specifically, we build an anchor graph on the database instead of a traditional k-nearest neighbor graph, and design a new form of adjacency matrix utilized to speed up the ranking. An approximate method is adopted for efficient out-of-sample retrieval. Experimental results on some large scale image databases demonstrate that EMR is a promising method for real world retrieval applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Spoken Content Retrieval—Beyond Cascading Speech Recognition with Text Retrieval\n",
            "Authors: Lin-Shan Lee, James R. Glass, Hung-yi Lee, Chun-an Chan\n",
            "Year: 2015\n",
            "Venue: IEEE/ACM Transactions on Audio Speech and Language Processing\n",
            "Abstract: Spoken content retrieval refers to directly indexing and retrieving spoken content based on the audio rather than text descriptions. This potentially eliminates the requirement of producing text descriptions for multimedia content for indexing and retrieval purposes, and is able to precisely locate the exact time the desired information appears in the multimedia. Spoken content retrieval has been very successfully achieved with the basic approach of cascading automatic speech recognition (ASR) with text information retrieval: after the spoken content is transcribed into text or lattice format, a text retrieval engine searches over the ASR output to find desired information. This framework works well when the ASR accuracy is relatively high, but becomes less adequate when more challenging real-world scenarios are considered, since retrieval performance depends heavily on ASR accuracy. This challenge leads to the emergence of another approach to spoken content retrieval: to go beyond the basic framework of cascading ASR with text retrieval in order to have retrieval performances that are less dependent on ASR accuracy. This overview article is intended to provide a thorough overview of the concepts, principles, approaches, and achievements of major technical contributions along this line of investigation. This includes five major directions: 1) Modified ASR for Retrieval Purposes: cascading ASR with text retrieval, but the ASR is modified or optimized for spoken content retrieval purposes; 2) Exploiting the Information not present in ASR outputs: to try to utilize the information in speech signals inevitably lost when transcribed into phonemes and words; 3) Directly Matching at the Acoustic Level without ASR: for spoken queries, the signals can be directly matched at the acoustic level, rather than at the phoneme or word levels, bypassing all ASR issues; 4) Semantic Retrieval of Spoken Content: trying to retrieve spoken content that is semantically related to the query, but not necessarily including the query terms themselves; 5) Interactive Retrieval and Efficient Presentation of the Retrieved Objects: with efficient presentation of the retrieved objects, an interactive retrieval process incorporating user actions may produce better retrieval results and user experiences.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluating Retrieval over Sessions: The TREC Session Track 2011-2014\n",
            "Authors: Ben Carterette, Paul D. Clough, M. Hall, E. Kanoulas, M. Sanderson\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Information Retrieval (IR) research has traditionally focused on serving the best results for a single query - so-called ad hoc retrieval. However, users typically search iteratively, refining and reformulating their queries during a session. A key challenge in the study of this interaction is the creation of suitable evaluation resources to assess the effectiveness of IR systems over sessions. This paper describes the TREC Session Track, which ran from 2010 through to 2014, which focussed on forming test collections that included various forms of implicit feedback. We describe the test collections; a brief analysis of the differences between datasets over the years; and the evaluation results that demonstrate that the use of user session data significantly improved effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pairwise geometric matching for large-scale object retrieval\n",
            "Authors: Xinchao Li, M. Larson, A. Hanjalic\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Spatial verification is a key step in boosting the performance of object-based image retrieval. It serves to eliminate unreliable correspondences between salient points in a given pair of images, and is typically performed by analyzing the consistency of spatial transformations between the image regions involved in individual correspondences. In this paper, we consider the pairwise geometric relations between correspondences and propose a strategy to incorporate these relations at significantly reduced computational cost, which makes it suitable for large-scale object retrieval. In addition, we combine the information on geometric relations from both the individual correspondences and pairs of correspondences to further improve the verification accuracy. Experimental results on three reference datasets show that the proposed approach results in a substantial performance improvement compared to the existing methods, without making concessions regarding computational efficiency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discriminative Dictionary Learning With Common Label Alignment for Cross-Modal Retrieval\n",
            "Authors: Cheng Deng, Xu Tang, Junchi Yan, W. Liu, Xinbo Gao\n",
            "Year: 2016\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Cross-modal retrieval has attracted much attention in recent years due to its widespread applications. In this area, how to capture and correlate heterogeneous features originating from different modalities remains a challenge. However, most existing methods dealing with cross-modal learning only focus on learning relevant features shared by two distinct feature spaces, therefore overlooking discriminative feature information of them. To remedy this issue and explicitly capture discriminative feature information, we propose a novel cross-modal retrieval approach based on discriminative dictionary learning that is augmented with common label alignment. Concretely, a discriminative dictionary is first learned to account for each modality, which boosts not only the discriminating capability of intra-modality data from different classes but also the relevance of inter-modality data in the same class. Subsequently, all the resulting sparse codes are simultaneously mapped to a common label space, where the cross-modal data samples are characterized and associated. Also in the label space, the discriminativeness and relevance of the considered cross-modal data can be further strengthened by enforcing a common label alignment. Finally, cross-modal retrieval is performed over the common label space. Experiments conducted on two public cross-modal datasets show that the proposed approach outperforms several state-of-the-art methods in term of retrieval accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Location and Time Aware Social Collaborative Retrieval for New Successive Point-of-Interest Recommendation\n",
            "Authors: Wei Zhang, Jianyong Wang\n",
            "Year: 2015\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: In location-based social networks (LBSNs), new successive point-of-interest (POI) recommendation is a newly formulated task which tries to regard the POI a user currently visits as his POI-related query and recommend new POIs the user has not visited before. While carefully designed methods are proposed to solve this problem, they ignore the essence of the task which involves retrieval and recommendation problem simultaneously and fail to employ the social relations or temporal information adequately to improve the results. In order to solve this problem, we propose a new model called location and time aware social collaborative retrieval model (LTSCR), which has two distinct advantages: (1) it models the location, time, and social information simultaneously for the successive POI recommendation task; (2) it efficiently utilizes the merits of the collaborative retrieval model which leverages weighted approximately ranked pairwise (WARP) loss for achieving better top-n ranking results, just as the new successive POI recommendation task needs. We conducted some comprehensive experiments on publicly available datasets and demonstrate the power of the proposed method, with 46.6% growth in Precision@5 and 47.3% improvement in Recall@5 over the best previous method.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Document Retrieval Using Entity-Based Language Models\n",
            "Authors: Hadas Raviv, Oren Kurland, David Carmel\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We address the ad hoc document retrieval task by devising novel types of entity-based language models. The models utilize information about single terms in the query and documents as well as term sequences marked as entities by some entity-linking tool. The key principle of the language models is accounting, simultaneously, for the uncertainty inherent in the entity-markup process and the balance between using entity-based and term-based information. Empirical evaluation demonstrates the merits of using the language models for retrieval. For example, the performance transcends that of a state-of-the-art term proximity method. We also show that the language models can be effectively used for cluster-based document retrieval and query expansion.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Emerging trends and new developments in information science: a document co-citation analysis (2009–2016)\n",
            "Authors: Jia-lin Hou, Xiucai Yang, Chaomei Chen\n",
            "Year: 2018\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-Based High-Resolution Remote Sensing Image Retrieval via Unsupervised Feature Learning and Collaborative Affinity Metric Fusion\n",
            "Authors: Yansheng Li, Yongjun Zhang, Chao Tao, Hu Zhu\n",
            "Year: 2016\n",
            "Venue: Remote Sensing\n",
            "Abstract: With the urgent demand for automatic management of large numbers of high-resolution remote sensing images, content-based high-resolution remote sensing image retrieval (CB-HRRS-IR) has attracted much research interest. Accordingly, this paper proposes a novel high-resolution remote sensing image retrieval approach via multiple feature representation and collaborative affinity metric fusion (IRMFRCAMF). In IRMFRCAMF, we design four unsupervised convolutional neural networks with different layers to generate four types of unsupervised features from the fine level to the coarse level. In addition to these four types of unsupervised features, we also implement four traditional feature descriptors, including local binary pattern (LBP), gray level co-occurrence (GLCM), maximal response 8 (MR8), and scale-invariant feature transform (SIFT). In order to fully incorporate the complementary information among multiple features of one image and the mutual information across auxiliary images in the image dataset, this paper advocates collaborative affinity metric fusion to measure the similarity between images. The performance evaluation of high-resolution remote sensing image retrieval is implemented on two public datasets, the UC Merced (UCM) dataset and the Wuhan University (WH) dataset. Large numbers of experiments show that our proposed IRMFRCAMF can significantly outperform the state-of-the-art approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content Based Image Retrieval Using Embedded Neural Networks with Bandletized Regions\n",
            "Authors: Rehan Ashraf, Khalid Bashir Bajwa, Aun Irtaza, M. Mahmood\n",
            "Year: 2015\n",
            "Venue: Entropy\n",
            "Abstract: One of the major requirements of content based image retrieval (CBIR) systems is to ensure meaningful image retrieval against query images. The performance of these systems is severely degraded by the inclusion of image content which does not contain the objects of interest in an image during the image representation phase. Segmentation of the images is considered as a solution but there is no technique that can guarantee the object extraction in a robust way. Another limitation of the segmentation is that most of the image segmentation techniques are slow and their results are not reliable. To overcome these problems, a bandelet transform based image representation technique is presented in this paper, which reliably returns the information about the major objects found in an image. For image retrieval purposes, artificial neural networks (ANN) are applied and the performance of the system and achievement is evaluated on three standard data sets used in the domain of CBIR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ventral fronto-temporal pathway supporting cognitive control of episodic memory retrieval.\n",
            "Authors: J. Barredo, Ilke Öztekin, David Badre\n",
            "Year: 2015\n",
            "Venue: Cerebral Cortex\n",
            "Abstract: Achieving our goals often requires guiding access to relevant information from memory. Such goal-directed retrieval requires interactions between systems supporting cognitive control, including ventrolateral prefrontal cortex (VLPFC), and those supporting declarative memory, such as the medial temporal lobes (MTL). However, the pathways by which VLPFC interacts with MTL during retrieval are underspecified. Prior neuroanatomical evidence suggests that a polysynaptic ventral fronto-temporal pathway may support VLPFC-MTL interactions. To test this hypothesis, human participants were scanned using fMRI during performance of a source-monitoring task. The strength of source information was varied via repetition during encoding. Single encoding events should produce a weaker memory trace, thus recovering source information about these items should demand greater cognitive control. Results demonstrated that cortical targets along the ventral path--anterior VLPFC, temporal pole, anterior parahippocampus, and hippocampus--exhibited increases in univariate BOLD response correlated with increases in controlled retrieval demand, independent of factors related to response selection. Further, a functional connectivity analysis indicated that these regions functionally couple and are distinguishable from a dorsal pathway related to response selection demands. These data support a ventral retrieval pathway linking PFC and MTL.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Large-Scale 3D Shape Retrieval from ShapeNet Core55\n",
            "Authors: M. Savva, F. Yu, Hao Su, Masaki Aono, Baoquan Chen, D. Cohen-Or, W. Deng, Hang Su, S. Bai, X. Bai, N. Fish, Jiajie Han, E. Kalogerakis, E. Learned-Miller, Yangyan Li, Minghui Liao, Subhransu Maji, A. Tatsuma, Yida Wang, Nanhai Zhang, Zhichao Zhou\n",
            "Year: 2016\n",
            "Venue: 3DOR@Eurographics\n",
            "Abstract: With the advent of commodity 3D capturing devices and better 3D modeling tools, 3D shape content is becoming increasingly prevalent. Therefore, the need for shape retrieval algorithms to handle large-scale shape repositories is more and more important. This track aims to provide a benchmark to evaluate large-scale shape retrieval based on the ShapeNet dataset. We use ShapeNet Core55, which provides more than 50 thousands models over 55 common categories in total for training and evaluating several algorithms. Five participating teams have submitted a variety of retrieval methods which were evaluated on several standard information retrieval performance metrics. We find the submitted methods work reasonably well on the track benchmark, but we also see significant space for improvement by future algorithms. We release all the data, results, and evaluation code for the benefit of the community.\n",
            "\n",
            "---\n",
            "\n",
            "Title: 3-D Object Retrieval With Hausdorff Distance Learning\n",
            "Authors: Yue Gao, Meng Wang, R. Ji, Xindong Wu, Qionghai Dai\n",
            "Year: 2014\n",
            "Venue: IEEE transactions on industrial electronics (1982. Print)\n",
            "Abstract: In view-based 3-D object retrieval, each object is described by a set of views. Group matching thus plays an important role. Previous research efforts have shown the effectiveness of Hausdorff distance in group matching. In this paper, we propose a 3-D object retrieval scheme with Hausdorff distance learning. In our approach, relevance feedback information is employed to select positive and negative view pairs with a probabilistic strategy, and a view-level Mahalanobis distance metric is learned. This Mahalanobis distance metric is adopted in estimating the Hausdorff distances between objects, based on which the objects in the 3-D database are ranked. We conduct experiments on three testing data sets, and the results demonstrate that the proposed Hausdorff learning approach can improve 3-D object retrieval performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Music Similarity and Retrieval: An Introduction to Audio- and Web-based Strategies\n",
            "Authors: Peter Knees, M. Schedl\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: This book provides a summary of the manifold audio- and web-based approaches to music information retrieval (MIR) research. In contrast to other books dealing solely with music signal processing, it addresses additional cultural and listener-centric aspects and thus provides a more holistic view. Consequently, the text includes methods operating on features extracted directly from the audio signal, as well as methods operating on features extracted from contextual information, either the cultural context of music as represented on the web or the user and usage context of music. Following the prevalent document-centered paradigm of information retrieval, the book addresses models of music similarity that extract computational features to describe an entity that represents music on any level (e.g., song, album, or artist), and methods to calculate the similarity between them. While this perspective and the representations discussed cannot describe all musical dimensions, they enable us to effectively find music of similar qualities by providing abstract summarizations of musical artifacts from different modalities. The text at hand provides a comprehensive and accessible introduction to the topics of music search, retrieval, and recommendation from an academic perspective. It will not only allow those new to the field to quickly access MIR from an information retrieval point of view but also raise awareness for the developments of the music domain within the greater IR community. In this regard, Part I deals with content-based MIR, in particular the extraction of features from the music signal and similarity calculation for content-based retrieval. Part II subsequently addresses MIR methods that make use of the digitally accessible cultural context of music. Part III addresses methods of collaborative filtering and user-aware and multi-modal retrieval, while Part IV explores current and future applications of music retrieval and recommendation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A retrieval algorithm of encrypted speech based on syllable-level perceptual hashing\n",
            "Authors: Shaofang He, Huan Zhao\n",
            "Year: 2017\n",
            "Venue: Computer Science and Information Systems\n",
            "Abstract: To retrieve voice information in a fast and accurate manner over encrypted speech, this study proposes a retrieval algorithm based on syllable-level perceptual hashing. It implements the function of retrieving speech segment and spoken term over encrypted speech database. Before uploading the speech to the cloud, it needs to embed the digital watermarks (perceptual hashing). In the retrieval process, it does not need search over encrypted speech data directly or decryption, but requires searching the system hash table. Experimental results show that the syllable-level perceptual hashing of the proposed scheme has good discrimination, uniqueness, and perceptual robustness to common speech. In addition, the proposed retrieval algorithm effectively improves the retrieval speed by reducing the matching number of query index. The precision ratio and recall ratio all achieve high under various signal processing.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effective Multi-Modal Retrieval based on Stacked Auto-Encoders\n",
            "Authors: Wei Wang, B. Ooi, Xiaoyan Yang, Dongxiang Zhang, Yueting Zhuang\n",
            "Year: 2014\n",
            "Venue: Proceedings of the VLDB Endowment\n",
            "Abstract: Multi-modal retrieval is emerging as a new search paradigm that enables seamless information retrieval from various types of media. For example, users can simply snap a movie poster to search relevant reviews and trailers. To solve the problem, a set of mapping functions are learned to project high-dimensional features extracted from data of different media types into a common low-dimensional space so that metric distance measures can be applied. In this paper, we propose an effective mapping mechanism based on deep learning (i.e., stacked auto-encoders) for multi-modal retrieval. Mapping functions are learned by optimizing a new objective function, which captures both intra-modal and inter-modal semantic relationships of data from heterogeneous sources effectively. Compared with previous works which require a substantial amount of prior knowledge such as similarity matrices of intra-modal data and ranking examples, our method requires little prior knowledge. Given a large training dataset, we split it into mini-batches and continually adjust the mapping functions for each batch of input. Hence, our method is memory efficient with respect to the data volume. Experiments on three real datasets illustrate that our proposed method achieves significant improvement in search accuracy over the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improved methodology for surface and atmospheric soundings, error estimates, and quality control procedures: the atmospheric infrared sounder science team version-6 retrieval algorithm\n",
            "Authors: J. Susskind, J. Blaisdell, L. Iredell\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Abstract The atmospheric infrared sounder (AIRS) science team version-6 AIRS/advanced microwave sounding unit (AMSU) retrieval algorithm is now operational at the Goddard Data and Information Services Center (DISC). AIRS version-6 level-2 products are generated near real time at the Goddard DISC and all level-2 and level-3 products are available starting from September 2002. Some of the significant improvements in retrieval methodology contained in the version-6 retrieval algorithm compared to that previously used in version-5 are described. In particular, the AIRS science team made major improvements with regard to the algorithms used to (1) derive surface skin temperature and surface spectral emissivity; (2) generate the initial state used to start the cloud clearing and retrieval procedures; and (3) derive error estimates and use them for quality control. Significant improvements have also been made in the generation of cloud parameters. In addition to the basic AIRS/AMSU mode, version-6 also operates in an AIRS only (AO) mode, which produces results almost as good as those of the full AIRS/AMSU mode. The improvements of some AIRS version-6 and version-6 AO products compared to those obtained using version-5 are also demonstrated.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval attempts enhance learning, but retrieval success (versus failure) does not matter.\n",
            "Authors: Nate Kornell, Patricia Jacobs Klein, Katherine A. Rawson\n",
            "Year: 2015\n",
            "Venue: Journal of Experimental Psychology. Learning, Memory and Cognition\n",
            "Abstract: Retrieving information from memory enhances learning. We propose a 2-stage framework to explain the benefits of retrieval. Stage 1 takes place as one attempts to retrieve an answer, which activates knowledge related to the retrieval cue. Stage 2 begins when the answer becomes available, at which point appropriate connections are strengthened and inappropriate connections may be weakened. This framework raises a basic question: Does it matter whether Stage 2 is initiated via successful retrieval or via an external presentation of the answer? To test this question, we asked participants to attempt retrieval and then randomly assigned items (which were equivalent otherwise) to be retrieved successfully or to be copied (i.e., not retrieved). Experiments 1, 2, 4, and 5 tested assumptions necessary for interpreting Experiments 3a, 3b, and 6. Experiments 3a, 3b, and 6 did not support the hypothesis that retrieval success produces more learning than does retrieval failure followed by feedback. It appears that retrieval attempts promote learning but retrieval success per se does not.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database Saliency for Fast Image Retrieval\n",
            "Authors: Yuan Gao, Miaojing Shi, D. Tao, Chao Xu\n",
            "Year: 2015\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: The bag-of-visual-words (BoW) model is effective for representing images and videos in many computer vision problems, and achieves promising performance in image retrieval. Nevertheless, the level of retrieval efficiency in a large-scale database is not acceptable for practical usage. Considering that the relevant images in the database of a given query are more likely to be distinctive than ambiguous, this paper defines “database saliency” as the distinctiveness score calculated for every image to measure its overall “saliency” in the database. By taking advantage of database saliency, we propose a saliency- inspired fast image retrieval scheme, S-sim, which significantly improves efficiency while retains state-of-the-art accuracy in image retrieval . There are two stages in S-sim: the bottom-up saliency mechanism computes the database saliency value of each image by hierarchically decomposing a posterior probability into local patches and visual words, the concurrent information of visual words is then bottom-up propagated to estimate the distinctiveness, and the top-down saliency mechanism discriminatively expands the query via a very low-dimensional linear SVM trained on the top-ranked images after initial search, ranking images are then sorted on their distances to the decision boundary as well as the database saliency values. We comprehensively evaluate S-sim on common retrieval benchmarks, e.g., Oxford and Paris datasets. Thorough experiments suggest that, because of the offline database saliency computation and online low-dimensional SVM, our approach significantly speeds up online retrieval and outperforms the state-of-the-art BoW-based image retrieval schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Schematic memory components converge within angular gyrus during retrieval\n",
            "Authors: Isabella C. Wagner, Mariët van Buuren, Marijn C. W. Kroes, T. Gutteling, Mieke van der Linden, R. Morris, G. Fernández\n",
            "Year: 2015\n",
            "Venue: eLife\n",
            "Abstract: Mental schemas form associative knowledge structures that can promote the encoding and consolidation of new and related information. Schemas are facilitated by a distributed system that stores components separately, presumably in the form of inter-connected neocortical representations. During retrieval, these components need to be recombined into one representation, but where exactly such recombination takes place is unclear. Thus, we asked where different schema components are neuronally represented and converge during retrieval. Subjects acquired and retrieved two well-controlled, rule-based schema structures during fMRI on consecutive days. Schema retrieval was associated with midline, medial-temporal, and parietal processing. We identified the multi-voxel representations of different schema components, which converged within the angular gyrus during retrieval. Critically, convergence only happened after 24-hour-consolidation and during a transfer test where schema material was applied to novel but related trials. Therefore, the angular gyrus appears to recombine consolidated schema components into one memory representation. DOI: http://dx.doi.org/10.7554/eLife.09668.001\n",
            "\n",
            "---\n",
            "\n",
            "Title: Scalable Mobile Image Retrieval by Exploring Contextual Saliency\n",
            "Authors: Xiyu Yang, Xueming Qian, Yao Xue\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Nowadays, it is very convenient to capture photos by a smart phone. As using, the smart phone is a convenient way to share what users experienced anytime and anywhere through social networks, it is very possible that we capture multiple photos to make sure the content is well photographed. In this paper, an effective scalable mobile image retrieval approach is proposed by exploring contextual salient information for the input query image. Our goal is to explore the high-level semantic information of an image by finding the contextual saliency from multiple relevant photos rather than solely using the input image. Thus, the proposed mobile image retrieval approach first determines the relevant photos according to visual similarity, then mines salient features by exploring contextual saliency from multiple relevant images, and finally determines contributions of salient features for scalable retrieval. Compared with the existing mobile-based image retrieval approaches, our approach requires less bandwidth and has better retrieval performance. We can carry out retrieval with <;200-B data, which is <;5% of existing approaches. Most importantly, when the bandwidth is limited, we can rank the transmitted features according to their contributions to retrieval. Experimental results show the effectiveness of the proposed approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Language Estimation with the Paragraph Vector Model for Ad-hoc Retrieval\n",
            "Authors: Qingyao Ai, Liu Yang, J. Guo, W. Bruce Croft\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Incorporating topic level estimation into language models has been shown to be beneficial for information retrieval (IR) models such as cluster-based retrieval and LDA-based document representation. Neural embedding models, such as paragraph vector (PV) models, on the other hand have shown their effectiveness and efficiency in learning semantic representations of documents and words in multiple Natural Language Processing (NLP) tasks. However, their effectiveness in information retrieval is mostly unknown. In this paper, we study how to effectively use the PV model to improve ad-hoc retrieval. We propose three major improvements over the original PV model to adapt it for the IR scenario: (1) we use a document frequency-based rather than the corpus frequency-based negative sampling strategy so that the importance of frequent words will not be suppressed excessively; (2) we introduce regularization over the document representation to prevent the model overfitting short documents along with the learning iterations; and (3) we employ a joint learning objective which considers both the document-word and word-context associations to produce better word probability estimation. By incorporating this enhanced PV model into the language modeling framework, we show that it can significantly outperform the state-of-the-art topic enhanced language models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Adaptive Information Seeking for Open-Domain Question Answering\n",
            "Authors: Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, Xueqi Cheng\n",
            "Year: 2021\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Information seeking is an essential step for open-domain question answering to efficiently gather evidence from a large corpus. Recently, iterative approaches have been proven to be effective for complex questions, by recursively retrieving new evidence at each step. However, almost all existing iterative approaches use predefined strategies, either applying the same retrieval function multiple times or fixing the order of different retrieval functions, which cannot fulfill the diverse requirements of various questions. In this paper, we propose a novel adaptive information-seeking strategy for open-domain question answering, namely AISO. Specifically, the whole retrieval and answer process is modeled as a partially observed Markov decision process, where three types of retrieval operations (e.g., BM25, DPR, and hyperlink) and one answer operation are defined as actions. According to the learned policy, AISO could adaptively select a proper retrieval action to seek the missing evidence at each step, based on the collected evidence and the reformulated query, or directly output the answer when the evidence set is sufficient for the question. Experiments on SQuAD Open and HotpotQA fullwiki, which serve as single-hop and multi-hop open-domain QA benchmarks, show that AISO outperforms all baseline methods with predefined strategies in terms of both retrieval and answer evaluations.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Novel Image Retrieval Based on a Combination of Local and Global Histograms of Visual Words\n",
            "Authors: Zahid Mehmood, S. Anwar, N. Ali, H. A. Habib, Muhammad Rashid\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Content-based image retrieval (CBIR) provides a sustainable solution to retrieve similar images from an image archive. In the last few years, the Bag-of-Visual-Words (BoVW) model gained attention and significantly improved the performance of image retrieval. In the standard BoVW model, an image is represented as an orderless global histogram of visual words by ignoring the spatial layout. The spatial layout of an image carries significant information that can enhance the performance of CBIR. In this paper, we are presenting a novel image representation that is based on a combination of local and global histograms of visual words. The global histogram of visual words is constructed over the whole image, while the local histogram of visual words is constructed over the local rectangular region of the image. The local histogram contains the spatial information about the salient objects. Extensive experiments and comparisons conducted on Corel-A, Caltech-256, and Ground Truth image datasets demonstrate that the proposed image representation increases the performance of image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Toward an episodic context account of retrieval-based learning: dissociating retrieval practice and elaboration.\n",
            "Authors: Melissa Lehman, Megan A. Smith, Jeffrey D. Karpicke\n",
            "Year: 2014\n",
            "Venue: Journal of Experimental Psychology. Learning, Memory and Cognition\n",
            "Abstract: We tested the predictions of 2 explanations for retrieval-based learning; while the elaborative retrieval hypothesis assumes that the retrieval of studied information promotes the generation of semantically related information, which aids in later retrieval (Carpenter, 2009), the episodic context account proposed by Karpicke, Lehman, and Aue (in press) assumes that retrieval alters the representation of episodic context and improves one's ability to guide memory search on future tests. Subjects studied multiple word lists and either recalled each list (retrieval practice), did a math task (control), or generated associates for each word (elaboration) after each list. After studying the last list, all subjects recalled the list and, after a 5-min delay, recalled all lists. Analyses of correct recall, intrusions, response times, and temporal clustering dissociate retrieval practice from elaboration, supporting the episodic context account.\n",
            "\n",
            "---\n",
            "\n",
            "Title: STFT Phase Retrieval: Uniqueness Guarantees and Recovery Algorithms\n",
            "Authors: K. Jaganathan, Yonina C. Eldar, B. Hassibi\n",
            "Year: 2015\n",
            "Venue: IEEE Journal on Selected Topics in Signal Processing\n",
            "Abstract: The problem of recovering a signal from its Fourier magnitude is of paramount importance in various fields of engineering and applied physics. Due to the absence of Fourier phase information, some form of additional information is required in order to be able to uniquely, efficiently, and robustly identify the underlying signal. Inspired by practical methods in optical imaging, we consider the problem of signal reconstruction from the short-time Fourier transform (STFT) magnitude. We first develop conditions under, which the STFT magnitude is an almost surely unique signal representation. We then consider a semidefinite relaxation-based algorithm (STliFT) and provide recovery guarantees. Numerical simulations complement our theoretical analysis and provide directions for future work.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Latent entity space: a novel retrieval approach for entity-bearing queries\n",
            "Authors: Xitong Liu, Hui Fang\n",
            "Year: 2015\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discriminative coupled dictionary hashing for fast cross-media retrieval\n",
            "Authors: Zhou Yu, Fei Wu, Yi Yang, Q. Tian, Jiebo Luo, Yueting Zhuang\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Cross-media hashing, which conducts cross-media retrieval by embedding data from different modalities into a common low-dimensional Hamming space, has attracted intensive attention in recent years. The existing cross-media hashing approaches only aim at learning hash functions to preserve the intra-modality and inter-modality correlations, but do not directly capture the underlying semantic information of the multi-modal data. We propose a discriminative coupled dictionary hashing (DCDH) method in this paper. In DCDH, the coupled dictionary for each modality is learned with side information (e.g., categories). As a result, the coupled dictionaries not only preserve the intra-similarity and inter-correlation among multi-modal data, but also contain dictionary atoms that are semantically discriminative (i.e., the data from the same category is reconstructed by the similar dictionary atoms). To perform fast cross-media retrieval, we learn hash functions which map data from the dictionary space to a low-dimensional Hamming space. Besides, we conjecture that a balanced representation is crucial in cross-media retrieval. We introduce multi-view features on the relatively ``weak'' modalities into DCDH and extend it to multi-view DCDH (MV-DCDH) in order to enhance their representation capability. The experiments on two real-world data sets show that our DCDH and MV-DCDH outperform the state-of-the-art methods significantly on cross-media retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An overview of approaches for content-based medical image retrieval\n",
            "Authors: P. Das, A. Neelima\n",
            "Year: 2017\n",
            "Venue: International Journal of Multimedia Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Classroom Study on the Relationship Between Student Achievement and Retrieval-Enhanced Learning\n",
            "Authors: Shana K. Carpenter, Terry J. S. Lund, C. Coffman, P. Armstrong, Monica H Lamm, R. Reason\n",
            "Year: 2015\n",
            "Venue: Educational Psychology Review\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Metamemory monitoring and control following retrieval practice for text\n",
            "Authors: Jeri L. Little, M. McDaniel\n",
            "Year: 2015\n",
            "Venue: Memory & Cognition\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Terminator-free template-independent enzymatic DNA synthesis for digital information storage\n",
            "Authors: Henry H. Lee, Reza Kalhor, Naveen Goela, J. Bolot, G. Church\n",
            "Year: 2019\n",
            "Venue: Nature Communications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access\n",
            "Authors: Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung (Vivian) Chen, Faisal Ahmed, L. Deng\n",
            "Year: 2016\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: This paper proposes KB-InfoBot - a multi-turn dialogue agent which helps users search Knowledge Bases (KBs) without composing complicated queries. Such goal-oriented dialogue agents typically need to interact with an external database to access real-world knowledge. Previous systems achieved this by issuing a symbolic query to the KB to retrieve entries based on their attributes. However, such symbolic operations break the differentiability of the system and prevent end-to-end training of neural dialogue agents. In this paper, we address this limitation by replacing symbolic queries with an induced “soft” posterior distribution over the KB that indicates which entities the user is interested in. Integrating the soft retrieval process with a reinforcement learner leads to higher task success rate and reward in both simulations and against real users. We also present a fully neural end-to-end agent, trained entirely from user feedback, and discuss its application towards personalized dialogue agents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Social identity and socially shared retrieval-induced forgetting: The effects of group membership.\n",
            "Authors: A. Coman, W. Hirst\n",
            "Year: 2015\n",
            "Venue: Journal of experimental psychology. General\n",
            "Abstract: In a conversation, speakers and listeners will often influence each other's memories, and in doing so, promote the formation of a shared, or collective, memory. One means by which a mnemonic consensus emerges is through socially shared retrieval-induced forgetting (SSRIF). When listeners attend to the speakers' selective retrieval of previously encountered events, they forget unmentioned but related information more than they forget unrelated, unmentioned previously studied information. As a consequence, both speaker and listeners come to remember-and forget-the event in a similar way. SSRIF appears to be dependent on listeners concurrently retrieving the information with the speaker. We asked here whether such concurrent retrieval is a function of group membership, thereby underscoring the connection between a basic mnemonic mechanism-retrieval-induced forgetting-and a social function of communicative interaction-building a shared representation. In Experiment 1, Princeton students listening to a speaker selectively recall previously studied material showed SSRIF when the speaker was identified as a fellow Princeton student, but not when he or she was identified as a Yale student. In Experiment 2, activating a common student identity before the listening task triggered concurrent retrieval in Princeton students when listening to both Princeton and Yale speakers. Thus, similar patterns of selective forgetting are more likely to occur between speakers and listeners if they belong to the same social group. Basic mnemonic mechanisms seem to be adapted to promote the emergence of shared mnemonic representations that preserve group membership and group identity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analysis of TF-IDF Model and its Variant for Document Retrieval\n",
            "Authors: Apra Mishra, Santosh K. Vishwakarma\n",
            "Year: 2015\n",
            "Venue: International Conference on Computational Intelligence and Communication Networks\n",
            "Abstract: An Information Retrieval System is a system that is capable of storage, retrieval, and maintenance of an Information. In this context Information can be composed of text (including numeric and date data), images, audio, video and other multi-media objects. The TF-IDF weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. There exist various models for weighting terms of corpus documents and query terms. This work is carried out to analyze and evaluate the retrieval effectiveness of vector -- space model while using the new data set of FIRE 2011. The experiments were performed with TF-IDF and its variants. For all experiments and evaluation the open search engine, Terrier 3.5 was used. Our result shows that TF-IDF model gives the highest precision values with the new corpus dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval practice enhances new learning: the forward effect of testing\n",
            "Authors: Bernhard Pastötter, K. Bäuml\n",
            "Year: 2014\n",
            "Venue: Frontiers in Psychology\n",
            "Abstract: In the last couple of years, there has been a dramatic increase in laboratory research examining the benefits of recall testing on long-term learning and retention. This work was largely on the backward effect of testing, which shows that retrieval practice on previously studied information, compared to restudy of the same material, renders the information more likely to be remembered in the future. Going beyond this prominent work, more recent laboratory research provided evidence that there is also a forward effect of testing, which shows that recall testing of previously studied information can enhance learning of subsequently presented new information. Here, we provide a review of research on this forward effect of testing. The review shows that the effect is a well replicated phenomenon in laboratory studies that has been observed for both veridical information and misinformation. In particular, the review demonstrates that the effect may be applied to educational and clinical settings, enhancing learning in students and reducing memory deficits in clinical populations. The review discusses current theoretical explanations of the forward effect of testing and provides suggestions for future research directions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ground-Based Temperature and Humidity Profiling Using Spectral Infrared and Microwave Observations. Part II: Actual Retrieval Performance in Clear-Sky and Cloudy Conditions\n",
            "Authors: W. Blumberg, D. Turner, U. Löhnert, S. Castleberry\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: AbstractAlthough current upper-air observing systems provide an impressive array of observations, many are deficient in observing the temporal evolution of the boundary layer thermodynamic profile. Ground-based remote sensing instruments such as the multichannel microwave radiometer (MWR) and Atmospheric Emitted Radiance Interferometer (AERI) are able to provide profiles of temperature and water vapor through the boundary layer at 5-min resolution or better. Previous work compared these instruments through optimal-estimation retrievals on simulated clear-sky spectra to evaluate the retrieval accuracy and information content of each instrument. In this study, this method is duplicated using real observations from collocated MWR and AERI instruments from a field campaign in southwestern Germany. When compared with radiosondes, this study confirms the previous results that AERI retrievals are more accurate than MWR retrievals in clear-sky and below-cloud-base profiling. These results demonstrate that the AER...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Probabilistic Multileave for Online Retrieval Evaluation\n",
            "Authors: Anne Schuth, Robert-Jan Bruintjes, Fritjof Buüttner, J. Doorn, C. Groenland, Harrie Oosterhuis, Cong-Nguyen Tran, Bastiaan S. Veeling, Jos van der Velde, R. Wechsler, David Woudenberg, M. de Rijke\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Online evaluation methods for information retrieval use implicit signals such as clicks from users to infer preferences between rankers. A highly sensitive way of inferring these preferences is through interleaved comparisons. Recently, interleaved comparisons methods that allow for simultaneous evaluation of more than two rankers have been introduced. These so-called multileaving methods are even more sensitive than their interleaving counterparts. Probabilistic interleaving--whose main selling point is the potential for reuse of historical data--has no multileaving counterpart yet. We propose probabilistic multileave and empirically show that it is highly sensitive and unbiased. An important implication of this result is that historical interactions with multileaved comparisons can be reused, allowing for ranker comparisons that need much less user interaction data. Furthermore, we show that our method, as opposed to earlier sensitive multileaving methods, scales well when the number of rankers increases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-based Image Retrieval by Exploring Bandletized Regions through Support Vector Machines\n",
            "Authors: Rehan Ashraf, Khalid Bashir Bajwa, Toqeer Mahmood\n",
            "Year: 2016\n",
            "Venue: Journal of information science and engineering\n",
            "Abstract: One of the major requirements of the Content Based Image Retrieval (CBIR) systems is to ensure the meaningful image retrieval against query images. CBIR systems provide potential solutions of retrieving semantically similar images from large image repositories against any query image. The performances of these systems severely degrade by the inclusion of image contents which do not comprise the objects of interest in an image during the image representation phase. Segmentation of the images is considered as a solution but there isn’t any technique which can guarantee the object extraction in a robust way. Another limitation of the segmentation is that, most of the image segmentation techniques are very slow and still their results are not reliable. To overcome these problems a Bandelets transform based image representation technique is presented in this paper, which reliably returns the information about the major objects found in an image. For image retrieval purposes Support Vector Machine are applied and the performance of the system is evaluated on three standard data sets used in the domain of content based image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Classical databases and knowledge organization: A case for boolean retrieval and human decision‐making during searches\n",
            "Authors: Birger Hjørland\n",
            "Year: 2015\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: This paper considers classical bibliographic databases based on the Boolean retrieval model (such as MEDLINE and PsycInfo). This model is challenged by modern search engines and information retrieval (IR) researchers, who often consider Boolean retrieval a less efficient approach. The paper examines this claim and argues for the continued value of Boolean systems, and suggests two further considerations: (a) the important role of human expertise in searching (expert searchers and “information literate” users) and (b) the role of library and information science and knowledge organization (KO) in the design and use of classical databases. An underlying issue is the kind of retrieval system for which one should aim. Warner's (2010) differentiation between the computer science traditions and an older library‐oriented tradition seems important; the former aim to transform queries automatically into (ranked) sets of relevant documents, whereas the latter aims to increase the “selection power” of users. The Boolean retrieval model is valuable in providing users with the power to make informed searches and have full control over what is found and what is not. These issues may have significant implications for the maintenance of information science and KO as research fields as well as for the information profession as a profession in its own right.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An effective approach to tweets opinion retrieval\n",
            "Authors: Zhunchen Luo, M. Osborne, Ting Wang\n",
            "Year: 2015\n",
            "Venue: World wide web (Bussum)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neuromodulatory signaling in hippocampus‐dependent memory retrieval\n",
            "Authors: S. Thomas\n",
            "Year: 2015\n",
            "Venue: Hippocampus\n",
            "Abstract: Considerable advances have been made toward understanding the molecular signaling events that underlie memory acquisition and consolidation. In contrast, less is known about memory retrieval, despite its necessity for utilizing learned information. This review focuses on neuromodulatory and intracellular signaling events that underlie memory retrieval mediated by the hippocampus, for which the most information is currently available. Among neuromodulators, adrenergic signaling is required for the retrieval of various types of hippocampus‐dependent memory. Although they contribute to acquisition and/or consolidation, cholinergic and dopaminergic signaling are generally not required for retrieval. Interestingly, while not required for retrieval, serotonergic and opioid signaling may actually constrain memory retrieval. Roles for histamine and non‐opioid neuropeptides are currently unclear but possible. A critical effector of adrenergic signaling in retrieval is reduction of the slow afterhyperpolarization mediated by β1 receptors, cyclic AMP, protein kinase A, Epac, and possibly ERK. In contrast, stress and glucocorticoids impair retrieval by decreasing cyclic AMP, mediated in part by the activation of β2‐adrenergic receptors. Clinically, alterations in neuromodulatory signaling and in memory retrieval occur in Alzheimer's disease, Down syndrome, depression, and post‐traumatic stress disorder, and recent evidence has begun to link changes in neuromodulatory signaling with effects on memory retrieval. © 2014 Wiley Periodicals, Inc.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval practice with short-answer, multiple-choice, and hybrid tests\n",
            "Authors: Megan A. Smith, Jeffrey D. Karpicke\n",
            "Year: 2014\n",
            "Venue: Memory\n",
            "Abstract: Retrieval practice improves meaningful learning, and the most frequent way of implementing retrieval practice in classrooms is to have students answer questions. In four experiments (N=372) we investigated the effects of different question formats on learning. Students read educational texts and practised retrieval by answering short-answer, multiple-choice, or hybrid questions. In hybrid conditions students first attempted to recall answers in short-answer format, then identified answers in multiple-choice format. We measured learning 1 week later using a final assessment with two types of questions: those that could be answered by recalling information verbatim from the texts and those that required inferences. Practising retrieval in all format conditions enhanced retention, relative to a study-only control condition, on both verbatim and inference questions. However, there were little or no advantages of answering short-answer or hybrid format questions over multiple-choice questions in three experiments. In Experiment 4, when retrieval success was improved under initial short-answer conditions, there was an advantage of answering short-answer or hybrid questions over multiple-choice questions. The results challenge the simple conclusion that short-answer questions always produce the best learning, due to increased retrieval effort or difficulty, and demonstrate the importance of retrieval success for retrieval-based learning activities.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On Type-Aware Entity Retrieval\n",
            "Authors: Darío Garigliotti, K. Balog\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Today, the practice of returning entities from a knowledge base in response to search queries has become widespread. One of the distinctive characteristics of entities is that they are typed, i.e., assigned to some hierarchically organized type system (type taxonomy). The primary objective of this paper is to gain a better understanding of how entity type information can be utilized in entity retrieval. We perform this investigation in an idealized \"oracle\" setting, assuming that we know the distribution of target types of the relevant entities for a given query. We perform a thorough analysis of three main aspects: (i) the choice of type taxonomy, (ii) the representation of hierarchical type information, and (iii) the combination of type-based and term-based similarity in the retrieval model. Using a standard entity search test collection based on DBpedia, we find that type information proves most useful when using large type taxonomies that provide very specific types. We provide further insights on the extensional coverage of entities and on the utility of target types.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information-centric networking for the internet of things: challenges and opportunities\n",
            "Authors: M. Amadeo, C. Campolo, José Quevedo, Daniel Corujo, A. Molinaro, A. Iera, R. Aguiar, A. Vasilakos\n",
            "Year: 2016\n",
            "Venue: IEEE Network\n",
            "Abstract: In view of evolving the Internet infrastructure, ICN is promoting a communication model that is fundamentally different from the traditional IP address-centric model. The ICN approach consists of the retrieval of content by (unique) names, regardless of origin server location (i.e., IP address), application, and distribution channel, thus enabling in-network caching/replication and content-based security. The expected benefits in terms of improved data dissemination efficiency and robustness in challenging communication scenarios indicate the high potential of ICN as an innovative networking paradigm in the IoT domain. IoT is a challenging environment, mainly due to the high number of heterogeneous and potentially constrained networked devices, and unique and heavy traffic patterns. The application of ICN principles in such a context opens new opportunities, while requiring careful design choices. This article critically discusses potential ways toward this goal by surveying the current literature after presenting several possible motivations for the introduction of ICN in the context of IoT. Major challenges and opportunities are also highlighted, serving as guidelines for progress beyond the state of the art in this timely and increasingly relevant topic.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Memory Retrieval in Mice and Men.\n",
            "Authors: A. Ben-Yakov, Y. Dudai, M. Mayford\n",
            "Year: 2015\n",
            "Venue: Cold Spring Harbor Perspectives in Biology\n",
            "Abstract: Retrieval, the use of learned information, was until recently mostly terra incognita in the neurobiology of memory, owing to shortage of research methods with the spatiotemporal resolution required to identify and dissect fast reactivation or reconstruction of complex memories in the mammalian brain. The development of novel paradigms, model systems, and new tools in molecular genetics, electrophysiology, optogenetics, in situ microscopy, and functional imaging, have contributed markedly in recent years to our ability to investigate brain mechanisms of retrieval. We review selected developments in the study of explicit retrieval in the rodent and human brain. The picture that emerges is that retrieval involves coordinated fast interplay of sparse and distributed corticohippocampal and neocortical networks that may permit permutational binding of representational elements to yield specific representations. These representations are driven largely by the activity patterns shaped during encoding, but are malleable, subject to the influence of time and interaction of the existing memory with novel information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Sketch based image retrieval using a soft computation of the histogram of edge local orientations (S-HELO)\n",
            "Authors: J. M. Saavedra\n",
            "Year: 2014\n",
            "Venue: International Conference on Information Photonics\n",
            "Abstract: This paper introduces S-HELO (Soft-Histogram of Edge Local Orientations), an outperforming method for describing images in the context of sketch based image retrieval (SBIR). This proposal exploits the advantages provided by the HELO descriptor for describing sketches, and improves significantly its performance by using a soft computation of local orientations and taking into account spatial information. We experimentally demonstrate that a soft computation process together with a local estimation of orientations are very suitable for describing sketches in the context of image retrieval. Indeed, our results show that S-HELO significantly outperforms not only HELO but also classical orientation-based descriptors as HOG. We also show that S-HELO performs very close to the optimal when what we want to retrieve are target images. Moreover, our proposal also shows an outstanding performance for similarity search, i.e., retrieving images that belong to the same category of the query sketch.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase retrieval with masks using convex optimization\n",
            "Authors: K. Jaganathan, Yonina C. Eldar, B. Hassibi\n",
            "Year: 2015\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: Signal recovery from the magnitude of the Fourier transform, or equivalently, from the autocorrelation, is a classical problem known as phase retrieval. Due to the absence of phase information, some form of additional information is required in order to be able to uniquely identify the underlying signal. In this work, we consider the problem of phase retrieval using masks. Due to our interest in developing robust algorithms with theoretical guarantees, we explore a convex optimization-based framework. In this work, we show that two specific masks (each mask provides 2n Fourier magnitude measurements) or five specific masks (each mask provides n Fourier magnitude measurements) are sufficient for a convex relaxation of the phase retrieval problem to provably recover almost all signals (up to global phase). We also show that the recovery is stable in the presence of measurement noise. This is a significant improvement over the existing results, which require O(log2 n) random masks (each mask provides n Fourier magnitude measurements) in order to guarantee unique recovery (up to global phase). Numerical experiments complement our theoretical analysis and show interesting trends, which we hope to explain in a future publication.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-based image retrieval by integrating color and texture features\n",
            "Authors: Xiang-yang Wang, Bei-Bei Zhang, Hongying Yang\n",
            "Year: 2014\n",
            "Venue: Multimedia tools and applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Semi-Synthetic Organism that Stores and Retrieves Increased Genetic Information\n",
            "Authors: Yorke Zhang, J. Ptacin, Emil C. Fischer, Hans R. Aerni, C. Caffaro, Kristine M San Jose, Aaron W Feldman, Court R. Turner, F. Romesberg\n",
            "Year: 2017\n",
            "Venue: Nature\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Listen up, eye movements play a role in verbal memory retrieval\n",
            "Authors: Agnes Scholz, K. Mehlhorn, J. Krems\n",
            "Year: 2014\n",
            "Venue: Psychological Research\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Medical Image Retrieval: A Multimodal Approach\n",
            "Authors: Yu Cao, Shawn Steffey, Jianbiao He, Degui Xiao, Cui Tao, Ping Chen, H. Müller\n",
            "Year: 2014\n",
            "Venue: Cancer Informatics\n",
            "Abstract: Medical imaging is becoming a vital component of war on cancer. Tremendous amounts of medical image data are captured and recorded in a digital format during cancer care and cancer research. Facing such an unprecedented volume of image data with heterogeneous image modalities, it is necessary to develop effective and efficient content-based medical image retrieval systems for cancer clinical practice and research. While substantial progress has been made in different areas of content-based image retrieval (CBIR) research, direct applications of existing CBIR techniques to the medical images produced unsatisfactory results, because of the unique characteristics of medical images. In this paper, we develop a new multimodal medical image retrieval approach based on the recent advances in the statistical graphic model and deep learning. Specifically, we first investigate a new extended probabilistic Latent Semantic Analysis model to integrate the visual and textual information from medical images to bridge the semantic gap. We then develop a new deep Boltzmann machine-based multimodal learning model to learn the joint density model from multimodal information in order to derive the missing modality. Experimental results with large volume of real-world medical images have shown that our new approach is a promising solution for the next-generation medical imaging indexing and retrieval system.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Response Ranking with Deep Matching Networks and External Knowledge in Information-seeking Conversation Systems\n",
            "Authors: Liu Yang, Minghui Qiu, Chen Qu, J. Guo, Yongfeng Zhang, W. Bruce Croft, Jun Huang, Haiqing Chen\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Intelligent personal assistant systems with either text-based or voice-based conversational interfaces are becoming increasingly popular around the world. Retrieval-based conversation models have the advantages of returning fluent and informative responses. Most existing studies in this area are on open domain ''chit-chat'' conversations or task / transaction oriented conversations. More research is needed for information-seeking conversations. There is also a lack of modeling external knowledge beyond the dialog utterances among current conversational models. In this paper, we propose a learning framework on the top of deep neural matching networks that leverages external knowledge for response ranking in information-seeking conversation systems. We incorporate external knowledge into deep neural models with pseudo-relevance feedback and QA correspondence knowledge distillation. Extensive experiments with three information-seeking conversation data sets including both open benchmarks and commercial data show that, our methods outperform various baseline methods including several deep text matching models and the state-of-the-art method on response selection in multi-turn conversations. We also perform analysis over different response types, model variations and ranking examples. Our models and research findings provide new insights on how to utilize external knowledge with deep neural models for response selection and have implications for the design of the next generation of information-seeking conversation systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Working memory retrieval as a decision process.\n",
            "Authors: B. Pearson, Julius Raskevicius, P. Bays, Y. Pertzov, M. Husain\n",
            "Year: 2014\n",
            "Venue: Journal of Vision\n",
            "Abstract: Working memory (WM) is a core cognitive process fundamental to human behavior, yet the mechanisms underlying it remain highly controversial. Here we provide a new framework for understanding retrieval of information from WM, conceptualizing it as a decision based on the quality of internal evidence. Recent findings have demonstrated that precision of WM decreases with memory load. If WM retrieval uses a decision process that depends on memory quality, systematic changes in response time distribution should occur as a function of WM precision. We asked participants to view sample arrays and, after a delay, report the direction of change in location or orientation of a probe. As WM precision deteriorated with increasing memory load, retrieval time increased systematically. Crucially, the shape of reaction time distributions was consistent with a linear accumulator decision process. Varying either task relevance of items or maintenance duration influenced memory precision, with corresponding shifts in retrieval time. These results provide strong support for a decision-making account of WM retrieval based on noisy storage of items. Furthermore, they show that encoding, maintenance, and retrieval in WM need not be considered as separate processes, but may instead be conceptually unified as operations on the same noise-limited, neural representation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Human Memory Retrieval and Inhibitory Control in the Brain: Beyond Correlational Evidence\n",
            "Authors: B. Penolazzi, D. Stramaccia, M. Braga, S. Mondini, G. Galfano\n",
            "Year: 2014\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Retrieving information from long-term memory can result in the episodic forgetting of related material. One influential account states that this retrieval-induced forgetting (RIF) phenomenon reflects inhibitory mechanisms called into play to decrease retrieval competition. Recent neuroimaging studies suggested that the prefrontal cortex, which is critically engaged in inhibitory processing, is also involved in retrieval competition situations. Here, we used transcranial direct current stimulation (tDCS) to address whether inhibitory processes could be causally linked to RIF. tDCS was administered over the right dorsolateral prefrontal cortex during the retrieval-practice phase in a standard retrieval-practice paradigm. Sixty human participants were randomly assigned to anodal, cathodal, or sham-control groups. The groups showed comparable benefits for practiced items. In contrast, unlike both the sham and anodal groups, the cathodal group exhibited no RIF. This pattern is interpreted as evidence for a causal role of inhibitory mechanisms in episodic retrieval and forgetting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Color Directional Local Quinary Patterns for Content Based Indexing and Retrieval\n",
            "Authors: Santosh Kumar Vipparthi, S. K. Nagar\n",
            "Year: 2014\n",
            "Venue: Human-Centric Computing and Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: CAsT-19: A Dataset for Conversational Information Seeking\n",
            "Authors: Jeffrey Dalton, Chenyan Xiong, Vaibhav Kumar, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: CAsT-19 is a new dataset that supports research on conversational information seeking. The corpus is 38,426,252 passages from the TREC Complex Answer Retrieval (CAR) and Microsoft MAchine Reading COmprehension (MARCO) datasets. Eighty information seeking dialogues (30 train, 50 test) are an average of 9 to 10 questions long. A dialogue may explore a topic broadly or drill down into subtopics. Questions contain ellipsis, implied context, mild topic shifts, and other characteristics of human conversation that may prevent them from being understood in isolation. Relevance assessments are provided for 30 training topics and 20 test topics. CAsT-19 promotes research on conversational information seeking by defining it as a task in which effective passage selection requires understanding a question's context (the dialogue history). It focuses attention on user modeling, analysis of prior retrieval results, transformation of questions into effective queries, and other topics that have been difficult to study with existing datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Mobile Information-Centric Networking: Research Issues and Challenges\n",
            "Authors: Chao Fang, Haipeng Yao, Zhuwei Wang, Wenjun Wu, Xiaoning Jin, F. R. Yu\n",
            "Year: 2018\n",
            "Venue: IEEE Communications Surveys and Tutorials\n",
            "Abstract: Recently, a series of innovative information-centric networking (ICN) architectures have been designed to better address the shift from host-centric end-to-end communication to requester-driven content retrieval. With the explosive increase of mobile data traffic, the mobility issue in ICN is a growing concern and a number of approaches have been proposed to deal with the mobility problem in ICN. Despite the potential advantages of ICN in mobile wireless environments, several significant research challenges remain to be addressed before its widespread deployment, including consistent routing, local cached content discovery, energy efficiency, privacy, security and trust, and practical deployment. In this paper, we present a brief survey on some of the works that have already been done to achieve mobile ICN, and discuss some research issues and challenges. We identify several important aspects of mobile ICN: overview, mobility enabling technologies, information-centric wireless mobile networks, and research challenges.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Meta Structure: Computing Relevance in Large Heterogeneous Information Networks\n",
            "Authors: Zhipeng Huang, Yudian Zheng, Reynold Cheng, Yizhou Sun, N. Mamoulis, Xiang Li\n",
            "Year: 2016\n",
            "Venue: Knowledge Discovery and Data Mining\n",
            "Abstract: A heterogeneous information network (HIN) is a graph model in which objects and edges are annotated with types. Large and complex databases, such as YAGO and DBLP, can be modeled as HINs. A fundamental problem in HINs is the computation of closeness, or relevance, between two HIN objects. Relevance measures can be used in various applications, including entity resolution, recommendation, and information retrieval. Several studies have investigated the use of HIN information for relevance computation, however, most of them only utilize simple structure, such as path, to measure the similarity between objects. In this paper, we propose to use meta structure, which is a directed acyclic graph of object types with edge types connecting in between, to measure the proximity between objects. The strength of meta structure is that it can describe complex relationship between two HIN objects (e.g., two papers in DBLP share the same authors and topics). We develop three relevance measures based on meta structure. Due to the computational complexity of these measures, we further design an algorithm with data structures proposed to support their evaluation. Our extensive experiments on YAGO and DBLP show that meta structure-based relevance is more effective than state-of-the-art approaches, and can be efficiently computed.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Caching Policies and Forwarding Mechanisms in Information-Centric Networking\n",
            "Authors: Andriana Ioannou, S. Weber\n",
            "Year: 2016\n",
            "Venue: IEEE Communications Surveys and Tutorials\n",
            "Abstract: Information-centric networking (ICN), an alternative to the host-centric model of the current Internet infrastructure, focuses on the distribution and retrieval of content instead of the transfer of information between specific endpoints. In order to achieve this, ICN is based on the paradigm of publish-subscribe and the concepts of naming and in-network caching. Current approaches to ICN employ caches within networks to minimize the latency of information retrieval. Content may be distributed either in caches along the delivery path(s), on-path caching or in any cache within a network, off-path caching. While approaches to off-path caching are comparable to traditional approaches for content replication and Web caching, approaches to on-path caching are specific to the ICN area. The purpose of this paper is to provide a review of the caching problem in ICN, with a focus on on-path caching. To this end, a detailed analysis of the existing caching policies and forwarding mechanisms that complement these policies is given. A number of criteria such as the caching model and level of operation and the evaluation parameters used in the evaluation of the existing caching policies are being employed to derive a taxonomy for on-path caching and highlight the trends and evaluation issues in this area. A discussion driven by the advantages and disadvantages of the existing caching policies and the challenges and open questions in on-path caching is finally being held.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Local quantized extrema patterns for content-based natural and texture image retrieval\n",
            "Authors: L. Rao, D. V. Rao\n",
            "Year: 2015\n",
            "Venue: Human-Centric Computing and Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Does the benefit of testing depend on lag, and if so, why? Evaluating the elaborative retrieval hypothesis\n",
            "Authors: Katherine A. Rawson, Kalif E. Vaughn, Shana K. Carpenter\n",
            "Year: 2014\n",
            "Venue: Memory & Cognition\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pareto-Depth for Multiple-Query Image Retrieval\n",
            "Authors: Ko-Jen Hsiao, Jeff Calder, Alfred O. Hero\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Most content-based image retrieval systems consider either one single query, or multiple queries that include the same object or represent the same semantic information. In this paper, we consider the content-based image retrieval problem for multiple query images corresponding to different image semantics. We propose a novel multiple-query information retrieval algorithm that combines the Pareto front method with efficient manifold ranking. We show that our proposed algorithm outperforms state of the art multiple-query retrieval algorithms on real-world image databases. We attribute this performance improvement to concavity properties of the Pareto fronts, and prove a theoretical result that characterizes the asymptotic concavity of the fronts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content Based Image Indexing and Retrieval\n",
            "Authors: A. Bhute, B. Meshram, Matunga Mumbai Vjti\n",
            "Year: 2014\n",
            "Venue: arXiv.org\n",
            "Abstract: In this paper, we present the efficient content based image retrieval systems which employ the color, texture and shape information of images to facilitate the retrieval process. For efficient feature extraction, we extract the color, texture and shape feature of images automatically using edge detection which is widely used in signal processing and image compression. For facilitated the speedy retrieval we are implements the antipole-tree algorithm for indexing the images.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An integrated approach to Content Based Image Retrieval\n",
            "Authors: R. Choudhary, Nikita Raina, N. Chaudhary, Rashmi Chauhan, R. Goudar\n",
            "Year: 2014\n",
            "Venue: International Conference on Advances in Computing, Communications and Informatics\n",
            "Abstract: Content based image retrieval, in the last few years has received a wide attention. Content Based Image Retrieval (CBIR) basically is a technique to perform retrieval of the images from a large database which are similar to image given as query. CBIR is closer to human semantics, in the context of image retrieval process. CBIR technique has its application in different domains such as crime prevention, medical images, weather forecasting, surveillance, historical research and remote sensing Here content refers to the visual information of images such as texture, shape and color. Contents of image are richer in information for an efficient retrieval in comparison to text based image retrieval. In this paper, we have proposed a content based image retrieval integrated technique which extracts both the color and texture feature. To extract the color feature, color moment (CM) is used on color images and to extract the texture feature, local binary pattern (LBP) is performed on the grayscale image. Then both color and texture feature of image are combined to form a single feature vector. In the end similarity matching is performed by Euclidian distance which compares feature vector of database images with query images. LBP mainly used for face recognition. But we are going to use LBP for natural images. This combined approach provides accurate, efficient, less complex retrieval system.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Variational Interaction Information Maximization for Cross-domain Disentanglement\n",
            "Authors: HyeongJoo Hwang, Geon-hyeong Kim, Seunghoon Hong, Kee-Eung Kim\n",
            "Year: 2020\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Cross-domain disentanglement is the problem of learning representations partitioned into domain-invariant and domain-specific representations, which is a key to successful domain transfer or measuring semantic distance between two domains. Grounded in information theory, we cast the simultaneous learning of domain-invariant and domain-specific representations as a joint objective of multiple information constraints, which does not require adversarial training or gradient reversal layers. We derive a tractable bound of the objective and propose a generative model named Interaction Information Auto-Encoder (IIAE). Our approach reveals insights on the desirable representation for cross-domain disentanglement and its connection to Variational Auto-Encoder (VAE). We demonstrate the validity of our model in the image-to-image translation and the cross-domain retrieval tasks. We further show that our model achieves the state-of-the-art performance in the zero-shot sketch based image retrieval task, even without external knowledge. Our implementation is publicly available at: https://github.com/gr8joo/IIAE\n",
            "\n",
            "---\n",
            "\n",
            "Title: Entity linking and retrieval for semantic search\n",
            "Authors: E. Meij, K. Balog, Daan Odijk\n",
            "Year: 2014\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: More and more search engine users are expecting direct answers to their information needs, rather than links to documents. Semantic search and its recent applications enabled search engines to organize their wealth of information around entities. Entity linking and retrieval provide the building stones for organizing the web of entities. This tutorial aims to cover all facets of semantic search from a unified point of view and connect real-world applications with results from scientific publications. We provide a comprehensive overview of entity linking and retrieval in the context of semantic search and thoroughly explore techniques for query understanding, entity-based retrieval and ranking on unstructured text, structured knowledge repositories, and a mixture of these. We point out the connections between published approaches and applications, and provide hands-on examples on real-world use cases and datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evolution of research subjects in library and information science based on keyword, bibliographical coupling, and co-citation analyses\n",
            "Authors: Yu-Wei Chang, Mu-Hsuan Huang, Chiao-Wen Lin\n",
            "Year: 2015\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information-centric networking for connected vehicles: a survey and future perspectives\n",
            "Authors: M. Amadeo, C. Campolo, A. Molinaro\n",
            "Year: 2016\n",
            "Venue: IEEE Communications Magazine\n",
            "Abstract: In the connected vehicle ecosystem, a high volume of information-rich and safety-critical data will be exchanged by roadside units and onboard transceivers to improve the driving and traveling experience. However, poor-quality wireless links and the mobility of vehicles highly challenge data delivery. The IP address-centric model of the current Internet barely works in such extremely dynamic environments and poorly matches the localized nature of the majority of vehicular communications, which typically target specific road areas (e.g., in the proximity of a hazard or a point of interest) regardless of the identity/address of a single vehicle passing by. Therefore, a paradigm shift is advocated from traditional IP-based networking toward the groundbreaking information- centric networking. In this article, we scrutinize the applicability of this paradigm in vehicular environments by reviewing its core functionalities and the related work. The analysis shows that, thanks to features like named content retrieval, innate multicast support, and in-network data caching, information-centric networking is positioned to meet the challenging demands of vehicular networks and their evolution. Interoperability with the standard architectures for vehicular applications along with synergies with emerging computing and networking paradigms are debated as future research perspectives.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Disentangled Representations via Mutual Information Estimation\n",
            "Authors: E. Sanchez, M. Serrurier, M. Ortner\n",
            "Year: 2019\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analyst Information Acquisition via EDGAR\n",
            "Authors: Brian Gibbons, P. Iliev, J. Kalodimos\n",
            "Year: 2019\n",
            "Venue: Management Sciences\n",
            "Abstract: We identify analysts’ information acquisition patterns by linking EDGAR (Electronic Data Gathering, Analysis, and Retrieval) server activity to analysts’ brokerage houses. Analysts rely on EDGAR in 24% of their estimate updates with an average of eight filings viewed. We document that analysts’ attention to public information is driven by the demand for information and the analysts’ incentives and career concerns. We find that information acquisition via EDGAR is associated with a significant reduction in analysts’ forecasting error relative to their peers. This relationship is likewise present when we focus on the intensity of analyst research. Attention to public information further enables analysts to provide forecasts for more time periods and more financial metrics. Informed recommendation updates are associated with substantial and persistent abnormal returns, even when the analyst accesses historical filings. Analysts’ use of EDGAR is associated with longer and more informative analysis within recommendation reports. This paper was accepted by Shiva Rajgopal, accounting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Making Information Seeking Easier: An Improved Pipeline for Conversational Search\n",
            "Authors: Vaibhav Kumar, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: Findings\n",
            "Abstract: This paper presents a highly effective pipeline for passage retrieval in a conversational search setting. The pipeline comprises of two components: Conversational Term Selection (CTS) and Multi-View Reranking (MVR). CTS is responsible for performing the first-stage of passage retrieval. Given an input question, it uses a BERT-based classifier (trained with weak supervision) to de-contextualize the input by selecting relevant terms from the dialog history. Using the question and the selected terms, it issues a query to a search engine to perform the first-stage of passage retrieval. On the other hand, MVR is responsible for contextualized passage reranking. It first constructs multiple views of the information need embedded within an input question. The views are based on the dialog history and the top documents obtained in the first-stage of retrieval. It then uses each view to rerank passages using BERT (fine-tuned for passage ranking). Finally, MVR performs a fusion over the rankings produced by the individual views. Experiments show that the above combination improves first-state retrieval as well as the overall accuracy in a reranking pipeline. On the key metric of NDCG@3, the proposed combination achieves a relative performance improvement of 14.8% over the state-of-the-art baseline and is also able to surpass the Oracle.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Too much information? Predictors of information overload in the context of online news exposure\n",
            "Authors: Josephine B. Schmitt, Christina A. Debbelt, F. Schneider\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: ABSTRACT As the Internet provides massive amounts of heterogeneous information, people may perceive this medium as challenging. The difficulty to evaluate and select relevant information increases as more and more diverse sources and content are available. Information overload (IO) may be the consequence. The research presented here gives a first comprehensive overview of possible indicators for IO in the context of online news exposure. Based on an online survey (N=419), we found that younger people with less information-seeking self-efficacy were more susceptible to experience IO. Additionally, we identified motivations for media consumption and information retrieval strategies in the Internet that imply IO. With our results, we contribute to a further understanding of IO and provide an important basis for future research needed to face the challenges resulting from the rising media diversity.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "def fetch_scholarly_articles(keyword, total_articles):\n",
        "\n",
        "    api_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "    query_params = {\n",
        "        \"query\": keyword,\n",
        "        \"offset\": 0,\n",
        "        \"limit\": 100,\n",
        "        \"fields\": \"title,authors,year,venue,abstract\",\n",
        "        \"year\": \"2014-2024\"\n",
        "    }\n",
        "\n",
        "    articles_collected = 0\n",
        "\n",
        "    while articles_collected < total_articles:\n",
        "        response = requests.get(api_url, params=query_params)\n",
        "        if response.status_code == 200:\n",
        "            articles = response.json().get('data', [])\n",
        "            for article in articles:\n",
        "                title = article.get('title', 'N/A')\n",
        "                authors = ', '.join([author['name'] for author in article.get('authors', [])])\n",
        "                year = article.get('year', 'N/A')\n",
        "                venue = article.get('venue', 'N/A')\n",
        "                abstract = article.get('abstract', 'N/A')\n",
        "                print(f\"Title: {title}\")\n",
        "                print(f\"Authors: {authors}\")\n",
        "                print(f\"Year: {year}\")\n",
        "                print(f\"Venue: {venue}\")\n",
        "                print(f\"Abstract: {abstract}\")\n",
        "                print(\"\\n---\\n\")\n",
        "                articles_collected += 1\n",
        "                if articles_collected >= total_articles:\n",
        "                    break\n",
        "            query_params['offset'] += 100\n",
        "\n",
        "        elif response.status_code == 429:\n",
        "            print(\"Rate limit exceeded. Waiting for 60 seconds before retrying...\")\n",
        "            time.sleep(60)\n",
        "            continue\n",
        "\n",
        "        else:\n",
        "            print(f\"Error fetching data: {response.status_code}\")\n",
        "            break\n",
        "fetch_scholarly_articles(\"information retrieval\", 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u24PqBY-3t1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKn2ATXqZ9dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e7b70bb-f1d5-494e-cf10-536a3e53159b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://myunt-my.sharepoint.com/:f:/g/personal/ganeshmarada_my_unt_edu/EhnF3E01IbREuZT_pbNcFUMBwQHzbH6UYPF-x1wsHty_KA?e=QyIF2E'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# write your answer here\n",
        "\"https://myunt-my.sharepoint.com/:f:/g/personal/ganeshmarada_my_unt_edu/EhnF3E01IbREuZT_pbNcFUMBwQHzbH6UYPF-x1wsHty_KA?e=QyIF2E\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZOhks1dXWEe"
      },
      "source": [
        "# Mandatory Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqmHVEwaWhbV"
      },
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akAVJn9YBTQT"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Personally, I find these tools beneficial when quick, reliable data extraction is needed without investing too much time in constructing custom scrapers. However, their limitations, such as restricted control over customizations and potential costs for large-scale projects, make them less tempting for developers who need more granular control, which is achievable using Python packages like BeautifulSoup and Selenium.\n",
        "\n",
        "\n",
        "The process of integrating a tool like ParseHub and exporting the data to formats such as CSV or Excel is efficient for data analysis and reporting. It's a fantastic answer for circumstances where coding might not be the most practical technique. Overall, I feel these tools strike a compromise between usability and functionality, delivering a viable solution for web scraping applications.\n",
        "'''\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FBKvD6O_TY6e",
        "E9RqrlwdTfvl",
        "03jb4GZsBkBS",
        "jJDe71iLB616",
        "55W9AMdXCSpV",
        "4ulBZ6yhCi9F",
        "6SmvS7nSfbj8",
        "sZOhks1dXWEe"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}