{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganesh1616/Ganesh_INFO5731_Fall2024/blob/main/Ganesh_Marada_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Research Question**:\n",
        " How can lengthy, complicated statements be summarized by deep learning models into smaller sentences while retaining all the necessary information?\n",
        "\n",
        "**What kind of Data Needed**:\n",
        "we need long form of text data from sources like article, research papers,blogs,transcripts,legal documents etc and reference summaries done by humans so that we can make use of great examples from the long news articles of academic papers done by humans.\n",
        "\n",
        "**Amount of Data that we need**:\n",
        "Basically we consider senyece of length between 50 to 200 words so that we consider as a lengthy sentence and then we can summarize the sentence within around 30 sentence and also the training sets,test sets need to be of huge samples.\n",
        "\n",
        "**Collecting the data and steps involved**:\n",
        "In the first step we have to identify the data source where the data ned to be taken from for instance it could be News,medical documents or legal documents etc.\n",
        "\n",
        "1.Tokenization:to break the long sentence into tokens and maintain in structure.\n",
        "2.Cleanup the data\n",
        "3.spliting the long sentence ith their corresponding summaries.\n",
        "\n",
        "**Storing the data**:\n",
        "Store the data in the appropriate format wether it could be csv with appropriate fields for long sentence ,short sentences and store them in cloud storage like AWS or Google drive or even in local database like SQL or NoSQL for easy access\n",
        "\n",
        "And by this way we can ensure that we have enough data for the hypothesis that we are expecting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0sffvSOWrffH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "'''\n",
        "\"Research Question: Identify trends and patterns in the success of the top 1000 songs and determine whether there is a correlation between factors such as genre, release date, artist popularity, duration, and critical reception that contribute to their success.\"\n",
        "\n",
        "Here is for this research question, I have to follow the steps below to collect and analyze data:\n",
        "\n",
        "1.Visit a website that provides information about the top 1000 songs, such as Billboard or Spotify Charts. The website should include details such as song title, artist, release year, genre, duration, chart position, stream count, and critical reviews.\n",
        "\n",
        "2.Right-click on the webpage and select the \"Inspect\" option to open the developer tools. This will allow you to access the HTML structure of the page. Use these tools to locate the class or id attributes associated with the data you want to scrape (e.g., song title, artist, release year, genre).\n",
        "\n",
        "3. Python program by importing the necessary libraries such as requests, BeautifulSoup, and pandas to perform the web scraping. Then have to  pass the URL of the website you wish to scrape as a string and send a GET request using the requests library to retrieve the webpage's content.\n",
        "\n",
        "4.Parse the HTML content of the webpage using BeautifulSoup with the \"html.parser\" parser. This will allow you to locate and extract specific HTML elements containing the song data, such as song titles, artists, and chart positions, using the class or id attributes you identified earlier.\n",
        "\n",
        "5.Create lists to store the scraped data for each attribute of interest. For example, create lists for song titles, artists, release years, and chart positions. Once you have collected the data into these lists, organize it into a pandas DataFrame.\n",
        "\n",
        "6.Save the data to a CSV file for further analysis. You can now analyze trends such as the correlation between genre and chart success, the impact of artist popularity on song performance, or the influence of song duration on its success.\"\n",
        "'''"
      ],
      "metadata": {
        "id": "cikVKDXdTbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.billboard.com/charts/hot-100/'\n",
        "\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "song_data = soup.find_all('li', class_='o-chart-results-list__item')\n",
        "\n",
        "song_info = []\n",
        "\n",
        "for store in song_data:\n",
        "\n",
        "    h3_tag = store.find('h3')\n",
        "    if h3_tag:\n",
        "        title = h3_tag.text.strip()\n",
        "\n",
        "        artist = h3_tag.find_next('span').text.strip()\n",
        "\n",
        "        rank = store.find('span', class_='c-label').text.strip()\n",
        "\n",
        "        last_week = store.find('span', class_='c-label--secondary').text.strip() if store.find('span', class_='c-label--secondary') else 'N/A'\n",
        "\n",
        "        peak_position = store.find('span', class_='c-label--tertiary').text.strip() if store.find('span', class_='c-label--tertiary') else 'N/A'\n",
        "\n",
        "        weeks_on_chart = store.find('span', class_='c-label--quaternary').text.strip() if store.find('span', class_='c-label--quaternary') else 'N/A'\n",
        "\n",
        "        song_info.append({\n",
        "            'Song Title': title,\n",
        "            'Artist': artist,\n",
        "            'Current Rank': rank,\n",
        "            'Last Week Rank': last_week,\n",
        "            'Peak Position': peak_position,\n",
        "            'Weeks on Chart': weeks_on_chart\n",
        "        })\n",
        "\n",
        "song_DF = pd.DataFrame(song_info)\n",
        "\n",
        "print(song_DF)\n",
        "\n",
        "song_DF.to_csv('top_100_songs.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54AN2nfwpGtI",
        "outputId": "b6ea3f6c-9a43-4da6-c505-73a58d44dfb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Song Title                                 Artist  \\\n",
            "0     A Bar Song (Tipsy)                              Shaboozey   \n",
            "1        I Had Some Help    Post Malone Featuring Morgan Wallen   \n",
            "2               Espresso                      Sabrina Carpenter   \n",
            "3   Please Please Please                      Sabrina Carpenter   \n",
            "4                  Taste                      Sabrina Carpenter   \n",
            "..                   ...                                    ...   \n",
            "95          Close To You                          Gracie Abrams   \n",
            "96              Prove It              21 Savage & Summer Walker   \n",
            "97           Parking Lot                 Mustard & Travis Scott   \n",
            "98       Sorry Not Sorry                     Lil Yachty & Veeze   \n",
            "99      California Sober  Post Malone Featuring Chris Stapleton   \n",
            "\n",
            "                             Current Rank Last Week Rank Peak Position  \\\n",
            "0                               Shaboozey            N/A           N/A   \n",
            "1     Post Malone Featuring Morgan Wallen            N/A           N/A   \n",
            "2                       Sabrina Carpenter            N/A           N/A   \n",
            "3                       Sabrina Carpenter            N/A           N/A   \n",
            "4                       Sabrina Carpenter            N/A           N/A   \n",
            "..                                    ...            ...           ...   \n",
            "95                          Gracie Abrams            N/A           N/A   \n",
            "96              21 Savage & Summer Walker            N/A           N/A   \n",
            "97                 Mustard & Travis Scott            N/A           N/A   \n",
            "98                     Lil Yachty & Veeze            N/A           N/A   \n",
            "99  Post Malone Featuring Chris Stapleton            N/A           N/A   \n",
            "\n",
            "   Weeks on Chart  \n",
            "0             N/A  \n",
            "1             N/A  \n",
            "2             N/A  \n",
            "3             N/A  \n",
            "4             N/A  \n",
            "..            ...  \n",
            "95            N/A  \n",
            "96            N/A  \n",
            "97            N/A  \n",
            "98            N/A  \n",
            "99            N/A  \n",
            "\n",
            "[100 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "def fetch_scholarly_articles(keyword, total_articles):\n",
        "\n",
        "    api_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "    query_params = {\n",
        "        \"query\": keyword,\n",
        "        \"offset\": 0,\n",
        "        \"limit\": 100,\n",
        "        \"fields\": \"title,authors,year,venue,abstract\",\n",
        "        \"year\": \"2014-2024\"\n",
        "    }\n",
        "\n",
        "    articles_collected = 0\n",
        "\n",
        "    while articles_collected < total_articles:\n",
        "        response = requests.get(api_url, params=query_params)\n",
        "        if response.status_code == 200:\n",
        "            articles = response.json().get('data', [])\n",
        "            for article in articles:\n",
        "                title = article.get('title', 'N/A')\n",
        "                authors = ', '.join([author['name'] for author in article.get('authors', [])])\n",
        "                year = article.get('year', 'N/A')\n",
        "                venue = article.get('venue', 'N/A')\n",
        "                abstract = article.get('abstract', 'N/A')\n",
        "                print(f\"Title: {title}\")\n",
        "                print(f\"Authors: {authors}\")\n",
        "                print(f\"Year: {year}\")\n",
        "                print(f\"Venue: {venue}\")\n",
        "                print(f\"Abstract: {abstract}\")\n",
        "                print(\"\\n---\\n\")\n",
        "                articles_collected += 1\n",
        "                if articles_collected >= total_articles:\n",
        "                    break\n",
        "\n",
        "            query_params['offset'] += 100\n",
        "\n",
        "        elif response.status_code == 429:\n",
        "            print(\"Rate limit exceeded. Waiting for 60 seconds before retrying...\")\n",
        "            time.sleep(60)\n",
        "            continue\n",
        "\n",
        "        else:\n",
        "            print(f\"Error fetching data: {response.status_code}\")\n",
        "            break\n",
        "\n",
        "fetch_scholarly_articles(\"information retrieval\", 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4DuUEPlqYHo",
        "outputId": "d30b3ce5-2fa6-4162-d7a2-3a98082e4147"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "---\n",
            "\n",
            "Title: Retrieval Augmented Classification for Long-Tail Visual Recognition\n",
            "Authors: Alex Long, Wei Yin, Thalaiyasingam Ajanthan, V. Nguyen, Pulak Purkait, Ravi Garg, Alan Blair, Chunhua Shen, A. Hengel\n",
            "Year: 2022\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: We introduce Retrieval Augmented Classification (RAC), a generic approach to augmenting standard image classification pipelines with an explicit retrieval module. RAC consists of a standard base image encoder fused with a parallel retrieval branch that queries a non-parametric external memory of pre-encoded images and associated text snippets. We apply RAC to the problem of long-tail classification and demonstrate a significant improvement over previous state-of-the-art on Places365-LT and iNaturalist-2018 (14.5% and 6.7% respectively), despite using only the training datasets themselves as the external information source. We demonstrate that RAC's retrieval module, without prompting, learns a high level of accuracy on tail classes. This, in turn, frees the base encoder to focus on common classes, and improve its performance thereon. RAC represents an alternative approach to utilizing large, pretrained models without requiring fine-tuning, as well as a first step towards more effectively making use of external memory within common computer vision architectures.\n",
            "\n",
            "---\n",
            "\n",
            "Title: AN EFFECTIVE TOKENIZATION ALGORITHM FOR INFORMATION RETRIEVAL SYSTEMS\n",
            "Authors: Vikram Singh, Balwinder Saini\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: In the web, amount of operational data has been increasing exponentially from past few decades, the expectations of data-user is changing proportionally as well. The data-user expects more deep, exact, and detailed results. Retrieval of relevant results is always affected by the pattern, how they are stored/ indexed. There are various techniques are designed to indexed the documents, which is done on the token’s identified with in documents. Tokenization process, primarily effective is to identifying the token and their count. In this paper, we have proposed an effective tokenization approach which is based on training vector and result shows that efficiency/ effectiveness of proposed algorithm.Tokenization of a given documents helps to satisfy user’s information need more precisely and reduced search sharply, is believed to be a part of information retrieval. Tokenization involves pre-processing of documents and generates its respective tokens which is the basis of these tokens probabilistic IR generate its scoring and gives reduced search space. No of Token generated is the parameters used for result analysis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: User-driven system-mediated collaborative information retrieval\n",
            "Authors: L. Soulier, C. Shah, L. Tamine\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Most of the previous approaches surrounding collaborative information retrieval (CIR) provide either a user-based mediation, in which the system only supports users' collaborative activities, or a system-based mediation, in which the system plays an active part in balancing user roles, re-ranking results, and distributing them to optimize overall retrieval performance. In this paper, we propose to combine both of these approaches by a role mining methodology that learns from users' actions about the retrieval strategy they adapt. This hybrid method aims at showing how users are different and how to use these differences for suggesting roles. The core of the method is expressed as an algorithm that (1) monitors users' actions in a CIR setting; (2) discovers differences among the collaborators along certain dimensions; and (3) suggests appropriate roles to make the most out of individual skills and optimize IR performance. Our approach is empirically evaluated and relies on two different laboratory studies involving 70 pairs of users. Our experiments show promising results that highlight how role mining could optimize the collaboration within a search session. The contributions of this work include a new algorithm for mining user roles in collaborative IR, an evaluation methodology, and a new approach to improve IR performance with the operationalization of user-driven system-mediated collaboration.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A nonparametric term weighting method for information retrieval based on measuring the divergence from independence\n",
            "Authors: I. Kocabas, Bekir Taner Dinçer, B. Karaoglan\n",
            "Year: 2014\n",
            "Venue: Information retrieval (Boston)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Aggregated search: A new information retrieval paradigm\n",
            "Authors: A. Kopliku, K. Pinel-Sauvagnat, M. Boughanem\n",
            "Year: 2014\n",
            "Venue: CSUR\n",
            "Abstract: Traditional search engines return ranked lists of search results. It is up to the user to scroll this list, scan within different documents, and assemble information that fulfill his/her information need. Aggregated search represents a new class of approaches where the information is not only retrieved but also assembled. This is the current evolution in Web search, where diverse content (images, videos, etc.) and relational content (similar entities, features) are included in search results.\n",
            " In this survey, we propose a simple analysis framework for aggregated search and an overview of existing work. We start with related work in related domains such as federated search, natural language generation, and question answering. Then we focus on more recent trends, namely cross vertical aggregated search and relational aggregated search, which are already present in current Web search.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Event graphs for information retrieval and multi-document summarization\n",
            "Authors: Goran Glavas, J. Šnajder\n",
            "Year: 2014\n",
            "Venue: Expert systems with applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Relevation!: An open source system for information retrieval relevance assessment\n",
            "Authors: B. Koopman, G. Zuccon\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Relevation! is a system for performing relevance judgements for information retrieval evaluation. Relevation! is web-based, fully configurable and expandable; it allows researchers to effectively collect assessments and additional qualitative data. The system is easily deployed allowing assessors to smoothly perform their relevance judging tasks, even remotely. Relevation! is available as an open source project at: http://ielab.github.io/relevation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-modal Transformer for Video Retrieval\n",
            "Authors: Valentin Gabeur, Chen Sun, Alahari Karteek, C. Schmid\n",
            "Year: 2020\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information Retrieval for Children: Search Behavior and Solutions\n",
            "Authors: Sergio Duarte Torres\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Nowadays, children of very young ages and teenagers use the Internet extensively for entertainment and educational purposes. The number of active young users in the Internet is increasing everyday as the Internet is more accessible at home, schools and even on a mobile basis through cellphones and tablets. The most popular search engines are designed for adults and they do not provide customize tools for young users. Given that young and adult users have different interests and search strategies, research aimed at understanding the activities that young users carried out on the Internet, the way the search for information, and the difficulties that they encounter with state-of-the-art search engines, are urgently needed. The first contribution of this thesis addresses these research aims by providing a characterization, on a large scale, of the search behavior of young users. The problems they face when they search for information on the web, the topics they searched and the online activities that motivate search were explored in detail and contrasted against the search behavior of adult users. The results presented in this thesis have important implications for the development of search tools for young users and for the design of educational literacy. \n",
            " \n",
            "Two central problems were identified in the search process of young users: (1) difficulty representing the information needs with keyword queries, and (2) difficulty exploring the list of results. We found that focused queries are often required to access high quality content for young user with modern search engines. However, young users were found to submit queries that lack the specificity needed to retrieve content that is suitable for them, which leads to frustration during the search process. This observation motivates the second contribution of this thesis. We propose novel query recommendation methods to improve the chances of young users to find content that is suitable and on topic. Concretely, we present an effective biased random walk based on information gain metrics. This method is combined with topical and specialized features designed for the information domain of young users. We show that our query suggestions outperform by a larger margin not only related query recommendation methods but also the query suggestions offered by the search services available today. In respect to the second difficulty, it was found that young users have a strong click bias, in which results ranked at the bottom of the result list are rarely clicked. This behavior greatly hampers their navigational skills and exploration of results. It also reduces the chances of young users to find suitable information, since appropriate content for this audience is ranked, on average, at lower positions in the result list in comparison to the content aimed at the average web user. The third contribution of this thesis aims at helping young users to improve their chances to find appropriate content and to ease the exploration of results. For this purpose, we envisage an aggregated search system in which parents, teachers and young users add search services with content of interests for young audiences. We propose a test collection with a wide number of verticals with moderated content, a carefully selected set of search queries and vertical relevant judgments. We also provide novel methods of vertical selection in this information domain based on social media and based on the estimation of the amount of content that is appropriate for young users in each vertical. We show that our methods outperform state-of-the-art vertical selection methods in this information domain. We also show in a case study with children aged 9 to 10 years old that result pages derived from the collection proposed are preferred over the result pages provided by modern search engines. We provide evidence showing that the interaction and exploration of results are improved with result pages built using this collection, even if the users of this case study were unaware between the differences between the types of pages displayed to them. This thesis is concluded by providing concrete follow-up research directions and by suggesting other information domains that can potentially benefit from the methods proposed in the thesis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey of stemming algorithms in information retrieval\n",
            "Authors: C. Moral, Angélica de Antonio Jiménez, R. Imbert, J. Ramírez\n",
            "Year: 2014\n",
            "Venue: Information Research\n",
            "Abstract: Cristian Moral, Angelica de Antonio, Ricardo Imbert and JaimeRamirezEscuela Tecnica Superior de Ingenieros Informaticos, UniversidadPolitecnica de Madrid, SpainAbstractBackground. During the last fifty years, improved information retrieval techniques havebecome necessary because of the huge amount of information people have available, whichcontinues to increase rapidly due to the use of new technologies and the Internet.Stemming is one of the processes that can improve information retrieval in terms ofaccuracy and performance.Aim. This paper provides a detailed assessment of the current status of the stemmingprocess framed in an information retrieval application field by tracing its historical evolution.Method. Papers presenting the first approaches for stemming were reviewed to extracttheir main features, benefits and drawbacks. Additionally, papers dealing with stemmersfor non-English languages or with some more recent proposals were also consulted andcompiled. Finally, experimental papers defining the most well-known methods and metricsaimed at evaluating and classifying stemmers were also taken into account to expose theircontributions and results. Results. Even if not all researchers agree on the benefits and drawbacks of usingstemming in an information retrieval process in general terms, many of them agree on itsbenefits in specific contexts, such as when the language is highly inflective, when documentsare short or when there is limited space for storing data. Some researchers also state thatthe nature of the documents can influence the performance and the accuracy of thestemmer. Conclusions. Despite many researchers having investigated this field over many years,there are still some open questions, such as how to evaluate a stemmer independently ofthe information retrieval process, or how much a stemmer improves an information retrievalapplication in terms of speed. As a summary, some guidelines are also provided to help\n",
            "\n",
            "---\n",
            "\n",
            "Title: Care episode retrieval: distributional semantic models for information retrieval in the clinical domain\n",
            "Authors: Hans Moen, Filip Ginter, E. Marsi, Laura-Maria Peltonen, T. Salakoski, S. Salanterä\n",
            "Year: 2014\n",
            "Venue: BMC Medical Informatics and Decision Making\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving geographic information retrieval in spatial data infrastructures\n",
            "Authors: Fabio Gomes de Andrade, C. Baptista, C. Davis\n",
            "Year: 2014\n",
            "Venue: GeoInformatica\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: An architectural design for effective information retrieval in semantic web\n",
            "Authors: M. Thangaraj, G. Sujatha\n",
            "Year: 2014\n",
            "Venue: Expert systems with applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Statistical reform in information retrieval?\n",
            "Authors: T. Sakai\n",
            "Year: 2014\n",
            "Venue: SIGF\n",
            "Abstract: IR revolves around evaluation. Therefore, IR researchers should employ sound evaluation practices. Nowadays many of us know that statistical significance testing is not enough, but not all of us know exactly what to do about it. This paper provides suggestions on how to report effect sizes and confidence intervals along with p-values, in the context of comparing IR systems using test collections. Hopefully, these practices will make IR papers more informative, and help researchers form more reliable conclusions that \"add up.\" Finally, I pose a specific question for the IR community: should IR journal editors and SIGIR PC chairs require (rather than encourage) reporting of effect sizes and confidence intervals.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FashionVLP: Vision Language Transformer for Fashion Retrieval with Feedback\n",
            "Authors: Sonam Goenka, Zhao-Heng Zheng, Ayush Jaiswal, Rakesh Chada, Yuehua Wu, Varsha Hedau, P. Natarajan\n",
            "Year: 2022\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Fashion image retrieval based on a query pair of reference image and natural language feedback is a challenging task that requires models to assess fashion related information from visual and textual modalities simultaneously. We propose a new vision-language transformer based model, FashionVLP, that brings the prior knowledge contained in large image-text corpora to the domain of fashion image retrieval, and combines visual information from multiple levels of context to effectively capture fashion-related information. While queries are encoded through the transformer layers, our asymmetric design adopts a novel attention-based approach for fusing target image features without involving text or transformer layers in the process. Extensive results show that FashionVLP achieves the state-of-the-art performance on benchmark datasets, with a large 23% relative improvement on the challenging FashionIQ dataset, which contains complex natural language feedback.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancing learning and retrieval of new information: a review of the forward testing effect\n",
            "Authors: Chunliang Yang, R. Potts, D. Shanks\n",
            "Year: 2018\n",
            "Venue: npj Science of Learning\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ontology-based similarity for product information retrieval\n",
            "Authors: Suriati Akmal, L. Shih, Rafael Batres\n",
            "Year: 2014\n",
            "Venue: Computers in industry (Print)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information\n",
            "Authors: Richa Tanya Jeff Dennis A Colleen Evan Devon J Rodney St Agarwala Barrett Beck Benson Bollin Bolton Bourexi, R. Agarwala, T. Barrett, J. Beck, Dennis A. Benson, Colleen J. Bollin, Evan E. Bolton, Devon Bourexis, J. R. Brister, S. Bryant, Kathi Canese, Mark Cavanaugh, Chad Charowhas, Karen Clark, I. Dondoshansky, M. Feolo, Lawrence Fitzpatrick, Kathryn Funk, Lewis Y. Geer, V. Gorelenkov, Alan Graeff, W. Hlavina, Brad Holmes, Mark Johnson, B. Kattman, Viatcheslav Khotomlianski, Avi Kimchi, Michael Kimelman, Masato Kimura, P. Kitts, W. Klimke, A. Kotliarov, S. Krasnov, A. Kuznetsov, M. Landrum, D. Landsman, S. Lathrop, Jennifer M. Lee, Carl Leubsdorf, Zhiyong Lu, Thomas L. Madden, Aron Marchler-Bauer, Adriana Malheiro, Peter A. Meric, I. Karsch-Mizrachi, Anatoly Mnev, Terence D. Murphy, R. Orris, J. Ostell, Christopher O'Sullivan, Vasuki Palanigobu, A. Panchenko, Lon Phan, Borys Pierov, K. Pruitt, K. Rodarmer, E. Sayers, Valerie A. Schneider, C. Schoch, G. Schuler, S. Sherry, Karanjit Siyan, Alexandra Soboleva, Vladimir Soussov, G. Starchenko, T. Tatusova, F. Thibaud-Nissen, K. Todorov, B. Trawick, D. Vakatov, Minghong Ward, E. Yaschenko, A. Zasypkin, Kerry Zbicz\n",
            "Year: 2017\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: Abstract The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. The Entrez system provides search and retrieval operations for most of these data from 39 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. New resources released in the past year include PubMed Data Management, RefSeq Functional Elements, genome data download, variation services API, Magic-BLAST, QuickBLASTp, and Identical Protein Groups. Resources that were updated in the past year include the genome data viewer, a human genome resources page, Gene, virus variation, OSIRIS, and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Kurdish Information Retrieval\n",
            "Authors: K. S. Esmaili, Shahin Salavati, Anwitaman Datta\n",
            "Year: 2014\n",
            "Venue: ACM Transactions on Asian Language Information Processing\n",
            "Abstract: The Kurdish language is an Indo-European language spoken in Kurdistan, a large geographical region in the Middle East. Despite having a large number of speakers, Kurdish is among the less-resourced languages and has not seen much attention from the IR and NLP research communities. This article reports on the outcomes of a project aimed at providing essential resources for processing Kurdish texts. A principal output of this project is Pewan, the first standard Test Collection to evaluate Kurdish Information Retrieval systems. The other language resources that we have built include a lightweight stemmer and a list of stopwords. Our second principal contribution is using these newly-built resources to conduct a thorough experimental study on Kurdish documents. Our experimental results show that normalization, and to a lesser extent, stemming, can greatly improve the performance of Kurdish IR systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Latent Retrieval for Weakly Supervised Open Domain Question Answering\n",
            "Authors: Kenton Lee, Ming-Wei Chang, Kristina Toutanova\n",
            "Year: 2019\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Lightweight Multi-Scale Crossmodal Text-Image Retrieval Method in Remote Sensing\n",
            "Authors: Zhiqiang Yuan, Wenkai Zhang, Xuee Rong, Xuan Li, Jialiang Chen, Hongqi Wang, Kun Fu, Xian Sun\n",
            "Year: 2022\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: Remote sensing (RS) crossmodal text-image retrieval has become a research hotspot in recent years for its application in semantic localization. However, since multiple inferences on slices are demanded in semantic localization, designing a crossmodal retrieval model with less computation but well performance becomes an emergent and challenging task. In this article, considering the characteristics of multi-scale and target redundancy in RS, a concise but effective crossmodal retrieval model (LW-MCR) is designed. The proposed model incorporates multi-scale information and dynamically filters out redundant features when encoding RS image, while text features are obtained via lightweight group convolution. To improve the retrieval performance of LW-MCR, we come up with a novel hidden supervised optimization method based on knowledge distillation. This method enables the proposed model to acquire dark knowledge of the multi-level layers and representation layers in the teacher network, which significantly improves the accuracy of our lightweight model. Finally, on the basis of contrast learning, we present a method employing unlabeled data to boost the performance of RS retrieval model further. The experiment results on four RS image-text datasets demonstrate the efficiency of LW-MCR in RS crossmodal retrieval (RSCR) tasks. We have released some codes of the semantic localization and made it open to access at https://github.com/xiaoyuan1996/retrievalSystem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction\n",
            "Authors: Xinyu Ma, J. Guo, Ruqing Zhang, Yixing Fan, Xueqi Cheng\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Dense retrieval has shown promising results in many information retrieval (IR) related tasks, whose foundation is high-quality text representation learning for effective search. Some recent studies have shown that autoencoder-based language models are able to boost the dense retrieval performance using a weak decoder. However, we argue that 1) it is not discriminative to decode all the input texts and, 2) even a weak decoder has the bypass effect on the encoder. Therefore, in this work, we introduce a novel contrastive span prediction task to pre-train the encoder alone, but still retain the bottleneck ability of the autoencoder. In this way, we can 1) learn discriminative text representations efficiently with the group-wise contrastive learning over spans and, 2) avoid the bypass effect of the decoder thoroughly. Comprehensive experiments over publicly available retrieval benchmark datasets show that our approach can outperform existing pre-training methods for dense retrieval significantly.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Codes for Information Retrieval With Small Uncertainty\n",
            "Authors: Ville Junnila, T. Laihonen\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: In a recent paper by Yaakobi and Bruck, the problem of information retrieval in associative memories has been considered. In an associative memory, each memory entry is associated to the neighboring entries. When searching information, a fixed number of input clues are given and the output set is formed by the entries associated to all the input clues. The maximum size of an output set is called the uncertainty of the associative memory. In this paper, we study the problem of information retrieval in associative memories with small uncertainty. In particular, we concentrate on the cases where the memory entries and their associations form a binary Hamming space or an infinite square grid. Particularly, we focus on minimizing the number of input clues needed to retrieve information with small uncertainty and present good constructions some of which are optimal, i.e., use the smallest possible number of clues.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic information retrieval research based on co-occurrence analysis\n",
            "Authors: Wen-Heng Lou, Junping Qiu\n",
            "Year: 2014\n",
            "Venue: Online information review (Print)\n",
            "Abstract: Purpose – The paper aims to develop a new method for potential relations retrieval. It aims to find common aspects between co-occurrence analysis and ontology to build a model of semantic information retrieval based on co-occurrence analysis. Design/methodology/approach – This paper used a literature review, co-occurrence analysis, ontology build and other methods to design a model and process of semantic information retrieval based on co-occurrence analysis. Archaeological data from Wuhan University Library's bibliographic retrieval systems was used for experimental analysis. Findings – The literature review found that semantic information retrieval research mainly concentrates on ontology-based query techniques, semantic annotation and semantic relation retrieval. Moreover most recent systems can only achieve obvious relations retrieval. Ontology and co-occurrence analysis have strong similarities in theoretical ideas, data types, expressions, and applications. Research limitations/implications – The ex...\n",
            "\n",
            "---\n",
            "\n",
            "Title: VIRLab: a web-based virtual lab for learning and studying information retrieval models\n",
            "Authors: Hui Fang, Hao Wu, Peilin Yang, ChengXiang Zhai\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In this paper, we describe VIRLab, a novel web-based virtual laboratory for Information Retrieval (IR). Unlike existing command line based IR toolkits, the VIRLab system provides a more interactive tool that enables easy implementation of retrieval functions with only a few lines of codes, simplified evaluation process over multiple data sets and parameter settings and straightforward result analysis interface through operational search engines and pair-wise comparisons. These features make VIRLab a unique and novel tool that can help teaching IR models, improving the productivity for doing IR model research, as well as promoting controlled experimental study of IR models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Autoregressive Entity Retrieval\n",
            "Authors: Nicola De Cao, Gautier Izacard, Sebastian Riedel, F. Petroni\n",
            "Year: 2020\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Entities are at the center of how we represent and aggregate knowledge. For instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one per article). The ability to retrieve such entities given a query is fundamental for knowledge-intensive tasks such as entity linking and open-domain question answering. One way to understand current approaches is as classifiers among atomic labels, one for each entity. Their weight vectors are dense entity representations produced by encoding entity information such as descriptions. This approach leads to several shortcomings: i) context and entity affinity is mainly captured through a vector dot product, potentially missing fine-grained interactions between the two; ii) a large memory footprint is needed to store dense representations when considering large entity sets; iii) an appropriately hard set of negative data has to be subsampled at training time. We propose GENRE, the first system that retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion, and conditioned on the context. This enables to mitigate the aforementioned technical issues: i) the autoregressive formulation allows us to directly capture relations between context and entity name, effectively cross encoding both; ii) the memory footprint is greatly reduced because the parameters of our encoder-decoder architecture scale with vocabulary size, not entity count; iii) the exact softmax loss can be efficiently computed without the need to subsample negative data. We show the efficacy of the approach with more than 20 datasets on entity disambiguation, end-to-end entity linking and document retrieval tasks, achieving new SOTA, or very competitive results while using a tiny fraction of the memory of competing systems. Finally, we demonstrate that new entities can be added by simply specifying their unambiguous name.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Statistical Significance Testing in Information Retrieval: Theory and Practice\n",
            "Authors: Ben Carterette\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The past 20 years have seen a great improvement in the rigor of information retrieval experimentation, due primarily to two factors: high-quality, public, portable test collections such as those produced by TREC (the Text REtrieval Conference [28]), and the increased practice of sta- tistical hypothesis testing to determine whether measured improvements can be ascribed to something other than random chance. Together these create a very useful standard for reviewers, program committees, and journal editors; work in information retrieval (IR) increasingly cannot be published unless it has been evaluated using a well-constructed test collection and shown to produce a statistically significant improvement over a good baseline. But, as the saying goes, any tool sharp enough to be useful is also sharp enough to be dangerous. Statistical tests of significance are widely misunderstood. Most researchers and developers treat them as a \"black box\": evaluation results go in and a p-value comes out. But because significance is such an important factor in determining what research directions to explore and what is published, using p-values obtained without thought can have consequences for everyone doing research in IR. Ioannidis has argued that the main consequence in the biomedical sciences is that most published research findings are false [12]; could that be the case in IR as well?\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Use of Arabic WordNet in Arabic Information Retrieval\n",
            "Authors: Ahmed Abbache, F. Barigou, Fatma Zohra Belkredim, Ghalem Belalem\n",
            "Year: 2014\n",
            "Venue: International Journal of Information Retrieval Research\n",
            "Abstract: Research and experimentation using Arabic WordNet in the field of information retrieval are relatively new. It is limited compared to the research that has been done using Princeton WordNet. This work attempts to study the impact of Arabic WordNet on the performance of Arabic information retrieval. We extend Lucene with Arabic WordNet to expand user's queries. The major contribution of this study is to propose an interactive query expansion IQE methodology using the word's part-of-speech, according to the part it plays in a query. First, the user selects the appropriate part of speech for each term in the original query, and then he reselects the appropriate synonyms. Experimental results show that our IQE strategy produces a good Mean Average Precision MAP, it is able to improve MAP by 12.6%, but no variant of automatic query expansion AQE strategies did. Nevertheless, the experiments allow us to conclude that with an appropriate use of Arabic WordNet as a source of linguistic information for AQE can improve effectiveness for Arabic information retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation\n",
            "Authors: Sebastian Hofstätter, Jiecao Chen, K. Raman, Hamed Zamani\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Retrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. In this work, we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. Our FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. Our experiments on a diverse set of seven knowledge intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier between query latency and effectiveness. FiD-Light with source pointing sets substantial new state-of-the-art results on six KILT tasks for combined text generation and provenance retrieval evaluation, while maintaining high efficiency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An analysis of query difficulty for information retrieval in the medical domain\n",
            "Authors: Lorraine Goeuriot, Liadh Kelly, Johannes Leveling\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We present a post-hoc analysis of a benchmarking activity for information retrieval (IR) in the medical domain to determine if performance for queries with different levels of complexity can be associated with different IR methods or techniques. Our analysis is based on data and runs for Task 3 of the CLEF 2013 eHealth lab, which provided patient queries and a large medical document collection for patient centred medical information retrieval technique development. We categorise the queries based on their complexity, which is defined as the number of medical concepts they contain. We then show how query complexity affects performance of runs submitted to the lab, and provide suggestions for improving retrieval quality for this complex retrieval task and similar IR evaluation tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Flowchart recognition for non-textual information retrieval in patent search\n",
            "Authors: Marçal Rusiñol, Lluís-Pere de las Heras, O. R. Terrades\n",
            "Year: 2014\n",
            "Venue: Information retrieval (Boston)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Advances in Information Retrieval\n",
            "Authors: C. Wilkie, Leif Azzopardi\n",
            "Year: 2014\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Information Retrieval Ontology for Information Retrieval Nanopublications\n",
            "Authors: Aldo Lipani, Florina Piroi, Linda Andersson, A. Hanbury\n",
            "Year: 2014\n",
            "Venue: Conference and Labs of the Evaluation Forum\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Divergent Routing of Positive and Negative Information from the Amygdala during Memory Retrieval\n",
            "Authors: A. Beyeler, P. Namburi, Gordon F. Glober, Clémence Simonnet, G. G. Calhoon, Garrett F. Conyers, Robert Luck, Craig P. Wildes, K. Tye\n",
            "Year: 2016\n",
            "Venue: Neuron\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pre-training Tasks for Embedding-based Large-scale Retrieval\n",
            "Authors: Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar\n",
            "Year: 2020\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: We consider the large-scale query-document retrieval problem: given a query (e.g., a question), return the set of relevant documents (e.g., paragraphs containing the answer) from a large document corpus. This problem is often solved in two steps. The retrieval phase first reduces the solution space, returning a subset of candidate documents. The scoring phase then re-ranks the documents. Critically, the retrieval algorithm not only desires high recall but also requires to be highly efficient, returning candidates in time sublinear to the number of documents. Unlike the scoring phase witnessing significant advances recently due to the BERT-style pre-training tasks on cross-attention models, the retrieval phase remains less well studied. Most previous works rely on classic Information Retrieval (IR) methods such as BM-25 (token matching + TF-IDF weights). These models only accept sparse handcrafted features and can not be optimized for different downstream tasks of interest. In this paper, we conduct a comprehensive study on the embedding-based retrieval models. We show that the key ingredient of learning a strong embedding-based Transformer model is the set of pre-training tasks. With adequately designed paragraph-level pre-training tasks, the Transformer models can remarkably improve over the widely-used BM-25 as well as embedding models without Transformers. The paragraph-level pre-training tasks we studied are Inverse Cloze Task (ICT), Body First Selection (BFS), Wiki Link Prediction (WLP), and the combination of all three.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval\n",
            "Authors: Mengjun Cheng, Yipeng Sun, Long Wang, Xiongwei Zhu, Kun Yao, Jie Chen, Guoli Song, Junyu Han, Jingtuo Liu, Errui Ding, Jingdong Wang\n",
            "Year: 2022\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Visual appearance is considered to be the most important cue to understand images for cross-modal retrieval, while sometimes the scene text appearing in images can provide valuable information to understand the visual semantics. Most of existing cross-modal retrieval approaches ignore the usage of scene text information and directly adding this information may lead to performance degradation in scene text free scenarios. To address this issue, we propose a full transformer architecture to unify these cross-modal retrieval scenarios in a single Vision and Scene Text Aggregation framework (ViSTA). Specifically, ViSTA utilizes transformer blocks to directly encode image patches and fuse scene text embedding to learn an aggregated visual representation for cross-modal retrieval. To tackle the modality missing problem of scene text, we propose a novel fusion token based transformer aggregation approach to exchange the necessary scene text information only through the fusion token and concentrate on the most important features in each modality. To further strengthen the visual modality, we develop dual contrastive learning losses to embed both image-text pairs and fusion-text pairs into a common cross-modal space. Compared to existing methods, ViSTA enables to aggregate relevant scene text semantics with visual appearance, and hence improve results under both scene text free and scene text aware scenarios. Experimental results show that ViSTA outperforms other methods by at least 8.4% at Recall@ 1 for scene text aware retrieval task. Compared with state-of-the-art scene text free retrieval methods, ViSTA can achieve better accuracy on Flicker30K and MSCOCO while running at least three times faster during the inference stage, which validates the effectiveness of the proposed framework.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval-Enhanced Machine Learning\n",
            "Authors: Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, Michael Bendersky\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Although information access systems have long supportedpeople in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. In this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. We describe a generic retrieval-enhanced machine learning (REML) framework, which includes a number of existing models as special cases. REML challenges information retrieval conventions, presenting opportunities for novel advances in core areas, including optimization. The REML research agenda lays a foundation for a new style of information access research and paves a path towards advancing machine learning and artificial intelligence.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Metric Spaces for Temporal Information Retrieval\n",
            "Authors: Matteo Brucato, D. Montesi\n",
            "Year: 2014\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization\n",
            "Authors: Amin Abolghasemi, S. Verberne, L. Azzopardi\n",
            "Year: 2022\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Power of Noise: Redefining Retrieval for RAG Systems\n",
            "Authors: Florin Cuconasu, Giovanni Trappolini, F. Siciliano, Simone Filice, Cesare Campagnano, Y. Maarek, Nicola Tonellotto, Fabrizio Silvestri\n",
            "Year: 2024\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Transfer Learning Approaches for Building Cross-Language Dense Retrieval Models\n",
            "Authors: Suraj Nair, Eugene Yang, Dawn J Lawrie, Kevin Duh, Paul McNamee, Kenton Murray, J. Mayfield, Douglas W. Oard\n",
            "Year: 2022\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information fusion in content based image retrieval: A comprehensive overview\n",
            "Authors: Luca Piras, G. Giacinto\n",
            "Year: 2017\n",
            "Venue: Information Fusion\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Distributed retrieval practice promotes superior recall of anatomy information\n",
            "Authors: John L. Dobson, Jose Perez, Tracy Linderholm\n",
            "Year: 2017\n",
            "Venue: Anatomical Sciences Education\n",
            "Abstract: Effortful retrieval produces greater long‐term recall of information when compared to studying (i.e., reading), as do learning sessions that are distributed (i.e., spaced apart) when compared to those that are massed together. Although the retrieval and distributed practice effects are well‐established in the cognitive science literature, no studies have examined their additive effect with regard to learning anatomy information. The aim of this study was to determine how the benefits of retrieval practice vary with massed versus distributed learning. Participants used the following strategies to learn sets of skeletal muscle anatomy: (1) studying on three different days over a seven day period (SSSS7,2,0), (2) studying and retrieving on three different days over a seven day period (SRSR7,2,0), (3) studying on two different days over a two day period (SSSSSS2,0), (4) studying and retrieving on two separate days over a two day period (SRSRSR2,0), and (5) studying and retrieving on one day (SRx60). All strategies consisted of 12 learning phases and lasted exactly 24 minutes. Muscle information retention was assessed via free recall and using repeated measures ANOVAs. A week after learning, the recall scores were 24.72 ± 3.12, 33.88 ± 3.48, 15.51 ± 2.48, 20.72 ± 2.94, and 12.86 ± 2.05 for the SSSS7,2,0, SRSR7,2,0, SSSSSS2,0, STSTST2,0, and SRx60 strategies, respectively. In conclusion, the distributed strategies produced significantly better recall than the massed strategies, the retrieval‐based strategies produced significantly better recall than the studying strategies, and the combination of distributed and retrieval practice generated the greatest recall of anatomy information. Anat Sci Educ 10: 339–347. © 2016 American Association of Anatomists.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Where Does the Performance Improvement Come From?: - A Reproducibility Concern about Image-Text Retrieval\n",
            "Authors: Jun Rao, Fei Wang, Liang Ding, Shuhan Qi, Yibing Zhan, Weifeng Liu, D. Tao\n",
            "Year: 2022\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This article aims to provide the information retrieval community with some reflections on recent advances in retrieval learning by analyzing the reproducibility of image-text retrieval models. Due to the increase of multimodal data over the last decade, image-text retrieval has steadily become a major research direction in the field of information retrieval. Numerous researchers train and evaluate image-text retrieval algorithms using benchmark datasets such as MS-COCO and Flickr30k. Research in the past has mostly focused on performance, with multiple state-of-the-art methodologies being suggested in a variety of ways. According to their assertions, these techniques provide improved modality interactions and hence more precise multimodal representations. In contrast to previous works, we focus on the reproducibility of the approaches and the examination of the elements that lead to improved performance by pretrained and nonpretrained models in retrieving images and text. To be more specific, we first examine the related reproducibility concerns and explain why our focus is on image-text retrieval tasks. Second, we systematically summarize the current paradigm of image-text retrieval models and the stated contributions of those approaches. Third, we analyze various aspects of the reproduction of pretrained and nonpretrained retrieval models. To complete this, we conducted ablation experiments and obtained some influencing factors that affect retrieval recall more than the improvement claimed in the original paper. Finally, we present some reflections and challenges that the retrieval community should consider in the future. Our source code is publicly available at https://github.com/WangFei-2019/Image-text-Retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dynamic Modality Interaction Modeling for Image-Text Retrieval\n",
            "Authors: Leigang Qu, Meng Liu, Jianlong Wu, Zan Gao, Liqiang Nie\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Image-text retrieval is a fundamental and crucial branch in information retrieval. Although much progress has been made in bridging vision and language, it remains challenging because of the difficult intra-modal reasoning and cross-modal alignment. Existing modality interaction methods have achieved impressive results on public datasets. However, they heavily rely on expert experience and empirical feedback towards the design of interaction patterns, therefore, lacking flexibility. To address these issues, we develop a novel modality interaction modeling network based upon the routing mechanism, which is the first unified and dynamic multimodal interaction framework towards image-text retrieval. In particular, we first design four types of cells as basic units to explore different levels of modality interactions, and then connect them in a dense strategy to construct a routing space. To endow the model with the capability of path decision, we integrate a dynamic router in each cell for pattern exploration. As the routers are conditioned on inputs, our model can dynamically learn different activated paths for different data. Extensive experiments on two benchmark datasets, i.e., Flickr30K and MS-COCO, verify the superiority of our model compared with several state-of-the-art baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DSSL: Deep Surroundings-person Separation Learning for Text-based Person Retrieval\n",
            "Authors: A. Zhu, Zijie Wang, Yifeng Li, Xili Wan, Jing Jin, Tian Wang, Fangqiang Hu, G. Hua\n",
            "Year: 2021\n",
            "Venue: ACM Multimedia\n",
            "Abstract: Many previous methods on text-based person retrieval tasks are devoted to learning a latent common space mapping, with the purpose of extracting modality-invariant features from both visual and textual modality. Nevertheless, due to the complexity of high-dimensional data, the unconstrained mapping paradigms are not able to properly catch discriminative clues about the corresponding person while drop the misaligned information. Intuitively, the information contained in visual data can be divided into person information (PI) and surroundings information (SI), which are mutually exclusive from each other. To this end, we propose a novel Deep Surroundings-person Separation Learning (DSSL) model in this paper to effectively extract and match person information, and hence achieve a superior retrieval accuracy. A surroundings-person separation and fusion mechanism plays the key role to realize an accurate and effective surroundings-person separation under a mutually exclusion constraint. In order to adequately utilize multi-modal and multi-granular information for a higher retrieval accuracy, five diverse alignment paradigms are adopted. Extensive experiments are carried out to evaluate the proposed DSSL on CUHK-PEDES, which is currently the only accessible dataset for text-base person retrieval task. DSSL achieves the state-of-the-art performance on CUHK-PEDES. To properly evaluate our proposed DSSL in the real scenarios, a Real Scenarios Text-based Person Reidentification (RSTPReid) dataset is constructed to benefit future research on text-based person retrieval, which will be publicly available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval-based Neural Source Code Summarization\n",
            "Authors: Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Xudong Liu\n",
            "Year: 2020\n",
            "Venue: International Conference on Software Engineering\n",
            "Abstract: Source code summarization aims to automatically generate concise summaries of source code in natural language texts, in order to help developers better understand and maintain source code. Traditional work generates a source code summary by utilizing information retrieval techniques, which select terms from original source code or adapt summaries of similar code snippets. Recent studies adopt Neural Machine Translation techniques and generate summaries from code snippets using encoder-decoder neural networks. The neural-based approaches prefer the high-frequency words in the corpus and have trouble with the low-frequency ones. In this paper, we propose a retrieval-based neural source code summarization approach where we enhance the neural model with the most similar code snippets retrieved from the training set. Our approach can take advantages of both neural and retrieval-based techniques. Specifically, we first train an attentional encoder-decoder model based on the code snippets and the summaries in the training set; Second, given one input code snippet for testing, we retrieve its two most similar code snippets in the training set from the aspects of syntax and semantics, respectively; Third, we encode the input and two retrieved code snippets, and predict the summary by fusing them during decoding. We conduct extensive experiments to evaluate our approach and the experimental results show that our proposed approach can improve the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Use What You Have: Video retrieval using representations from collaborative experts\n",
            "Authors: Yang Liu, Samuel Albanie, Arsha Nagrani, Andrew Zisserman\n",
            "Year: 2019\n",
            "Venue: British Machine Vision Conference\n",
            "Abstract: The rapid growth of video on the internet has made searching for video content using natural language queries a significant challenge. Human-generated queries for video datasets `in the wild' vary a lot in terms of degree of specificity, with some queries describing specific details such as the names of famous identities, content from speech, or text available on the screen. Our goal is to condense the multi-modal, extremely high dimensional information from videos into a single, compact video representation for the task of video retrieval using free-form text queries, where the degree of specificity is open-ended. \n",
            "For this we exploit existing knowledge in the form of pre-trained semantic embeddings which include 'general' features such as motion, appearance, and scene features from visual content. We also explore the use of more 'specific' cues from ASR and OCR which are intermittently available for videos and find that these signals remain challenging to use effectively for retrieval. We propose a collaborative experts model to aggregate information from these different pre-trained experts and assess our approach empirically on five retrieval benchmarks: MSR-VTT, LSMDC, MSVD, DiDeMo, and ActivityNet. Code and data can be found at this http URL. This paper contains a correction to results reported in the previous version.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Multi-View Enhancement Hashing for Image Retrieval\n",
            "Authors: C. Yan, Biao Gong, Yuxuan Wei, Yue Gao\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "Abstract: Hashing is an efficient method for nearest neighbor search in large-scale data space by embedding high-dimensional feature descriptors into a similarity preserving Hamming space with a low dimension. However, large-scale high-speed retrieval through binary code has a certain degree of reduction in retrieval accuracy compared to traditional retrieval methods. We have noticed that multi-view methods can well preserve the diverse characteristics of data. Therefore, we try to introduce the multi-view deep neural network into the hash learning field, and design an efficient and innovative retrieval model, which has achieved a significant improvement in retrieval performance. In this paper, we propose a supervised multi-view hash model which can enhance the multi-view information through neural networks. This is a completely new hash learning method that combines multi-view and deep learning methods. The proposed method utilizes an effective view stability evaluation method to actively explore the relationship among views, which will affect the optimization direction of the entire network. We have also designed a variety of multi-data fusion methods in the Hamming space to preserve the advantages of both convolution and multi-view. In order to avoid excessive computing resources on the enhancement procedure during retrieval, we set up a separate structure called memory network which participates in training together. The proposed method is systematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and the results show that our method significantly outperforms the state-of-the-art single-view and multi-view hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Episodic Memory Retrieval Functionally Relies on Very Rapid Reactivation of Sensory Information\n",
            "Authors: G. Waldhauser, Verena Braun, S. Hanslmayr\n",
            "Year: 2016\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Episodic memory retrieval is assumed to rely on the rapid reactivation of sensory information that was present during encoding, a process termed “ecphory.” We investigated the functional relevance of this scarcely understood process in two experiments in human participants. We presented stimuli to the left or right of fixation at encoding, followed by an episodic memory test with centrally presented retrieval cues. This allowed us to track the reactivation of lateralized sensory memory traces during retrieval. Successful episodic retrieval led to a very early (∼100–200 ms) reactivation of lateralized alpha/beta (10–25 Hz) electroencephalographic (EEG) power decreases in the visual cortex contralateral to the visual field at encoding. Applying rhythmic transcranial magnetic stimulation to interfere with early retrieval processing in the visual cortex led to decreased episodic memory performance specifically for items encoded in the visual field contralateral to the site of stimulation. These results demonstrate, for the first time, that episodic memory functionally relies on very rapid reactivation of sensory information. SIGNIFICANCE STATEMENT Remembering personal experiences requires a “mental time travel” to revisit sensory information perceived in the past. This process is typically described as a controlled, relatively slow process. However, by using electroencephalography to measure neural activity with a high time resolution, we show that such episodic retrieval entails a very rapid reactivation of sensory brain areas. Using transcranial magnetic stimulation to alter brain function during retrieval revealed that this early sensory reactivation is causally relevant for conscious remembering. These results give first neural evidence for a functional, preconscious component of episodic remembering. This provides new insight into the nature of human memory and may help in the understanding of psychiatric conditions that involve the automatic intrusion of unwanted memories.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LibGuides: Guide to information retrieval: Executing information retrieval\n",
            "Authors: Harri Maikola\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information retrieval\n",
            "Authors: Lawrence Herbert Berul\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Identifying and exploiting target entity type information for ad hoc entity retrieval\n",
            "Authors: Darío Garigliotti, Faegheh Hasibi, K. Balog\n",
            "Year: 2018\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploring User-Specific Information in Music Retrieval\n",
            "Authors: Zhiyong Cheng, Jialie Shen, Liqiang Nie, Tat-Seng Chua, M. Kankanhalli\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: With the advancement of mobile computing technology and cloud-based streaming music service, user-centered music retrieval has become increasingly important. User-specific information has a fundamental impact on personal music preferences and interests. However, existing research pays little attention to the modeling and integration of user-specific information in music retrieval algorithms/models to facilitate music search. In this paper, we propose a novel model, named User-Information-Aware Music Interest Topic (UIA-MIT) model. The model is able to effectively capture the influence of user-specific information on music preferences, and further associate users' music preferences and search terms under the same latent space. Based on this model, a user information aware retrieval system is developed, which can search and re-rank the results based on age- and/or gender-specific music preferences. A comprehensive experimental study demonstrates that our methods can significantly improve the search accuracy over existing text-based music retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Large-Scale Retrieval for Reinforcement Learning\n",
            "Authors: P. Humphreys, A. Guez, O. Tieleman, L. Sifre, T. Weber, T. Lillicrap\n",
            "Year: 2022\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Effective decision making involves flexibly relating past experiences and relevant contextual information to a novel situation. In deep reinforcement learning (RL), the dominant paradigm is for an agent to amortise information that helps decision making into its network weights via gradient descent on training losses. Here, we pursue an alternative approach in which agents can utilise large-scale context sensitive database lookups to support their parametric computations. This allows agents to directly learn in an end-to-end manner to utilise relevant information to inform their outputs. In addition, new information can be attended to by the agent, without retraining, by simply augmenting the retrieval dataset. We study this approach for offline RL in 9x9 Go, a challenging game for which the vast combinatorial state space privileges generalisation over direct matching to past experiences. We leverage fast, approximate nearest neighbor techniques in order to retrieve relevant data from a set of tens of millions of expert demonstration states. Attending to this information provides a significant boost to prediction accuracy and game-play performance over simply using these demonstrations as training trajectories, providing a compelling demonstration of the value of large-scale retrieval in offline RL agents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Particular object retrieval with integral max-pooling of CNN activations\n",
            "Authors: Giorgos Tolias, R. Sicre, H. Jégou\n",
            "Year: 2015\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Recently, image representation built upon Convolutional Neural Network (CNN) has been shown to provide effective descriptors for image search, outperforming pre-CNN features as short-vector representations. Yet such models are not compatible with geometry-aware re-ranking methods and still outperformed, on some particular object retrieval benchmarks, by traditional image search systems relying on precise descriptor matching, geometric re-ranking, or query expansion. This work revisits both retrieval stages, namely initial search and re-ranking, by employing the same primitive information derived from the CNN. We build compact feature vectors that encode several image regions without the need to feed multiple inputs to the network. Furthermore, we extend integral images to handle max-pooling on convolutional layer activations, allowing us to efficiently localize matching objects. The resulting bounding box is finally used for image re-ranking. As a result, this paper significantly improves existing CNN-based recognition pipeline: We report for the first time results competing with traditional methods on the challenging Oxford5k and Paris6k datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval\n",
            "Authors: Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, Barlas Oğuz\n",
            "Year: 2020\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CoSMo: Content-Style Modulation for Image Retrieval with Text Feedback\n",
            "Authors: Seung-Min Lee, Dongwan Kim, Bohyung Han\n",
            "Year: 2021\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: We tackle the task of image retrieval with text feedback, where a reference image and modifier text are combined to identify the desired target image. We focus on designing an image-text compositor, i.e., integrating multi-modal inputs to produce a representation similar to that of the target image. In our algorithm, Content-Style Modulation (CoSMo), we approach this challenge by introducing two modules based on deep neural networks: the content and style modulators. The content modulator performs local updates to the reference image feature after normalizing the style of the image, where a disentangled multi-modal non-local block is employed to achieve the desired content modifications. Then, the style modulator reintroduces global style information to the updated feature. We provide an in-depth view of our algorithm and its design choices, and show that it accomplishes outstanding performance on multiple image-text retrieval benchmarks. Our code can be found at: https://github.com/postBG/CosMo.pytorch\n",
            "\n",
            "---\n",
            "\n",
            "Title: Case Retrieval in Medical Databases by Fusing Heterogeneous Information\n",
            "Authors: G. Quellec, M. Lamard, G. Cazuguel, C. Roux, B. Cochener\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Medical Imaging\n",
            "Abstract: A novel content-based heterogeneous information retrieval framework, particularly well suited to browse medical databases and support new generation computer aided diagnosis (CADx) systems, is presented in this paper. It was designed to retrieve possibly incomplete documents, consisting of several images and semantic information, from a database; more complex data types such as videos can also be included in the framework. The proposed retrieval method relies on image processing, in order to characterize each individual image in a document by their digital content, and information fusion. Once the available images in a query document are characterized, a degree of match, between the query document and each reference document stored in the database, is defined for each attribute (an image feature or a metadata). A Bayesian network is used to recover missing information if need be. Finally, two novel information fusion methods are proposed to combine these degrees of match, in order to rank the reference documents by decreasing relevance for the query. In the first method, the degrees of match are fused by the Bayesian network itself. In the second method, they are fused by the Dezert-Smarandache theory: the second approach lets us model our confidence in each source of information (i.e., each attribute) and take it into account in the fusion process for a better retrieval performance. The proposed methods were applied to two heterogeneous medical databases, a diabetic retinopathy database and a mammography screening database, for computer aided diagnosis. Precisions at five of 0.809 ± 0.158 and 0.821 ± 0.177, respectively, were obtained for these two databases, which is very promising.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Lucene for Information Access and Retrieval Research (LIARR) Workshop at SIGIR 2017\n",
            "Authors: L. Azzopardi, Matt Crane, Hui Fang, Grant Ingersoll, Jimmy J. Lin, Yashar Moshfeghi, Harrisen Scells, Peilin Yang, G. Zuccon\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: As an empirical discipline, information access and retrieval research requires substantial software infrastructure to index and search large collections. This workshop is motivated by the desire to better align information retrieval research with the practice of building search applications from the perspective of open-source information retrieval systems. Our goal is to promote the use of Lucene for information access and retrieval research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PyTerrier: Declarative Experimentation in Python from BM25 to Dense Retrieval\n",
            "Authors: Craig Macdonald, N. Tonellotto, Sean MacAvaney, I. Ounis\n",
            "Year: 2021\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: PyTerrier is a Python-based retrieval framework for expressing simple and complex information retrieval (IR) pipelines in a declarative manner. While making use of the long-established Terrier IR platform for basic text indexing and retrieval, its salient utility comes from its expressive Python operators, which allow for individual IR operations to be pipelined and combined in different flexible manners as requested by the search application. Each operation applies a transformation upon a dataframe, while operators are defined with clear semantics in relational algebra. Going further, we have recently expanded the PyTerrier framework to include additional support for state-of-the-art BERT-based text re-rankers (such as EPIC) and dense retrieval implementations (such as ANCE and ColBERT). Transformer pipelines can be tuned and evaluated in a declarative manner. To increase the reusability of this framework as a resource for the IR community, PyTerrier provides easy access to a variety of standard benchmark datasets, including pre-built indices. Finally, we highlight the advantages of such a framework for information retrieval researchers and educators.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase Retrieval from Incomplete Magnitude Information via Total Variation Regularization\n",
            "Authors: Huibin Chang, Y. Lou, M. Ng, T. Zeng\n",
            "Year: 2016\n",
            "Venue: SIAM Journal on Scientific Computing\n",
            "Abstract: The phase retrieval problem has drawn considerable attention, as many optical detection devices can only measure magnitudes of the Fourier transform of the underlying object (signal or image). This paper addresses the phase retrieval problem from incomplete data, where only partial magnitudes of Fourier transform are obtained. In particular, we consider structured illuminated patterns in holography and find that noninteger values used in designing such patterns often yield better reconstruction than the conventional integer-valued ones. Furthermore, we demonstrate theoretically and numerically that three diffracted sets of (complete) magnitude data are sufficient to recover the object. To compensate for incomplete information, we incorporate a total variation regularization a priori to guarantee that the reconstructed image satisfies some desirable properties. The proposed model can be solved efficiently by an alternative directional multiplier method with provable convergence. Numerical experiments valid...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval of ice cloud properties using an optimal estimation algorithm and MODIS infrared observations: 1. Forward model, error analysis, and information content\n",
            "Authors: Chenxi Wang, S. Platnick, Zhibo Zhang, K. Meyer, P. Yang\n",
            "Year: 2016\n",
            "Venue: Journal of Geophysical Research - Atmospheres\n",
            "Abstract: An optimal estimation (OE) retrieval method is developed to infer three ice cloud properties simultaneously: optical thickness (τ), effective radius (reff), and cloud top height (h). This method is based on a fast radiative transfer (RT) model and infrared (IR) observations from the MODerate resolution Imaging Spectroradiometer (MODIS). This study conducts thorough error and information content analyses to understand the error propagation and performance of retrievals from various MODIS band combinations under different cloud/atmosphere states. Specifically, the algorithm takes into account four error sources: measurement uncertainty, fast RT model uncertainty, uncertainties in ancillary data sets (e.g., atmospheric state), and assumed ice crystal habit uncertainties. It is found that the ancillary and ice crystal habit error sources dominate the MODIS IR retrieval uncertainty and cannot be ignored. The information content analysis shows that for a given ice cloud, the use of four MODIS IR observations is sufficient to retrieve the three cloud properties. However, the selection of MODIS IR bands that provide the most information and their order of importance varies with both the ice cloud properties and the ambient atmospheric and the surface states. As a result, this study suggests the inclusion of all MODIS IR bands in practice since little a priori information is available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Video Corpus Moment Retrieval with Contrastive Learning\n",
            "Authors: Hao Zhang, Aixin Sun, Wei Jing, Guoshun Nan, Liangli Zhen, Joey Tianyi Zhou, R. Goh\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Given a collection of untrimmed and unsegmented videos, video corpus moment retrieval (VCMR) is to retrieve a temporal moment (i.e., a fraction of a video) that semantically corresponds to a given text query. As video and text are from two distinct feature spaces, there are two general approaches to address VCMR: (i) to separately encode each modality representations, then align the two modality representations for query processing, and (ii) to adopt fine-grained cross-modal interaction to learn multi-modal representations for query processing. While the second approach often leads to better retrieval accuracy, the first approach is far more efficient. In this paper, we propose a Retrieval and Localization Network with Contrastive Learning (ReLoCLNet) for VCMR. We adopt the first approach and introduce two contrastive learning objectives to refine video encoder and text encoder to learn video and text representations separately but with better alignment for VCMR. The video contrastive learning (VideoCL) is to maximize mutual information between query and candidate video at video-level. The frame contrastive learning (FrameCL) aims to highlight the moment region corresponds to the query at frame-level, within a video. Experimental results show that, although ReLoCLNet encodes text and video separately for efficiency, its retrieval accuracy is comparable with baselines adopting cross-modal interaction learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries\n",
            "Authors: Carl N. Edwards, Chengxiang Zhai, Heng Ji\n",
            "Year: 2021\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We propose a new task, Text2Mol, to retrieve molecules using natural language descriptions as queries. Natural language and molecules encode information in very different ways, which leads to the exciting but challenging problem of integrating these two very different modalities. Although some work has been done on text-based retrieval and structure-based retrieval, this new task requires integrating molecules and natural language more directly. Moreover, this can be viewed as an especially challenging cross-lingual retrieval problem by considering the molecules as a language with a very unique grammar. We construct a paired dataset of molecules and their corresponding text descriptions, which we use to learn an aligned common semantic embedding space for retrieval. We extend this to create a cross-modal attention-based model for explainability and reranking by interpreting the attentions as association rules. We also employ an ensemble approach to integrate our different architectures, which significantly improves results from 0.372 to 0.499 MRR. This new multimodal approach opens a new perspective on solving problems in chemistry literature understanding and molecular machine learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LeCaRD: A Legal Case Retrieval Dataset for Chinese Law System\n",
            "Authors: Yixiao Ma, Yunqiu Shao, Yueyue Wu, Yiqun Liu, Ruizhe Zhang, M. Zhang, Shaoping Ma\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Legal case retrieval is of vital importance for ensuring justice in different kinds of law systems and has recently received increasing attention in information retrieval (IR) research. However, the relevance judgment criteria of previous retrieval datasets are either not applicable to non-cited relationship cases or not instructive enough for future datasets to follow. Besides, most existing benchmark datasets do not focus on the selection of queries. In this paper, we construct the Chinese Legal Case Retrieval Dataset (LeCaRD), which contains 107 query cases and over 43,000 candidate cases. Queries and results are adopted from criminal cases published by the Supreme People's Court of China. In particular, to address the difficulty in relevance definition, we propose a series of relevance judgment criteria designed by our legal team and corresponding candidate case annotations are conducted by legal experts. Also, we develop a novel query sampling strategy that takes both query difficulty and diversity into consideration. For dataset evaluation, we implemented several existing retrieval models on LeCaRD as baselines. The dataset is now available to the public together with the complete data processing details.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text\n",
            "Authors: Haitian Sun, Tania Bedrax-Weiss, William W. Cohen\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We consider open-domain question answering (QA) where answers are drawn from either a corpus, a knowledge base (KB), or a combination of both of these. We focus on a setting in which a corpus is supplemented with a large but incomplete KB, and on questions that require non-trivial (e.g., “multi-hop”) reasoning. We describe PullNet, an integrated framework for (1) learning what to retrieve and (2) reasoning with this heterogeneous information to find the best answer. PullNet uses an iterative process to construct a question-specific subgraph that contains information relevant to the question. In each iteration, a graph convolutional network (graph CNN) is used to identify subgraph nodes that should be expanded using retrieval (or “pull”) operations on the corpus and/or KB. After the subgraph is complete, another graph CNN is used to extract the answer from the subgraph. This retrieve-and-reason process allows us to answer multi-hop questions using large KBs and corpora. PullNet is weakly supervised, requiring question-answer pairs but not gold inference paths. Experimentally PullNet improves over the prior state-of-the art, and in the setting where a corpus is used with incomplete KB these improvements are often dramatic. PullNet is also often superior to prior systems in a KB-only setting or a text-only setting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features\n",
            "Authors: Min Yang, Dongliang He, M. Fan, Baorong Shi, Xuetong Xue, Fu Li, Errui Ding, Jizhou Huang\n",
            "Year: 2021\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Image Retrieval is a fundamental task of obtaining images similar to the query one from a database. A common image retrieval practice is to firstly retrieve candidate images via similarity search using global image features and then re-rank the candidates by leveraging their local features. Previous learning-based studies mainly focus on either global or local image representation learning to tackle the retrieval task. In this paper, we abandon the two-stage paradigm and seek to design an effective single-stage solution by integrating local and global information inside images into compact image representations. Specifically, we propose a Deep Orthogonal Local and Global (DOLG) information fusion framework for end-to-end image retrieval. It attentively extracts representative local information with multi-atrous convolutions and self-attention at first. Components orthogonal to the global image representation are then extracted from the local information. At last, the orthogonal components are concatenated with the global representation as a complementary, and then aggregation is performed to generate the final representation. The whole framework is end-to-end differentiable and can be trained with image-level labels. Extensive experimental results validate the effectiveness of our solution and show that our model achieves state-of-the-art image retrieval performances on Revisited Oxford and Paris datasets. 1\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase Retrieval via Wirtinger Flow: Theory and Algorithms\n",
            "Authors: E. Candès, Xiaodong Li, M. Soltanolkotabi\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We study the problem of recovering the phase from magnitude measurements; specifically, we wish to reconstruct a complex-valued signal x ∈ ℂn about which we have phaseless samples of the form yr = |〈ar, x〉|2, r = 1, ..., m (knowledge of the phase of these samples would yield a linear system). This paper develops a nonconvex formulation of the phase retrieval problem as well as a concrete solution algorithm. In a nutshell, this algorithm starts with a careful initialization obtained by means of a spectral method, and then refines this initial estimate by iteratively applying novel update rules, which have low computational complexity, much like in a gradient descent scheme. The main contribution is that this algorithm is shown to rigorously allow the exact retrieval of phase information from a nearly minimal number of random measurements. Indeed, the sequence of successive iterates provably converges to the solution at a geometric rate so that the proposed scheme is efficient both in terms of computational and data resources. In theory, a variation on this scheme leads to a near-linear time algorithm for a physically realizable model based on coded diffraction patterns. We illustrate the effectiveness of our methods with various experiments on image data. Underlying our analysis are insights for the analysis of nonconvex optimization schemes that may have implications for computational problems beyond phase retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Image retrieval by addition of spatial information based on histograms of triangular regions\n",
            "Authors: N. Ali, Khalid Bashir Bajwa, Robert Sablatnig, Zahid Mehmood\n",
            "Year: 2016\n",
            "Venue: Computers & electrical engineering\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Open-Retrieval Conversational Question Answering\n",
            "Authors: Chen Qu, Liu Yang, Cen Chen, Minghui Qiu, W. Bruce Croft, Mohit Iyyer\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Conversational search is one of the ultimate goals of information retrieval. Recent research approaches conversational search by simplified settings of response ranking and conversational question answering, where an answer is either selected from a given candidate set or extracted from a given passage. These simplifications neglect the fundamental role of retrieval in conversational search. To address this limitation, we introduce an open-retrieval conversational question answering (ORConvQA) setting, where we learn to retrieve evidence from a large collection before extracting answers, as a further step towards building functional conversational search systems. We create a dataset, OR-QuAC, to facilitate research on ORConvQA. We build an end-to-end system for ORConvQA, featuring a retriever, a reranker, and a reader that are all based on Transformers. Our extensive experiments on OR-QuAC demonstrate that a learnable retriever is crucial for ORConvQA. We further show that our system can make a substantial improvement when we enable history modeling in all system components. Moreover, we show that the reranker component contributes to the model performance by providing a regularization effect. Finally, further in-depth analyses are performed to provide new insights into ORConvQA.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Key-Value Retrieval Networks for Task-Oriented Dialogue\n",
            "Authors: Mihail Eric, Lakshmi. Krishnan, F. Charette, Christopher D. Manning\n",
            "Year: 2017\n",
            "Venue: SIGDIAL Conference\n",
            "Abstract: Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The model is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation. Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Domain-matched Pre-training Tasks for Dense Retrieval\n",
            "Authors: Barlas Oğuz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Wen-tau Yih, Sonal Gupta, Yashar Mehdad\n",
            "Year: 2021\n",
            "Venue: NAACL-HLT\n",
            "Abstract: Pre-training on larger datasets with ever increasing model size is now a proven recipe for increased performance across almost all NLP tasks. A notable exception is information retrieval, where additional pre-training has so far failed to produce convincing results. We show that, with the right pre-training setup, this barrier can be overcome. We demonstrate this by pre-training large bi-encoder models on 1) a recently released set of 65 million synthetically generated questions, and 2) 200 million post-comment pairs from a preexisting dataset of Reddit conversations made available by pushshift.io. We evaluate on a set of information retrieval and dialogue retrieval benchmarks, showing substantial improvements over supervised baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Jointly Optimizing Query Encoder and Product Quantization to Improve Retrieval Performance\n",
            "Authors: Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, M. Zhang, Shaoping Ma\n",
            "Year: 2021\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Recently, Information Retrieval community has witnessed fast-paced advances in Dense Retrieval (DR), which performs first-stage retrieval with embedding-based search. Despite the impressive ranking performance, previous studies usually adopt brute-force search to acquire candidates, which is prohibitive in practical Web search scenarios due to its tremendous memory usage and time cost. To overcome these problems, vector compression methods have been adopted in many practical embedding-based retrieval applications. One of the most popular methods is Product Quantization (PQ). However, although existing vector compression methods including PQ can help improve the efficiency of DR, they incur severely decayed retrieval performance due to the separation between encoding and compression. To tackle this problem, we present JPQ, which stands for Joint optimization of query encoding and Product Quantization. It trains the query encoder and PQ index jointly in an end-to-end manner based on three optimization strategies, namely ranking-oriented loss, PQ centroid optimization, and end-to-end negative sampling. We evaluate JPQ on two publicly available retrieval benchmarks. Experimental results show that JPQ significantly outperforms popular vector compression methods. Compared with previous DR models that use brute-force search, JPQ almost matches the best retrieval performance with 30x compression on index size. The compressed index further brings 10x speedup on CPU and 2x speedup on GPU in query latency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval\n",
            "Authors: Xiao Wang, Craig Macdonald, N. Tonellotto, I. Ounis\n",
            "Year: 2021\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Pseudo-relevance feedback mechanisms, from Rocchio to the relevance models, have shown the usefulness of expanding and reweighting the users' initial queries using information occurring in an initial set of retrieved documents, known as the pseudo-relevant set. Recently, dense retrieval -- through the use of neural contextual language models such as BERT for analysing the documents' and queries' contents and computing their relevance scores -- has shown a promising performance on several information retrieval tasks still relying on the traditional inverted index for identifying documents relevant to a query. Two different dense retrieval families have emerged: the use of single embedded representations for each passage and query (e.g. using BERT's [CLS] token), or via multiple representations (e.g. using an embedding for each token of the query and document). In this work, we conduct the first study into the potential for multiple representation dense retrieval to be enhanced using pseudo-relevance feedback. In particular, based on the pseudo-relevant set of documents identified using a first-pass dense retrieval, we extract representative feedback embeddings (using KMeans clustering) -- while ensuring that these embeddings discriminate among passages (based on IDF) -- which are then added to the query representation. These additional feedback embeddings are shown to both enhance the effectiveness of a reranking as well as an additional dense retrieval operation. Indeed, experiments on the MSMARCO passage ranking dataset show that MAP can be improved by upto 26% on the TREC 2019 query set and 10% on the TREC 2020 query set by the application of our proposed ColBERT-PRF method on a ColBERT dense retrieval approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: B-PROP: Bootstrapped Pre-training with Representative Words Prediction for Ad-hoc Retrieval\n",
            "Authors: Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Yingyan Li, Xueqi Cheng\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Pre-training and fine-tuning have achieved remarkable success in many downstream natural language processing (NLP) tasks. Recently, pre-training methods tailored for information retrieval (IR) have also been explored, and the latest success is the PROP method which has reached new SOTA on a variety of ad-hoc retrieval benchmarks. The basic idea of PROP is to construct therepresentative words prediction (ROP) task for pre-training inspired by the query likelihood model. Despite its exciting performance, the effectiveness of PROP might be bounded by the classical unigram language model adopted in the ROP task construction process. To tackle this problem, we propose a bootstrapped pre-training method (namely B-PROP) based on BERT for ad-hoc retrieval. The key idea is to use the powerful contextual language model BERT to replace the classical unigram language model for the ROP task construction, and re-train BERT itself towards the tailored objective for IR. Specifically, we introduce a novel contrastive method, inspired by the divergence-from-randomness idea, to leverage BERT's self-attention mechanism to sample representative words from the document. By further fine-tuning on downstream ad-hoc retrieval tasks, our method achieves significant improvements over PROP and other baselines, and further pushes forward the SOTA on a variety of ad-hoc retrieval tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term Importance Estimation and Neural Query Rewriting\n",
            "Authors: Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai, Chuan-Ju Wang, Jimmy J. Lin\n",
            "Year: 2021\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: Conversational search plays a vital role in conversational information seeking. As queries in information seeking dialogues are ambiguous for traditional ad hoc information retrieval (IR) systems due to the coreference and omission resolution problems inherent in natural language dialogue, resolving these ambiguities is crucial. In this article, we tackle conversational passage retrieval, an important component of conversational search, by addressing query ambiguities with query reformulation integrated into a multi-stage ad hoc IR system. Specifically, we propose two conversational query reformulation (CQR) methods: (1) term importance estimation and (2) neural query rewriting. For the former, we expand conversational queries using important terms extracted from the conversational context with frequency-based signals. For the latter, we reformulate conversational queries into natural, stand-alone, human-understandable queries with a pretrained sequence-to-sequence model. Detailed analyses of the two CQR methods are provided quantitatively and qualitatively, explaining their advantages, disadvantages, and distinct behaviors. Moreover, to leverage the strengths of both CQR methods, we propose combining their output with reciprocal rank fusion, yielding state-of-the-art retrieval effectiveness, 30% improvement in terms of NDCG@3 compared to the best submission of Text REtrieval Conference (TREC) Conversational Assistant Track (CAsT) 2019.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content Based Lecture Video Retrieval Using Speech and Video Text Information\n",
            "Authors: Haojin Yang, C. Meinel\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Learning Technologies\n",
            "Abstract: In the last decade e-lecturing has become more and more popular. The amount of lecture video data on the World Wide Web (WWW) is growing rapidly. Therefore, a more efficient method for video retrieval in WWW or within large lecture video archives is urgently needed. This paper presents an approach for automated video indexing and video search in large lecture video archives. First of all, we apply automatic video segmentation and key-frame detection to offer a visual guideline for the video content navigation. Subsequently, we extract textual metadata by applying video Optical Character Recognition (OCR) technology on key-frames and Automatic Speech Recognition (ASR) on lecture audio tracks. The OCR and ASR transcript as well as detected slide text line types are adopted for keyword extraction, by which both video- and segment-level keywords are extracted for content-based video browsing and search. The performance and the effectiveness of proposed indexing functionalities is proven by evaluation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Not All Relevance Scores are Equal: Efficient Uncertainty and Calibration Modeling for Deep Retrieval Models\n",
            "Authors: Daniel Cohen, Bhaskar Mitra, Oleg Lesota, Navid Rekabsaz, Carsten Eickhoff\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In any ranking system, the retrieval model outputs a single score for a document based on its belief on how relevant it is to a given search query. While retrieval models have continued to improve with the introduction of increasingly complex architectures, few works have investigated a retrieval model's belief in the score beyond the scope of a single value. We argue that capturing the model's uncertainty with respect to its own scoring of a document is a critical aspect of retrieval that allows for greater use of current models across new document distributions, collections, or even improving effectiveness for down-stream tasks. In this paper, we address this problem via an efficient Bayesian framework for retrieval models which captures the model's belief in the relevance score through a stochastic process while adding only negligible computational overhead. We evaluate this belief via a ranking based calibration metric showing that our approximate Bayesian framework significantly improves a retrieval model's ranking effectiveness through a risk aware reranking as well as its confidence calibration. Lastly, we demonstrate that this additional uncertainty information is actionable and reliable on down-stream tasks represented via cutoff prediction.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots\n",
            "Authors: Jia-Chen Gu, Tianda Li, Quan Liu, Xiao-Dan Zhu, Zhenhua Ling, Zhiming Su, Si Wei\n",
            "Year: 2020\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: In this paper, we study the problem of employing pre-trained language models for multi-turn response selection in retrieval-based chatbots. A new model, named Speaker-Aware BERT (SA-BERT), is proposed in order to make the model aware of the speaker change information, which is an important and intrinsic property of multi-turn dialogues. Furthermore, a speaker-aware disentanglement strategy is proposed to tackle the entangled dialogues. This strategy selects a small number of most important utterances as the filtered context according to the speakers' information in them. Finally, domain adaptation is performed to incorporate the in-domain knowledge into pre-trained language models. Experiments on five public datasets show that our proposed model outperforms the present models on all metrics by large margins and achieves new state-of-the-art performances for multi-turn response selection.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback\n",
            "Authors: HongChien Yu, Chenyan Xiong, Jamie Callan\n",
            "Year: 2021\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Dense retrieval systems conduct first-stage retrieval using embedded representations and simple similarity metrics to match a query to documents. Its effectiveness depends on encoded embeddings to capture the semantics of queries and documents, a challenging task due to the shortness and ambiguity of search queries. This paper proposes ANCE-PRF, a new query encoder that uses pseudo relevance feedback (PRF) to improve query representations for dense retrieval. ANCE-PRF uses a BERT encoder that consumes the query and the top retrieved documents from a dense retrieval model, ANCE, and it learns to produce better query embeddings directly from relevance labels. It also keeps the document index unchanged to reduce overhead. ANCE-PRF significantly outperforms ANCE and other recent dense retrieval systems on several datasets. Analysis shows that the PRF encoder effectively captures the relevant and complementary information from PRF documents, while ignoring the noise with its learned attention mechanism.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TRECVID 2020: A comprehensive campaign for evaluating video retrieval tasks across multiple application domains\n",
            "Authors: G. Awad, A. Butt, Keith Curtis, Jonathan G. Fiscus, A. Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas L. Diduch, Jeffrey Liu, A. Smeaton, Yvette Graham, Gareth J.F. Jones, Wessel Kraaij, G. Quénot\n",
            "Year: 2021\n",
            "Venue: TREC Video Retrieval Evaluation\n",
            "Abstract: The TREC Video Retrieval Evaluation (TRECVID) is a TREC-style video analysis and retrieval evaluation with the goal of promoting progress in research and development of content-based exploitation and retrieval of information from digital video via open, metrics-based evaluation. Over the last twenty years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID has been funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addition, many organizations and individuals worldwide contribute significant time and effort. TRECVID 2020 represented a continuation of four tasks and the addition of two new tasks. In total, 29 teams from various research organizations worldwide completed one or more of the following six tasks: 1. Ad-hoc Video Search (AVS), 2. Instance Search (INS), 3. Disaster Scene Description and Indexing (DSDI), 4. Video to Text Description (VTT), 5. Activities in Extended Video (ActEV), 6. Video Summarization (VSUM). This paper is an introduction to the evaluation framework, tasks, data, and measures used in the evaluation campaign.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Supervised Hashing for Image Retrieval via Image Representation Learning\n",
            "Authors: Rongkai Xia, Yan Pan, Hanjiang Lai, Cong Liu, Shuicheng Yan\n",
            "Year: 2014\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " Hashing is a popular approximate nearest neighbor search approach for large-scale image retrieval. Supervised hashing, which incorporates similarity/dissimilarity information on entity pairs to improve the quality of hashing function learning, has recently received increasing attention. However, in the existing supervised hashing methods for images, an input image is usually encoded by a vector of hand-crafted visual features. Such hand-crafted feature vectors do not necessarily preserve the accurate semantic similarities of images pairs, which may often degrade the performance of hashing function learning. In this paper, we propose a supervised hashing method for image retrieval, in which we automatically learn a good image representation tailored to hashing as well as a set of hash functions. The proposed method has two stages. In the first stage, given the pairwise similarity matrix $S$ over training images, we propose a scalable coordinate descent method to decompose $S$ into a product of $HH^T$ where $H$ is a matrix with each of its rows being the approximate hash code associated to a training image. In the second stage, we propose to simultaneously learn a good feature representation for the input images as well as a set of hash functions, via a deep convolutional network tailored to the learned hash codes in $H$ and optionally the discrete class labels of the images. Extensive empirical evaluations on three benchmark datasets with different kinds of images show that the proposed method has superior performance gains over several state-of-the-art supervised and unsupervised hashing methods.\n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots\n",
            "Authors: Yu Wu, Wei Yu Wu, Ming Zhou, Zhoujun Li\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: We study response selection for multi-turn conversation in retrieval based chatbots. Existing works either ignores relationships among utterances, or misses important information in context when matching a response with a highly abstract context vector finally. We propose a new session based matching model to address both problems. The model first matches a response with each utterance on multiple granularities, and distills important matching information from each pair as a vector with convolution and pooling operations. The vectors are then accumulated in a chronological order through a recurrent neural network (RNN) which models the relationships among the utterances. The final matching score is calculated with the hidden states of the RNN. Empirical study on two public data sets shows that our model can significantly outperform the state-of-the-art methods for response selection in multi-turn conversation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Transfer Hashing for Image Retrieval\n",
            "Authors: Hongjia Zhai, Shenqi Lai, Hanyang Jin, Xueming Qian, Tao Mei\n",
            "Year: 2021\n",
            "Venue: IEEE transactions on circuits and systems for video technology (Print)\n",
            "Abstract: Deep supervised hashing has emerged as an influential solution to large-scale semantic image retrieval problems in computer vision. In the light of recent progress, image label is the common way to define whether two images belong to the same category, but it contains little supervised information. The one-hot label can’t accurately define the similarity of two images, which is important for image retrieval. In this paper, we propose an effective method, Deep Transfer Hashing(DTH) which uses the knowledge from teacher model as the supervised information. Inspired by knowledge distillation for model compression and deep hashing for fast image retrieval, we transfer the knowledge from a complex convolutional neural network(teacher) to a small neural network(student) which is used for fast image retrieval. The distance of the knowledge from teacher model can indicate the similarity of images. By minimizing the hashing codes distribution between the hashing layers of teacher model and student model, we can improve the retrieval performance. And we also evaluate the performance of the compressed model at inference stage. We test our method on widely used datasets CIFAR-10 and NUS-WIDE and we compare our method with other state-of-the-art methods in image retrieval domain. The experimental results show that our method can improve the image retrieval baseline by a large margin and better than other methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\n",
            "Authors: Zihao Wang, Xihui Liu, Hongsheng Li, Lu Sheng, Junjie Yan, Xiaogang Wang, Jing Shao\n",
            "Year: 2019\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Text-image cross-modal retrieval is a challenging task in the field of language and vision. Most previous approaches independently embed images and sentences into a joint embedding space and compare their similarities. However, previous approaches rarely explore the interactions between images and sentences before calculating similarities in the joint space. Intuitively, when matching between images and sentences, human beings would alternatively attend to regions in images and words in sentences, and select the most salient information considering the interaction between both modalities. In this paper, we propose Cross-modal Adaptive Message Passing (CAMP), which adaptively controls the information flow for message passing across modalities. Our approach not only takes comprehensive and fine-grained cross-modal interactions into account, but also properly handles negative pairs and irrelevant information with an adaptive gating scheme. Moreover, instead of conventional joint embedding approaches for text-image matching, we infer the matching score based on the fused features, and propose a hardest negative binary cross-entropy loss for training. Results on COCO and Flickr30k significantly surpass state-of-the-art methods, demonstrating the effectiveness of our approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: XOR QA: Cross-lingual Open-Retrieval Question Answering\n",
            "Authors: Akari Asai, Jungo Kasai, J. Clark, Kenton Lee, Eunsol Choi, Hannaneh Hajishirzi\n",
            "Year: 2020\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Multilingual question answering tasks typically assume that answers exist in the same language as the question. Yet in practice, many languages face both information scarcity—where languages have few reference articles—and information asymmetry—where questions reference concepts from other cultures. This work extends open-retrieval question answering to a cross-lingual setting enabling questions from one language to be answered via answer content from another language. We construct a large-scale dataset built on 40K information-seeking questions across 7 diverse non-English languages that TyDi QA could not find same-language answers for. Based on this dataset, we introduce a task framework, called Cross-lingual Open-Retrieval Question Answering (XOR QA), that consists of three new tasks involving cross-lingual document retrieval from multilingual and English resources. We establish baselines with state-of-the-art machine translation systems and cross-lingual pretrained models. Experimental results suggest that XOR QA is a challenging task that will facilitate the development of novel techniques for multilingual question answering. Our data and code are available at https://nlp.cs.washington.edu/xorqa/.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Hierarchical Cross-Modal Graph Consistency Learning for Video-Text Retrieval\n",
            "Authors: Weike Jin, Zhou Zhao, Pengcheng Zhang, Jieming Zhu, Xiuqiang He, Yueting Zhuang\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Due to the popularity of video contents on the Internet, the information retrieval between videos and texts has attracted broad interest from researchers, which is a challenging cross-modal retrieval task. A common solution is to learn a joint embedding space to measure the cross-modal similarity. However, many existing approaches either pay more attention to textual information, video information, or cross-modal matching methods, but less to all three. We believe that a good video-text retrieval system should take into account all three points, fully exploiting the semantic information of both modalities and considering a comprehensive match. In this paper, we propose a Hierarchical Cross-Modal Graph Consistency Learning Network (HCGC) for video-text retrieval task, which considers multi-level graph consistency for video-text matching. Specifically, we first construct a hierarchical graph representation for the video, which includes three levels from global to local: video, clips and objects. Similarly, the corresponding text graph is constructed according to the semantic relationships among sentence, actions and entities. Then, in order to learn a better match between the video and text graph, we design three types of graph consistency (both direct and indirect): inter-graph parallel consistency, inter-graph cross consistency and intra-graph cross consistency. Extensive experimental results on different video-text datasets demonstrate the effectiveness of our approach on both text-to-video and video-to-text retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluating the Robustness of Retrieval Pipelines with Query Variation Generators\n",
            "Authors: Gustavo Penha, A. Câmara, C. Hauff\n",
            "Year: 2021\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fine-Grained Visual Textual Alignment for Cross-Modal Retrieval Using Transformer Encoders\n",
            "Authors: Nicola Messina, G. Amato, Andrea Esuli, F. Falchi, C. Gennaro, S. Marchand-Maillet\n",
            "Year: 2020\n",
            "Venue: ACM Trans. Multim. Comput. Commun. Appl.\n",
            "Abstract: Despite the evolution of deep-learning-based visual-textual processing systems, precise multi-modal matching remains a challenging task. In this work, we tackle the task of cross-modal retrieval through image-sentence matching based on word-region alignments, using supervision only at the global image-sentence level. Specifically, we present a novel approach called Transformer Encoder Reasoning and Alignment Network (TERAN). TERAN enforces a fine-grained match between the underlying components of images and sentences (i.e., image regions and words, respectively) to preserve the informative richness of both modalities. TERAN obtains state-of-the-art results on the image retrieval task on both MS-COCO and Flickr30k datasets. Moreover, on MS-COCO, it also outperforms current approaches on the sentence retrieval task. Focusing on scalable cross-modal information retrieval, TERAN is designed to keep the visual and textual data pipelines well separated. Cross-attention links invalidate any chance to separately extract visual and textual features needed for the online search and the offline indexing steps in large-scale retrieval systems. In this respect, TERAN merges the information from the two domains only during the final alignment phase, immediately before the loss computation. We argue that the fine-grained alignments produced by TERAN pave the way toward the research for effective and efficient methods for large-scale cross-modal information retrieval. We compare the effectiveness of our approach against relevant state-of-the-art methods. On the MS-COCO 1K test set, we obtain an improvement of 5.7% and 3.5% respectively on the image and the sentence retrieval tasks on the Recall@1 metric. The code used for the experiments is publicly available on GitHub at https://github.com/mesnico/TERAN.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep semantic ranking based hashing for multi-label image retrieval\n",
            "Authors: F. Zhao, Yongzhen Huang, Liang Wang, T. Tan\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: With the rapid growth of web images, hashing has received increasing interests in large scale image retrieval. Research efforts have been devoted to learning compact binary codes that preserve semantic similarity based on labels. However, most of these hashing methods are designed to handle simple binary similarity. The complex multi-level semantic structure of images associated with multiple labels have not yet been well explored. Here we propose a deep semantic ranking based method for learning hash functions that preserve multilevel semantic similarity between multi-label images. In our approach, deep convolutional neural network is incorporated into hash functions to jointly learn feature representations and mappings from them to hash codes, which avoids the limitation of semantic representation power of hand-crafted features. Meanwhile, a ranking list that encodes the multilevel similarity information is employed to guide the learning of such deep hash functions. An effective scheme based on surrogate loss is used to solve the intractable optimization problem of nonsmooth and multivariate ranking measures involved in the learning procedure. Experimental results show the superiority of our proposed approach over several state-of-the-art hashing methods in term of ranking evaluation metrics when tested on multi-label image datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval\n",
            "Authors: O. Khattab, Christopher Potts, M. Zaharia\n",
            "Year: 2021\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Multi-hop reasoning (i.e., reasoning across two or more documents) is a key ingredient for NLP models that leverage large corpora to exhibit broad knowledge. To retrieve evidence passages, multi-hop models must contend with a fast-growing search space across the hops, represent complex queries that combine multiple information needs, and resolve ambiguity about the best order in which to hop between training passages. We tackle these problems via Baleen, a system that improves the accuracy of multi-hop retrieval while learning robustly from weak training signals in the many-hop setting. To tame the search space, we propose condensed retrieval, a pipeline that summarizes the retrieved passages after each hop into a single compact context. To model complex queries, we introduce a focused late interaction retriever that allows different parts of the same query representation to match disparate relevant passages. Lastly, to infer the hopping dependencies among unordered training passages, we devise latent hop ordering, a weak-supervision strategy in which the trained retriever itself selects the sequence of hops. We evaluate Baleen on retrieval for two-hop question answering and many-hop claim verification, establishing state-of-the-art performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: More Robust Dense Retrieval with Contrastive Dual Learning\n",
            "Authors: Yizhi Li, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu\n",
            "Year: 2021\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Dense retrieval conducts text retrieval in the embedding space and has shown many advantages compared to sparse retrieval. Existing dense retrievers optimize representations of queries and documents with contrastive training and map them to the embedding space. The embedding space is optimized by aligning the matched query-document pairs and pushing the negative documents away from the query. However, in such training paradigm, the queries are only optimized to align to the documents and are coarsely positioned, leading to an anisotropic query embedding space. In this paper, we analyze the embedding space distributions and propose an effective training paradigm, Contrastive Dual Learning for Approximate Nearest Neighbor (DANCE) to learn fine-grained query representations for dense retrieval. DANCE incorporates an additional dual training object of query retrieval, inspired by the classic information retrieval training axiom, query likelihood. With contrastive learning, the dual training object of DANCE learns more tailored representations for queries and documents to keep the embedding space smooth and uniform, thriving on the ranking performance of DANCE on the MS MARCO document retrieval task. Different from ANCE that only optimized with the document retrieval task, DANCE concentrates the query embeddings closer to document representations while making the document distribution more discriminative. Such concentrated query embedding distribution assigns more uniform negative sampling probabilities to queries and helps to sufficiently optimize query representations in the query retrieval task. Our codes are released at https://github.com/thunlp/DANCE.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DoSSIER@COLIEE 2021: Leveraging dense retrieval and summarization-based re-ranking for case law retrieval\n",
            "Authors: Sophia Althammer, Arian Askari, S. Verberne, A. Hanbury\n",
            "Year: 2021\n",
            "Venue: arXiv.org\n",
            "Abstract: In this paper, we present our approaches for the case law retrieval and the legal case entailment task in the Competition on Legal Information Extraction/Entailment (COLIEE) 2021. As first stage retrieval methods combined with neural re-ranking methods using contextualized language models like BERT achieved great performance improvements for information retrieval in the web and news domain, we evaluate these methods for the legal domain. A distinct characteristic of legal case retrieval is that the query case and case description in the corpus tend to be long documents and therefore exceed the input length of BERT. We address this challenge by combining lexical and dense retrieval methods on the paragraph-level of the cases for the first stage retrieval. Here we demonstrate that the retrieval on the paragraph-level outperforms the retrieval on the document-level. Furthermore the experiments suggest that dense retrieval methods outperform lexical retrieval. For re-ranking we address the problem of long documents by summarizing the cases and fine-tuning a BERT-based re-ranker with the summaries. Overall, our best results were obtained with a combination of BM25 and dense passage retrieval using domain-specific embeddings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Passage Retrieval for Outside-Knowledge Visual Question Answering\n",
            "Authors: Chen Qu, Hamed Zamani, Liu Yang, W. Bruce Croft, E. Learned-Miller\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In this work, we address multi-modal information needs that contain text questions and images by focusing on passage retrieval for outside-knowledge visual question answering. This task requires access to outside knowledge, which in our case we define to be a large unstructured passage collection. We first conduct sparse retrieval with BM25 and study expanding the question with object names and image captions. We verify that visual clues play an important role and captions tend to be more informative than object names in sparse retrieval. We then construct a dual-encoder dense retriever, with the query encoder being LXMERT, a multi-modal pre-trained transformer. We further show that dense retrieval significantly outperforms sparse retrieval that uses object expansion. Moreover, dense retrieval matches the performance of sparse retrieval that leverages human-generated captions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Natural Language Object Retrieval\n",
            "Authors: Ronghang Hu, Huazhe Xu, Marcus Rohrbach, Jiashi Feng, Kate Saenko, Trevor Darrell\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: In this paper, we address the task of natural language object retrieval, to localize a target object within a given image based on a natural language query of the object. Natural language object retrieval differs from text-based image retrieval task as it involves spatial information about objects within the scene and global scene context. To address this issue, we propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate boxes for object retrieval, integrating spatial configurations and global scene-level contextual information into the network. Our model processes query text, local image descriptors, spatial configurations and global context features through a recurrent network, outputs the probability of the query text conditioned on each candidate box as a score for the box, and can transfer visual-linguistic knowledge from image captioning domain to our task. Experimental results demonstrate that our method effectively utilizes both local and global information, outperforming previous baseline methods significantly on different datasets and scenarios, and can exploit large scale vision and language datasets for knowledge transfer.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Conversational Fashion Image Retrieval via Multiturn Natural Language Feedback\n",
            "Authors: Yifei Yuan, W. Lam\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We study the task of conversational fashion image retrieval via multiturn natural language feedback. Most previous studies are based on single-turn settings. Existing models on multiturn conversational fashion image retrieval have limitations, such as employing traditional models, and leading to ineffective performance. We propose a novel framework that can effectively handle conversational fashion image retrieval with multiturn natural language feedback texts. One characteristic of the framework is that it searches for candidate images based on exploitation of the encoded reference image and feedback text information together with the conversation history. Furthermore, the image fashion attribute information is leveraged via a mutual attention strategy. Since there is no existing fashion dataset suitable for the multiturn setting of our task, we derive a large-scale multiturn fashion dataset via additional manual annotation efforts on an existing single-turn dataset. The experiments show that our proposed model significantly outperforms existing state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Tip of the Tongue Known-Item Retrieval: A Case Study in Movie Identification\n",
            "Authors: Jaime Arguello, Adam Ferguson, Emery Fine, Bhaskar Mitra, Hamed Zamani, Fernando Diaz\n",
            "Year: 2021\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: While current information retrieval systems are effective for known-item retrieval where the searcher provides a precise name or identifier for the item being sought, systems tend to be much less effective for cases where the searcher is unable to express a precise name or identifier. We refer to this as tip of the tongue (TOT) known-item retrieval, named after the cognitive state of not being able to retrieve an item from memory. Using movie search as a case study, we explore the characteristics of questions posed by searchers in TOT states in a community question answering website. We analyze how searchers express their information needs during TOT states in the movie domain. Specifically, what information do searchers remember about the item being sought and how do they convey this information? Our results suggest that searchers use a combination of information about: (1) the content of the item sought, (2) the context in which they previously engaged with the item, and (3) previous attempts to find the item using other resources (e.g., search engines). Additionally, searchers convey information by sometimes expressing uncertainty (i.e., hedging), opinions, emotions, and by performing relative (vs. absolute) comparisons with attributes of the item. As a result of our analysis, we believe that searchers in TOT states may require specialized query understanding methods or document representations. Finally, our preliminary retrieval experiments show the impact of each information type presented in information requests on retrieval performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Privacy-Preserving and Copy-Deterrence Content-Based Image Retrieval Scheme in Cloud Computing\n",
            "Authors: Zhihua Xia, Xinhui Wang, Liangao Zhang, Zhan Qin, Xingming Sun, K. Ren\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: With the increasing importance of images in people's daily life, content-based image retrieval (CBIR) has been widely studied. Compared with text documents, images consume much more storage space. Hence, its maintenance is considered to be a typical example for cloud storage outsourcing. For privacy-preserving purposes, sensitive images, such as medical and personal images, need to be encrypted before outsourcing, which makes the CBIR technologies in plaintext domain to be unusable. In this paper, we propose a scheme that supports CBIR over encrypted images without leaking the sensitive information to the cloud server. First, feature vectors are extracted to represent the corresponding images. After that, the pre-filter tables are constructed by locality-sensitive hashing to increase search efficiency. Moreover, the feature vectors are protected by the secure kNN algorithm, and image pixels are encrypted by a standard stream cipher. In addition, considering the case that the authorized query users may illegally copy and distribute the retrieved images to someone unauthorized, we propose a watermark-based protocol to deter such illegal distributions. In our watermark-based protocol, a unique watermark is directly embedded into the encrypted images by the cloud server before images are sent to the query user. Hence, when image copy is found, the unlawful query user who distributed the image can be traced by the watermark extraction. The security analysis and the experiments show the security and efficiency of the proposed scheme.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval\n",
            "Authors: Chao Li, Cheng Deng, Ning Li, W. Liu, Xinbo Gao, D. Tao\n",
            "Year: 2018\n",
            "Venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: Thanks to the success of deep learning, cross-modal retrieval has made significant progress recently. However, there still remains a crucial bottleneck: how to bridge the modality gap to further enhance the retrieval accuracy. In this paper, we propose a self-supervised adversarial hashing (SSAH) approach, which lies among the early attempts to incorporate adversarial learning into cross-modal hashing in a self-supervised fashion. The primary contribution of this work is that two adversarial networks are leveraged to maximize the semantic correlation and consistency of the representations between different modalities. In addition, we harness a self-supervised semantic network to discover high-level semantic information in the form of multi-label annotations. Such information guides the feature learning process and preserves the modality relationships in both the common semantic space and the Hamming space. Extensive experiments carried out on three benchmark datasets validate that the proposed SSAH surpasses the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effects of load and maintenance duration on the time course of information encoding and retrieval in working memory: from perceptual analysis to post-categorization processes\n",
            "Authors: D. Pinal, M. Zurrón, F. Díaz\n",
            "Year: 2014\n",
            "Venue: Frontiers in Human Neuroscience\n",
            "Abstract: Working memory (WM) involves three cognitive events: information encoding, maintenance, and retrieval; these are supported by brain activity in a network of frontal, parietal and temporal regions. Manipulation of WM load and duration of the maintenance period can modulate this activity. Although such modulations have been widely studied using the event-related potentials (ERP) technique, a precise description of the time course of brain activity during encoding and retrieval is still required. Here, we used this technique and principal component analysis to assess the time course of brain activity during encoding and retrieval in a delayed match to sample task. We also investigated the effects of memory load and duration of the maintenance period on ERP activity. Brain activity was similar during information encoding and retrieval and comprised six temporal factors, which closely matched the latency and scalp distribution of some ERP components: P1, N1, P2, N2, P300, and a slow wave. Changes in memory load modulated task performance and yielded variations in frontal lobe activation. Moreover, the P300 amplitude was smaller in the high than in the low load condition during encoding and retrieval. Conversely, the slow wave amplitude was higher in the high than in the low load condition during encoding, and the same was true for the N2 amplitude during retrieval. Thus, during encoding, memory load appears to modulate the processing resources for context updating and post-categorization processes, and during retrieval it modulates resources for stimulus classification and context updating. Besides, despite the lack of differences in task performance related to duration of the maintenance period, larger N2 amplitude and stronger activation of the left temporal lobe after long than after short maintenance periods were found during information retrieval. Thus, results regarding the duration of maintenance period were complex, and future work is required to test the time-based decay theory predictions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN\n",
            "Authors: Shangqing Liu, Yu Chen, Xiaofei Xie, J. Siow, Yang Liu\n",
            "Year: 2020\n",
            "Venue: \n",
            "Abstract: Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural ranking models for document retrieval\n",
            "Authors: M. Trabelsi, Zhiyu Chen, Brian D. Davison, J. Heflin\n",
            "Year: 2021\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: When textual and visual information join forces for multimedia retrieval\n",
            "Authors: Bahjat Safadi, Mathilde Sahuguet, B. Huet\n",
            "Year: 2014\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Currently, popular search engines retrieve documents on the basis of text information. However, integrating the visual information with the text-based search for video and image retrieval is still a hot research topic. In this paper, we propose and evaluate a video search framework based on using visual information to enrich the classic text-based search for video retrieval. The framework extends conventional text-based search by fusing together text and visual scores, obtained from video subtitles (or automatic speech recognition) and visual concept detectors respectively. We attempt to overcome the so called problem of semantic gap by automatically mapping query text to semantic concepts. With the proposed framework, we endeavor to show experimentally, on a set of real world scenarios, that visual cues can effectively contribute to the quality improvement of video retrieval. Experimental results show that mapping text-based queries to visual concepts improves the performance of the search system. Moreover, when appropriately selecting the relevant visual concepts for a query, a very significant improvement of the system's performance is achieved.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PROP: Pre-training with Representative Words Prediction for Ad-hoc Retrieval\n",
            "Authors: Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Xiang Ji, Xueqi Cheng\n",
            "Year: 2020\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: Recently pre-trained language representation models such as BERT have shown great success when fine-tuned on downstream tasks including information retrieval (IR). However, pre-training objectives tailored for ad-hoc retrieval have not been well explored. In this paper, we propose Pre-training with Representative wOrds Prediction (PROP) for ad-hoc retrieval. PROP is inspired by the classical statistical language model for IR, specifically the query likelihood model, which assumes that the query is generated as the piece of text representative of the \"ideal\" document. Based on this idea, we construct the representative words prediction (ROP) task for pre-training. Given an input document, we sample a pair of word sets according to the document language model, where the set with higher likelihood is deemed as more representative of the document. We then pre-train the Transformer model to predict the pairwise preference between the two word sets, jointly with the Masked Language Model (MLM) objective. By further fine-tuning on a variety of representative downstream ad-hoc retrieval tasks, PROP achieves significant improvements over baselines without pre-training or with other pre-training methods. We also show that PROP can achieve exciting performance under both the zero- and low-resource IR settings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval\n",
            "Authors: Wenhao Lu, Jian Jiao, Ruofei Zhang\n",
            "Year: 2020\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Pre-trained language models have achieved great success in a wide variety of natural language processing (NLP) tasks, while the superior performance comes with high demand in computational resources, which hinders the application in low-latency information retrieval (IR) systems. To address the problem, we present TwinBERT model, which has two improvements: 1) represent query and document separately using twin-structured encoders and 2) each encoder is a highly compressed BERT-like model with less than one third of the parameters. The former allows document embeddings to be pre-computed offline and cached in memory, which is different from BERT, where the two input sentences are concatenated and encoded together. The change saves large amount of computation time, however, it is still not sufficient for real-time retrieval considering the complexity of BERT model itself. To further reduce computational cost, a compressed multi-layer transformer encoder is proposed with special training strategies as a substitution of the original complex BERT encoder. Lastly, two versions of TwinBERT are developed to combine the query and keyword embeddings for retrieval and relevance tasks correspondingly. Both of them have met the real-time latency requirement and achieve close or on-par performance to BERT-Base model. The models were trained following the teacher-student framework and evaluated with data from one of the major search engines. Experimental results showed that the inference time was significantly reduced and was for the first time controlled within 20ms on CPUs while at the same time the performance gain from fine-tuned BERT-Base model was mostly retained. Integration of the models in production systems also demonstrated remarkable improvements on relevance metrics with negligible influence on latency. The models were released in 2019 with significant production impacts.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Local Self-Attention over Long Text for Efficient Document Retrieval\n",
            "Authors: Sebastian Hofstätter, Hamed Zamani, Bhaskar Mitra, Nick Craswell, A. Hanbury\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Neural networks, particularly Transformer-based architectures, have achieved significant performance improvements on several retrieval benchmarks. When the items being retrieved are documents, the time and memory cost of employing Transformers over a full sequence of document terms can be prohibitive. A popular strategy involves considering only the first n terms of the document. This can, however, result in a biased system that under retrieves longer documents. In this work, we propose a local self-attention which considers a moving window over the document terms and for each term attends only to other terms in the same window. This local attention incurs a fraction of the compute and memory cost of attention over the whole document. The windowed approach also leads to more compact packing of padded documents in minibatches resulting in additional savings. We also employ a learned saturation function and a two-staged pooling strategy to identify relevant regions of the document. The Transformer-Kernel pooling model with these changes can efficiently elicit relevance information from documents with thousands of tokens. We benchmark our proposed modifications on the document ranking task from the TREC 2019 Deep Learning track and observe significant improvements in retrieval quality as well as increased retrieval of longer documents at moderate increase in compute and memory costs.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Attentive Moment Retrieval in Videos\n",
            "Authors: Meng Liu, Xiang Wang, Liqiang Nie, Xiangnan He, Baoquan Chen, Tat-Seng Chua\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In the past few years, language-based video retrieval has attracted a lot of attention. However, as a natural extension, localizing the specific video moments within a video given a description query is seldom explored. Although these two tasks look similar, the latter is more challenging due to two main reasons: 1) The former task only needs to judge whether the query occurs in a video and returns an entire video, but the latter is expected to judge which moment within a video matches the query and accurately returns the start and end points of the moment. Due to the fact that different moments in a video have varying durations and diverse spatial-temporal characteristics, uncovering the underlying moments is highly challenging. 2) As for the key component of relevance estimation, the former usually embeds a video and the query into a common space to compute the relevance score. However, the later task concerns moment localization where not only the features of a specific moment matter, but the context information of the moment also contributes a lot. For example, the query may contain temporal constraint words, such as \"first'', therefore need temporal context to properly comprehend them. To address these issues, we develop an Attentive Cross-Modal Retrieval Network. In particular, we design a memory attention mechanism to emphasize the visual features mentioned in the query and simultaneously incorporate their context. In the light of this, we obtain the augmented moment representation. Meanwhile, a cross-modal fusion sub-network learns both the intra-modality and inter-modality dynamics, which can enhance the learning of moment-query representation. We evaluate our method on two datasets: DiDeMo and TACoS. Extensive experiments show the effectiveness of our model as compared to the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SOLAR: Second-Order Loss and Attention for Image Retrieval\n",
            "Authors: Tony Ng, Vassileios Balntas, Yurun Tian, K. Mikolajczyk\n",
            "Year: 2020\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information in 2023\n",
            "Authors: E. Sayers, Evan E. Bolton, J. R. Brister, Kathi Canese, Jessica Chan, Donald C. Comeau, C. Farrell, M. Feldgarden, Anna M. Fine, Kathryn Funk, Eneida L. Hatcher, S. Kannan, Christopher Kelly, Sunghwan Kim, W. Klimke, M. Landrum, S. Lathrop, Zhiyong Lu, Thomas L. Madden, A. Malheiro, Aron Marchler-Bauer, Terence D. Murphy, Lon Phan, S. Pujar, S. Rangwala, Valerie A. Schneider, Tony Tse, Jiyao Wang, Jian Ye, B. Trawick, K. Pruitt, S. Sherry\n",
            "Year: 2022\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides online information resources for biology, including the GenBank® nucleic acid sequence database and the PubMed® database of citations and abstracts published in life science journals. NCBI provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for most of these databases. New resources include the Comparative Genome Resource (CGR) and the BLAST ClusteredNR database. Resources receiving significant updates in the past year include PubMed, PMC, Bookshelf, IgBLAST, GDV, RefSeq, NCBI Virus, GenBank type assemblies, iCn3D, ClinVar, GTR, dbGaP, ALFA, ClinicalTrials.gov, Pathogen Detection, antimicrobial resistance resources, and PubChem. These resources can be accessed through the NCBI home page at https://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Complementing Lexical Retrieval with Semantic Residual Embedding\n",
            "Authors: Luyu Gao, Zhuyun Dai, Zhenhua Fan, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: arXiv.org\n",
            "Abstract: Information retrieval traditionally has relied on lexical matching signals, but lexical matching cannot handle vocabulary mismatch or topic-level matching. Neural embedding based retrieval models can match queries and documents in a latent semantic space, but they lose token-level matching information that is critical to IR. This paper presents CLEAR, a deep retrieval model that seeks to complement lexical retrieval with semantic embedding retrieval. Importantly, CLEAR uses a residual-based embedding learning framework, which focuses the embedding on the deep language structures and semantics that the lexical retrieval fails to capture. Empirical evaluation demonstrates the advantages of CLEAR over classic bag-of-words retrieval models, recent BERT-enhanced lexical retrieval models, as well as a BERT-based embedding retrieval. A full-collection retrieval with CLEAR can be as effective as a BERT-based reranking system, substantially narrowing the gap between full-collection retrieval and cost-prohibitive reranking systems\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancing Sketch-Based Image Retrieval by CNN Semantic Re-ranking\n",
            "Authors: Luo Wang, Xueming Qian, Yuting Zhang, Jialie Shen, Xiaochun Cao\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Cybernetics\n",
            "Abstract: This paper introduces a convolutional neural network (CNN) semantic re-ranking system to enhance the performance of sketch-based image retrieval (SBIR). Distinguished from the existing approaches, the proposed system can leverage category information brought by CNNs to support effective similarity measurement between the images. To achieve effective classification of query sketches and high-quality initial retrieval results, one CNN model is trained for classification of sketches, another for that of natural images. Through training dual CNN models, the semantic information of both the sketches and natural images is captured by deep learning. In order to measure the category similarity between images, a category similarity measurement method is proposed. Category information is then used for re-ranking. Re-ranking operation first infers the retrieval category of the query sketch and then uses the category similarity measurement to measure the category similarity between the query sketch and each initial retrieval result. Finally, the initial retrieval results are re-ranked. The experiments on different types of SBIR datasets demonstrate the effectiveness of the proposed re-ranking method. Comparisons with other re-ranking algorithms are also given to show the proposed method’s superiority. Further, compared to the baseline systems, the proposed re-ranking approach achieves significantly higher precision in the top ten different SBIR methods and datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Revealing the Importance of Semantic Retrieval for Machine Reading at Scale\n",
            "Authors: Yixin Nie, Songhe Wang, Mohit Bansal\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Machine Reading at Scale (MRS) is a challenging task in which a system is given an input query and is asked to produce a precise output by “reading” information from a large knowledge base. The task has gained popularity with its natural combination of information retrieval (IR) and machine comprehension (MC). Advancements in representation learning have led to separated progress in both IR and MC; however, very few studies have examined the relationship and combined design of retrieval and comprehension at different levels of granularity, for development of MRS systems. In this work, we give general guidelines on system design for MRS by proposing a simple yet effective pipeline system with special consideration on hierarchical semantic retrieval at both paragraph and sentence level, and their potential effects on the downstream task. The system is evaluated on both fact verification and open-domain multihop QA, achieving state-of-the-art results on the leaderboard test sets of both FEVER and HOTPOTQA. To further demonstrate the importance of semantic retrieval, we present ablation and analysis studies to quantify the contribution of neural retrieval modules at both paragraph-level and sentence-level, and illustrate that intermediate semantic retrieval modules are vital for not only effectively filtering upstream information and thus saving downstream computation, but also for shaping upstream data distribution and providing better data for downstream modeling.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Wafer Map Defect Pattern Classification and Image Retrieval Using Convolutional Neural Network\n",
            "Authors: Takeshi Nakazawa, Deepak V. Kulkarni\n",
            "Year: 2018\n",
            "Venue: IEEE transactions on semiconductor manufacturing\n",
            "Abstract: Wafer maps provide important information for engineers in identifying root causes of die failures during semiconductor manufacturing processes. We present a method for wafer map defect pattern classification and image retrieval using convolutional neural networks (CNNs). Twenty eight thousand six hundred synthetic wafer maps for 22 defect classes are generated theoretically and used for CNN training, validation, and testing. The overall classification accuracy for the 6600 test dataset is 98.2%. One thousand one hundred and ninety one real wafer maps are used for CNN performance evaluation for the same model trained by synthetic wafer maps. We demonstrate that by using only synthetic data for network training, real wafer maps can be classified with high accuracy. For image retrieval, a binary code for each wafer map is generated from an output of a fully connected layer with sigmoid activation. A retrieval error rate is 0.36% for the test dataset and 3.7% for the real wafers. Image retrieval takes 0.13 s per wafer map from the 18 000 wafer map library.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase Retrieval Under a Generative Prior\n",
            "Authors: Paul Hand, Oscar Leong, V. Voroninski\n",
            "Year: 2018\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: The phase retrieval problem asks to recover a natural signal $y_0 \\in \\mathbb{R}^n$ from $m$ quadratic observations, where $m$ is to be minimized. As is common in many imaging problems, natural signals are considered sparse with respect to a known basis, and the generic sparsity prior is enforced via $\\ell_1$ regularization. While successful in the realm of linear inverse problems, such $\\ell_1$ methods have encountered possibly fundamental limitations, as no computationally efficient algorithm for phase retrieval of a $k$-sparse signal has been proven to succeed with fewer than $O(k^2\\log n)$ generic measurements, exceeding the theoretical optimum of $O(k \\log n)$. In this paper, we propose a novel framework for phase retrieval by 1) modeling natural signals as being in the range of a deep generative neural network $G : \\mathbb{R}^k \\rightarrow \\mathbb{R}^n$ and 2) enforcing this prior directly by optimizing an empirical risk objective over the domain of the generator. Our formulation has provably favorable global geometry for gradient methods, as soon as $m = O(kd^2\\log n)$, where $d$ is the depth of the network. Specifically, when suitable deterministic conditions on the generator and measurement matrix are met, we construct a descent direction for any point outside of a small neighborhood around the unique global minimizer and its negative multiple, and show that such conditions hold with high probability under Gaussian ensembles of multilayer fully-connected generator networks and measurement matrices. This formulation for structured phase retrieval thus has two advantages over sparsity based methods: 1) deep generative priors can more tightly represent natural signals and 2) information theoretically optimal sample complexity. We corroborate these results with experiments showing that exploiting generative models in phase retrieval tasks outperforms sparse phase retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the national center for biotechnology information\n",
            "Authors: E. Sayers, Evan E. Bolton, J. R. Brister, Kathi Canese, Jessica Chan, Donald C. Comeau, Ryan Connor, Kathryn Funk, Christopher Kelly, Sunghwan Kim, T. Madej, Aron Marchler-Bauer, C. Lanczycki, S. Lathrop, Zhiyong Lu, F. Thibaud-Nissen, Terence D. Murphy, Lon Phan, Yuri Skripchenko, Tony Tse, Jiyao Wang, Rebecca J Williams, B. Trawick, K. Pruitt, S. Sherry\n",
            "Year: 2021\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) produces a variety of online information resources for biology, including the GenBank® nucleic acid sequence database and the PubMed® database of citations and abstracts published in life science journals. NCBI provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the most of these databases. Resources receiving significant updates in the past year include PubMed, PMC, Bookshelf, RefSeq, SRA, Virus, dbSNP, dbVar, ClinicalTrials.gov, MMDB, iCn3D and PubChem. These resources can be accessed through the NCBI home page at https://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analysis of CYGNSS Data for Soil Moisture Retrieval\n",
            "Authors: M. Clarizia, N. Pierdicca, Fabiano Costantini, N. Floury\n",
            "Year: 2019\n",
            "Venue: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n",
            "Abstract: Data from the CYGNSS mission, originally conceived to monitor tropical cyclones, are being investigated here for land applications as well. In this paper, a methodology for soil moisture (SM) retrieval from CYGNSS data is presented. The approach derives Level 3 gridded daily SM estimations, over the latitudinal band covered by CYGNSS, at a resolution of 36 km × 36 km, using the CYGNSS reflectivity over land, coupled with ancillary vegetation and roughness information from the SMAP mission. The results are compared globally with SM measurements from SMAP, which are assumed to be ground truth, showing a good agreement, and a global root-mean-square difference of 0.07 cm3/cm3. A more extensive comparison is performed over two test regions—Texas in the United States and New South Wales in Australia—where reference data from SMAP are complemented with measurements from the SMOS mission. The results over both regions are generally consistent with the global results, and a good agreement is observed between CYGNSS and reference SM measurements from SMAP and SMOS. The study demonstrates that SM can be successfully retrieved from the CYGNSS mission on a global scale and using ancillary information about the overlying vegetation and the characteristics of the soil. The results open up further future perspectives for global, high-resolution SM products from spaceborne Global Navigation Satellite System-Reflectometry data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-Based Brain Tumor Retrieval for MR Images Using Transfer Learning\n",
            "Authors: Zar Nawab Khan Swati, Qinghua Zhao, Muhammad Kabir, Farman Ali, Zakir Ali, Saeed Ahmed, Jianfeng Lu\n",
            "Year: 2019\n",
            "Venue: IEEE Access\n",
            "Abstract: This paper presents an automatic content-based image retrieval (CBIR) system for brain tumors on T1-weighted contrast-enhanced magnetic resonance images (CE-MRI). The key challenge in CBIR systems for MR images is the semantic gap between the low-level visual information captured by the MRI machine and the high-level information perceived by the human evaluator. The traditional feature extraction methods focus only on low-level or high-level features and use some handcrafted features to reduce this gap. It is necessary to design a feature extraction framework to reduce this gap without using handcrafted features by encoding/combining low-level and high-level features. Deep learning is very powerful for feature representation that can depict low-level and high-level information completely and embed the phase of feature extraction in self-learning. Therefore, we propose a deep convolutional neural network VGG19-based novel feature extraction framework and apply closed-form metric learning to measure the similarity between the query image and database images. Furthermore, we adopt transfer learning and propose a block-wise fine-tuning strategy to enhance the retrieval performance. The extensive experiments are performed on a publicly available CE-MRI dataset that consists of three types of brain tumors (i.e., glioma, meningioma, and pituitary tumor) collected from 233 patients with a total of 3064 images across the axial, coronal, and sagittal views. Our method is more generic, as we do not use any handcrafted features; it requires minimal preprocessing, tested as robust on fivefold cross-validation, can achieve a fivefold mean average precision of 96.13%, and outperforms the state-of-the-art CBIR systems on the CE-MRI dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Multi-View Representation With LSTM for 3-D Shape Recognition and Retrieval\n",
            "Authors: Chao Ma, Yulan Guo, Jungang Yang, W. An\n",
            "Year: 2019\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Shape representation for 3-D models is an important topic in computer vision, multimedia analysis, and computer graphics. Recent multiview-based methods demonstrate promising performance for 3-D shape recognition and retrieval. However, most multiview-based methods ignore the correlations of multiple views or suffer from high computional cost. In this paper, we propose a novel multiview-based network architecture for 3-D shape recognition and retrieval. Our network combines convolutional neural networks (CNNs) with long short-term memory (LSTM) to exploit the correlative information from multiple views. Well-pretrained CNNs with residual connections are first used to extract a low-level feature of each view image rendered from a 3-D shape. Then, a LSTM and a sequence voting layer are employed to aggregate these features into a shape descriptor. The highway network and a three-step training strategy are also adopted to boost the optimization of the deep network. Experimental results on two public datasets demonstrate that the proposed method achieves promising performance for 3-D shape recognition and the state-of-the-art performance for the 3-D shape retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval\n",
            "Authors: Anjan Dutta, Zeynep Akata\n",
            "Year: 2019\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Zero-shot sketch-based image retrieval (SBIR) is an emerging task in computer vision, allowing to retrieve natural images relevant to sketch queries that might not been seen in the training phase. Existing works either require aligned sketch-image pairs or inefficient memory fusion layer for mapping the visual information to a semantic space. In this work, we propose a semantically aligned paired cycle-consistent generative (SEM-PCYC) model for zero-shot SBIR, where each branch maps the visual information to a common semantic space via an adversarial training. Each of these branches maintains a cycle consistency that only requires supervision at category levels, and avoids the need of highly-priced aligned sketch-image pairs. A classification criteria on the generators' outputs ensures the visual to semantic space mapping to be discriminating. Furthermore, we propose to combine textual and hierarchical side information via a feature selection auto-encoder that selects discriminating side information within a same end-to-end model. Our results demonstrate a significant boost in zero-shot SBIR performance over the state-of-the-art on the challenging Sketchy and TU-Berlin datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Respond with Deep Neural Networks for Retrieval-Based Human-Computer Conversation System\n",
            "Authors: Rui Yan, Yiping Song, Hua Wu\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: To establish an automatic conversation system between humans and computers is regarded as one of the most hardcore problems in computer science, which involves interdisciplinary techniques in information retrieval, natural language processing, artificial intelligence, etc. The challenges lie in how to respond so as to maintain a relevant and continuous conversation with humans. Along with the prosperity of Web 2.0, we are now able to collect extremely massive conversational data, which are publicly available. It casts a great opportunity to launch automatic conversation systems. Owing to the diversity of Web resources, a retrieval-based conversation system will be able to find at least some responses from the massive repository for any user inputs. Given a human issued message, i.e., query, our system would provide a reply after adequate training and learning of how to respond. In this paper, we propose a retrieval-based conversation system with the deep learning-to-respond schema through a deep neural network framework driven by web data. The proposed model is general and unified for different conversation scenarios in open domain. We incorporate the impact of multiple data inputs, and formulate various features and factors with optimization into the deep learning framework. In the experiments, we investigate the effectiveness of the proposed deep neural network structures with better combinations of all different evidence. We demonstrate significant performance improvement against a series of standard and state-of-art baselines in terms of p@1, MAP, nDCG, and MRR for conversational purposes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-based image retrieval using high-dimensional information geometry\n",
            "Authors: Wenming Cao, Ning Liu, Qicong Kong, H. Feng\n",
            "Year: 2014\n",
            "Venue: Science China Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\n",
            "Authors: Zhijie Lin, Zhou Zhao, Zhu Zhang, Qi Wang, Huasheng Liu\n",
            "Year: 2019\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: Video moment retrieval is to search the moment that is most relevant to the given natural language query. Existing methods are mostly trained in a fully-supervised setting, which requires the full annotations of temporal boundary for each query. However, manually labeling the annotations is actually time-consuming and expensive. In this paper, we propose a novel weakly-supervised moment retrieval framework requiring only coarse video-level annotations for training. Specifically, we devise a proposal generation module that aggregates the context information to generate and score all candidate proposals in one single pass. We then devise an algorithm that considers both exploitation and exploration to select top-K proposals. Next, we build a semantic completion module to measure the semantic similarity between the selected proposals and query, compute reward and provide feedbacks to the proposal generation module for scoring refinement. Experiments on the ActivityCaptions and Charades-STA demonstrate the effectiveness of our proposed method.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Semantic-Alignment Hashing for Unsupervised Cross-Modal Retrieval\n",
            "Authors: Dejie Yang, Dayan Wu, Wanqian Zhang, Haisu Zhang, Bo Li, Weiping Wang\n",
            "Year: 2020\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Deep hashing methods have achieved tremendous success in cross-modal retrieval, due to its low storage consumption and fast retrieval speed. In real cross-modal retrieval applications, it's hard to obtain label information. Recently, increasing attention has been paid to unsupervised cross-modal hashing. However, existing methods fail to exploit the intrinsic connections between images and their corresponding descriptions or tags (text modality). In this paper, we propose a novel Deep Semantic-Alignment Hashing (DSAH) for unsupervised cross-modal retrieval, which sufficiently utilizes the co-occurred image-text pairs. DSAH explores the similarity information of different modalities and we elaborately design a semantic-alignment loss function, which elegantly aligns the similarities between features with those between hash codes. Moreover, to further bridge the modality gap, we innovatively propose to reconstruct features of one modality with hash codes of the other one. Extensive experiments on three cross-modal retrieval datasets demonstrate that DSAH achieves the state-of-the-art performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Level Correlation Adversarial Hashing for Cross-Modal Retrieval\n",
            "Authors: Xinhong Ma, Tianzhu Zhang, Changsheng Xu\n",
            "Year: 2020\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Cross-modal hashing (CMH) has been widely used for similarity search in multimedia retrieval applications, thanks to low storage cost and fast query speed. However, preserving the content similarities in finite-length hash codes between different data modalities is still challenging due to the existing heterogeneity gap. To further address the crucial bottleneck, we propose a Multi-Level Correlation Adversarial Hashing (MLCAH) algorithm to integrate the multi-level correlation information into hash codes. The proposed MLCAH model enjoys several merits. First, to the best of our knowledge, it is the early attempt of leveraging the multi-level correlation information for cross-modal hashing retrieval. Second, we propose global and local semantic alignment mechanisms, which can effectively encode multi-level correlation information, including global information, local information, and label information into hash codes. Third, a label-consistency attention mechanism with adversarial training is designed for exploiting the local cross-modality similarity from multi-modality data. Extensive evaluations on four benchmarks demonstrate that the proposed model brings significant improvements over several state-of-the-art cross-modal hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FAQ Retrieval using Query-Question Similarity and BERT-Based Query-Answer Relevance\n",
            "Authors: Wataru Sakata, Tomohide Shibata, Ribeka Tanaka, S. Kurohashi\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Frequently Asked Question (FAQ) retrieval is an important task where the objective is to retrieve an appropriate Question-Answer (QA) pair from a database based on a user's query. We propose a FAQ retrieval system that considers the similarity between a user's query and a question as well as the relevance between the query and an answer. Although a common approach to FAQ retrieval is to construct labeled data for training, it takes annotation costs. Therefore, we use a traditional unsupervised information retrieval system to calculate the similarity between the query and question. On the other hand, the relevance between the query and answer can be learned by using QA pairs in a FAQ database. The recently-proposed BERT model is used for the relevance calculation. Since the number of QA pairs in FAQ page is not enough to train a model, we cope with this issue by leveraging FAQ sets that are similar to the one in question. We evaluate our approach on two datasets. The first one is localgovFAQ, a dataset we construct in a Japanese administrative municipality domain. The second is StackExchange dataset, which is the public dataset in English. We demonstrate that our proposed method outperforms baseline methods on these datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Applying BERT to Document Retrieval with Birch\n",
            "Authors: Zeynep Akkalyoncu Yilmaz, Shengjin Wang, Wei Yang, Haotian Zhang, Jimmy J. Lin\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We present Birch, a system that applies BERT to document retrieval via integration with the open-source Anserini information retrieval toolkit to demonstrate end-to-end search over large document collections. Birch implements simple ranking models that achieve state-of-the-art effectiveness on standard TREC newswire and social media test collections. This demonstration focuses on technical challenges in the integration of NLP and IR capabilities, along with the design rationale behind our approach to tightly-coupled integration between Python (to support neural networks) and the Java Virtual Machine (to support document retrieval using the open-source Lucene search library). We demonstrate integration of Birch with an existing search interface as well as interactive notebooks that highlight its capabilities in an easy-to-understand manner.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantics-preserving hashing for cross-view retrieval\n",
            "Authors: Zijia Lin, Guiguang Ding, Mingqing Hu, Jianmin Wang\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: With benefits of low storage costs and high query speeds, hashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts. In this paper, we study the problem of cross-view retrieval and propose an effective Semantics-Preserving Hashing method, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them into a probability distribution and approximates it with to-be-learnt hash codes in Hamming space via minimizing the Kullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt hash codes. And for any unseen instance, predicted hash codes and their corresponding output probabilities from observed views are utilized to determine its unified hash code, using a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval on source code: a neural code search\n",
            "Authors: Saksham Sachdev, Hongyu Li, Sifei Luan, Seohyun Kim, Koushik Sen, S. Chandra\n",
            "Year: 2018\n",
            "Venue: MAPL@PLDI\n",
            "Abstract: Searching over large code corpora can be a powerful productivity tool for both beginner and experienced developers because it helps them quickly find examples of code related to their intent. Code search becomes even more attractive if developers could express their intent in natural language, similar to the interaction that Stack Overflow supports. In this paper, we investigate the use of natural language processing and information retrieval techniques to carry out natural language search directly over source code, i.e. without having a curated Q&A forum such as Stack Overflow at hand. Our experiments using a benchmark suite derived from Stack Overflow and GitHub repositories show promising results. We find that while a basic word–embedding based search procedure works acceptably, better results can be obtained by adding a layer of supervision, as well as by a customized ranking strategy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Time-Series Retrieval of Soil Moisture Using CYGNSS\n",
            "Authors: Mohammad M. Al-Khaldi, J. Johnson, A. O'Brien, A. Balenzano, F. Mattia\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: Time-series retrievals of soil moisture obtained from the Cyclone Global Navigation Satellite System (CYGNSS) constellation are presented. The retrieval approach assumes that vegetation and roughness changes occur on timescales longer than those associated with soil moisture changes to allow soil moisture sensing in the presence of vegetation and surface roughness contributions as well as the varying incidence angles associated with spaceborne Global Navigation Satellite System-Reflectometry (GNSS-R) systems. The approach is focused on incoherent scattering from land surfaces due to the expectation that coherent land surface returns arise primarily from inland water body contributions that are not directly representative of soil moisture. An approach for discarding coherent CYGNSS measurements is therefore developed and described. Because the approach requires the retrieval of  $N$  temporal soil moisture samples at a given location but uses only  $N-1$  ratios of CYGNSS measured quantities, ancillary information is incorporated in the retrieval through the use of maximum and minimum monthly soil moisture maps obtained from the Soil Moisture Active Passive (SMAP) mission. Retrieved soil moistures are presented for the 6-month period December 2017–May 2018 and are compared against values reported by the SMAP mission. The comparisons suggest that there exists the potential for using spaceborne GNSS-R systems for global soil moisture retrievals with an rms error on the order of 0.04 cm3/cm3 over varied terrain.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval\n",
            "Authors: Lin Wu, Yang Wang, Ling Shao\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: In this paper, we propose a novel deep generative approach to cross-modal retrieval to learn hash functions in the absence of paired training samples through the cycle consistency loss. Our proposed approach employs adversarial training scheme to learn a couple of hash functions enabling translation between modalities while assuming the underlying semantic relationship. To induce the hash codes with semantics to the input-output pair, cycle consistency loss is further delved into the adversarial training to strengthen the correlation between the inputs and corresponding outputs. Our approach is generative to learn hash functions, such that the learned hash codes can maximally correlate each input–output correspondence and also regenerate the inputs so as to minimize the information loss. The learning to hash embedding is thus performed to jointly optimize the parameters of the hash functions across modalities as well as the associated generative models. Extensive experiments on a variety of large-scale cross-modal data sets demonstrate that our proposed method outperforms the state of the arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Cross-Modal Image–Voice Retrieval in Remote Sensing\n",
            "Authors: Yaxiong Chen, Xiaoqiang Lu, Shuai Wang\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: With the rapid progress of satellite and aircraft technologies, cross-modal remote sensing image–voice retrieval has been studied in geography recently. However, there still exist some bottlenecks: how to consider the characteristics of remote sensing data adequately and how to reduce the memory and improve the retrieval efficiency in large-scale remote sensing data. In this article, we propose a novel deep cross-modal remote sensing image–voice retrieval approach, namely, deep image–voice retrieval (DIVR), to capture more information of remote sensing data to generate hash codes with low memory and fast retrieval properties. Especially, the DIVR approach proposes inception dilated convolution module to capture multiscale contextual information of remote sensing images and voices. Moreover, in order to enhance cross-modal similarity, the deep features’ similarity term is designed to make paired similar deep features as close as possible and paired dissimilar deep features as mutually far as possible. In addition, the quantization error term is designed to drive hash-like codes to approximate hash codes, which can effectively reduce the quantization error for hash codes’ learning. Extensive experimental results on three remote sensing image–voice data sets show that the proposed DIVR approach can outperform other cross-modal retrieval approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bilinear Attention Networks for Person Retrieval\n",
            "Authors: Pengfei Fang, Jieming Zhou, S. Roy, L. Petersson, M. Harandi\n",
            "Year: 2019\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: This paper investigates a novel Bilinear attention (Bi-attention) block, which discovers and uses second order statistical information in an input feature map, for the purpose of person retrieval. The Bi-attention block uses bilinear pooling to model the local pairwise feature interactions along each channel, while preserving the spatial structural information. We propose an Attention in Attention (AiA) mechanism to build inter-dependency among the second order local and global features with the intent to make better use of, or pay more attention to, such higher order statistical relationships. The proposed network, equipped with the proposed Bi-attention is referred to as Bilinear ATtention network (BAT-net). Our approach outperforms current state-of-the-art by a considerable margin across the standard benchmark datasets (e.g., CUHK03, Market-1501, DukeMTMC-reID and MSMT17).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Memory retrieval by activating engram cells in mouse models of early Alzheimer’s disease\n",
            "Authors: Dheeraj S. Roy, Autumn L Arons, Teryn Mitchell, Michele Pignatelli, T. Ryan, S. Tonegawa\n",
            "Year: 2016\n",
            "Venue: Nature\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Privacy-Preserving Image Retrieval for Medical IoT Systems: A Blockchain-Based Approach\n",
            "Authors: Meng Shen, Yawen Deng, Liehuang Zhu, Xiaojiang Du, Nadra Guizani\n",
            "Year: 2019\n",
            "Venue: IEEE Network\n",
            "Abstract: With the advent of medical IoT devices, the types and volumes of medical images have significantly increased. Retrieving of medical images is of great importance to facilitate disease diagnosis and improve treatment efficiency. However, it may raise privacy concerns from individuals, since medical images contain patients' sensitive and private information. Existing studies on retrieval of medical data either fail to protect sensitive information of medical images or are limited to a single image data provider. In this article, we propose a blockchain-based system for medical image retrieval with privacy protection. We first describe the typical scenarios of medical image retrieval and summarize the corresponding requirements in system design. Using the emerging blockchain techniques, we present the layered architecture and threat model of the proposed system. In order to accommodate large-size images with storage-constrained blocks, we capture a carefully selected feature vector from each medical image and design a customized transaction structure, which protects the privacy of medical images and image features. We also discuss the challenges and opportunities of future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FUNDAMENTALS OF CONTENT-BASED IMAGE RETRIEVAL\n",
            "Authors: S. V. Sakhare, V. G. Nasre, Fuhui Long, Hongjiang Zhang, David Dagan Feng, A. Khaparde, B.L.Deekshatulu, M. Madhavilath, Zakira Farheen, S. Kumari, Guoping Qiu, Sudeep D. Thepade, S. Rajala\n",
            "Year: 2020\n",
            "Venue: \n",
            "Abstract: Advances in data storage and image acquisition technologies have enabled the creation of large image datasets. In this scenario, it is necessary to develop appropriate information systems to efficiently manage these collections. The most common approaches use Content-Based Image Retrieval (CBIR).The goal of such CBIR systems is to support image retrieval based on content e.g., shape, color, texture. Retrieval of images based on visual features such as color, texture and shape have proven to have its own set of limitations under different conditions. In this paper we propose a novel method with highly accurate and retrieval efficient approach which will work on large image database with varied contents and background.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Coupled CycleGAN: Unsupervised Hashing Network for Cross-Modal Retrieval\n",
            "Authors: Chao Li, Cheng Deng, Lei Wang, De Xie, Xianglong Liu\n",
            "Year: 2019\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: In recent years, hashing has attracted more and more attention owing to its superior capacity of low storage cost and high query efficiency in large-scale cross-modal retrieval. Benefiting from deep leaning, continuously compelling results in cross-modal retrieval community have been achieved. However, existing deep cross-modal hashing methods either rely on amounts of labeled information or have no ability to learn an accuracy correlation between different modalities. In this paper, we proposed Unsupervised coupled Cycle generative adversarial Hashing networks (UCH), for cross-modal retrieval, where outer-cycle network is used to learn powerful common representation, and inner-cycle network is explained to generate reliable hash codes. Specifically, our proposed UCH seamlessly couples these two networks with generative adversarial mechanism, which can be optimized simultaneously to learn representation and hash codes. Extensive experiments on three popular benchmark datasets show that the proposed UCH outperforms the state-of-the-art unsupervised cross-modal hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Graph Convolutional Network Hashing for Cross-Modal Retrieval\n",
            "Authors: Ruiqing Xu, Chao Li, Junchi Yan, Cheng Deng, Xianglong Liu\n",
            "Year: 2019\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract: Deep network based cross-modal retrieval has recently made significant progress. However, bridging modality gap to further enhance the retrieval accuracy still remains a crucial bottleneck. In this paper, we propose a Graph Convolutional Hashing (GCH) approach, which learns modality-unified binary codes via an affinity graph. An end-to-end deep architecture is constructed with three main components: a semantic encoder module, two feature encoding networks, and a graph convolutional network (GCN). We design a semantic encoder as a teacher module to guide the feature encoding process, a.k.a. student module, for semantic information exploiting. Furthermore, GCN is utilized to explore the inherent similarity structure among data points, which will help to generate discriminative hash codes. Extensive experiments on three benchmark datasets demonstrate that the proposed GCH outperforms the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information\n",
            "Authors: E. Sayers, J. Beck, Evan E. Bolton, Devon Bourexis, J. R. Brister, Kathi Canese, Donald C. Comeau, Kathryn Funk, Sunghwan Kim, W. Klimke, Aron Marchler-Bauer, M. Landrum, S. Lathrop, Zhiyong Lu, Thomas L. Madden, N. O'Leary, Lon Phan, S. Rangwala, Valerie A. Schneider, Yuri Skripchenko, Jiyao Wang, Jian Ye, B. Trawick, K. Pruitt, S. Sherry\n",
            "Year: 2020\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed® database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 34 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface and NCBI datasets. Additional resources that were updated in the past year include PMC, Bookshelf, Genome Data Viewer, SRA, ClinVar, dbSNP, dbVar, Pathogen Detection, BLAST, Primer-BLAST, IgBLAST, iCn3D and PubChem. All of these resources can be accessed through the NCBI home page at https://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-modal Retrieval with Correspondence Autoencoder\n",
            "Authors: Fangxiang Feng, Xiaojie Wang, Ruifan Li\n",
            "Year: 2014\n",
            "Venue: ACM Multimedia\n",
            "Abstract: The problem of cross-modal retrieval, e.g., using a text query to search for images and vice-versa, is considered in this paper. A novel model involving correspondence autoencoder (Corr-AE) is proposed here for solving this problem. The model is constructed by correlating hidden representations of two uni-modal autoencoders. A novel optimal objective, which minimizes a linear combination of representation learning errors for each modality and correlation learning error between hidden representations of two modalities, is used to train the model as a whole. Minimization of correlation learning error forces the model to learn hidden representations with only common information in different modalities, while minimization of representation learning error makes hidden representations are good enough to reconstruct input of each modality. A parameter $\\alpha$ is used to balance the representation learning error and the correlation learning error. Based on two different multi-modal autoencoders, Corr-AE is extended to other two correspondence models, here we called Corr-Cross-AE and Corr-Full-AE. The proposed models are evaluated on three publicly available data sets from real scenes. We demonstrate that the three correspondence autoencoders perform significantly better than three canonical correlation analysis based models and two popular multi-modal deep models on cross-modal retrieval tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Adaptive Semi-Supervised Feature Selection for Cross-Modal Retrieval\n",
            "Authors: En Yu, Jiande Sun, Jing Li, Xiaojun Chang, Xianhua Han, Alexander Hauptmann\n",
            "Year: 2019\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: In order to exploit the abundant potential information of the unlabeled data and contribute to analyzing the correlation among heterogeneous data, we propose the semi-supervised model named adaptive semi-supervised feature selection for cross-modal retrieval. First, we utilize the semantic regression to strengthen the neighboring relationship between the data with the same semantic. And the correlation between heterogeneous data can be optimized via keeping the pairwise closeness when learning the common latent space. Second, we adopt the graph-based constraint to predict accurate labels for unlabeled data, and it can also keep the geometric structure consistency between the label space and the feature space of heterogeneous data in the common latent space. Finally, an efficient joint optimization algorithm is proposed to update the mapping matrices and the label matrix for unlabeled data simultaneously and iteratively. It makes samples from different classes to be far apart, while the samples from same class lie as close as possible. Meanwhile, the ${l_{2,1}}$-norm constraint is used for feature selection and outlier reduction when the mapping matrices are learned. In addition, we propose learning different mapping matrices corresponding to different sub-tasks to emphasize the semantic and structural information of query data. Experiment results on three datasets demonstrate that our method performs better than the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Spatial-Semantic Attention for Fine-Grained Sketch-Based Image Retrieval\n",
            "Authors: Jifei Song, Qian Yu, Yi-Zhe Song, T. Xiang, Timothy M. Hospedales\n",
            "Year: 2017\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Human sketches are unique in being able to capture both the spatial topology of a visual object, as well as its subtle appearance details. Fine-grained sketch-based image retrieval (FG-SBIR) importantly leverages on such fine-grained characteristics of sketches to conduct instance-level retrieval of photos. Nevertheless, human sketches are often highly abstract and iconic, resulting in severe misalignments with candidate photos which in turn make subtle visual detail matching difficult. Existing FG-SBIR approaches focus only on coarse holistic matching via deep cross-domain representation learning, yet ignore explicitly accounting for fine-grained details and their spatial context. In this paper, a novel deep FG-SBIR model is proposed which differs significantly from the existing models in that: (1) It is spatially aware, achieved by introducing an attention module that is sensitive to the spatial position of visual details: (2) It combines coarse and fine semantic information via a shortcut connection fusion block: and (3) It models feature correlation and is robust to misalignments between the extracted features across the two domains by introducing a novel higher-order learnable energy function (HOLEF) based loss. Extensive experiments show that the proposed deep spatial-semantic attention model significantly outperforms the state-of-the-art.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Privacy-Preserving Content-Based Image Retrieval in Cloud Computing\n",
            "Authors: Zhihua Xia, Yi Zhu, Xingming Sun, Zhan Qin, K. Ren\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Cloud Computing\n",
            "Abstract: Content-based image retrieval (CBIR) applications have been rapidly developed along with the increase in the quantity, availability and importance of images in our daily life. However, the wide deployment of CBIR scheme has been limited by its the severe computation and storage requirement. In this paper, we propose a privacy-preserving content-based image retrieval scheme, which allows the data owner to outsource the image database and CBIR service to the cloud, without revealing the actual content of the database to the cloud server. Local features are utilized to represent the images, and earth mover's distance (EMD) is employed to evaluate the similarity of images. The EMD computation is essentially a linear programming (LP) problem. The proposed scheme transforms the EMD problem in such a way that the cloud server can solve it without learning the sensitive information. In addition, local sensitive hash (LSH) is utilized to improve the search efficiency. The security analysis and experiments show the security and efficiency of the proposed scheme.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Practicing Retrieval Facilitates Learning.\n",
            "Authors: K. McDermott\n",
            "Year: 2020\n",
            "Venue: Annual Review of Psychology\n",
            "Abstract: How do we go about learning new information? This article reviews the importance of practicing retrieval of newly experienced information if one wants to be able to retrieve it again in the future. Specifically, practicing retrieval shortly after learning can slow the forgetting process. This benefit can be seen across various material types, and it seems prevalent in all ages and learner abilities and on all types of test. It can also be used to enhance student learning in a classroom setting. I review theoretical understanding of this phenomenon (sometimes referred to as the testing effect or as retrieval-based learning) and consider directions for future research. Expected final online publication date for the Annual Review of Psychology, Volume 72 is January 5, 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Diagnosing BERT with Retrieval Heuristics\n",
            "Authors: A. Câmara, C. Hauff\n",
            "Year: 2020\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Modal Video Moment Retrieval with Spatial and Language-Temporal Attention\n",
            "Authors: Bin Jiang, Xin Huang, Chao Yang, Junsong Yuan\n",
            "Year: 2019\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Given an untrimmed video and a description query, temporal moment retrieval aims to localize the temporal segment within the video that best describes the textual query. Existing studies predominantly employ coarse frame-level features as the visual representation, obfuscating the specific details which may provide critical cues for localizing the desired moment. We propose a SLTA (short for \"Spatial and Language-Temporal Attention\") method to address the detail missing issue. Specifically, the SLTA method takes advantage of object-level local features and attends to the most relevant local features (e.g., the local features \"girl\", \"cup\") by spatial attention. Then we encode the sequence of local features on consecutive frames to capture the interaction information among these objects (e.g., the interaction \"pour\" involving these two objects). Meanwhile, a language-temporal attention is utilized to emphasize the keywords based on moment context information. Therefore, our proposed two attention sub-networks can recognize the most relevant objects and interactions in the video, and simultaneously highlight the keywords in the query. Extensive experiments on TACOS, Charades-STA and DiDeMo datasets demonstrate the effectiveness of our model as compared to state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Nanophotonic rare-earth quantum memory with optically controlled retrieval\n",
            "Authors: T. Zhong, J. Kindem, J. Bartholomew, Jake Rochman, I. Craiciu, Evan Miyazono, M. Bettinelli, E. Cavalli, V. Verma, S. Nam, F. Marsili, M. Shaw, A. Beyer, A. Faraon\n",
            "Year: 2017\n",
            "Venue: Science\n",
            "Abstract: A rare-earth quantum memory The development of global quantum networks will require chip-scale optically addressable quantum memories for quantum state storage, manipulation, and state swapping. Zhong et al. fabricated a nanostructured photonic crystal cavity in a rare-earth-doped material to form a high-fidelity quantum memory (see the Perspective by Waks and Goldschmidt). The cavity enhanced the light-matter interaction, allowing quantum states to be stored and retrieved from the memory on demand. The high fidelity and small footprint of the device offer a powerful building block for a quantum information platform. Science, this issue p. 1392; see also p. 1354 Rare-earth atoms in a nanophotonic crystal provide a scalable platform for quantum memories. Optical quantum memories are essential elements in quantum networks for long-distance distribution of quantum entanglement. Scalable development of quantum network nodes requires on-chip qubit storage functionality with control of the readout time. We demonstrate a high-fidelity nanophotonic quantum memory based on a mesoscopic neodymium ensemble coupled to a photonic crystal cavity. The nanocavity enables >95% spin polarization for efficient initialization of the atomic frequency comb memory and time bin–selective readout through an enhanced optical Stark shift of the comb frequencies. Our solid-state memory is integrable with other chip-scale photon source and detector devices for multiplexed quantum and classical information processing at the network nodes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: End-to-End Retrieval in Continuous Space\n",
            "Authors: D. Gillick, Alessandro Presta, Gaurav Singh Tomar\n",
            "Year: 2018\n",
            "Venue: arXiv.org\n",
            "Abstract: Most text-based information retrieval (IR) systems index objects by words or phrases. These discrete systems have been augmented by models that use embeddings to measure similarity in continuous space. But continuous-space models are typically used just to re-rank the top candidates. We consider the problem of end-to-end continuous retrieval, where standard approximate nearest neighbor (ANN) search replaces the usual discrete inverted index, and rely entirely on distances between learned embeddings. By training simple models specifically for retrieval, with an appropriate model architecture, we improve on a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval tasks. We also discuss the problem of evaluation for retrieval systems, and show how to modify existing pairwise similarity datasets for this purpose.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Night-Time Pedestrian Retrieval With Distribution Alignment and Contextual Distance\n",
            "Authors: Mang Ye, Yi Cheng, X. Lan, Hongyuan Zhu\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Industrial Informatics\n",
            "Abstract: Night-time pedestrian retrieval is a cross-modality retrieval task of retrieving person images between day-time visible images and night-time thermal images. It is a very challenging problem due to modality difference, camera variations, and person variations, but it plays an important role in night-time video surveillance. The existing cross-modality retrieval usually focuses on learning modality sharable feature representations to bridge the modality gap. In this article, we propose to utilize auxiliary information to improve the retrieval performance, which consistently improves the performance with different baseline loss functions. Our auxiliary information contains two major parts: cross-modality feature distribution and contextual information. The former aligns the cross-modality feature distributions between two modalities to improve the performance, and the latter optimizes the cross-modality distance measurement with the contextual information. We also demonstrate that abundant annotated visible pedestrian images, which are easily accessible, help to improve the cross-modality pedestrian retrieval as well. The proposed method is featured in two aspects: the auxiliary information does not need additional human intervention or annotation; it learns discriminative feature representations in an end-to-end deep learning manner. Extensive experiments on two cross-modality pedestrian retrieval datasets demonstrate the superiority of the proposed method, achieving much better performance than the state-of-the-arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information.\n",
            "Authors: E. Sayers, J. Beck, J. R. Brister, Evan E. Bolton, Kathi Canese, Donald C. Comeau, Kathryn Funk, A. Ketter, Sunghwan Kim, Avi Kimchi, P. Kitts, A. Kuznetsov, S. Lathrop, Zhiyong Lu, Kelly M. McGarvey, Thomas L. Madden, Terence D. Murphy, N. O'Leary, Lon Phan, Valerie A. Schneider, F. Thibaud-Nissen, B. Trawick, K. Pruitt, J. Ostell\n",
            "Year: 2019\n",
            "Venue: Nucleic Acids Research\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 35 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Custom implementations of the BLAST program provide sequence-based searching of many specialized datasets. New resources released in the past year include a new PubMed interface, a sequence database search and a gene orthologs page. Additional resources that were updated in the past year include PMC, Bookshelf, My Bibliography, Assembly, RefSeq, viral genomes, the prokaryotic genome annotation pipeline, Genome Workbench, dbSNP, BLAST, Primer-BLAST, IgBLAST and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ReQA: An Evaluation for End-to-End Answer Retrieval Models\n",
            "Authors: Amin Ahmad, Noah Constant, Yinfei Yang, Daniel Matthew Cer\n",
            "Year: 2019\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Popular QA benchmarks like SQuAD have driven progress on the task of identifying answer spans within a specific passage, with models now surpassing human performance. However, retrieving relevant answers from a huge corpus of documents is still a challenging problem, and places different requirements on the model architecture. There is growing interest in developing scalable answer retrieval models trained end-to-end, bypassing the typical document retrieval step. In this paper, we introduce Retrieval Question-Answering (ReQA), a benchmark for evaluating large-scale sentence-level answer retrieval models. We establish baselines using both neural encoding models as well as classical information retrieval techniques. We release our evaluation code to encourage further work on this challenging task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Rank Using User Clicks and Visual Features for Image Retrieval\n",
            "Authors: Jun Yu, D. Tao, Meng Wang, Y. Rui\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Cybernetics\n",
            "Abstract: The inconsistency between textual features and visual contents can cause poor image search results. To solve this problem, click features, which are more reliable than textual information in justifying the relevance between a query and clicked images, are adopted in image ranking model. However, the existing ranking model cannot integrate visual features, which are efficient in refining the click-based search results. In this paper, we propose a novel ranking model based on the learning to rank framework. Visual features and click features are simultaneously utilized to obtain the ranking model. Specifically, the proposed approach is based on large margin structured output learning and the visual consistency is integrated with the click features through a hypergraph regularizer term. In accordance with the fast alternating linearization method, we design a novel algorithm to optimize the objective function. This algorithm alternately minimizes two different approximations of the original objective function by keeping one function unchanged and linearizing the other. We conduct experiments on a large-scale dataset collected from the Microsoft Bing image search engine, and the results demonstrate that the proposed learning to rank models based on visual features and user clicks outperforms state-of-the-art algorithms.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ad Hoc Table Retrieval using Semantic Similarity\n",
            "Authors: Shuo Zhang, K. Balog\n",
            "Year: 2018\n",
            "Venue: The Web Conference\n",
            "Abstract: We introduce and address the problem of ad hoc table retrieval: answering a keyword query with a ranked list of tables. This task is not only interesting on its own account, but is also being used as a core component in many other table-based information access scenarios, such as table completion or table mining. The main novel contribution of this work is a method for performing semantic matching between queries and tables. Specifically, we (i) represent queries and tables in multiple semantic spaces (both discrete sparse and continuous dense vector representations) and (ii) introduce various similarity measures for matching those semantic representations. We consider all possible combinations of semantic representations and similarity measures and use these as features in a supervised learning model. Using a purpose-built test collection based on Wikipedia tables, we demonstrate significant and substantial improvements over a state-of-the-art baseline.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Distilling Knowledge for Fast Retrieval-based Chat-bots\n",
            "Authors: Amir Vakili Tahami, Kamyar Ghajar, A. Shakery\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Response retrieval is a subset of neural ranking in which a model selects a suitable response from a set of candidates given a conversation history. Retrieval-based chat-bots are typically employed in information seeking conversational systems such as customer support agents. To make pairwise comparisons between a conversation history and a candidate response, two approaches are common: cross-encoders performing full self-attention over the pair and bi-encoders encoding the pair separately. The former gives better prediction quality but is too slow for practical use. In this paper, we propose a new cross-encoder architecture and transfer knowledge from this model to a bi-encoder model using distillation. This effectively boosts bi-encoder performance at no cost during inference time. We perform a detailed analysis of this approach on three response retrieval datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural Embedding-Based Metrics for Pre-retrieval Query Performance Prediction\n",
            "Authors: Negar Arabzadeh, Fattane Zarrinkalam, J. Jovanović, E. Bagheri\n",
            "Year: 2020\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: TRECVID 2019: An evaluation campaign to benchmark Video Activity Detection, Video Captioning and Matching, and Video Search & retrieval\n",
            "Authors: G. Awad, A. Butt, Keith Curtis, Yooyoung Lee, Jonathan G. Fiscus, A. Godil, Andrew Delgado, Jesse Zhang, Eliot Godard, Lukas L. Diduch, A. Smeaton, Yyette Graham, Wessel Kraaij, G. Quénot\n",
            "Year: 2019\n",
            "Venue: TREC Video Retrieval Evaluation\n",
            "Abstract: The TREC Video Retrieval Evaluation (TRECVID) 2019 was a TREC-style video analysis and retrieval evaluation, the goal of which remains to promote progress in research and development of content-based exploitation and retrieval of information from digital video via open, metrics-based evaluation. Over the last nineteen years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID has been funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addition, many organizations and individuals worldwide contribute significant time and effort. TRECVID 2019 represented a continuation of four tasks from TRECVID 2018. In total, 27 teams from various research organizations worldwide completed one or more of the following four tasks: 1. Ad-hoc Video Search (AVS) 2. Instance Search (INS) 3. Activities in Extended Video (ActEV) 4. Video to Text Description (VTT) This paper is an introduction to the evaluation framework, tasks, data, and measures used in the workshop.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Quantum Interference Inspired Neural Matching Model for Ad-hoc Retrieval\n",
            "Authors: Yongyu Jiang, Peng Zhang, Hui Gao, D. Song\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: An essential task of information retrieval (IR) is to compute the probability of relevance of a document given a query. If we regard a query term or n-gram fragment as a relevance matching unit, most retrieval models firstly calculate the relevance evidence between the given query and the candidate document separately, and then accumulate these evidences as the final document relevance prediction. This kind of approach obeys the the classical probability, which is not fully consistent with human cognitive rules in the actual retrieval process, due to the possible existence of interference effect between relevance matching units. In our work, we propose a Quantum Interference inspired Neural Matching model (QINM), which can apply the interference effects to guide the construction of additional evidence generated by the interaction between matching units in the retrieval process. Experimental results on two benchmark collections demonstrate that our approach outperforms the quantum-inspired retrieval models, and some well-known neural retrieval models in the ad-hoc retrieval task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Web Table Extraction, Retrieval and Augmentation\n",
            "Authors: Shuo Zhang, K. Balog\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This tutorial synthesizes and presents research on web tables over the past two decades. We group the tasks into six main categories of information access tasks: (i) table extraction, (ii) table interpretation, (iii) table search, (iv) question answering on tables, (v) knowledge base augmentation, and (vi) table completion. For each category, we identify and introduce seminal approaches, present relevant resources, and point out interdependencies among the different tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Triplet Neural Networks with Cluster-CCA for Audio-Visual Cross-Modal Retrieval\n",
            "Authors: Donghuo Zeng, Yi Yu, K. Oyama\n",
            "Year: 2019\n",
            "Venue: ACM Trans. Multim. Comput. Commun. Appl.\n",
            "Abstract: Cross-modal retrieval aims to retrieve data in one modality by a query in another modality, which has been a very interesting research issue in the field of multimedia, information retrieval, and computer vision, and database. Most existing works focus on cross-modal retrieval between text-image, text-video, and lyrics-audio. Little research addresses cross-modal retrieval between audio and video due to limited audio-video paired datasets and semantic information. The main challenge of the audio-visual cross-modal retrieval task focuses on learning joint embeddings from a shared subspace for computing the similarity across different modalities, where generating new representations is to maximize the correlation between audio and visual modalities space. In this work, we propose TNN-C-CCA, a novel deep triplet neural network with cluster canonical correlation analysis, which is an end-to-end supervised learning architecture with an audio branch and a video branch. We not only consider the matching pairs in the common space but also compute the mismatching pairs when maximizing the correlation. In particular, two significant contributions are made. First, a better representation by constructing a deep triplet neural network with triplet loss for optimal projections can be generated to maximize correlation in the shared subspace. Second, positive examples and negative examples are used in the learning stage to improve the capability of embedding learning between audio and video. Our experiment is run over fivefold cross validation, where average performance is applied to demonstrate the performance of audio-video cross-modal retrieval. The experimental results achieved on two different audio-visual datasets show that the proposed learning architecture with two branches outperforms existing six canonical correlation analysis–based methods and four state-of-the-art-based cross-modal retrieval methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory\n",
            "Authors: Deng Cai, Yan Wang, Victoria Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam, Shuming Shi\n",
            "Year: 2018\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: Traditional generative dialogue models generate responses solely from input queries. Such information is insufficient for generating a specific response since a certain query could be answered in multiple ways. Recently, researchers have attempted to fill the information gap by exploiting information retrieval techniques. For a given query, similar dialogues are retrieved from the entire training data and considered as an additional knowledge source. While the use of retrieval may harvest extensive information, the generative models could be overwhelmed, leading to unsatisfactory performance. In this paper, we propose a new framework which exploits retrieval results via a skeleton-to-response paradigm. At first, a skeleton is extracted from the retrieved dialogues. Then, both the generated skeleton and the original query are used for response generation via a novel response generator. Experimental results show that our approach significantly improves the informativeness of the generated responses\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems\n",
            "Authors: Yiping Song, Cheng-te Li, Jian-Yun Nie, Ming Zhang, Dongyan Zhao, Rui Yan\n",
            "Year: 2018\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract:  Human-computer conversation systems have attracted much attention in Natural Language Processing. Conversation systems can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (namely a query ) in a large conversational repository and return a reply that best matches the query. Generative approaches synthesize new replies. Both ways have certain advantages but suffer from their own disadvantages. We propose a novel ensemble of retrieval-based and generation-based conversation system. The retrieved candidates, in addition to the original query, are fed to a reply generator via a neural network, so that the model is aware of more information. The generated reply together with the retrieved ones then participates in a re-ranking process to find the final reply to output. Experimental results show that such an ensemble system outperforms each single module by a large margin.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modeling Diverse Relevance Patterns in Ad-hoc Retrieval\n",
            "Authors: Yixing Fan, J. Guo, Yanyan Lan, Jun Xu, ChengXiang Zhai, Xueqi Cheng\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Assessing relevance between a query and a document is challenging in ad-hoc retrieval due to its diverse patterns, i.e., a document could be relevant to a query as a whole or partially as long as it provides sufficient information for users' need. Such diverse relevance patterns require an ideal retrieval model to be able to assess relevance in the right granularity adaptively. Unfortunately, most existing retrieval models compute relevance at a single granularity, either document-wide or passage-level, or use fixed combination strategy, restricting their ability in capturing diverse relevance patterns. In this work, we propose a data-driven method to allow relevance signals at different granularities to compete with each other for final relevance assessment. Specifically, we propose a HIerarchical Neural maTching model (HiNT) which consists of two stacked components, namely local matching layer and global decision layer. The local matching layer focuses on producing a set of local relevance signals by modeling the semantic matching between a query and each passage of a document. The global decision layer accumulates local signals into different granularities and allows them to compete with each other to decide the final relevance score.Experimental results demonstrate that our HiNT model outperforms existing state-of-the-art retrieval models significantly on benchmark ad-hoc retrieval datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The LFM-1b Dataset for Music Retrieval and Recommendation\n",
            "Authors: M. Schedl\n",
            "Year: 2016\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: We present the LFM-1b dataset of more than one billion music listening events created by more than 120,000 users of Last.fm. Each listening event is characterized by artist, album, and track name, and further includes a timestamp. On the (anonymous) user level, basic demographics and a selection of more elaborate user descriptors are included. The dataset is foremost intended for benchmarking in music information retrieval and recommendation. To facilitate experimentation in a straightforward manner, it also includes a precomputed user-item-playcount matrix. In addition, sample Python scripts showing how to load the data and perform efficient computations are provided. An implementation of a simple collaborative filtering recommender rounds off the code package. We discuss in detail the LFM-1b dataset's acquisition, availability, statistics, and content, and place it in the context of existing datasets. We also showcase its usage in a simple artist recommendation task, whose results are intended to serve as baseline against which more elaborate techniques can be assessed. The two unique features of the dataset in comparison to existing ones are (i) its substantial size and (ii) a wide range of additional user descriptors that reflect their music taste and consumption behavior.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effective Multi-Query Expansions: Collaborative Deep Networks for Robust Landmark Retrieval\n",
            "Authors: Yang Wang, Xuemin Lin, Lin Wu, W. Zhang\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Given a query photo issued by a user (q-user), the landmark retrieval is to return a set of photos with their landmarks similar to those of the query, while the existing studies on the landmark retrieval focus on exploiting geometries of landmarks for similarity matches between candidate photos and a query photo. We observe that the same landmarks provided by different users over social media community may convey different geometry information depending on the viewpoints and/or angles, and may, subsequently, yield very different results. In fact, dealing with the landmarks with low quality shapes caused by the photography of q-users is often nontrivial and has seldom been studied. In this paper, we propose a novel framework, namely, multi-query expansions, to retrieve semantically robust landmarks by two steps. First, we identify the top- $k$  photos regarding the latent topics of a query landmark to construct multi-query set so as to remedy its possible low quality shape. For this purpose, we significantly extend the techniques of Latent Dirichlet Allocation. Then, motivated by the typical collaborative filtering methods, we propose to learn a collaborative deep networks-based semantically, nonlinear, and high-level features over the latent factor for landmark photo as the training set, which is formed by matrix factorization over collaborative user-photo matrix regarding the multi-query set. The learned deep network is further applied to generate the features for all the other photos, meanwhile resulting into a compact multi-query set within such space. Then, the final ranking scores are calculated over the high-level feature space between the multi-query set and all other photos, which are ranked to serve as the final ranking list of landmark retrieval. Extensive experiments are conducted on real-world social media data with both landmark photos together with their user information to show the superior performance over the existing methods, especially our recently proposed multi-query based mid-level pattern representation method [1].\n",
            "\n",
            "---\n",
            "\n",
            "Title: Guided Similarity Separation for Image Retrieval\n",
            "Authors: Chundi Liu, Guangwei Yu, M. Volkovs, Cheng Chang, Himanshu Rai, Junwei Ma, S. Gorti\n",
            "Year: 2019\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Despite recent progress in computer vision, image retrieval remains a challenging open problem. Numerous variations such as view angle, lighting and occlusion make it difficult to design models that are both robust and efficient. Many leading methods traverse the nearest neighbor graph to exploit higher order neighbor information and uncover the highly complex underlying manifold. In this work we propose a different approach where we leverage graph convolutional networks to directly encode neighbor information into image descriptors. We further leverage ideas from clustering and manifold learning, and introduce an unsupervised loss based on pairwise separation of image similarities. Empirically, we demonstrate that our model is able to successfully learn a new descriptor space that significantly improves retrieval accuracy, while still allowing efficient inner product inference. Experiments on five public benchmarks show highly competitive performance with up to 24\\% relative improvement in mAP over leading baselines. Full code for this work is available here: https://github.com/layer6ai-labs/GSS.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Use of Ontology in Retrieval: A Study on Textual, Multilingual, and Multimedia Retrieval\n",
            "Authors: M. Asim, Muhammad Wasim, M. U. Ghani Khan, Nasir Mahmood, Waqar Mahmood\n",
            "Year: 2019\n",
            "Venue: IEEE Access\n",
            "Abstract: Web contains a vast amount of data, which are accumulated, studied, and utilized by a huge number of users on a daily basis. A substantial amount of data on the Web is available in an unstructured format, such as Web pages, books, journals, and files. Acquiring appropriate information from such humongous data has become quite challenging and a time-consuming task. Trivial keyword-based information retrieval systems highly depend on the statistics of data, thus facing word mismatch problem due to inevitable semantic and context variations of a certain word. Therefore, this marks the desperate need to organize such massive data into a structured format so that information can be easily processed in a large context by taking data semantics into account. Ontologies are not only being extensively employed in the semantic Web to store unstructured information in an organized and structured way but it has also raised the performance of diverse information retrieval approaches to a great extent. Ontological information retrieval systems retrieve data based on the similarity of semantics between the user query and the indexed data. This paper reviews modern ontology-based information retrieval methods for textual, multimedia, and cross-lingual data types. Furthermore, we compare and categorize the most recent approaches used in the above-mentioned information retrieval methods along with their major drawbacks and advantages.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database resources of the National Center for Biotechnology Information\n",
            "Authors: David L. Wheeler, T. Barrett, Dennis A. Benson, Stephen H. Bryant, Kathi Canese, V. Chetvernin, Deanna M. Church, Michael DiCuccio, Ron Edgar, S. Federhen, Lewis Y. Geer, Wolfgang Helmberg, Yuri Kapustin, D. L. Kenton, Oleg Khovayko, D. Lipman, Thomas L. Madden, D. Maglott, J. Ostell, K. Pruitt, Gregory D. Schuler, L. M. Schriml, Edwin Sequeira, Stephen T. Sherry, K. Sirotkin, A. Souvorov, G. Starchenko, Tugba Onal Suzek, R. Tatusov, T. Tatusova, Lukas Wagner, E. Yaschenko\n",
            "Year: 2014\n",
            "Venue: Nucleic Acids Res.\n",
            "Abstract: The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. Additional NCBI resources focus on literature (Bookshelf, PubMed Central (PMC) and PubReader); medical genetics (ClinVar, dbMHC, the Genetic Testing Registry, HIV-1/Human Protein Interaction Database and MedGen); genes and genomics (BioProject, BioSample, dbSNP, dbVar, Epigenomics, Gene, Gene Expression Omnibus (GEO), Genome, HomoloGene, the Map Viewer, Nucleotide, PopSet, Probe, RefSeq, Sequence Read Archive, the Taxonomy Browser, Trace Archive and UniGene); and proteins and chemicals (Biosystems, COBALT, the Conserved Domain Database (CDD), the Conserved Domain Architecture Retrieval Tool (CDART), the Molecular Modeling Database (MMDB), Protein Clusters, Protein and the PubChem suite of small molecule databases). The Entrez system provides search and retrieval operations for many of these databases. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. All of these resources can be accessed through the NCBI home page at http://www.ncbi.nlm.nih.gov.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Supervised Matrix Factorization Hashing for Cross-Modal Retrieval\n",
            "Authors: Jun Tang, Ke Wang, Ling Shao\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: The target of cross-modal hashing is to embed heterogeneous multimedia data into a common low-dimensional Hamming space, which plays a pivotal part in multimedia retrieval due to the emergence of big multimodal data. Recently, matrix factorization has achieved great success in cross-modal hashing. However, how to effectively use label information and local geometric structure is still a challenging problem for these approaches. To address this issue, we propose a cross-modal hashing method based on collective matrix factorization, which considers both the label consistency across different modalities and the local geometric consistency in each modality. These two elements are formulated as a graph Laplacian term in the objective function, leading to a substantial improvement on the discriminative power of latent semantic features obtained by collective matrix factorization. Moreover, the proposed method learns unified hash codes for different modalities of an instance to facilitate cross-modal search, and the objective function is solved using an iterative strategy. The experimental results on two benchmark data sets show the effectiveness of the proposed method and its superiority over state-of-the-art cross-modal hashing methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Visual-Semantic Quantization for Efficient Image Retrieval\n",
            "Authors: Yue Cao, Mingsheng Long, Jianmin Wang, Shichen Liu\n",
            "Year: 2017\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Compact coding has been widely applied to approximate nearest neighbor search for large-scale image retrieval, due to its computation efficiency and retrieval quality. This paper presents a compact coding solution with a focus on the deep learning to quantization approach, which improves retrieval quality by end-to-end representation learning and compact encoding and has already shown the superior performance over the hashing solutions for similarity retrieval. We propose Deep Visual-Semantic Quantization (DVSQ), which is the first approach to learning deep quantization models from labeled image data as well as the semantic information underlying general text domains. The main contribution lies in jointly learning deep visual-semantic embeddings and visual-semantic quantizers using carefully-designed hybrid networks and well-specified loss functions. DVSQ enables efficient and effective image retrieval by supporting maximum inner-product search, which is computed based on learned codebooks with fast distance table lookup. Comprehensive empirical evidence shows that DVSQ can generate compact binary codes and yield state-of-the-art similarity retrieval performance on standard benchmarks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: BioWordVec, improving biomedical word embeddings with subword information and MeSH\n",
            "Authors: Yijia Zhang, Qingyu Chen, Zhihao Yang, Hongfei Lin, Zhiyong Lu\n",
            "Year: 2019\n",
            "Venue: Scientific Data\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Hierarchical Attention Retrieval Model for Healthcare Question Answering\n",
            "Authors: Ming Zhu, Aman Ahuja, Wei Wei, Chandan K. Reddy\n",
            "Year: 2019\n",
            "Venue: The Web Conference\n",
            "Abstract: The growth of the Web in recent years has resulted in the development of various online platforms that provide healthcare information services. These platforms contain an enormous amount of information, which could be beneficial for a large number of people. However, navigating through such knowledgebases to answer specific queries of healthcare consumers is a challenging task. A majority of such queries might be non-factoid in nature, and hence, traditional keyword-based retrieval models do not work well for such cases. Furthermore, in many scenarios, it might be desirable to get a short answer that sufficiently answers the query, instead of a long document with only a small amount of useful information. In this paper, we propose a neural network model for ranking documents for question answering in the healthcare domain. The proposed model uses a deep attention mechanism at word, sentence, and document levels, for efficient retrieval for both factoid and non-factoid queries, on documents of varied lengths. Specifically, the word-level cross-attention allows the model to identify words that might be most relevant for a query, and the hierarchical attention at sentence and document levels allows it to do effective retrieval on both long and short documents. We also construct a new large-scale healthcare question-answering dataset, which we use to evaluate our model. Experimental evaluation results against several state-of-the-art baselines show that our model outperforms the existing retrieval techniques.\n",
            "\n",
            "---\n",
            "\n",
            "Title: WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval\n",
            "Authors: Daniel Cohen, Liu Yang, W. Bruce Croft\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: With the rise in mobile and voice search, answer passage retrieval acts as a critical component of an effective information retrieval system for open domain question answering. Currently, there are no comparable collections that address non-factoid question answering within larger documents while simultaneously providing enough examples sufficient to train a deep neural network. In this paper, we introduce a new Wikipedia based collection specific for non-factoid answer passage retrieval containing thousands of questions with annotated answers and show benchmark results on a variety of state of the art neural architectures and retrieval models. The experimental results demonstrate the unique challenges presented by answer passage retrieval within topically relevant documents for future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fairness and Discrimination in Retrieval and Recommendation\n",
            "Authors: Michael D. Ekstrand, R. Burke, Fernando Diaz\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Fairness and related concerns have become of increasing importance in a variety of AI and machine learning contexts. They are also highly relevant to information retrieval and related problems such as recommendation, as evidenced by the growing literature in SIGIR, FAT*, RecSys, and special sessions such as the FATREC workshop and the Fairness track at TREC 2019; however, translating algorithmic fairness constructs from classification, scoring, and even many ranking settings into information retrieval and recommendation scenarios is not a straightforward task. This tutorial will help to orient IR researchers to algorithmic fairness, understand how concepts do and do not translate from other settings, and provide an introduction to the growing literature on this topic.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-label Cross-Modal Retrieval\n",
            "Authors: Viresh Ranjan, Nikhil Rasiwasia, C. V. Jawahar\n",
            "Year: 2015\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: In this work, we address the problem of cross-modal retrieval in presence of multi-label annotations. In particular, we introduce multi-label Canonical Correlation Analysis (ml-CCA), an extension of CCA, for learning shared subspaces taking into account high level semantic information in the form of multi-label annotations. Unlike CCA, ml-CCA does not rely on explicit pairing between modalities, instead it uses the multi-label information to establish correspondences. This results in a discriminative subspace which is better suited for cross-modal retrieval tasks. We also present Fast ml-CCA, a computationally efficient version of ml-CCA, which is able to handle large scale datasets. We show the efficacy of our approach by conducting extensive cross-modal retrieval experiments on three standard benchmark datasets. The results show that the proposed approach achieves state of the art retrieval performance on the three datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The operational cloud retrieval algorithms from TROPOMI on board Sentinel-5 Precursor\n",
            "Authors: D. Loyola, S. G. García, R. Lutz, A. Argyrouli, F. Romahn, R. Spurr, Mattia Pedergnana, A. Doicu, V. M. García, Olena Schüssler\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: Abstract. This paper presents the operational cloud retrieval algorithms for\n",
            "the TROPOspheric Monitoring Instrument (TROPOMI) on board the European Space\n",
            "Agency Sentinel-5 Precursor (S5P) mission scheduled for launch in 2017. Two algorithms working in tandem are used for retrieving cloud properties:\n",
            "OCRA (Optical Cloud Recognition Algorithm) and ROCINN (Retrieval of Cloud\n",
            "Information using Neural Networks). OCRA retrieves the cloud fraction using\n",
            "TROPOMI measurements in the ultraviolet (UV) and visible (VIS) spectral regions, and ROCINN retrieves the\n",
            "cloud top height (pressure) and optical thickness (albedo) using TROPOMI\n",
            "measurements in and around the oxygen A -band in the near infrared (NIR). Cloud parameters from TROPOMI/S5P will be used not only for enhancing the\n",
            "accuracy of trace gas retrievals but also for extending the satellite data\n",
            "record of cloud information derived from oxygen A -band measurements, a record\n",
            "initiated with the Global Ozone Monitoring Experiment (GOME) on board the second European Remote-Sensing Satellite (ERS-2) over 20 years ago. The OCRA and ROCINN algorithms are integrated in the S5P operational\n",
            "processor UPAS (Universal Processor for UV/VIS/NIR Atmospheric\n",
            "Spectrometers), and we present here UPAS cloud results using the Ozone Monitoring Instrument (OMI) and GOME-2\n",
            "measurements. In addition, we examine anticipated challenges for the\n",
            "TROPOMI/S5P cloud retrieval algorithms, and we discuss the future validation\n",
            "needs for OCRA and ROCINN.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploiting Deep Features for Remote Sensing Image Retrieval: A Systematic Investigation\n",
            "Authors: Gui-Song Xia, Xin-Yi Tong, Fan Hu, Yanfei Zhong, M. Datcu, Liangpei Zhang\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Big Data\n",
            "Abstract: Remote sensing (RS) image retrieval is of great significant for geological information mining. Over the past two decades, a large amount of research on this task has been carried out, which mainly focuses on the following three core issues: feature extraction, similarity metric, and relevance feedback. Due to the complexity and multiformity of ground objects in high-resolution remote sensing (HRRS) images, there is still room for improvement in the current retrieval approaches. In this article, we analyze the three core issues of RS image retrieval and provide a comprehensive review on existing methods. Furthermore, for the goal to advance the state-of-the-art in HRRS image retrieval, we focus on the feature extraction issue and delve how to use powerful deep representations to address this task. We conduct systematic investigation on evaluating correlative factors that may affect the performance of deep features. By optimizing each factor, we acquire remarkable retrieval results on publicly available HRRS datasets. Finally, we explain the experimental phenomenon in detail and draw conclusions according to our analysis. Our work can serve as a guiding role for the research of content-based RS image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Legal Document Retrieval using Document Vector Embeddings and Deep Learning\n",
            "Authors: Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, A. Perera, Vindula Jayawardana, Dimuthu Lakmal, M. Perera\n",
            "Year: 2018\n",
            "Venue: Advances in Intelligent Systems and Computing\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Privacy-Preserving Smart Parking Navigation Supporting Efficient Driving Guidance Retrieval\n",
            "Authors: Jianbing Ni, Kuan Zhang, Yong Yu, Xiaodong Lin, X. Shen\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Vehicular Technology\n",
            "Abstract: It is frustrating and time consuming for drivers to find an available parking spot in a congested area, such as downtown and shopping malls, especially in peak hours. Thus, it is very helpful for drivers to have real-time parking information to assist them in finding vacant parking spots timely. Unfortunately, to acquire needed parking information, the drivers have to submit personal queries for the availability of parking spaces in their destinations, and this could result in privacy violation if the queries are not protected. To reduce drivers’ hassle and preserve drivers’ privacy, we propose a privacy-preserving smart parking navigation system (P-SPAN) with efficient navigation result retrieval for drivers using Bloom filters. P-SPAN enables a cloud to guide vehicles to vacant parking spaces in the destinations based on real-time parking information without disclosing any personal information about drivers. Specifically, an efficient data retrieval mechanism is developed based on Bloom filters to support navigation result retrieval for querying vehicles. The drivers can anonymously query accessible parking spots to the cloud, and efficiently retrieve the encrypted navigation results from the passing-by roadside units. Therefore, it is unnecessary for a vehicle to keep connected with the queried roadside unit for acquiring the navigation result. Performance evaluation demonstrates that P-SPAN can provide effective parking navigation with high navigation result retrieving probability and low computational and communication overhead.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards Large-Scale Histopathological Image Analysis: Hashing-Based Image Retrieval\n",
            "Authors: Xiaofan Zhang, W. Liu, Murat Dundar, S. Badve, Shaoting Zhang\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Medical Imaging\n",
            "Abstract: Automatic analysis of histopathological images has been widely utilized leveraging computational image-processing methods and modern machine learning techniques. Both computer-aided diagnosis (CAD) and content-based image-retrieval (CBIR) systems have been successfully developed for diagnosis, disease detection, and decision support in this area. Recently, with the ever-increasing amount of annotated medical data, large-scale and data-driven methods have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing scalable image-retrieval techniques to cope intelligently with massive histopathological images. Specifically, we present a supervised kernel hashing technique which leverages a small amount of supervised information in learning to compress a 10 \\thinspace000-dimensional image feature vector into only tens of binary bits with the informative signatures preserved. These binary codes are then indexed into a hash table that enables real-time retrieval of images in a large database. Critically, the supervised information is employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build a scalable image-retrieval framework based on the supervised hashing technique and validate its performance on several thousand histopathological images acquired from breast microscopic tissues. Extensive evaluations are carried out in terms of image classification (i.e., benign versus actionable categorization) and retrieval tests. Our framework achieves about 88.1% classification accuracy as well as promising time efficiency. For example, the framework can execute around 800 queries in only 0.01 s, comparing favorably with other commonly used dimensionality reduction and feature selection methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A surface reflectance scheme for retrieving aerosol optical depth over urbansurfaces in MODIS Dark Target retrieval algorithm\n",
            "Authors: Pawan Gupta, R. Levy, S. Mattoo, L. Remer, L. Munchak\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Abstract. The MODerate resolution Imaging Spectroradiometer (MODIS) instruments, aboard the two Earth Observing System (EOS) satellites Terra and Aqua, provide aerosol information with nearly daily global coverage at moderate spatial resolution (10 and 3 km). Almost 15 years of aerosol data records are now available from MODIS that can be used for various climate and air-quality applications. However, the application of MODIS aerosol products for air-quality concerns is limited by a reduction in retrieval accuracy over urban surfaces. This is largely because the urban surface reflectance behaves differently than that assumed for natural surfaces. In this study, we address the inaccuracies produced by the MODIS Dark Target (MDT) algorithm aerosol optical depth (AOD) retrievals over urban areas and suggest improvements by modifying the surface reflectance scheme in the algorithm. By integrating MODIS Land Surface Reflectance and Land Cover Type information into the aerosol surface parameterization scheme for urban areas, much of the issues associated with the standard algorithm have been mitigated for our test region, the continental United States (CONUS). The new surface scheme takes into account the change in underlying surface type and is only applied for MODIS pixels with urban percentage (UP) larger than 20 %. Over the urban areas where the new scheme has been applied (UP > 20 %), the number of AOD retrievals falling within expected error (EE %) has increased by 20 %, and the strong positive bias against ground-based sun photometry has been eliminated. However, we note that the new retrieval introduces a small negative bias for AOD values less than 0.1 due to the ultra-sensitivity of the AOD retrieval to the surface parameterization under low atmospheric aerosol loadings. Global application of the new urban surface parameterization appears promising, but further research and analysis are required before global implementation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions\n",
            "Authors: Peter Clark, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter D. Turney, Daniel Khashabi\n",
            "Year: 2016\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " What capabilities are required for an AI system to pass standard 4th Grade Science Tests? Previous work has examined the use of Markov Logic Networks (MLNs) to represent the requisite background knowledge and interpret test questions, but did not improve upon an information retrieval (IR) baseline. In this paper, we describe an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base, to achieve substantially improved results. We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions), and show that our overall system’s score is 71.3%, an improvement of 23.8% (absolute) over the MLN-based method described in previous work. We conclude with a detailed analysis, illustrating the complementary strengths of each method in the ensemble. Our datasets are being released to enable further research.\n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Parietal Representations of Stimulus Features Are Amplified during Memory Retrieval and Flexibly Aligned with Top-Down Goals\n",
            "Authors: Serra E. Favila, Rosalie Samide, Sarah C. Sweigart, Brice A. Kuhl\n",
            "Year: 2018\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: In studies of human episodic memory, the phenomenon of reactivation has traditionally been observed in regions of occipitotemporal cortex (OTC) involved in visual perception. However, reactivation also occurs in lateral parietal cortex (LPC), and recent evidence suggests that stimulus-specific reactivation may be stronger in LPC than in OTC. These observations raise important questions about the nature of memory representations in LPC and their relationship to representations in OTC. Here, we report two fMRI experiments that quantified stimulus feature information (color and object category) within LPC and OTC, separately during perception and memory retrieval, in male and female human subjects. Across both experiments, we observed a clear dissociation between OTC and LPC: while feature information in OTC was relatively stronger during perception than memory, feature information in LPC was relatively stronger during memory than perception. Thus, while OTC and LPC represented common stimulus features in our experiments, they preferentially represented this information during different stages. In LPC, this bias toward mnemonic information co-occurred with stimulus-level reinstatement during memory retrieval. In Experiment 2, we considered whether mnemonic feature information in LPC was flexibly and dynamically shaped by top-down retrieval goals. Indeed, we found that dorsal LPC preferentially represented retrieved feature information that addressed the current goal. In contrast, ventral LPC represented retrieved features independent of the current goal. Collectively, these findings provide insight into the nature and significance of mnemonic representations in LPC and constitute an important bridge between putative mnemonic and control functions of parietal cortex. SIGNIFICANCE STATEMENT When humans remember an event from the past, patterns of sensory activity that were present during the initial event are thought to be reactivated. Here, we investigated the role of lateral parietal cortex (LPC), a high-level region of association cortex, in representing prior visual experiences. We find that LPC contained stronger information about stimulus features during memory retrieval than during perception. We also found that current task goals influenced the strength of stimulus feature information in LPC during memory. These findings suggest that, in addition to early sensory areas, high-level areas of cortex, such as LPC, represent visual information during memory retrieval, and that these areas may play a special role in flexibly aligning memories with current goals.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Idea Grou p Inc . Copy right Idea Grou p Inc . Copy right Idea Grou p Inc . Copy right Idea Grou p Inc . Chapter II Bridging the Semantic Gap in Image Retrieval\n",
            "Authors: R. Zhao, W. Grosky\n",
            "Year: 2018\n",
            "Venue: \n",
            "Abstract: INTRODUCTION The emergence of multimedia technology and the rapidly expanding image and video collections on the Internet have attracted significant research efforts in providing tools for effective retrieval and management of visual data. Image retrieval is based on the availability of a representation scheme of image content. Image content descriptors may be visual features such as color, texture, shape, and spatial relationships, or semantic primitives. Conventional information retrieval was based solely on text, and those approaches to textual information retrieval have been transplanted into image retrieval in a variety of ways. However, a picture is worth a thousand words. Image content is much more versatile compared with text, and the amount of visual data is already enormous and still expanding very rapidly. Hoping to cope with these special characteristics of visual data, content-based image retrieval methods have been introduced. It has been widely recognized that the family of image retrieval techniques should become an integration of both low-level visual features addressing the more detailed perceptual aspects and high-level semantic features underlying the more general conceptual aspects of visual data. Neither of these two types of features is sufficient to retrieve or manage visual data in an effective or efficient way (Smeulders, et al., 2000). Although efforts have been devoted to combining these two aspects of visual data, the gap between them is still a huge barrier in front of researchers. Intuitive and heuristic approaches do not provide us with satisfactory performance. Therefore, there is an urgent need of finding the latent correlation between low-level features and high-level concepts and merging them from a different perspective. How to find this new perspective and bridge the gap between visual features and semantic features has been a major challenge in this research field. Our chapter addresses these issues.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Storage and retrieval of vector beams of light in a multiple-degree-of-freedom quantum memory\n",
            "Authors: V. Parigi, V. D’Ambrosio, C. Arnold, L. Marrucci, F. Sciarrino, J. Laurat\n",
            "Year: 2015\n",
            "Venue: Nature Communications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Semantic Topic Multimodal Hashing for Cross-Media Retrieval\n",
            "Authors: Di Wang, Xinbo Gao, Xiumei Wang, Lihuo He\n",
            "Year: 2015\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract: Multimodal hashing is essential to cross-media similarity search for its low storage cost and fast query speed. Most existing multimodal hashing methods embedded heterogeneous data into a common low-dimensional Hamming space, and then rounded the continuous embeddings to obtain the binary codes. Yet they usually neglect the inherent discrete nature of hashing for relaxing the discrete constraints, which will cause degraded retrieval performance especially for long codes. For this purpose, a novel Semantic Topic Multimodal Hashing (STMH) is developed by considering latent semantic information in coding procedure. It first discovers clustering patterns of texts and robust factorizes the matrix of images to obtain multiple semantic topics of texts and concepts of images. Then the learned multimodal semantic features are transformed into a common subspace by their correlations. Finally, each bit of unified hash code can be generated directly by figuring out whether a topic or concept is contained in a text or an image. Therefore, the obtained model by STMH is more suitable for hashing scheme as it directly learns discrete hash codes in the coding process. Experimental results demonstrate that the proposed method outperforms several state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Healthcare information on YouTube: A systematic review\n",
            "Authors: K. Madathil, A Joy Rivera-Rodriguez, J. Greenstein, A. Gramopadhye\n",
            "Year: 2015\n",
            "Venue: Health Informatics Journal\n",
            "Abstract: This article reviews the peer-reviewed literature addressing the healthcare information available on YouTube. Inclusion and exclusion criteria were determined, and the online databases PubMed and Web of Knowledge were searched using the search phrases: (1) YouTube* AND Health* and (2) YouTube* AND Healthcare*. In all, 18 articles were reviewed, with the results suggesting that (1) YouTube is increasingly being used as a platform for disseminating health information; (2) content and frame analysis were the primary techniques employed by researchers to analyze the characteristics of this information; (3) YouTube contains misleading information, primarily anecdotal, that contradicts the reference standards and the probability of a lay user finding such content is relatively high; (4) the retrieval of relevant videos is dependent on the search term used; and (5) videos from government organizations and professional associations contained trustworthy and high-quality information. YouTube is used as a medium for promoting unscientific therapies and drugs that are yet to be approved by the appropriate agencies and has the potential to change the beliefs of patients concerning controversial topics such as vaccinations. This review recognizes the need to design interventions to enable consumers to critically assimilate the information posted on YouTube with more authoritative information sources to make effective healthcare decisions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Continuous Word Embedding with Metadata for Question Retrieval in Community Question Answering\n",
            "Authors: Guangyou Zhou, Tingting He, Jun Zhao, P. Hu\n",
            "Year: 2015\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Community question answering (cQA) has become an important issue due to the popularity of cQA archives on the web. This paper is concerned with the problem of question retrieval. Question retrieval in cQA archives aims to find the existing questions that are semantically equivalent or relevant to the queried questions. However, the lexical gap problem brings about new challenge for question retrieval in cQA. In this paper, we propose to learn continuous word embeddings with metadata of category information within cQA pages for question retrieval. To deal with the variable size of word embedding vectors, we employ the framework of fisher kernel to aggregated them into the fixedlength vectors. Experimental results on large-scale real world cQA data set show that our approach can significantly outperform state-of-the-art translation models and topic-based models for question re-\n",
            "\n",
            "---\n",
            "\n",
            "Title: Teaching a New Dog Old Tricks: Resurrecting Multilingual Retrieval Using Zero-Shot Learning\n",
            "Authors: Sean MacAvaney, Luca Soldaini, Nazli Goharian\n",
            "Year: 2019\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal Feature Integration in the Angular Gyrus during Episodic and Semantic Retrieval\n",
            "Authors: Heidi M. Bonnici, Franziska R. Richter, Yasemin Yazar, J. Simons\n",
            "Year: 2016\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Much evidence from distinct lines of investigation indicates the involvement of angular gyrus (AnG) in the retrieval of both episodic and semantic information, but the region's precise function and whether that function differs across episodic and semantic retrieval have yet to be determined. We used univariate and multivariate fMRI analysis methods to examine the role of AnG in multimodal feature integration during episodic and semantic retrieval. Human participants completed episodic and semantic memory tasks involving unimodal (auditory or visual) and multimodal (audio-visual) stimuli. Univariate analyses revealed the recruitment of functionally distinct AnG subregions during the retrieval of episodic and semantic information. Consistent with a role in multimodal feature integration during episodic retrieval, significantly greater AnG activity was observed during retrieval of integrated multimodal episodic memories compared with unimodal episodic memories. Multivariate classification analyses revealed that individual multimodal episodic memories could be differentiated in AnG, with classification accuracy tracking the vividness of participants' reported recollections, whereas distinct unimodal memories were represented in sensory association areas only. In contrast to episodic retrieval, AnG was engaged to a statistically equivalent degree during retrieval of unimodal and multimodal semantic memories, suggesting a distinct role for AnG during semantic retrieval. Modality-specific sensory association areas exhibited corresponding activity during both episodic and semantic retrieval, which mirrored the functional specialization of these regions during perception. The results offer new insights into the integrative processes subserved by AnG and its contribution to our subjective experience of remembering. SIGNIFICANCE STATEMENT Using univariate and multivariate fMRI analyses, we provide evidence that functionally distinct subregions of angular gyrus (AnG) contribute to the retrieval of episodic and semantic memories. Our multivariate pattern classifier could distinguish episodic memory representations in AnG according to whether they were multimodal (audio-visual) or unimodal (auditory or visual) in nature, whereas statistically equivalent AnG activity was observed during retrieval of unimodal and multimodal semantic memories. Classification accuracy during episodic retrieval scaled with the trial-by-trial vividness with which participants experienced their recollections. Therefore, the findings offer new insights into the integrative processes subserved by AnG and how its function may contribute to our subjective experience of remembering.\n",
            "\n",
            "---\n",
            "\n",
            "Title: GEO matching regions: multiple regions of interests using content based image retrieval based on relative locations\n",
            "Authors: Muhammad Hammad Memon, Jianping Li, I. Memon, Q. Arain\n",
            "Year: 2017\n",
            "Venue: Multimedia tools and applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: ContextNet: representation and exploration for painting classification and retrieval in context\n",
            "Authors: Noa García, B. Renoust, Yuta Nakashima\n",
            "Year: 2019\n",
            "Venue: International Journal of Multimedia Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Feature extraction and image retrieval based on AlexNet\n",
            "Authors: Zhe Yuan, Jun Zhang\n",
            "Year: 2016\n",
            "Venue: International Conference on Digital Image Processing\n",
            "Abstract: Convolutional Neural Network is a hot research topic in image recognition. The latest research shows that Deep CNN model is good at extracting features and representing images. This capacity is applied to image retrieval in this paper. We study on the significance of each layer and do image retrieval experiments on the fusion features. Caffe framework and AlexNet model were used to extract the feature information about images. Two public image datasets, Inria Holidays and Oxford Buildings, were used in our experiment to search for the influence of different datasets. The results showed the fusion feature of Deep CNN model can improve the result of image retrieval and should apply different weights for different datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond Instance-Level Image Retrieval: Leveraging Captions to Learn a Global Visual Representation for Semantic Retrieval\n",
            "Authors: Albert Gordo, Diane Larlus\n",
            "Year: 2017\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Querying with an example image is a simple and intuitive interface to retrieve information from a visual database. Most of the research in image retrieval has focused on the task of instance-level image retrieval, where the goal is to retrieve images that contain the same object instance as the query image. In this work we move beyond instance-level retrieval and consider the task of semantic image retrieval in complex scenes, where the goal is to retrieve images that share the same semantics as the query image. We show that, despite its subjective nature, the task of semantically ranking visual scenes is consistently implemented across a pool of human annotators. We also show that a similarity based on human-annotated region-level captions is highly correlated with the human ranking and constitutes a good computable surrogate. Following this observation, we learn a visual embedding of the images where the similarity in the visual space is correlated with their semantic similarity surrogate. We further extend our model to learn a joint embedding of visual and textual cues that allows one to query the database using a text modifier in addition to the query image, adapting the results to the modifier. Finally, our model can ground the ranking decisions by showing regions that contributed the most to the similarity between pairs of images, providing a visual explanation of the similarity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Patent retrieval: a literature review\n",
            "Authors: W. Shalaby, Wlodek Zadrozny\n",
            "Year: 2017\n",
            "Venue: Knowledge and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Stochastic Multiview Hashing for Large-Scale Near-Duplicate Video Retrieval\n",
            "Authors: Y. Hao, Tingting Mu, Richang Hong, Meng Wang, Ning An, J. Y. Goulermas\n",
            "Year: 2017\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Near-duplicate video retrieval (NDVR) has been a significant research task in multimedia given its high impact in applications, such as video search, recommendation, and copyright protection. In addition to accurate retrieval performance, the exponential growth of online videos has imposed heavy demands on the efficiency and scalability of the existing systems. Aiming at improving both the retrieval accuracy and speed, we propose a novel stochastic multiview hashing algorithm to facilitate the construction of a large-scale NDVR system. Reliable mapping functions, which convert multiple types of keyframe features, enhanced by auxiliary information such as video-keyframe association and ground truth relevance to binary hash code strings, are learned by maximizing a mixture of the generalized retrieval precision and recall scores. A composite Kullback-Leibler divergence measure is used to approximate the retrieval scores, which aligns stochastically the neighborhood structures between the original feature and the relaxed hash code spaces. The efficiency and effectiveness of the proposed method are examined using two public near-duplicate video collections and are compared against various classical and state-of-the-art NDVR systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal Multimedia Retrieval with vitrivr\n",
            "Authors: Ralph Gasser, Luca Rossetto, H. Schuldt\n",
            "Year: 2019\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: The steady growth of multimedia collections - both in terms of size and heterogeneity - necessitates systems that are able to conjointly deal with several types of media as well as large volumes of data. This is especially true when it comes to satisfying a particular information need, i.e., retrieving a particular object of interest from a large collection. Nevertheless, existing multimedia management and retrieval systems are mostly organized in silos and treat different media types separately. Hence, they are limited when it comes to crossing these silos for accessing objects. In this paper, we present vitrivr, a general-purpose content-based multimedia retrieval stack. In addition to the keyword search provided by most media management systems, vitrivr also exploits the object's content in order to facilitate different types of similarity search. This can be done within and, most importantly, across different media types giving rise to new, interesting use cases. To the best of our knowledge, the full vitrivr stack is unique in that it seamlessly integrates support for four different types of media, namely images, audio, videos, and 3D models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval Algorithms Optimized for Human Learning\n",
            "Authors: Rohail Syed, Kevyn Collins-Thompson\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: While search technology is widely used for learning-oriented information needs, the results provided by popular services such as Web search engines are optimized primarily for generic relevance, not effective learning outcomes. As a result, the typical information trail that a user must follow while searching to achieve a learning goal may be an inefficient one involving unnecessarily easy or difficult content, or material that is irrelevant to actual learning progress relative to a user's existing knowledge. We address this problem by introducing a novel theoretical framework, algorithms, and empirical analysis of an information retrieval model that is optimized for learning outcomes instead of generic relevance. We do this by formulating an optimization problem that incorporates a cognitive learning model into a retrieval objective, and then give an algorithm for an efficient approximate solution to find the search results that represent the best 'training set' for a human learner. Our model can personalize results for an individual user's learning goals, as well as account for the effort required to achieve those goals for a given set of retrieval results. We investigate the effectiveness and efficiency of our retrieval framework relative to a commercial search engine baseline ('Google') through a crowdsourced user study involving a vocabulary learning task, and demonstrate the effectiveness of personalized results from our model on word learning outcomes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Searching Data: A Review of Observational Data Retrieval Practices in Selected Disciplines\n",
            "Authors: Kathleen Gregory, Paul T. Groth, Helena Cousijn, A. Scharnhorst, S. Wyatt\n",
            "Year: 2017\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: A cross‐disciplinary examination of the user behaviors involved in seeking and evaluating data is surprisingly absent from the research data discussion. This review explores the data retrieval literature to identify commonalities in how users search for and evaluate observational research data in selected disciplines. Two analytical frameworks, rooted in information retrieval and science and technology studies, are used to identify key similarities in practices as a first step toward developing a model describing data retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A System for Efficient High-Recall Retrieval\n",
            "Authors: Mustafa Abualsaud, Nimesh Ghelani, Haotian Zhang, Mark D. Smucker, G. Cormack, Maura R. Grossman\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The goal of high-recall information retrieval (HRIR) is to find all or nearly all relevant documents for a search topic. In this paper, we present the design of our system that affords efficient high-recall retrieval. HRIR systems commonly rely on iterative relevance feedback. Our system uses a state-of-the-art implementation of continuous active learning (CAL), and is designed to allow other feedback systems to be attached with little work. Our system allows users to judge documents as fast as possible with no perceptible interface lag. We also support the integration of a search engine for users who would like to interactively search and judge documents. In addition to detailing the design of our system, we report on user feedback collected as part of a 50 participants user study. While we have found that users find the most relevant documents when we restrict user interaction, a majority of participants prefer having flexibility in user interaction. Our work has implications on how to build effective assessment systems and what features of the system are believed to be useful by users.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Minimum Information about a Biosynthetic Gene cluster.\n",
            "Authors: M. Medema, R. Kottmann, Pelin Yilmaz, M. Cummings, J. Biggins, K. Blin, I. de Bruijn, Y. Chooi, Jan Claesen, R. Coates, Pablo Cruz-Morales, Srikanth Duddela, Stephanie Düsterhus, D. J. Edwards, D. Fewer, Neha Garg, Christoph Geiger, J. Gomez-Escribano, Anja Greule, Michalis Hadjithomas, A. Haines, Eric J. N. Helfrich, Matthew L. Hillwig, K. Ishida, Adam C. Jones, Carla S. Jones, K. Jungmann, Carsten Kegler, H. Kim, P. Kötter, D. Krug, J. Masschelein, A. Melnik, S. M. Mantovani, Emily A. Monroe, M. Moore, N. Moss, Hans-Wilhelm Nützmann, Guohui Pan, Amrita Pati, D. Petráš, F. Reen, Federico Rosconi, Z. Rui, Zhenhua Tian, Nicholas J. Tobias, Y. Tsunematsu, Philipp Wiemann, E. Wyckoff, Xiaohui Yan, Grace Yim, F. Yu, Yunchang Xie, B. Aigle, A. Apel, C. Balibar, E. Balskus, F. Barona-Gómez, A. Bechthold, H. Bode, R. Borriss, S. Brady, A. Brakhage, P. Caffrey, Yi-Qiang Cheng, J. Clardy, Russell John Cox, R. De Mot, S. Donadio, M. Donia, W. A. van der Donk, P. Dorrestein, S. Doyle, A. Driessen, M. Ehling-Schulz, K. Entian, M. Fischbach, L. Gerwick, W. Gerwick, H. Gross, B. Gust, C. Hertweck, M. Höfte, S. Jensen, J. Ju, L. Katz, Leonard Kaysser, J. Klassen, N. Keller, J. Kormanec, O. Kuipers, T. Kuzuyama, N. Kyrpides, H. Kwon, S. Lautru, R. Lavigne, Chia Y. Lee, B. Linquan, Xinyu Liu, Wen Liu, A. Luzhetskyy, T. Mahmud, Yvonne Mast, C. Méndez, M. Metsä‐Ketelä, Jason Micklefield, D. Mitchell, B. Moore, L. M. Moreira, R. Müller, B. Neilan, M. Nett, J. Nielsen, F. O'Gara, H. Oikawa, A. Osbourn, M. Osburne, B. Ostash, Shelley M. Payne, J. Pernodet, M. Petříček, J. Piel, O. Ploux, J. Raaijmakers, J. Salas, E. Schmitt, B. Scott, R. Seipke, B. Shen, D. Sherman, K. Sivonen, M. Smanski, M. Sosio, E. Stegmann, R. Süssmuth, K. Tahlan, Christopher M Thomas, Yi Tang, A. Truman, M. Viaud, J. Walton, C. Walsh, T. Weber, G. V. van Wezel, B. Wilkinson, J. Willey, W. Wohlleben, Gerard D. Wright, N. Ziemert, Changsheng Zhang, S. Zotchev, R. Breitling, E. Takano, F. Glöckner\n",
            "Year: 2015\n",
            "Venue: Nature Chemical Biology\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Healthy ageing reduces the precision of episodic memory retrieval\n",
            "Authors: Saana M. Korkki, Franziska R. Richter, Priyanga Jeyarathnarajah, J. Simons\n",
            "Year: 2018\n",
            "Venue: bioRxiv\n",
            "Abstract: Episodic memory declines with older age, but it is unresolved whether this decline reflects reduced probability of successfully retrieving information from memory, or decreased precision of the retrieved information. Here, we used continuous measures of episodic memory retrieval in combination with computational modelling of participants’ retrieval errors to distinguish between these two potential accounts of age-related memory deficits. In three experiments, young and older participants encoded stimuli displays consisting of everyday objects varying along different perceptual features (e.g., location, colour and orientation) in a circular space. At test, participants recreated the features of studied objects using a continuous response dial. Across all three experiments, we observed age-related declines in the precision of episodic memory retrieval, whereas age differences in retrieval success were limited to the most challenging task condition. Reductions in mnemonic precision were evident for retrieval of both item-based and contextual information, and persisted after controlling for age-related decreases in the fidelity of perception and working memory. The findings highlight impoverished precision of memory representations as one factor contributing to age-related episodic memory loss, and suggest that the cognitive and neural changes associated with older age can differentially affect distinct aspects of episodic retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Weakly Supervised Deep Metric Learning for Community-Contributed Image Retrieval\n",
            "Authors: Zechao Li, Jinhui Tang\n",
            "Year: 2015\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Recent years have witnessed the explosive growth of community-contributed images with rich context information, which is beneficial to the task of image retrieval. It can help us to learn a suitable metric to alleviate the semantic gap. In this paper, we propose a new distance metric learning algorithm, namely weakly-supervised deep metric learning (WDML), under the deep learning framework. It utilizes a progressive learning manner to discover knowledge by jointly exploiting the heterogeneous data structures from visual contents and user-provided tags of social images. The semantic structure in the textual space is expected to be well preserved while the problem of the noisy, incomplete or subjective tags is addressed by leveraging the visual structure in the original visual space. Besides, a sparse model with the l2,1 mixed norm is imposed on the transformation matrix of the first layer in the deep architecture to compress the noisy or redundant visual features. The proposed problem is formulated as an optimization problem with a well-defined objective function and a simple yet efficient iterative algorithm is proposed to solve it. Extensive experiments on real-world social image datasets are conducted to verify the effectiveness of the proposed method for image retrieval. Encouraging experimental results are achieved compared with several representative metric learning methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Biomartr: genomic data retrieval with R\n",
            "Authors: Hajk-Georg Drost, J. Paszkowski\n",
            "Year: 2017\n",
            "Venue: Bioinform.\n",
            "Abstract: Motivation: Retrieval and reproducible functional annotation of genomic data are crucial in biology. However, the current poor usability and transparency of retrieval methods hinders reproducibility. Here we present an open source R package, biomartr, which provides a comprehensive easy‐to‐use framework for automating data retrieval and functional annotation for meta‐genomic approaches. The functions of biomartr achieve a high degree of clarity, transparency and reproducibility of analyses. Results: The biomartr package implements straightforward functions for bulk retrieval of all genomic data or data for selected genomes, proteomes, coding sequences and annotation files present in databases hosted by the National Center for Biotechnology Information (NCBI) and European Bioinformatics Institute (EMBL‐EBI). In addition, biomartr communicates with the BioMart database for functional annotation of retrieved sequences. Comprehensive documentation of biomartr functions and five tutorial vignettes provide step‐by‐step instructions on how to use the package in a reproducible manner. Availability and Implementation: The open source biomartr package is available at https://github.com/HajkD/biomartr and https://cran.r‐project.org/web/packages/biomartr/index.html. Contact: hgd23@cam.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Web Forum Retrieval and Text Analytics: A Survey\n",
            "Authors: Doris Hoogeveen, Li Wang, Timothy Baldwin, Karin M. Verspoor\n",
            "Year: 2018\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: This survey presents an overview of information retrieval, natural languageprocessing and machine learning research that makes use of forumdata, including both discussion forums and community questionansweringcQA archives. The focus is on automated analysis, withthe goal of gaining a better understanding of the data and its users.We discuss the different strategies used for both retrieval taskspost retrieval, question retrieval, and answer retrieval and classificationtasks post type classification, question classification, post qualityassessment, subjectivity, and viewpoint classification at the postlevel, as well as at the thread level thread retrieval, solvedness andtask orientation, discourse structure recovery and dialogue act tagging,QA-pair extraction, and thread summarisation. We also review workon forum users, including user satisfaction, expert finding, questionrecommendation and routing, and community analysis.The survey includes a brief history of forums, an overview of thedifferent kinds of forums, a summary of publicly available datasets forforum research, and a short discussion on the evaluation of retrievaltasks using forum data.The aim is to give a broad overview of the different kinds of forumresearch, a summary of the methods that have been applied, some insightsinto successful strategies, and potential areas for future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fairness in Information Access Systems\n",
            "Authors: Michael D. Ekstrand, Anubrata Das, R. Burke, Fernando Diaz\n",
            "Year: 2021\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Recommendation, information retrieval, and other information access systems pose unique challenges for investigating and applying the fairness and non-discrimination concepts that have been developed for studying other machine learning systems. While fair information access shares many commonalities with fair classification, the multistakeholder nature of information access applications, the rank-based problem setting, the centrality of personalization in many cases, and the role of user response complicate the problem of identifying precisely what types and operationalizations of fairness may be relevant, let alone measuring or promoting them. In this monograph, we present a taxonomy of the various dimensions of fair information access and survey the literature to date on this new and rapidly-growing topic. We preface this with brief introductions to information access and algorithmic fairness, to facilitate use of this work by scholars with experience in one (or neither) of these fields who wish to learn about their intersection. We conclude with several open problems in fair information access, along with some suggestions for how to approach research in this space.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Local Wavelet Pattern: A New Feature Descriptor for Image Retrieval in Medical CT Databases\n",
            "Authors: S. Dubey, S. Singh, R. Singh\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: A new image feature description based on the local wavelet pattern (LWP) is proposed in this paper to characterize the medical computer tomography (CT) images for content-based CT image retrieval. In the proposed work, the LWP is derived for each pixel of the CT image by utilizing the relationship of center pixel with the local neighboring information. In contrast to the local binary pattern that only considers the relationship between a center pixel and its neighboring pixels, the presented approach first utilizes the relationship among the neighboring pixels using local wavelet decomposition, and finally considers its relationship with the center pixel. A center pixel transformation scheme is introduced to match the range of center value with the range of local wavelet decomposed values. Moreover, the introduced local wavelet decomposition scheme is centrally symmetric and suitable for CT images. The novelty of this paper lies in the following two ways: 1) encoding local neighboring information with local wavelet decomposition and 2) computing LWP using local wavelet decomposed values and transformed center pixel values. We tested the performance of our method over three CT image databases in terms of the precision and recall. We also compared the proposed LWP descriptor with the other state-of-the-art local image descriptors, and the experimental results suggest that the proposed method outperforms other methods for CT image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Local Wavelet Pattern: A New Feature Descriptor for Image Retrieval in Medical CT Databases\n",
            "Authors: S. Dubey, S. Singh, R. Singh\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: A new image feature description based on the local wavelet pattern (LWP) is proposed in this paper to characterize the medical computer tomography (CT) images for content-based CT image retrieval. In the proposed work, the LWP is derived for each pixel of the CT image by utilizing the relationship of center pixel with the local neighboring information. In contrast to the local binary pattern that only considers the relationship between a center pixel and its neighboring pixels, the presented approach first utilizes the relationship among the neighboring pixels using local wavelet decomposition, and finally considers its relationship with the center pixel. A center pixel transformation scheme is introduced to match the range of center value with the range of local wavelet decomposed values. Moreover, the introduced local wavelet decomposition scheme is centrally symmetric and suitable for CT images. The novelty of this paper lies in the following two ways: 1) encoding local neighboring information with local wavelet decomposition and 2) computing LWP using local wavelet decomposed values and transformed center pixel values. We tested the performance of our method over three CT image databases in terms of the precision and recall. We also compared the proposed LWP descriptor with the other state-of-the-art local image descriptors, and the experimental results suggest that the proposed method outperforms other methods for CT image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Test Collection for Interactive Lifelog Retrieval\n",
            "Authors: C. Gurrin, Klaus Schöffmann, Hideo Joho, Bernd Münzer, Rami Albatal, F. Hopfgartner, Liting Zhou, Duc-Tien Dang-Nguyen\n",
            "Year: 2018\n",
            "Venue: Conference on Multimedia Modeling\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Natural‐Language‐Based Approach to Intelligent Data Retrieval and Representation for Cloud BIM\n",
            "Authors: Jia-Rui Lin, Zhen-Zhong Hu, Jianping Zhang, F. Yu\n",
            "Year: 2016\n",
            "Venue: Comput. Aided Civ. Infrastructure Eng.\n",
            "Abstract: As the information from diverse disciplines continues to integrate during the whole life cycle of an Architecture, Engineering, and Construction (AEC) project, the BIM (Building Information Model/Modeling) becomes increasingly large. This condition will cause users difficulty in acquiring the information they truly desire on a mobile device with limited space for interaction. The situation will be even worse for personnel without extensive knowledge of Industry Foundation Classes (IFC) or for nonexperts of the BIM software. To improve the value of the big data of BIM, an approach to intelligent data retrieval and representation for cloud BIM applications based on natural language processing was proposed. First, strategies for data storage and query acceleration based on the popular cloud‐based database were explored to handle the large amount of BIM data. Then, the concepts “keyword” and “constraint” were proposed to capture the key objects and their specifications in a natural‐language‐based sentence that expresses the requirements of the user. Keywords and constraints can be mapped to IFC entities or properties through the International Framework for Dictionaries (IFD). The relationship between the user's requirement and the IFC‐based data model was established by path finding in a graph generated from the IFC schema, enabling data retrieval and analysis. Finally, the analyzed and summarized results of BIM data were represented based on the structure of the retrieved data. A prototype application was developed to validate the proposed approach on the data collected during the construction of the terminal of Kunming Airport, the largest single building in China. The case study illustrated the following: (1) relationships between the user requirements and the data users concerned are established, (2) user‐concerned data can be automatically retrieved and aggregated based on the cloud for BIM, and (3) the data are represented in a proper form for a visual view and a comprehensive report. With this approach, users can significantly benefit from requesting for information and the value of BIM will be enhanced.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Private function retrieval\n",
            "Authors: Mahtab Mirmohseni, M. Maddah-ali\n",
            "Year: 2017\n",
            "Venue: Iran Workshop on Communication and Information Theory\n",
            "Abstract: The widespread use of cloud computing services raises the question of how one can delegate the processing tasks to the untrusted distributed parties without breaching the privacy of its data and algorithms. Motivated by the algorithm privacy concerns in a distributed computing system, in this paper, we introduce the private function retrieval (PFR) problem, where a user wishes to efficiently retrieve a linear function of K messages from N non-communicating replicated servers while keeping the function hidden from each individual server. The goal is to find a scheme with minimum communication cost. To characterize the fundamental limits of the communication cost, we define the capacity of PFR problem as the maximum size of the message that can be privately retrieved (which is the size of one file) normalized to the required downloaded information bits. We first show that for the PFR problem with K messages, N = 2 servers and a linear function with binary coefficients the capacity is C = 1/2 (1-1/2K)−1. Interestingly, this is the capacity of retrieving one of K messages from N = 2 servers while keeping the index of the requested message hidden from each individual server, the problem known as private information retrieval (PIR). Then, we extend the proposed achievable scheme to the case of arbitrary number of servers and coefficients in the field GF (q) with arbitrary q and obtain an achievable rate R = (1-1/N)(1+1/N-1/(qK-1/q-1)N-1.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Document Retrieval Model Through Semantic Linking\n",
            "Authors: F. Ensan, E. Bagheri\n",
            "Year: 2017\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: This paper addresses the task of document retrieval based on the degree of document relatedness to the meanings of a query by presenting a semantic-enabled language model. Our model relies on the use of semantic linking systems for forming a graph representation of documents and queries, where nodes represent concepts extracted from documents and edges represent semantic relatedness between concepts. Based on this graph, our model adopts a probabilistic reasoning model for calculating the conditional probability of a query concept given values assigned to document concepts. We present an integration framework for interpolating other retrieval systems with the presented model in this paper. Our empirical experiments on a number of TREC collections show that the semantic retrieval has a synergetic impact on the results obtained through state of the art keyword-based approaches, and the consideration of semantic information obtained from entity linking on queries and documents can complement and enhance the performance of other retrieval models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effective deep learning-based multi-modal retrieval\n",
            "Authors: Wei Wang, Xiaoyan Yang, B. Ooi, Dongxiang Zhang, Yueting Zhuang\n",
            "Year: 2015\n",
            "Venue: The VLDB journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neighborhood Discriminant Hashing for Large-Scale Image Retrieval\n",
            "Authors: Jinhui Tang, Zechao Li, Meng Wang, Ruizhen Zhao\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: With the proliferation of large-scale community-contributed images, hashing-based approximate nearest neighbor search in huge databases has aroused considerable interest from the fields of computer vision and multimedia in recent years because of its computational and memory efficiency. In this paper, we propose a novel hashing method named neighborhood discriminant hashing (NDH) (for short) to implement approximate similarity search. Different from the previous work, we propose to learn a discriminant hashing function by exploiting local discriminative information, i.e., the labels of a sample can be inherited from the neighbor samples it selects. The hashing function is expected to be orthogonal to avoid redundancy in the learned hashing bits as much as possible, while an information theoretic regularization is jointly exploited using maximum entropy principle. As a consequence, the learned hashing function is compact and nonredundant among bits, while each bit is highly informative. Extensive experiments are carried out on four publicly available data sets and the comparison results demonstrate the outperforming performance of the proposed NDH method over state-of-the-art hashing techniques.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval\n",
            "Authors: Anan Liu, Weizhi Nie, Yue Gao, Yuting Su\n",
            "Year: 2016\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Multi-view matching is an important but a challenging task in view-based 3D model retrieval. To address this challenge, we propose an original multi-modal clique graph (MCG) matching method in this paper. We systematically present a method for MCG generation that is composed of cliques, which consist of neighbor nodes in multi-modal feature space and hyper-edges that link pairwise cliques. Moreover, we propose an image set-based clique/edgewise similarity measure to address the issue of the set-to-set distance measure, which is the core problem in MCG matching. The proposed MCG provides the following benefits: 1) preserves the local and global attributes of a graph with the designed structure; 2) eliminates redundant and noisy information by strengthening inliers while suppressing outliers; and 3) avoids the difficulty of defining high-order attributes and solving hyper-graph matching. We validate the MCG-based 3D model retrieval using three popular single-modal data sets and one novel multi-modal data set. Extensive experiments show the superiority of the proposed method through comparisons. Moreover, we contribute a novel real-world 3D object data set, the multi-view RGB-D object data set. To the best of our knowledge, it is the largest real-world 3D object data set containing multi-modal and multi-view information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SHREC’16 Track Large-Scale 3D Shape Retrieval from ShapeNet Core55\n",
            "Authors: M. Savva, F. Yu, Hao Su, M. Aono, B. Chen, D. Cohen-Or, W. Deng, Hang Su, S. Bai, X. Bai, N. Fish, J. Han, E. Kalogerakis, E. Learned-Miller, Y. Li, M. Liao, S. Maji, A. Tatsuma, Y. Wang, N. Zhang, Z. Zhou\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: With the advent of commodity 3D capturing devices and better 3D modeling tools, 3D shape content is becoming increasingly prevalent. Therefore, the need for shape retrieval algorithms to handle large-scale shape repositories is more and more important. This track aims to provide a benchmark to evaluate large-scale shape retrieval based on the ShapeNet dataset. We use ShapeNet Core55, which provides more than 50 thousands models over 55 common categories in total for training and evaluating several algorithms. Five participating teams have submitted a variety of retrieval methods which were evaluated on several standard information retrieval performance metrics. We ﬁnd the submitted methods work reasonably well on the track benchmark, but we also see signiﬁcant space for improvement by future algorithms. We release all the data, results, and evaluation code for the beneﬁt of the community.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Computer-Aided Diagnosis of Mammographic Masses Using Scalable Image Retrieval\n",
            "Authors: Menglin Jiang, Shaoting Zhang, Hongsheng Li, Dimitris N. Metaxas\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Biomedical Engineering\n",
            "Abstract: Computer-aided diagnosis of masses in mammograms is important to the prevention of breast cancer. Many approaches tackle this problem through content-based image retrieval techniques. However, most of them fall short of scalability in the retrieval stage, and their diagnostic accuracy is, therefore, restricted. To overcome this drawback, we propose a scalable method for retrieval and diagnosis of mammographic masses. Specifically, for a query mammographic region of interest (ROI), scale-invariant feature transform (SIFT) features are extracted and searched in a vocabulary tree, which stores all the quantized features of previously diagnosed mammographic ROIs. In addition, to fully exert the discriminative power of SIFT features, contextual information in the vocabulary tree is employed to refine the weights of tree nodes. The retrieved ROIs are then used to determine whether the query ROI contains a mass. The presented method has excellent scalability due to the low spatial-temporal cost of vocabulary tree. Extensive experiments are conducted on a large dataset of 11 553 ROIs extracted from the digital database for screening mammography, which demonstrate the accuracy and scalability of our approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dynamic neural architecture for social knowledge retrieval\n",
            "Authors: Y. Wang, Jessica A. Collins, Jessica E Koski, T. Nugiel, Athanasia Metoki, I. Olson\n",
            "Year: 2017\n",
            "Venue: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Abstract: Significance Knowledge about other people is critical for group survival and may have unique cognitive processing demands. Here, we investigate how person knowledge is represented, organized, and retrieved in the brain. We show that the anterior temporal lobe (ATL) stores abstract person identity representation that is commonly embedded in multiple sources (e.g. face, name, scene, and personal object). We also found the ATL serves as a “neural switchboard,” coordinating with a network of other brain regions in a rapid and need-specific way to retrieve different aspects of biographical information (e.g., occupation and personality traits). Our findings endorse the ATL as a central hub for representing and retrieving person knowledge. Social behavior is often shaped by the rich storehouse of biographical information that we hold for other people. In our daily life, we rapidly and flexibly retrieve a host of biographical details about individuals in our social network, which often guide our decisions as we navigate complex social interactions. Even abstract traits associated with an individual, such as their political affiliation, can cue a rich cascade of person-specific knowledge. Here, we asked whether the anterior temporal lobe (ATL) serves as a hub for a distributed neural circuit that represents person knowledge. Fifty participants across two studies learned biographical information about fictitious people in a 2-d training paradigm. On day 3, they retrieved this biographical information while undergoing an fMRI scan. A series of multivariate and connectivity analyses suggest that the ATL stores abstract person identity representations. Moreover, this region coordinates interactions with a distributed network to support the flexible retrieval of person attributes. Together, our results suggest that the ATL is a central hub for representing and retrieving person knowledge.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Planning Education for Long-Term Retention: The Cognitive Science and Implementation of Retrieval Practice\n",
            "Authors: Douglas P. Larsen\n",
            "Year: 2018\n",
            "Venue: Seminars in neurology\n",
            "Abstract: Abstract Educational systems are rarely designed for long-term retention of information. Strong evidence has emerged from cognitive psychology and applied education studies that repeated retrieval of information significantly improves retention compared to repeated studying. This effect likely emerges from the processes of memory consolidation and reconsolidation. Consolidation and reconsolidation are the means by which memories are organized into associational networks or schemas that are created and recreated as memories are formed and recalled. As educators implement retrieval practice, they should consider how various test formats lead to different degrees of schema activation. Repeated acts of retrieval provide opportunities for schemas to be updated and strengthened. Spacing of retrieval allows more consolidated schemas to be reactivated. Feedback provides metacognitive monitoring to ensure retrieval accuracy and can lead to shifts from ineffective to effective retrieval strategies. By using the principles of retrieval practice, educators can improve the likelihood that learners will retain information for longer periods of time.\n",
            "\n",
            "---\n",
            "\n",
            "Title: State-of-the-art in biomedical literature retrieval for clinical cases: a survey of the TREC 2014 CDS track\n",
            "Authors: Kirk Roberts, Matthew S. Simpson, Dina Demner-Fushman, E. Voorhees, W. Hersh\n",
            "Year: 2016\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Delay-dependent contributions of medial temporal lobe regions to episodic memory retrieval\n",
            "Authors: Maureen Ritchey, Maria E. Montchal, A. Yonelinas, C. Ranganath\n",
            "Year: 2015\n",
            "Venue: eLife\n",
            "Abstract: The medial temporal lobes play an important role in episodic memory, but over time, hippocampal contributions to retrieval may be diminished. However, it is unclear whether such changes are related to the ability to retrieve contextual information, and whether they are common across all medial temporal regions. Here, we used functional neuroimaging to compare neural responses during immediate and delayed recognition. Results showed that recollection-related activity in the posterior hippocampus declined after a 1-day delay. In contrast, activity was relatively stable in the anterior hippocampus and in neocortical areas. Multi-voxel pattern similarity analyses also revealed that anterior hippocampal patterns contained information about context during item recognition, and after a delay, context coding in this region was related to successful retention of context information. Together, these findings suggest that the anterior and posterior hippocampus have different contributions to memory over time and that neurobiological models of memory must account for these differences. DOI: http://dx.doi.org/10.7554/eLife.05025.001\n",
            "\n",
            "---\n",
            "\n",
            "Title: Benchmark for Complex Answer Retrieval\n",
            "Authors: F. Nanni, Bhaskar Mitra, Matthew Magnusson, Laura Dietz\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Providing answers to complex information needs is a challenging task. The new TREC Complex Answer Retrieval (TREC CAR) track introduces a large-scale dataset where paragraphs are to be retrieved in response to outlines of Wikipedia articles representing complex information needs. We present early results from a variety of approaches -- from standard information retrieval methods (e.g., TF-IDF) to complex systems that adopt query expansion, knowledge bases and deep neural networks. The goal is to offer an overview of some promising approaches to tackle this problem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Asking Clarifying Questions in Open-Domain Information-Seeking Conversations\n",
            "Authors: Mohammad Aliannejadi, Hamed Zamani, F. Crestani, W. Bruce Croft\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Users often fail to formulate their complex information needs in a single query. As a consequence, they may need to scan multiple result pages or reformulate their queries, which may be a frustrating experience. Alternatively, systems can improve user satisfaction by proactively asking questions of the users to clarify their information needs. Asking clarifying questions is especially important in conversational systems since they can only return a limited number of (often only one) result(s). In this paper, we formulate the task of asking clarifying questions in open-domain information-seeking conversational systems. To this end, we propose an offline evaluation methodology for the task and collect a dataset, called Qulac, through crowdsourcing. Our dataset is built on top of the TREC Web Track 2009-2012 data and consists of over 10K question-answer pairs for 198 TREC topics with 762 facets. Our experiments on an oracle model demonstrate that asking only one good question leads to over 170% retrieval performance improvement in terms of P@1, which clearly demonstrates the potential impact of the task. We further propose a retrieval framework consisting of three components: question retrieval, question selection, and document retrieval. In particular, our question selection model takes into account the original query and previous question-answer interactions while selecting the next question. Our model significantly outperforms competitive baselines. To foster research in this area, we have made Qulac publicly available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discrete Multi-view Hashing for Effective Image Retrieval\n",
            "Authors: Rui Yang, Yuliang Shi, Xin-Shun Xu\n",
            "Year: 2017\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Recently, hashing techniques have witnessed an increase in popularity due to their low storage cost and high query speed for large scale data retrieval task, e.g., image retrieval. Many methods have been proposed; however, most existing hashing techniques focus on single view data. In many scenarios, there are multiple views in data samples. Thus, those methods working on single view can not make full use of rich information contained in multi-view data. Although some methods have been proposed for multi-view data; they usually relax binary constraints or separate the process of learning hash functions and binary codes into two independent stages to bypass the obstacle of handling the discrete constraints on binary codes for optimization, which may generate large quantization error. To consider these problems, in this paper, we propose a novel hashing method, i.e., Discrete Multi-view Hashing (DMVH), which can work on multi-view data directly and make full use of rich information in multi-view data. Moreover, in DMVH, we optimize discrete codes directly instead of relaxing the binary constraints so that we could obtain high-quality hash codes. Simultaneously, we present a novel approach to construct similarity matrix, which can not only preserve local similarity structure, but also keep semantic similarity between data points. To solve the optimization problem in DMVH, we further propose an alternate algorithm. We test the proposed model on three large scale data sets. Experimental results show that it outperforms or is comparable to several state-of-the-arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval Consistency in the Presence of Query Variations\n",
            "Authors: P. Bailey, Alistair Moffat, Falk Scholer, Paul Thomas\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: A search engine that can return the ideal results for a person's information need, independent of the specific query that is used to express that need, would be preferable to one that is overly swayed by the individual terms used; search engines should be consistent in the presence of syntactic query variations responding to the same information need. In this paper we examine the retrieval consistency of a set of five systems responding to syntactic query variations over one hundred topics, working with the UQV100 test collection, and using Rank-Biased Overlap (RBO) relative to a centroid ranking over the query variations per topic as a measure of consistency. We also introduce a new data fusion algorithm, Rank-Biased Centroid (RBC), for constructing a centroid ranking over a set of rankings from query variations for a topic. RBC is compared with alternative data fusion algorithms. Our results indicate that consistency is positively correlated to a moderate degree with \"deep'' relevance measures. However, it is only weakly correlated with \"shallow'' relevance measures, as well as measures of topic complexity and variety in query expression. These findings support the notion that consistency is an independent property of a search engine's retrieval effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: on Information and Communication Technologies\n",
            "Authors: Sharmila Kumari, Li Sun, Guizhong Liu, Huan Wang, Rui Su, quot\n",
            "Year: 2020\n",
            "Venue: \n",
            "Abstract: Video text information plays an important role in semantic-based video analysis, indexing and retrieval. It is observed that the detection of texts in video remains as a challenging task due to its complex varying conditions. In this paper, we present a study on local features based text detection in document images and more focus is provided for text detection based on Laplacian method. The document image is convolved with Laplacian operator to filter the document image. Then the maximum gradient difference value is computed for each pixel to generate threshold. Based on the computed threshold, a binarized frame is obtained which highlights the text block. The candidate text block regions are further verified and refined that is, the\n",
            "\n",
            "---\n",
            "\n",
            "Title: Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems\n",
            "Authors: Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, Ming Zhang\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: Open-domain human-computer conversation has attracted much attention in the field of NLP. Contrary to rule- or template-based domain-specific dialog systems, open-domain conversation usually requires data-driven approaches, which can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (called a query) in a large database, and return a reply that best matches the query. Generative approaches, typically based on recurrent neural networks (RNNs), can synthesize new replies, but they suffer from the problem of generating short, meaningless utterances. In this paper, we propose a novel ensemble of retrieval-based and generation-based dialog systems in the open domain. In our approach, the retrieved candidate, in addition to the original query, is fed to an RNN-based reply generator, so that the neural model is aware of more information. The generated reply is then fed back as a new candidate for post-reranking. Experimental results show that such ensemble outperforms each single part of it by a large margin.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Packing and Padding: Coupled Multi-index for Accurate Image Retrieval\n",
            "Authors: Liang Zheng, Shengjin Wang, Ziqiong Liu, Q. Tian\n",
            "Year: 2014\n",
            "Venue: 2014 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: In Bag-of-Words (BoW) based image retrieval, the SIFT visual word has a low discriminative power, so false positive matches occur prevalently. Apart from the information loss during quantization, another cause is that the SIFT feature only describes the local gradient distribution. To address this problem, this paper proposes a coupled Multi-Index (c-MI) framework to perform feature fusion at indexing level. Basically, complementary features are coupled into a multi-dimensional inverted index. Each dimension of c-MI corresponds to one kind of feature, and the retrieval process votes for images similar in both SIFT and other feature spaces. Specifically, we exploit the fusion of local color feature into c-MI. While the precision of visual match is greatly enhanced, we adopt Multiple Assignment to improve recall. The joint cooperation of SIFT and color features significantly reduces the impact of false positive matches. Extensive experiments on several benchmark datasets demonstrate that c-MI improves the retrieval accuracy significantly, while consuming only half of the query time compared to the baseline. Importantly, we show that c-MI is well complementary to many prior techniques. Assembling these methods, we have obtained an mAP of 85.8% and N-S score of 3.85 on Holidays and Ukbench datasets, respectively, which compare favorably with the state-of-the-arts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Novel Image Retrieval Based on Visual Words Integration of SIFT and SURF\n",
            "Authors: N. Ali, Khalid Bashir Bajwa, Robert Sablatnig, S. Chatzichristofis, Zeshan Iqbal, Muhammad Rashid, H. A. Habib\n",
            "Year: 2016\n",
            "Venue: PLoS ONE\n",
            "Abstract: With the recent evolution of technology, the number of image archives has increased exponentially. In Content-Based Image Retrieval (CBIR), high-level visual information is represented in the form of low-level features. The semantic gap between the low-level features and the high-level image concepts is an open research problem. In this paper, we present a novel visual words integration of Scale Invariant Feature Transform (SIFT) and Speeded-Up Robust Features (SURF). The two local features representations are selected for image retrieval because SIFT is more robust to the change in scale and rotation, while SURF is robust to changes in illumination. The visual words integration of SIFT and SURF adds the robustness of both features to image retrieval. The qualitative and quantitative comparisons conducted on Corel-1000, Corel-1500, Corel-2000, Oliva and Torralba and Ground Truth image benchmarks demonstrate the effectiveness of the proposed visual words integration.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Enhancement of encoding and retrieval functions through theta phase-specific manipulation of hippocampus\n",
            "Authors: J. Siegle, M. Wilson\n",
            "Year: 2014\n",
            "Venue: eLife\n",
            "Abstract: Assessing the behavioral relevance of the hippocampal theta rhythm has proven difficult, due to a shortage of experiments that selectively manipulate phase-specific information processing. Using closed-loop stimulation, we triggered inhibition of dorsal CA1 at specific phases of the endogenous theta rhythm in freely behaving mice. This intervention enhanced performance on a spatial navigation task that requires the encoding and retrieval of information related to reward location on every trial. In agreement with prior models of hippocampal function, the behavioral effects depended on both the phase of theta and the task segment at which we stimulated. Stimulation in the encoding segment enhanced performance when inhibition was triggered by the peak of theta. Conversely, stimulation in the retrieval segment enhanced performance when inhibition was triggered by the trough of theta. These results suggest that processes related to the encoding and retrieval of task-relevant information are preferentially active at distinct phases of theta. DOI: http://dx.doi.org/10.7554/eLife.03061.001\n",
            "\n",
            "---\n",
            "\n",
            "Title: Look Here, Eye Movements Play a Functional Role in Memory Retrieval\n",
            "Authors: R. Johansson, M. Johansson\n",
            "Year: 2014\n",
            "Venue: Psychology Science\n",
            "Abstract: Research on episodic memory has established that spontaneous eye movements occur to spaces associated with retrieved information even if those spaces are blank at the time of retrieval. Although it has been claimed that such looks to “nothing” can function as facilitatory retrieval cues, there is currently no conclusive evidence for such an effect. In the present study, we addressed this fundamental issue using four direct eye manipulations in the retrieval phase of an episodic memory task: (a) free viewing on a blank screen, (b) maintaining central fixation, (c) looking inside a square congruent with the location of the to-be-recalled objects, and (d) looking inside a square incongruent with the location of the to-be-recalled objects. Our results provide novel evidence of an active and facilitatory role of gaze position during memory retrieval and demonstrate that memory for the spatial relationship between objects is more readily affected than memory for intrinsic object features.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Breast Histopathological Image Retrieval Based on Latent Dirichlet Allocation\n",
            "Authors: Yibing Ma, Zhi-guo Jiang, Haopeng Zhang, Feng-ying Xie, Yushan Zheng, Huaqiang Shi, Yu Zhao\n",
            "Year: 2017\n",
            "Venue: IEEE journal of biomedical and health informatics\n",
            "Abstract: In the field of pathology, whole slide image (WSI) has become the major carrier of visual and diagnostic information. Content-based image retrieval among WSIs can aid the diagnosis of an unknown pathological image by finding its similar regions in WSIs with diagnostic information. However, the huge size and complex content of WSI pose several challenges for retrieval. In this paper, we propose an unsupervised, accurate, and fast retrieval method for a breast histopathological image. Specifically, the method presents a local statistical feature of nuclei for morphology and distribution of nuclei, and employs the Gabor feature to describe the texture information. The latent Dirichlet allocation model is utilized for high-level semantic mining. Locality-sensitive hashing is used to speed up the search. Experiments on a WSI database with more than 8000 images from 15 types of breast histopathology demonstrate that our method achieves about 0.9 retrieval precision as well as promising efficiency. Based on the proposed framework, we are developing a search engine for an online digital slide browsing and retrieval platform, which can be applied in computer-aided diagnosis, pathology education, and WSI archiving and management.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Achievable Rate of Private Function Retrieval from MDS Coded Databases\n",
            "Authors: Sarah A. Obead, J. Kliewer\n",
            "Year: 2018\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: We study the problem of private function retrieval (PFR) in a distributed storage system. In PFR the user wishes to retrieve a linear combination of $M$ messages stored in non-colluding (N, K) MDS coded databases while revealing no information about the coefficients of the intended linear combination to any of the individual databases. We present an achievable scheme for MDS coded PFR with a rate that matches the capacity for coded private information retrieval derived recently, $R= (1+R_{c}+R_{c}^{2}+\\cdots +R_{c}^{M-1})^{-1}=\\frac{1-R_{c}}{1-R_{c}^{M}}$, where $R_{c}=\\frac{K}{N}$ is the rate of the MDS code.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Data Collection for Evaluating the Retrieval of Related Tweets to News Articles\n",
            "Authors: Axel Suarez, M. Albakour, D. Corney, Miguel Martinez-Alvarez, José Esquivel\n",
            "Year: 2018\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: EMR: A Scalable Graph-Based Ranking Model for Content-Based Image Retrieval\n",
            "Authors: Bin Xu, Jiajun Bu, Chun Chen, C. Wang, Deng Cai, Xiaofei He\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Knowledge and Data Engineering\n",
            "Abstract: Graph-based ranking models have been widely applied in information retrieval area. In this paper, we focus on a well known graph-based model - the Ranking on Data Manifold model, or Manifold Ranking (MR). Particularly, it has been successfully applied to content-based image retrieval, because of its outstanding ability to discover underlying geometrical structure of the given image database. However, manifold ranking is computationally very expensive, which significantly limits its applicability to large databases especially for the cases that the queries are out of the database (new samples). We propose a novel scalable graph-based ranking model called Efficient Manifold Ranking (EMR), trying to address the shortcomings of MR from two main perspectives: scalable graph construction and efficient ranking computation. Specifically, we build an anchor graph on the database instead of a traditional k-nearest neighbor graph, and design a new form of adjacency matrix utilized to speed up the ranking. An approximate method is adopted for efficient out-of-sample retrieval. Experimental results on some large scale image databases demonstrate that EMR is a promising method for real world retrieval applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Spoken Content Retrieval—Beyond Cascading Speech Recognition with Text Retrieval\n",
            "Authors: Lin-Shan Lee, James R. Glass, Hung-yi Lee, Chun-an Chan\n",
            "Year: 2015\n",
            "Venue: IEEE/ACM Transactions on Audio Speech and Language Processing\n",
            "Abstract: Spoken content retrieval refers to directly indexing and retrieving spoken content based on the audio rather than text descriptions. This potentially eliminates the requirement of producing text descriptions for multimedia content for indexing and retrieval purposes, and is able to precisely locate the exact time the desired information appears in the multimedia. Spoken content retrieval has been very successfully achieved with the basic approach of cascading automatic speech recognition (ASR) with text information retrieval: after the spoken content is transcribed into text or lattice format, a text retrieval engine searches over the ASR output to find desired information. This framework works well when the ASR accuracy is relatively high, but becomes less adequate when more challenging real-world scenarios are considered, since retrieval performance depends heavily on ASR accuracy. This challenge leads to the emergence of another approach to spoken content retrieval: to go beyond the basic framework of cascading ASR with text retrieval in order to have retrieval performances that are less dependent on ASR accuracy. This overview article is intended to provide a thorough overview of the concepts, principles, approaches, and achievements of major technical contributions along this line of investigation. This includes five major directions: 1) Modified ASR for Retrieval Purposes: cascading ASR with text retrieval, but the ASR is modified or optimized for spoken content retrieval purposes; 2) Exploiting the Information not present in ASR outputs: to try to utilize the information in speech signals inevitably lost when transcribed into phonemes and words; 3) Directly Matching at the Acoustic Level without ASR: for spoken queries, the signals can be directly matched at the acoustic level, rather than at the phoneme or word levels, bypassing all ASR issues; 4) Semantic Retrieval of Spoken Content: trying to retrieve spoken content that is semantically related to the query, but not necessarily including the query terms themselves; 5) Interactive Retrieval and Efficient Presentation of the Retrieved Objects: with efficient presentation of the retrieved objects, an interactive retrieval process incorporating user actions may produce better retrieval results and user experiences.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluating Retrieval over Sessions: The TREC Session Track 2011-2014\n",
            "Authors: Ben Carterette, Paul D. Clough, M. Hall, E. Kanoulas, M. Sanderson\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Information Retrieval (IR) research has traditionally focused on serving the best results for a single query - so-called ad hoc retrieval. However, users typically search iteratively, refining and reformulating their queries during a session. A key challenge in the study of this interaction is the creation of suitable evaluation resources to assess the effectiveness of IR systems over sessions. This paper describes the TREC Session Track, which ran from 2010 through to 2014, which focussed on forming test collections that included various forms of implicit feedback. We describe the test collections; a brief analysis of the differences between datasets over the years; and the evaluation results that demonstrate that the use of user session data significantly improved effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pairwise geometric matching for large-scale object retrieval\n",
            "Authors: Xinchao Li, M. Larson, A. Hanjalic\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Spatial verification is a key step in boosting the performance of object-based image retrieval. It serves to eliminate unreliable correspondences between salient points in a given pair of images, and is typically performed by analyzing the consistency of spatial transformations between the image regions involved in individual correspondences. In this paper, we consider the pairwise geometric relations between correspondences and propose a strategy to incorporate these relations at significantly reduced computational cost, which makes it suitable for large-scale object retrieval. In addition, we combine the information on geometric relations from both the individual correspondences and pairs of correspondences to further improve the verification accuracy. Experimental results on three reference datasets show that the proposed approach results in a substantial performance improvement compared to the existing methods, without making concessions regarding computational efficiency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discriminative Dictionary Learning With Common Label Alignment for Cross-Modal Retrieval\n",
            "Authors: Cheng Deng, Xu Tang, Junchi Yan, W. Liu, Xinbo Gao\n",
            "Year: 2016\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: Cross-modal retrieval has attracted much attention in recent years due to its widespread applications. In this area, how to capture and correlate heterogeneous features originating from different modalities remains a challenge. However, most existing methods dealing with cross-modal learning only focus on learning relevant features shared by two distinct feature spaces, therefore overlooking discriminative feature information of them. To remedy this issue and explicitly capture discriminative feature information, we propose a novel cross-modal retrieval approach based on discriminative dictionary learning that is augmented with common label alignment. Concretely, a discriminative dictionary is first learned to account for each modality, which boosts not only the discriminating capability of intra-modality data from different classes but also the relevance of inter-modality data in the same class. Subsequently, all the resulting sparse codes are simultaneously mapped to a common label space, where the cross-modal data samples are characterized and associated. Also in the label space, the discriminativeness and relevance of the considered cross-modal data can be further strengthened by enforcing a common label alignment. Finally, cross-modal retrieval is performed over the common label space. Experiments conducted on two public cross-modal datasets show that the proposed approach outperforms several state-of-the-art methods in term of retrieval accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Location and Time Aware Social Collaborative Retrieval for New Successive Point-of-Interest Recommendation\n",
            "Authors: Wei Zhang, Jianyong Wang\n",
            "Year: 2015\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: In location-based social networks (LBSNs), new successive point-of-interest (POI) recommendation is a newly formulated task which tries to regard the POI a user currently visits as his POI-related query and recommend new POIs the user has not visited before. While carefully designed methods are proposed to solve this problem, they ignore the essence of the task which involves retrieval and recommendation problem simultaneously and fail to employ the social relations or temporal information adequately to improve the results. In order to solve this problem, we propose a new model called location and time aware social collaborative retrieval model (LTSCR), which has two distinct advantages: (1) it models the location, time, and social information simultaneously for the successive POI recommendation task; (2) it efficiently utilizes the merits of the collaborative retrieval model which leverages weighted approximately ranked pairwise (WARP) loss for achieving better top-n ranking results, just as the new successive POI recommendation task needs. We conducted some comprehensive experiments on publicly available datasets and demonstrate the power of the proposed method, with 46.6% growth in Precision@5 and 47.3% improvement in Recall@5 over the best previous method.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Document Retrieval Using Entity-Based Language Models\n",
            "Authors: Hadas Raviv, Oren Kurland, David Carmel\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We address the ad hoc document retrieval task by devising novel types of entity-based language models. The models utilize information about single terms in the query and documents as well as term sequences marked as entities by some entity-linking tool. The key principle of the language models is accounting, simultaneously, for the uncertainty inherent in the entity-markup process and the balance between using entity-based and term-based information. Empirical evaluation demonstrates the merits of using the language models for retrieval. For example, the performance transcends that of a state-of-the-art term proximity method. We also show that the language models can be effectively used for cluster-based document retrieval and query expansion.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Emerging trends and new developments in information science: a document co-citation analysis (2009–2016)\n",
            "Authors: Jia-lin Hou, Xiucai Yang, Chaomei Chen\n",
            "Year: 2018\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-Based High-Resolution Remote Sensing Image Retrieval via Unsupervised Feature Learning and Collaborative Affinity Metric Fusion\n",
            "Authors: Yansheng Li, Yongjun Zhang, Chao Tao, Hu Zhu\n",
            "Year: 2016\n",
            "Venue: Remote Sensing\n",
            "Abstract: With the urgent demand for automatic management of large numbers of high-resolution remote sensing images, content-based high-resolution remote sensing image retrieval (CB-HRRS-IR) has attracted much research interest. Accordingly, this paper proposes a novel high-resolution remote sensing image retrieval approach via multiple feature representation and collaborative affinity metric fusion (IRMFRCAMF). In IRMFRCAMF, we design four unsupervised convolutional neural networks with different layers to generate four types of unsupervised features from the fine level to the coarse level. In addition to these four types of unsupervised features, we also implement four traditional feature descriptors, including local binary pattern (LBP), gray level co-occurrence (GLCM), maximal response 8 (MR8), and scale-invariant feature transform (SIFT). In order to fully incorporate the complementary information among multiple features of one image and the mutual information across auxiliary images in the image dataset, this paper advocates collaborative affinity metric fusion to measure the similarity between images. The performance evaluation of high-resolution remote sensing image retrieval is implemented on two public datasets, the UC Merced (UCM) dataset and the Wuhan University (WH) dataset. Large numbers of experiments show that our proposed IRMFRCAMF can significantly outperform the state-of-the-art approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content Based Image Retrieval Using Embedded Neural Networks with Bandletized Regions\n",
            "Authors: Rehan Ashraf, Khalid Bashir Bajwa, Aun Irtaza, M. Mahmood\n",
            "Year: 2015\n",
            "Venue: Entropy\n",
            "Abstract: One of the major requirements of content based image retrieval (CBIR) systems is to ensure meaningful image retrieval against query images. The performance of these systems is severely degraded by the inclusion of image content which does not contain the objects of interest in an image during the image representation phase. Segmentation of the images is considered as a solution but there is no technique that can guarantee the object extraction in a robust way. Another limitation of the segmentation is that most of the image segmentation techniques are slow and their results are not reliable. To overcome these problems, a bandelet transform based image representation technique is presented in this paper, which reliably returns the information about the major objects found in an image. For image retrieval purposes, artificial neural networks (ANN) are applied and the performance of the system and achievement is evaluated on three standard data sets used in the domain of CBIR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ventral fronto-temporal pathway supporting cognitive control of episodic memory retrieval.\n",
            "Authors: J. Barredo, Ilke Öztekin, David Badre\n",
            "Year: 2015\n",
            "Venue: Cerebral Cortex\n",
            "Abstract: Achieving our goals often requires guiding access to relevant information from memory. Such goal-directed retrieval requires interactions between systems supporting cognitive control, including ventrolateral prefrontal cortex (VLPFC), and those supporting declarative memory, such as the medial temporal lobes (MTL). However, the pathways by which VLPFC interacts with MTL during retrieval are underspecified. Prior neuroanatomical evidence suggests that a polysynaptic ventral fronto-temporal pathway may support VLPFC-MTL interactions. To test this hypothesis, human participants were scanned using fMRI during performance of a source-monitoring task. The strength of source information was varied via repetition during encoding. Single encoding events should produce a weaker memory trace, thus recovering source information about these items should demand greater cognitive control. Results demonstrated that cortical targets along the ventral path--anterior VLPFC, temporal pole, anterior parahippocampus, and hippocampus--exhibited increases in univariate BOLD response correlated with increases in controlled retrieval demand, independent of factors related to response selection. Further, a functional connectivity analysis indicated that these regions functionally couple and are distinguishable from a dorsal pathway related to response selection demands. These data support a ventral retrieval pathway linking PFC and MTL.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Large-Scale 3D Shape Retrieval from ShapeNet Core55\n",
            "Authors: M. Savva, F. Yu, Hao Su, Masaki Aono, Baoquan Chen, D. Cohen-Or, W. Deng, Hang Su, S. Bai, X. Bai, N. Fish, Jiajie Han, E. Kalogerakis, E. Learned-Miller, Yangyan Li, Minghui Liao, Subhransu Maji, A. Tatsuma, Yida Wang, Nanhai Zhang, Zhichao Zhou\n",
            "Year: 2016\n",
            "Venue: 3DOR@Eurographics\n",
            "Abstract: With the advent of commodity 3D capturing devices and better 3D modeling tools, 3D shape content is becoming increasingly prevalent. Therefore, the need for shape retrieval algorithms to handle large-scale shape repositories is more and more important. This track aims to provide a benchmark to evaluate large-scale shape retrieval based on the ShapeNet dataset. We use ShapeNet Core55, which provides more than 50 thousands models over 55 common categories in total for training and evaluating several algorithms. Five participating teams have submitted a variety of retrieval methods which were evaluated on several standard information retrieval performance metrics. We find the submitted methods work reasonably well on the track benchmark, but we also see significant space for improvement by future algorithms. We release all the data, results, and evaluation code for the benefit of the community.\n",
            "\n",
            "---\n",
            "\n",
            "Title: 3-D Object Retrieval With Hausdorff Distance Learning\n",
            "Authors: Yue Gao, Meng Wang, R. Ji, Xindong Wu, Qionghai Dai\n",
            "Year: 2014\n",
            "Venue: IEEE transactions on industrial electronics (1982. Print)\n",
            "Abstract: In view-based 3-D object retrieval, each object is described by a set of views. Group matching thus plays an important role. Previous research efforts have shown the effectiveness of Hausdorff distance in group matching. In this paper, we propose a 3-D object retrieval scheme with Hausdorff distance learning. In our approach, relevance feedback information is employed to select positive and negative view pairs with a probabilistic strategy, and a view-level Mahalanobis distance metric is learned. This Mahalanobis distance metric is adopted in estimating the Hausdorff distances between objects, based on which the objects in the 3-D database are ranked. We conduct experiments on three testing data sets, and the results demonstrate that the proposed Hausdorff learning approach can improve 3-D object retrieval performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Music Similarity and Retrieval: An Introduction to Audio- and Web-based Strategies\n",
            "Authors: Peter Knees, M. Schedl\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: This book provides a summary of the manifold audio- and web-based approaches to music information retrieval (MIR) research. In contrast to other books dealing solely with music signal processing, it addresses additional cultural and listener-centric aspects and thus provides a more holistic view. Consequently, the text includes methods operating on features extracted directly from the audio signal, as well as methods operating on features extracted from contextual information, either the cultural context of music as represented on the web or the user and usage context of music. Following the prevalent document-centered paradigm of information retrieval, the book addresses models of music similarity that extract computational features to describe an entity that represents music on any level (e.g., song, album, or artist), and methods to calculate the similarity between them. While this perspective and the representations discussed cannot describe all musical dimensions, they enable us to effectively find music of similar qualities by providing abstract summarizations of musical artifacts from different modalities. The text at hand provides a comprehensive and accessible introduction to the topics of music search, retrieval, and recommendation from an academic perspective. It will not only allow those new to the field to quickly access MIR from an information retrieval point of view but also raise awareness for the developments of the music domain within the greater IR community. In this regard, Part I deals with content-based MIR, in particular the extraction of features from the music signal and similarity calculation for content-based retrieval. Part II subsequently addresses MIR methods that make use of the digitally accessible cultural context of music. Part III addresses methods of collaborative filtering and user-aware and multi-modal retrieval, while Part IV explores current and future applications of music retrieval and recommendation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A retrieval algorithm of encrypted speech based on syllable-level perceptual hashing\n",
            "Authors: Shaofang He, Huan Zhao\n",
            "Year: 2017\n",
            "Venue: Computer Science and Information Systems\n",
            "Abstract: To retrieve voice information in a fast and accurate manner over encrypted speech, this study proposes a retrieval algorithm based on syllable-level perceptual hashing. It implements the function of retrieving speech segment and spoken term over encrypted speech database. Before uploading the speech to the cloud, it needs to embed the digital watermarks (perceptual hashing). In the retrieval process, it does not need search over encrypted speech data directly or decryption, but requires searching the system hash table. Experimental results show that the syllable-level perceptual hashing of the proposed scheme has good discrimination, uniqueness, and perceptual robustness to common speech. In addition, the proposed retrieval algorithm effectively improves the retrieval speed by reducing the matching number of query index. The precision ratio and recall ratio all achieve high under various signal processing.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Effective Multi-Modal Retrieval based on Stacked Auto-Encoders\n",
            "Authors: Wei Wang, B. Ooi, Xiaoyan Yang, Dongxiang Zhang, Yueting Zhuang\n",
            "Year: 2014\n",
            "Venue: Proceedings of the VLDB Endowment\n",
            "Abstract: Multi-modal retrieval is emerging as a new search paradigm that enables seamless information retrieval from various types of media. For example, users can simply snap a movie poster to search relevant reviews and trailers. To solve the problem, a set of mapping functions are learned to project high-dimensional features extracted from data of different media types into a common low-dimensional space so that metric distance measures can be applied. In this paper, we propose an effective mapping mechanism based on deep learning (i.e., stacked auto-encoders) for multi-modal retrieval. Mapping functions are learned by optimizing a new objective function, which captures both intra-modal and inter-modal semantic relationships of data from heterogeneous sources effectively. Compared with previous works which require a substantial amount of prior knowledge such as similarity matrices of intra-modal data and ranking examples, our method requires little prior knowledge. Given a large training dataset, we split it into mini-batches and continually adjust the mapping functions for each batch of input. Hence, our method is memory efficient with respect to the data volume. Experiments on three real datasets illustrate that our proposed method achieves significant improvement in search accuracy over the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improved methodology for surface and atmospheric soundings, error estimates, and quality control procedures: the atmospheric infrared sounder science team version-6 retrieval algorithm\n",
            "Authors: J. Susskind, J. Blaisdell, L. Iredell\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Abstract The atmospheric infrared sounder (AIRS) science team version-6 AIRS/advanced microwave sounding unit (AMSU) retrieval algorithm is now operational at the Goddard Data and Information Services Center (DISC). AIRS version-6 level-2 products are generated near real time at the Goddard DISC and all level-2 and level-3 products are available starting from September 2002. Some of the significant improvements in retrieval methodology contained in the version-6 retrieval algorithm compared to that previously used in version-5 are described. In particular, the AIRS science team made major improvements with regard to the algorithms used to (1) derive surface skin temperature and surface spectral emissivity; (2) generate the initial state used to start the cloud clearing and retrieval procedures; and (3) derive error estimates and use them for quality control. Significant improvements have also been made in the generation of cloud parameters. In addition to the basic AIRS/AMSU mode, version-6 also operates in an AIRS only (AO) mode, which produces results almost as good as those of the full AIRS/AMSU mode. The improvements of some AIRS version-6 and version-6 AO products compared to those obtained using version-5 are also demonstrated.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval attempts enhance learning, but retrieval success (versus failure) does not matter.\n",
            "Authors: Nate Kornell, Patricia Jacobs Klein, Katherine A. Rawson\n",
            "Year: 2015\n",
            "Venue: Journal of Experimental Psychology. Learning, Memory and Cognition\n",
            "Abstract: Retrieving information from memory enhances learning. We propose a 2-stage framework to explain the benefits of retrieval. Stage 1 takes place as one attempts to retrieve an answer, which activates knowledge related to the retrieval cue. Stage 2 begins when the answer becomes available, at which point appropriate connections are strengthened and inappropriate connections may be weakened. This framework raises a basic question: Does it matter whether Stage 2 is initiated via successful retrieval or via an external presentation of the answer? To test this question, we asked participants to attempt retrieval and then randomly assigned items (which were equivalent otherwise) to be retrieved successfully or to be copied (i.e., not retrieved). Experiments 1, 2, 4, and 5 tested assumptions necessary for interpreting Experiments 3a, 3b, and 6. Experiments 3a, 3b, and 6 did not support the hypothesis that retrieval success produces more learning than does retrieval failure followed by feedback. It appears that retrieval attempts promote learning but retrieval success per se does not.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Database Saliency for Fast Image Retrieval\n",
            "Authors: Yuan Gao, Miaojing Shi, D. Tao, Chao Xu\n",
            "Year: 2015\n",
            "Venue: IEEE transactions on multimedia\n",
            "Abstract: The bag-of-visual-words (BoW) model is effective for representing images and videos in many computer vision problems, and achieves promising performance in image retrieval. Nevertheless, the level of retrieval efficiency in a large-scale database is not acceptable for practical usage. Considering that the relevant images in the database of a given query are more likely to be distinctive than ambiguous, this paper defines “database saliency” as the distinctiveness score calculated for every image to measure its overall “saliency” in the database. By taking advantage of database saliency, we propose a saliency- inspired fast image retrieval scheme, S-sim, which significantly improves efficiency while retains state-of-the-art accuracy in image retrieval . There are two stages in S-sim: the bottom-up saliency mechanism computes the database saliency value of each image by hierarchically decomposing a posterior probability into local patches and visual words, the concurrent information of visual words is then bottom-up propagated to estimate the distinctiveness, and the top-down saliency mechanism discriminatively expands the query via a very low-dimensional linear SVM trained on the top-ranked images after initial search, ranking images are then sorted on their distances to the decision boundary as well as the database saliency values. We comprehensively evaluate S-sim on common retrieval benchmarks, e.g., Oxford and Paris datasets. Thorough experiments suggest that, because of the offline database saliency computation and online low-dimensional SVM, our approach significantly speeds up online retrieval and outperforms the state-of-the-art BoW-based image retrieval schemes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Schematic memory components converge within angular gyrus during retrieval\n",
            "Authors: Isabella C. Wagner, Mariët van Buuren, Marijn C. W. Kroes, T. Gutteling, Mieke van der Linden, R. Morris, G. Fernández\n",
            "Year: 2015\n",
            "Venue: eLife\n",
            "Abstract: Mental schemas form associative knowledge structures that can promote the encoding and consolidation of new and related information. Schemas are facilitated by a distributed system that stores components separately, presumably in the form of inter-connected neocortical representations. During retrieval, these components need to be recombined into one representation, but where exactly such recombination takes place is unclear. Thus, we asked where different schema components are neuronally represented and converge during retrieval. Subjects acquired and retrieved two well-controlled, rule-based schema structures during fMRI on consecutive days. Schema retrieval was associated with midline, medial-temporal, and parietal processing. We identified the multi-voxel representations of different schema components, which converged within the angular gyrus during retrieval. Critically, convergence only happened after 24-hour-consolidation and during a transfer test where schema material was applied to novel but related trials. Therefore, the angular gyrus appears to recombine consolidated schema components into one memory representation. DOI: http://dx.doi.org/10.7554/eLife.09668.001\n",
            "\n",
            "---\n",
            "\n",
            "Title: Scalable Mobile Image Retrieval by Exploring Contextual Saliency\n",
            "Authors: Xiyu Yang, Xueming Qian, Yao Xue\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Nowadays, it is very convenient to capture photos by a smart phone. As using, the smart phone is a convenient way to share what users experienced anytime and anywhere through social networks, it is very possible that we capture multiple photos to make sure the content is well photographed. In this paper, an effective scalable mobile image retrieval approach is proposed by exploring contextual salient information for the input query image. Our goal is to explore the high-level semantic information of an image by finding the contextual saliency from multiple relevant photos rather than solely using the input image. Thus, the proposed mobile image retrieval approach first determines the relevant photos according to visual similarity, then mines salient features by exploring contextual saliency from multiple relevant images, and finally determines contributions of salient features for scalable retrieval. Compared with the existing mobile-based image retrieval approaches, our approach requires less bandwidth and has better retrieval performance. We can carry out retrieval with <;200-B data, which is <;5% of existing approaches. Most importantly, when the bandwidth is limited, we can rank the transmitted features according to their contributions to retrieval. Experimental results show the effectiveness of the proposed approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Language Estimation with the Paragraph Vector Model for Ad-hoc Retrieval\n",
            "Authors: Qingyao Ai, Liu Yang, J. Guo, W. Bruce Croft\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Incorporating topic level estimation into language models has been shown to be beneficial for information retrieval (IR) models such as cluster-based retrieval and LDA-based document representation. Neural embedding models, such as paragraph vector (PV) models, on the other hand have shown their effectiveness and efficiency in learning semantic representations of documents and words in multiple Natural Language Processing (NLP) tasks. However, their effectiveness in information retrieval is mostly unknown. In this paper, we study how to effectively use the PV model to improve ad-hoc retrieval. We propose three major improvements over the original PV model to adapt it for the IR scenario: (1) we use a document frequency-based rather than the corpus frequency-based negative sampling strategy so that the importance of frequent words will not be suppressed excessively; (2) we introduce regularization over the document representation to prevent the model overfitting short documents along with the learning iterations; and (3) we employ a joint learning objective which considers both the document-word and word-context associations to produce better word probability estimation. By incorporating this enhanced PV model into the language modeling framework, we show that it can significantly outperform the state-of-the-art topic enhanced language models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Adaptive Information Seeking for Open-Domain Question Answering\n",
            "Authors: Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, Xueqi Cheng\n",
            "Year: 2021\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Information seeking is an essential step for open-domain question answering to efficiently gather evidence from a large corpus. Recently, iterative approaches have been proven to be effective for complex questions, by recursively retrieving new evidence at each step. However, almost all existing iterative approaches use predefined strategies, either applying the same retrieval function multiple times or fixing the order of different retrieval functions, which cannot fulfill the diverse requirements of various questions. In this paper, we propose a novel adaptive information-seeking strategy for open-domain question answering, namely AISO. Specifically, the whole retrieval and answer process is modeled as a partially observed Markov decision process, where three types of retrieval operations (e.g., BM25, DPR, and hyperlink) and one answer operation are defined as actions. According to the learned policy, AISO could adaptively select a proper retrieval action to seek the missing evidence at each step, based on the collected evidence and the reformulated query, or directly output the answer when the evidence set is sufficient for the question. Experiments on SQuAD Open and HotpotQA fullwiki, which serve as single-hop and multi-hop open-domain QA benchmarks, show that AISO outperforms all baseline methods with predefined strategies in terms of both retrieval and answer evaluations.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Novel Image Retrieval Based on a Combination of Local and Global Histograms of Visual Words\n",
            "Authors: Zahid Mehmood, S. Anwar, N. Ali, H. A. Habib, Muhammad Rashid\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Content-based image retrieval (CBIR) provides a sustainable solution to retrieve similar images from an image archive. In the last few years, the Bag-of-Visual-Words (BoVW) model gained attention and significantly improved the performance of image retrieval. In the standard BoVW model, an image is represented as an orderless global histogram of visual words by ignoring the spatial layout. The spatial layout of an image carries significant information that can enhance the performance of CBIR. In this paper, we are presenting a novel image representation that is based on a combination of local and global histograms of visual words. The global histogram of visual words is constructed over the whole image, while the local histogram of visual words is constructed over the local rectangular region of the image. The local histogram contains the spatial information about the salient objects. Extensive experiments and comparisons conducted on Corel-A, Caltech-256, and Ground Truth image datasets demonstrate that the proposed image representation increases the performance of image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Toward an episodic context account of retrieval-based learning: dissociating retrieval practice and elaboration.\n",
            "Authors: Melissa Lehman, Megan A. Smith, Jeffrey D. Karpicke\n",
            "Year: 2014\n",
            "Venue: Journal of Experimental Psychology. Learning, Memory and Cognition\n",
            "Abstract: We tested the predictions of 2 explanations for retrieval-based learning; while the elaborative retrieval hypothesis assumes that the retrieval of studied information promotes the generation of semantically related information, which aids in later retrieval (Carpenter, 2009), the episodic context account proposed by Karpicke, Lehman, and Aue (in press) assumes that retrieval alters the representation of episodic context and improves one's ability to guide memory search on future tests. Subjects studied multiple word lists and either recalled each list (retrieval practice), did a math task (control), or generated associates for each word (elaboration) after each list. After studying the last list, all subjects recalled the list and, after a 5-min delay, recalled all lists. Analyses of correct recall, intrusions, response times, and temporal clustering dissociate retrieval practice from elaboration, supporting the episodic context account.\n",
            "\n",
            "---\n",
            "\n",
            "Title: STFT Phase Retrieval: Uniqueness Guarantees and Recovery Algorithms\n",
            "Authors: K. Jaganathan, Yonina C. Eldar, B. Hassibi\n",
            "Year: 2015\n",
            "Venue: IEEE Journal on Selected Topics in Signal Processing\n",
            "Abstract: The problem of recovering a signal from its Fourier magnitude is of paramount importance in various fields of engineering and applied physics. Due to the absence of Fourier phase information, some form of additional information is required in order to be able to uniquely, efficiently, and robustly identify the underlying signal. Inspired by practical methods in optical imaging, we consider the problem of signal reconstruction from the short-time Fourier transform (STFT) magnitude. We first develop conditions under, which the STFT magnitude is an almost surely unique signal representation. We then consider a semidefinite relaxation-based algorithm (STliFT) and provide recovery guarantees. Numerical simulations complement our theoretical analysis and provide directions for future work.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Latent entity space: a novel retrieval approach for entity-bearing queries\n",
            "Authors: Xitong Liu, Hui Fang\n",
            "Year: 2015\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discriminative coupled dictionary hashing for fast cross-media retrieval\n",
            "Authors: Zhou Yu, Fei Wu, Yi Yang, Q. Tian, Jiebo Luo, Yueting Zhuang\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Cross-media hashing, which conducts cross-media retrieval by embedding data from different modalities into a common low-dimensional Hamming space, has attracted intensive attention in recent years. The existing cross-media hashing approaches only aim at learning hash functions to preserve the intra-modality and inter-modality correlations, but do not directly capture the underlying semantic information of the multi-modal data. We propose a discriminative coupled dictionary hashing (DCDH) method in this paper. In DCDH, the coupled dictionary for each modality is learned with side information (e.g., categories). As a result, the coupled dictionaries not only preserve the intra-similarity and inter-correlation among multi-modal data, but also contain dictionary atoms that are semantically discriminative (i.e., the data from the same category is reconstructed by the similar dictionary atoms). To perform fast cross-media retrieval, we learn hash functions which map data from the dictionary space to a low-dimensional Hamming space. Besides, we conjecture that a balanced representation is crucial in cross-media retrieval. We introduce multi-view features on the relatively ``weak'' modalities into DCDH and extend it to multi-view DCDH (MV-DCDH) in order to enhance their representation capability. The experiments on two real-world data sets show that our DCDH and MV-DCDH outperform the state-of-the-art methods significantly on cross-media retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An overview of approaches for content-based medical image retrieval\n",
            "Authors: P. Das, A. Neelima\n",
            "Year: 2017\n",
            "Venue: International Journal of Multimedia Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Classroom Study on the Relationship Between Student Achievement and Retrieval-Enhanced Learning\n",
            "Authors: Shana K. Carpenter, Terry J. S. Lund, C. Coffman, P. Armstrong, Monica H Lamm, R. Reason\n",
            "Year: 2015\n",
            "Venue: Educational Psychology Review\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Metamemory monitoring and control following retrieval practice for text\n",
            "Authors: Jeri L. Little, M. McDaniel\n",
            "Year: 2015\n",
            "Venue: Memory & Cognition\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Terminator-free template-independent enzymatic DNA synthesis for digital information storage\n",
            "Authors: Henry H. Lee, Reza Kalhor, Naveen Goela, J. Bolot, G. Church\n",
            "Year: 2019\n",
            "Venue: Nature Communications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access\n",
            "Authors: Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung (Vivian) Chen, Faisal Ahmed, L. Deng\n",
            "Year: 2016\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: This paper proposes KB-InfoBot - a multi-turn dialogue agent which helps users search Knowledge Bases (KBs) without composing complicated queries. Such goal-oriented dialogue agents typically need to interact with an external database to access real-world knowledge. Previous systems achieved this by issuing a symbolic query to the KB to retrieve entries based on their attributes. However, such symbolic operations break the differentiability of the system and prevent end-to-end training of neural dialogue agents. In this paper, we address this limitation by replacing symbolic queries with an induced “soft” posterior distribution over the KB that indicates which entities the user is interested in. Integrating the soft retrieval process with a reinforcement learner leads to higher task success rate and reward in both simulations and against real users. We also present a fully neural end-to-end agent, trained entirely from user feedback, and discuss its application towards personalized dialogue agents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Social identity and socially shared retrieval-induced forgetting: The effects of group membership.\n",
            "Authors: A. Coman, W. Hirst\n",
            "Year: 2015\n",
            "Venue: Journal of experimental psychology. General\n",
            "Abstract: In a conversation, speakers and listeners will often influence each other's memories, and in doing so, promote the formation of a shared, or collective, memory. One means by which a mnemonic consensus emerges is through socially shared retrieval-induced forgetting (SSRIF). When listeners attend to the speakers' selective retrieval of previously encountered events, they forget unmentioned but related information more than they forget unrelated, unmentioned previously studied information. As a consequence, both speaker and listeners come to remember-and forget-the event in a similar way. SSRIF appears to be dependent on listeners concurrently retrieving the information with the speaker. We asked here whether such concurrent retrieval is a function of group membership, thereby underscoring the connection between a basic mnemonic mechanism-retrieval-induced forgetting-and a social function of communicative interaction-building a shared representation. In Experiment 1, Princeton students listening to a speaker selectively recall previously studied material showed SSRIF when the speaker was identified as a fellow Princeton student, but not when he or she was identified as a Yale student. In Experiment 2, activating a common student identity before the listening task triggered concurrent retrieval in Princeton students when listening to both Princeton and Yale speakers. Thus, similar patterns of selective forgetting are more likely to occur between speakers and listeners if they belong to the same social group. Basic mnemonic mechanisms seem to be adapted to promote the emergence of shared mnemonic representations that preserve group membership and group identity.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analysis of TF-IDF Model and its Variant for Document Retrieval\n",
            "Authors: Apra Mishra, Santosh K. Vishwakarma\n",
            "Year: 2015\n",
            "Venue: International Conference on Computational Intelligence and Communication Networks\n",
            "Abstract: An Information Retrieval System is a system that is capable of storage, retrieval, and maintenance of an Information. In this context Information can be composed of text (including numeric and date data), images, audio, video and other multi-media objects. The TF-IDF weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. There exist various models for weighting terms of corpus documents and query terms. This work is carried out to analyze and evaluate the retrieval effectiveness of vector -- space model while using the new data set of FIRE 2011. The experiments were performed with TF-IDF and its variants. For all experiments and evaluation the open search engine, Terrier 3.5 was used. Our result shows that TF-IDF model gives the highest precision values with the new corpus dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval practice enhances new learning: the forward effect of testing\n",
            "Authors: Bernhard Pastötter, K. Bäuml\n",
            "Year: 2014\n",
            "Venue: Frontiers in Psychology\n",
            "Abstract: In the last couple of years, there has been a dramatic increase in laboratory research examining the benefits of recall testing on long-term learning and retention. This work was largely on the backward effect of testing, which shows that retrieval practice on previously studied information, compared to restudy of the same material, renders the information more likely to be remembered in the future. Going beyond this prominent work, more recent laboratory research provided evidence that there is also a forward effect of testing, which shows that recall testing of previously studied information can enhance learning of subsequently presented new information. Here, we provide a review of research on this forward effect of testing. The review shows that the effect is a well replicated phenomenon in laboratory studies that has been observed for both veridical information and misinformation. In particular, the review demonstrates that the effect may be applied to educational and clinical settings, enhancing learning in students and reducing memory deficits in clinical populations. The review discusses current theoretical explanations of the forward effect of testing and provides suggestions for future research directions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ground-Based Temperature and Humidity Profiling Using Spectral Infrared and Microwave Observations. Part II: Actual Retrieval Performance in Clear-Sky and Cloudy Conditions\n",
            "Authors: W. Blumberg, D. Turner, U. Löhnert, S. Castleberry\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: AbstractAlthough current upper-air observing systems provide an impressive array of observations, many are deficient in observing the temporal evolution of the boundary layer thermodynamic profile. Ground-based remote sensing instruments such as the multichannel microwave radiometer (MWR) and Atmospheric Emitted Radiance Interferometer (AERI) are able to provide profiles of temperature and water vapor through the boundary layer at 5-min resolution or better. Previous work compared these instruments through optimal-estimation retrievals on simulated clear-sky spectra to evaluate the retrieval accuracy and information content of each instrument. In this study, this method is duplicated using real observations from collocated MWR and AERI instruments from a field campaign in southwestern Germany. When compared with radiosondes, this study confirms the previous results that AERI retrievals are more accurate than MWR retrievals in clear-sky and below-cloud-base profiling. These results demonstrate that the AER...\n",
            "\n",
            "---\n",
            "\n",
            "Title: Probabilistic Multileave for Online Retrieval Evaluation\n",
            "Authors: Anne Schuth, Robert-Jan Bruintjes, Fritjof Buüttner, J. Doorn, C. Groenland, Harrie Oosterhuis, Cong-Nguyen Tran, Bastiaan S. Veeling, Jos van der Velde, R. Wechsler, David Woudenberg, M. de Rijke\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Online evaluation methods for information retrieval use implicit signals such as clicks from users to infer preferences between rankers. A highly sensitive way of inferring these preferences is through interleaved comparisons. Recently, interleaved comparisons methods that allow for simultaneous evaluation of more than two rankers have been introduced. These so-called multileaving methods are even more sensitive than their interleaving counterparts. Probabilistic interleaving--whose main selling point is the potential for reuse of historical data--has no multileaving counterpart yet. We propose probabilistic multileave and empirically show that it is highly sensitive and unbiased. An important implication of this result is that historical interactions with multileaved comparisons can be reused, allowing for ranker comparisons that need much less user interaction data. Furthermore, we show that our method, as opposed to earlier sensitive multileaving methods, scales well when the number of rankers increases.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-based Image Retrieval by Exploring Bandletized Regions through Support Vector Machines\n",
            "Authors: Rehan Ashraf, Khalid Bashir Bajwa, Toqeer Mahmood\n",
            "Year: 2016\n",
            "Venue: Journal of information science and engineering\n",
            "Abstract: One of the major requirements of the Content Based Image Retrieval (CBIR) systems is to ensure the meaningful image retrieval against query images. CBIR systems provide potential solutions of retrieving semantically similar images from large image repositories against any query image. The performances of these systems severely degrade by the inclusion of image contents which do not comprise the objects of interest in an image during the image representation phase. Segmentation of the images is considered as a solution but there isn’t any technique which can guarantee the object extraction in a robust way. Another limitation of the segmentation is that, most of the image segmentation techniques are very slow and still their results are not reliable. To overcome these problems a Bandelets transform based image representation technique is presented in this paper, which reliably returns the information about the major objects found in an image. For image retrieval purposes Support Vector Machine are applied and the performance of the system is evaluated on three standard data sets used in the domain of content based image retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Classical databases and knowledge organization: A case for boolean retrieval and human decision‐making during searches\n",
            "Authors: Birger Hjørland\n",
            "Year: 2015\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: This paper considers classical bibliographic databases based on the Boolean retrieval model (such as MEDLINE and PsycInfo). This model is challenged by modern search engines and information retrieval (IR) researchers, who often consider Boolean retrieval a less efficient approach. The paper examines this claim and argues for the continued value of Boolean systems, and suggests two further considerations: (a) the important role of human expertise in searching (expert searchers and “information literate” users) and (b) the role of library and information science and knowledge organization (KO) in the design and use of classical databases. An underlying issue is the kind of retrieval system for which one should aim. Warner's (2010) differentiation between the computer science traditions and an older library‐oriented tradition seems important; the former aim to transform queries automatically into (ranked) sets of relevant documents, whereas the latter aims to increase the “selection power” of users. The Boolean retrieval model is valuable in providing users with the power to make informed searches and have full control over what is found and what is not. These issues may have significant implications for the maintenance of information science and KO as research fields as well as for the information profession as a profession in its own right.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An effective approach to tweets opinion retrieval\n",
            "Authors: Zhunchen Luo, M. Osborne, Ting Wang\n",
            "Year: 2015\n",
            "Venue: World wide web (Bussum)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neuromodulatory signaling in hippocampus‐dependent memory retrieval\n",
            "Authors: S. Thomas\n",
            "Year: 2015\n",
            "Venue: Hippocampus\n",
            "Abstract: Considerable advances have been made toward understanding the molecular signaling events that underlie memory acquisition and consolidation. In contrast, less is known about memory retrieval, despite its necessity for utilizing learned information. This review focuses on neuromodulatory and intracellular signaling events that underlie memory retrieval mediated by the hippocampus, for which the most information is currently available. Among neuromodulators, adrenergic signaling is required for the retrieval of various types of hippocampus‐dependent memory. Although they contribute to acquisition and/or consolidation, cholinergic and dopaminergic signaling are generally not required for retrieval. Interestingly, while not required for retrieval, serotonergic and opioid signaling may actually constrain memory retrieval. Roles for histamine and non‐opioid neuropeptides are currently unclear but possible. A critical effector of adrenergic signaling in retrieval is reduction of the slow afterhyperpolarization mediated by β1 receptors, cyclic AMP, protein kinase A, Epac, and possibly ERK. In contrast, stress and glucocorticoids impair retrieval by decreasing cyclic AMP, mediated in part by the activation of β2‐adrenergic receptors. Clinically, alterations in neuromodulatory signaling and in memory retrieval occur in Alzheimer's disease, Down syndrome, depression, and post‐traumatic stress disorder, and recent evidence has begun to link changes in neuromodulatory signaling with effects on memory retrieval. © 2014 Wiley Periodicals, Inc.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval practice with short-answer, multiple-choice, and hybrid tests\n",
            "Authors: Megan A. Smith, Jeffrey D. Karpicke\n",
            "Year: 2014\n",
            "Venue: Memory\n",
            "Abstract: Retrieval practice improves meaningful learning, and the most frequent way of implementing retrieval practice in classrooms is to have students answer questions. In four experiments (N=372) we investigated the effects of different question formats on learning. Students read educational texts and practised retrieval by answering short-answer, multiple-choice, or hybrid questions. In hybrid conditions students first attempted to recall answers in short-answer format, then identified answers in multiple-choice format. We measured learning 1 week later using a final assessment with two types of questions: those that could be answered by recalling information verbatim from the texts and those that required inferences. Practising retrieval in all format conditions enhanced retention, relative to a study-only control condition, on both verbatim and inference questions. However, there were little or no advantages of answering short-answer or hybrid format questions over multiple-choice questions in three experiments. In Experiment 4, when retrieval success was improved under initial short-answer conditions, there was an advantage of answering short-answer or hybrid questions over multiple-choice questions. The results challenge the simple conclusion that short-answer questions always produce the best learning, due to increased retrieval effort or difficulty, and demonstrate the importance of retrieval success for retrieval-based learning activities.\n",
            "\n",
            "---\n",
            "\n",
            "Title: On Type-Aware Entity Retrieval\n",
            "Authors: Darío Garigliotti, K. Balog\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Today, the practice of returning entities from a knowledge base in response to search queries has become widespread. One of the distinctive characteristics of entities is that they are typed, i.e., assigned to some hierarchically organized type system (type taxonomy). The primary objective of this paper is to gain a better understanding of how entity type information can be utilized in entity retrieval. We perform this investigation in an idealized \"oracle\" setting, assuming that we know the distribution of target types of the relevant entities for a given query. We perform a thorough analysis of three main aspects: (i) the choice of type taxonomy, (ii) the representation of hierarchical type information, and (iii) the combination of type-based and term-based similarity in the retrieval model. Using a standard entity search test collection based on DBpedia, we find that type information proves most useful when using large type taxonomies that provide very specific types. We provide further insights on the extensional coverage of entities and on the utility of target types.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information-centric networking for the internet of things: challenges and opportunities\n",
            "Authors: M. Amadeo, C. Campolo, José Quevedo, Daniel Corujo, A. Molinaro, A. Iera, R. Aguiar, A. Vasilakos\n",
            "Year: 2016\n",
            "Venue: IEEE Network\n",
            "Abstract: In view of evolving the Internet infrastructure, ICN is promoting a communication model that is fundamentally different from the traditional IP address-centric model. The ICN approach consists of the retrieval of content by (unique) names, regardless of origin server location (i.e., IP address), application, and distribution channel, thus enabling in-network caching/replication and content-based security. The expected benefits in terms of improved data dissemination efficiency and robustness in challenging communication scenarios indicate the high potential of ICN as an innovative networking paradigm in the IoT domain. IoT is a challenging environment, mainly due to the high number of heterogeneous and potentially constrained networked devices, and unique and heavy traffic patterns. The application of ICN principles in such a context opens new opportunities, while requiring careful design choices. This article critically discusses potential ways toward this goal by surveying the current literature after presenting several possible motivations for the introduction of ICN in the context of IoT. Major challenges and opportunities are also highlighted, serving as guidelines for progress beyond the state of the art in this timely and increasingly relevant topic.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Memory Retrieval in Mice and Men.\n",
            "Authors: A. Ben-Yakov, Y. Dudai, M. Mayford\n",
            "Year: 2015\n",
            "Venue: Cold Spring Harbor Perspectives in Biology\n",
            "Abstract: Retrieval, the use of learned information, was until recently mostly terra incognita in the neurobiology of memory, owing to shortage of research methods with the spatiotemporal resolution required to identify and dissect fast reactivation or reconstruction of complex memories in the mammalian brain. The development of novel paradigms, model systems, and new tools in molecular genetics, electrophysiology, optogenetics, in situ microscopy, and functional imaging, have contributed markedly in recent years to our ability to investigate brain mechanisms of retrieval. We review selected developments in the study of explicit retrieval in the rodent and human brain. The picture that emerges is that retrieval involves coordinated fast interplay of sparse and distributed corticohippocampal and neocortical networks that may permit permutational binding of representational elements to yield specific representations. These representations are driven largely by the activity patterns shaped during encoding, but are malleable, subject to the influence of time and interaction of the existing memory with novel information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Sketch based image retrieval using a soft computation of the histogram of edge local orientations (S-HELO)\n",
            "Authors: J. M. Saavedra\n",
            "Year: 2014\n",
            "Venue: International Conference on Information Photonics\n",
            "Abstract: This paper introduces S-HELO (Soft-Histogram of Edge Local Orientations), an outperforming method for describing images in the context of sketch based image retrieval (SBIR). This proposal exploits the advantages provided by the HELO descriptor for describing sketches, and improves significantly its performance by using a soft computation of local orientations and taking into account spatial information. We experimentally demonstrate that a soft computation process together with a local estimation of orientations are very suitable for describing sketches in the context of image retrieval. Indeed, our results show that S-HELO significantly outperforms not only HELO but also classical orientation-based descriptors as HOG. We also show that S-HELO performs very close to the optimal when what we want to retrieve are target images. Moreover, our proposal also shows an outstanding performance for similarity search, i.e., retrieving images that belong to the same category of the query sketch.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Phase retrieval with masks using convex optimization\n",
            "Authors: K. Jaganathan, Yonina C. Eldar, B. Hassibi\n",
            "Year: 2015\n",
            "Venue: International Symposium on Information Theory\n",
            "Abstract: Signal recovery from the magnitude of the Fourier transform, or equivalently, from the autocorrelation, is a classical problem known as phase retrieval. Due to the absence of phase information, some form of additional information is required in order to be able to uniquely identify the underlying signal. In this work, we consider the problem of phase retrieval using masks. Due to our interest in developing robust algorithms with theoretical guarantees, we explore a convex optimization-based framework. In this work, we show that two specific masks (each mask provides 2n Fourier magnitude measurements) or five specific masks (each mask provides n Fourier magnitude measurements) are sufficient for a convex relaxation of the phase retrieval problem to provably recover almost all signals (up to global phase). We also show that the recovery is stable in the presence of measurement noise. This is a significant improvement over the existing results, which require O(log2 n) random masks (each mask provides n Fourier magnitude measurements) in order to guarantee unique recovery (up to global phase). Numerical experiments complement our theoretical analysis and show interesting trends, which we hope to explain in a future publication.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content-based image retrieval by integrating color and texture features\n",
            "Authors: Xiang-yang Wang, Bei-Bei Zhang, Hongying Yang\n",
            "Year: 2014\n",
            "Venue: Multimedia tools and applications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Semi-Synthetic Organism that Stores and Retrieves Increased Genetic Information\n",
            "Authors: Yorke Zhang, J. Ptacin, Emil C. Fischer, Hans R. Aerni, C. Caffaro, Kristine M San Jose, Aaron W Feldman, Court R. Turner, F. Romesberg\n",
            "Year: 2017\n",
            "Venue: Nature\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Listen up, eye movements play a role in verbal memory retrieval\n",
            "Authors: Agnes Scholz, K. Mehlhorn, J. Krems\n",
            "Year: 2014\n",
            "Venue: Psychological Research\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Medical Image Retrieval: A Multimodal Approach\n",
            "Authors: Yu Cao, Shawn Steffey, Jianbiao He, Degui Xiao, Cui Tao, Ping Chen, H. Müller\n",
            "Year: 2014\n",
            "Venue: Cancer Informatics\n",
            "Abstract: Medical imaging is becoming a vital component of war on cancer. Tremendous amounts of medical image data are captured and recorded in a digital format during cancer care and cancer research. Facing such an unprecedented volume of image data with heterogeneous image modalities, it is necessary to develop effective and efficient content-based medical image retrieval systems for cancer clinical practice and research. While substantial progress has been made in different areas of content-based image retrieval (CBIR) research, direct applications of existing CBIR techniques to the medical images produced unsatisfactory results, because of the unique characteristics of medical images. In this paper, we develop a new multimodal medical image retrieval approach based on the recent advances in the statistical graphic model and deep learning. Specifically, we first investigate a new extended probabilistic Latent Semantic Analysis model to integrate the visual and textual information from medical images to bridge the semantic gap. We then develop a new deep Boltzmann machine-based multimodal learning model to learn the joint density model from multimodal information in order to derive the missing modality. Experimental results with large volume of real-world medical images have shown that our new approach is a promising solution for the next-generation medical imaging indexing and retrieval system.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Response Ranking with Deep Matching Networks and External Knowledge in Information-seeking Conversation Systems\n",
            "Authors: Liu Yang, Minghui Qiu, Chen Qu, J. Guo, Yongfeng Zhang, W. Bruce Croft, Jun Huang, Haiqing Chen\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Intelligent personal assistant systems with either text-based or voice-based conversational interfaces are becoming increasingly popular around the world. Retrieval-based conversation models have the advantages of returning fluent and informative responses. Most existing studies in this area are on open domain ''chit-chat'' conversations or task / transaction oriented conversations. More research is needed for information-seeking conversations. There is also a lack of modeling external knowledge beyond the dialog utterances among current conversational models. In this paper, we propose a learning framework on the top of deep neural matching networks that leverages external knowledge for response ranking in information-seeking conversation systems. We incorporate external knowledge into deep neural models with pseudo-relevance feedback and QA correspondence knowledge distillation. Extensive experiments with three information-seeking conversation data sets including both open benchmarks and commercial data show that, our methods outperform various baseline methods including several deep text matching models and the state-of-the-art method on response selection in multi-turn conversations. We also perform analysis over different response types, model variations and ranking examples. Our models and research findings provide new insights on how to utilize external knowledge with deep neural models for response selection and have implications for the design of the next generation of information-seeking conversation systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Working memory retrieval as a decision process.\n",
            "Authors: B. Pearson, Julius Raskevicius, P. Bays, Y. Pertzov, M. Husain\n",
            "Year: 2014\n",
            "Venue: Journal of Vision\n",
            "Abstract: Working memory (WM) is a core cognitive process fundamental to human behavior, yet the mechanisms underlying it remain highly controversial. Here we provide a new framework for understanding retrieval of information from WM, conceptualizing it as a decision based on the quality of internal evidence. Recent findings have demonstrated that precision of WM decreases with memory load. If WM retrieval uses a decision process that depends on memory quality, systematic changes in response time distribution should occur as a function of WM precision. We asked participants to view sample arrays and, after a delay, report the direction of change in location or orientation of a probe. As WM precision deteriorated with increasing memory load, retrieval time increased systematically. Crucially, the shape of reaction time distributions was consistent with a linear accumulator decision process. Varying either task relevance of items or maintenance duration influenced memory precision, with corresponding shifts in retrieval time. These results provide strong support for a decision-making account of WM retrieval based on noisy storage of items. Furthermore, they show that encoding, maintenance, and retrieval in WM need not be considered as separate processes, but may instead be conceptually unified as operations on the same noise-limited, neural representation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Human Memory Retrieval and Inhibitory Control in the Brain: Beyond Correlational Evidence\n",
            "Authors: B. Penolazzi, D. Stramaccia, M. Braga, S. Mondini, G. Galfano\n",
            "Year: 2014\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Retrieving information from long-term memory can result in the episodic forgetting of related material. One influential account states that this retrieval-induced forgetting (RIF) phenomenon reflects inhibitory mechanisms called into play to decrease retrieval competition. Recent neuroimaging studies suggested that the prefrontal cortex, which is critically engaged in inhibitory processing, is also involved in retrieval competition situations. Here, we used transcranial direct current stimulation (tDCS) to address whether inhibitory processes could be causally linked to RIF. tDCS was administered over the right dorsolateral prefrontal cortex during the retrieval-practice phase in a standard retrieval-practice paradigm. Sixty human participants were randomly assigned to anodal, cathodal, or sham-control groups. The groups showed comparable benefits for practiced items. In contrast, unlike both the sham and anodal groups, the cathodal group exhibited no RIF. This pattern is interpreted as evidence for a causal role of inhibitory mechanisms in episodic retrieval and forgetting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Color Directional Local Quinary Patterns for Content Based Indexing and Retrieval\n",
            "Authors: Santosh Kumar Vipparthi, S. K. Nagar\n",
            "Year: 2014\n",
            "Venue: Human-Centric Computing and Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: CAsT-19: A Dataset for Conversational Information Seeking\n",
            "Authors: Jeffrey Dalton, Chenyan Xiong, Vaibhav Kumar, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: CAsT-19 is a new dataset that supports research on conversational information seeking. The corpus is 38,426,252 passages from the TREC Complex Answer Retrieval (CAR) and Microsoft MAchine Reading COmprehension (MARCO) datasets. Eighty information seeking dialogues (30 train, 50 test) are an average of 9 to 10 questions long. A dialogue may explore a topic broadly or drill down into subtopics. Questions contain ellipsis, implied context, mild topic shifts, and other characteristics of human conversation that may prevent them from being understood in isolation. Relevance assessments are provided for 30 training topics and 20 test topics. CAsT-19 promotes research on conversational information seeking by defining it as a task in which effective passage selection requires understanding a question's context (the dialogue history). It focuses attention on user modeling, analysis of prior retrieval results, transformation of questions into effective queries, and other topics that have been difficult to study with existing datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Mobile Information-Centric Networking: Research Issues and Challenges\n",
            "Authors: Chao Fang, Haipeng Yao, Zhuwei Wang, Wenjun Wu, Xiaoning Jin, F. R. Yu\n",
            "Year: 2018\n",
            "Venue: IEEE Communications Surveys and Tutorials\n",
            "Abstract: Recently, a series of innovative information-centric networking (ICN) architectures have been designed to better address the shift from host-centric end-to-end communication to requester-driven content retrieval. With the explosive increase of mobile data traffic, the mobility issue in ICN is a growing concern and a number of approaches have been proposed to deal with the mobility problem in ICN. Despite the potential advantages of ICN in mobile wireless environments, several significant research challenges remain to be addressed before its widespread deployment, including consistent routing, local cached content discovery, energy efficiency, privacy, security and trust, and practical deployment. In this paper, we present a brief survey on some of the works that have already been done to achieve mobile ICN, and discuss some research issues and challenges. We identify several important aspects of mobile ICN: overview, mobility enabling technologies, information-centric wireless mobile networks, and research challenges.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Meta Structure: Computing Relevance in Large Heterogeneous Information Networks\n",
            "Authors: Zhipeng Huang, Yudian Zheng, Reynold Cheng, Yizhou Sun, N. Mamoulis, Xiang Li\n",
            "Year: 2016\n",
            "Venue: Knowledge Discovery and Data Mining\n",
            "Abstract: A heterogeneous information network (HIN) is a graph model in which objects and edges are annotated with types. Large and complex databases, such as YAGO and DBLP, can be modeled as HINs. A fundamental problem in HINs is the computation of closeness, or relevance, between two HIN objects. Relevance measures can be used in various applications, including entity resolution, recommendation, and information retrieval. Several studies have investigated the use of HIN information for relevance computation, however, most of them only utilize simple structure, such as path, to measure the similarity between objects. In this paper, we propose to use meta structure, which is a directed acyclic graph of object types with edge types connecting in between, to measure the proximity between objects. The strength of meta structure is that it can describe complex relationship between two HIN objects (e.g., two papers in DBLP share the same authors and topics). We develop three relevance measures based on meta structure. Due to the computational complexity of these measures, we further design an algorithm with data structures proposed to support their evaluation. Our extensive experiments on YAGO and DBLP show that meta structure-based relevance is more effective than state-of-the-art approaches, and can be efficiently computed.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Caching Policies and Forwarding Mechanisms in Information-Centric Networking\n",
            "Authors: Andriana Ioannou, S. Weber\n",
            "Year: 2016\n",
            "Venue: IEEE Communications Surveys and Tutorials\n",
            "Abstract: Information-centric networking (ICN), an alternative to the host-centric model of the current Internet infrastructure, focuses on the distribution and retrieval of content instead of the transfer of information between specific endpoints. In order to achieve this, ICN is based on the paradigm of publish-subscribe and the concepts of naming and in-network caching. Current approaches to ICN employ caches within networks to minimize the latency of information retrieval. Content may be distributed either in caches along the delivery path(s), on-path caching or in any cache within a network, off-path caching. While approaches to off-path caching are comparable to traditional approaches for content replication and Web caching, approaches to on-path caching are specific to the ICN area. The purpose of this paper is to provide a review of the caching problem in ICN, with a focus on on-path caching. To this end, a detailed analysis of the existing caching policies and forwarding mechanisms that complement these policies is given. A number of criteria such as the caching model and level of operation and the evaluation parameters used in the evaluation of the existing caching policies are being employed to derive a taxonomy for on-path caching and highlight the trends and evaluation issues in this area. A discussion driven by the advantages and disadvantages of the existing caching policies and the challenges and open questions in on-path caching is finally being held.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Local quantized extrema patterns for content-based natural and texture image retrieval\n",
            "Authors: L. Rao, D. V. Rao\n",
            "Year: 2015\n",
            "Venue: Human-Centric Computing and Information Sciences\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Does the benefit of testing depend on lag, and if so, why? Evaluating the elaborative retrieval hypothesis\n",
            "Authors: Katherine A. Rawson, Kalif E. Vaughn, Shana K. Carpenter\n",
            "Year: 2014\n",
            "Venue: Memory & Cognition\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pareto-Depth for Multiple-Query Image Retrieval\n",
            "Authors: Ko-Jen Hsiao, Jeff Calder, Alfred O. Hero\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Most content-based image retrieval systems consider either one single query, or multiple queries that include the same object or represent the same semantic information. In this paper, we consider the content-based image retrieval problem for multiple query images corresponding to different image semantics. We propose a novel multiple-query information retrieval algorithm that combines the Pareto front method with efficient manifold ranking. We show that our proposed algorithm outperforms state of the art multiple-query retrieval algorithms on real-world image databases. We attribute this performance improvement to concavity properties of the Pareto fronts, and prove a theoretical result that characterizes the asymptotic concavity of the fronts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Content Based Image Indexing and Retrieval\n",
            "Authors: A. Bhute, B. Meshram, Matunga Mumbai Vjti\n",
            "Year: 2014\n",
            "Venue: arXiv.org\n",
            "Abstract: In this paper, we present the efficient content based image retrieval systems which employ the color, texture and shape information of images to facilitate the retrieval process. For efficient feature extraction, we extract the color, texture and shape feature of images automatically using edge detection which is widely used in signal processing and image compression. For facilitated the speedy retrieval we are implements the antipole-tree algorithm for indexing the images.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An integrated approach to Content Based Image Retrieval\n",
            "Authors: R. Choudhary, Nikita Raina, N. Chaudhary, Rashmi Chauhan, R. Goudar\n",
            "Year: 2014\n",
            "Venue: International Conference on Advances in Computing, Communications and Informatics\n",
            "Abstract: Content based image retrieval, in the last few years has received a wide attention. Content Based Image Retrieval (CBIR) basically is a technique to perform retrieval of the images from a large database which are similar to image given as query. CBIR is closer to human semantics, in the context of image retrieval process. CBIR technique has its application in different domains such as crime prevention, medical images, weather forecasting, surveillance, historical research and remote sensing Here content refers to the visual information of images such as texture, shape and color. Contents of image are richer in information for an efficient retrieval in comparison to text based image retrieval. In this paper, we have proposed a content based image retrieval integrated technique which extracts both the color and texture feature. To extract the color feature, color moment (CM) is used on color images and to extract the texture feature, local binary pattern (LBP) is performed on the grayscale image. Then both color and texture feature of image are combined to form a single feature vector. In the end similarity matching is performed by Euclidian distance which compares feature vector of database images with query images. LBP mainly used for face recognition. But we are going to use LBP for natural images. This combined approach provides accurate, efficient, less complex retrieval system.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Variational Interaction Information Maximization for Cross-domain Disentanglement\n",
            "Authors: HyeongJoo Hwang, Geon-hyeong Kim, Seunghoon Hong, Kee-Eung Kim\n",
            "Year: 2020\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Cross-domain disentanglement is the problem of learning representations partitioned into domain-invariant and domain-specific representations, which is a key to successful domain transfer or measuring semantic distance between two domains. Grounded in information theory, we cast the simultaneous learning of domain-invariant and domain-specific representations as a joint objective of multiple information constraints, which does not require adversarial training or gradient reversal layers. We derive a tractable bound of the objective and propose a generative model named Interaction Information Auto-Encoder (IIAE). Our approach reveals insights on the desirable representation for cross-domain disentanglement and its connection to Variational Auto-Encoder (VAE). We demonstrate the validity of our model in the image-to-image translation and the cross-domain retrieval tasks. We further show that our model achieves the state-of-the-art performance in the zero-shot sketch based image retrieval task, even without external knowledge. Our implementation is publicly available at: https://github.com/gr8joo/IIAE\n",
            "\n",
            "---\n",
            "\n",
            "Title: Entity linking and retrieval for semantic search\n",
            "Authors: E. Meij, K. Balog, Daan Odijk\n",
            "Year: 2014\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: More and more search engine users are expecting direct answers to their information needs, rather than links to documents. Semantic search and its recent applications enabled search engines to organize their wealth of information around entities. Entity linking and retrieval provide the building stones for organizing the web of entities. This tutorial aims to cover all facets of semantic search from a unified point of view and connect real-world applications with results from scientific publications. We provide a comprehensive overview of entity linking and retrieval in the context of semantic search and thoroughly explore techniques for query understanding, entity-based retrieval and ranking on unstructured text, structured knowledge repositories, and a mixture of these. We point out the connections between published approaches and applications, and provide hands-on examples on real-world use cases and datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evolution of research subjects in library and information science based on keyword, bibliographical coupling, and co-citation analyses\n",
            "Authors: Yu-Wei Chang, Mu-Hsuan Huang, Chiao-Wen Lin\n",
            "Year: 2015\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information-centric networking for connected vehicles: a survey and future perspectives\n",
            "Authors: M. Amadeo, C. Campolo, A. Molinaro\n",
            "Year: 2016\n",
            "Venue: IEEE Communications Magazine\n",
            "Abstract: In the connected vehicle ecosystem, a high volume of information-rich and safety-critical data will be exchanged by roadside units and onboard transceivers to improve the driving and traveling experience. However, poor-quality wireless links and the mobility of vehicles highly challenge data delivery. The IP address-centric model of the current Internet barely works in such extremely dynamic environments and poorly matches the localized nature of the majority of vehicular communications, which typically target specific road areas (e.g., in the proximity of a hazard or a point of interest) regardless of the identity/address of a single vehicle passing by. Therefore, a paradigm shift is advocated from traditional IP-based networking toward the groundbreaking information- centric networking. In this article, we scrutinize the applicability of this paradigm in vehicular environments by reviewing its core functionalities and the related work. The analysis shows that, thanks to features like named content retrieval, innate multicast support, and in-network data caching, information-centric networking is positioned to meet the challenging demands of vehicular networks and their evolution. Interoperability with the standard architectures for vehicular applications along with synergies with emerging computing and networking paradigms are debated as future research perspectives.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Disentangled Representations via Mutual Information Estimation\n",
            "Authors: E. Sanchez, M. Serrurier, M. Ortner\n",
            "Year: 2019\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Analyst Information Acquisition via EDGAR\n",
            "Authors: Brian Gibbons, P. Iliev, J. Kalodimos\n",
            "Year: 2019\n",
            "Venue: Management Sciences\n",
            "Abstract: We identify analysts’ information acquisition patterns by linking EDGAR (Electronic Data Gathering, Analysis, and Retrieval) server activity to analysts’ brokerage houses. Analysts rely on EDGAR in 24% of their estimate updates with an average of eight filings viewed. We document that analysts’ attention to public information is driven by the demand for information and the analysts’ incentives and career concerns. We find that information acquisition via EDGAR is associated with a significant reduction in analysts’ forecasting error relative to their peers. This relationship is likewise present when we focus on the intensity of analyst research. Attention to public information further enables analysts to provide forecasts for more time periods and more financial metrics. Informed recommendation updates are associated with substantial and persistent abnormal returns, even when the analyst accesses historical filings. Analysts’ use of EDGAR is associated with longer and more informative analysis within recommendation reports. This paper was accepted by Shiva Rajgopal, accounting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Making Information Seeking Easier: An Improved Pipeline for Conversational Search\n",
            "Authors: Vaibhav Kumar, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: Findings\n",
            "Abstract: This paper presents a highly effective pipeline for passage retrieval in a conversational search setting. The pipeline comprises of two components: Conversational Term Selection (CTS) and Multi-View Reranking (MVR). CTS is responsible for performing the first-stage of passage retrieval. Given an input question, it uses a BERT-based classifier (trained with weak supervision) to de-contextualize the input by selecting relevant terms from the dialog history. Using the question and the selected terms, it issues a query to a search engine to perform the first-stage of passage retrieval. On the other hand, MVR is responsible for contextualized passage reranking. It first constructs multiple views of the information need embedded within an input question. The views are based on the dialog history and the top documents obtained in the first-stage of retrieval. It then uses each view to rerank passages using BERT (fine-tuned for passage ranking). Finally, MVR performs a fusion over the rankings produced by the individual views. Experiments show that the above combination improves first-state retrieval as well as the overall accuracy in a reranking pipeline. On the key metric of NDCG@3, the proposed combination achieves a relative performance improvement of 14.8% over the state-of-the-art baseline and is also able to surpass the Oracle.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Too much information? Predictors of information overload in the context of online news exposure\n",
            "Authors: Josephine B. Schmitt, Christina A. Debbelt, F. Schneider\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: ABSTRACT As the Internet provides massive amounts of heterogeneous information, people may perceive this medium as challenging. The difficulty to evaluate and select relevant information increases as more and more diverse sources and content are available. Information overload (IO) may be the consequence. The research presented here gives a first comprehensive overview of possible indicators for IO in the context of online news exposure. Based on an online survey (N=419), we found that younger people with less information-seeking self-efficacy were more susceptible to experience IO. Additionally, we identified motivations for media consumption and information retrieval strategies in the Internet that imply IO. With our results, we contribute to a further understanding of IO and provide an important basis for future research needed to face the challenges resulting from the rising media diversity.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Research Methods in Library and Information Science\n",
            "Authors: A. Togia, Afrodite Malliari\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: Library and information science (LIS) is a very broad discipline, which uses a wide range of constantly evolving research strategies and techniques. The aim of this chapter is to provide an updated view of research issues in library and information science. A strati‐ fied random sample of 440 articles published in five prominent journals was analyzed and classified to identify (i) research approach, (ii) research methodology, and (iii) method of data analysis. For each variable, a coding scheme was developed, and the articles were coded accordingly. A total of 78% of the articles reported empirical research. The rest 22% were classified as non‐empirical research papers. The five most popular topics were “information retrieval,” “information behaviour,” “information literacy,” “library ser‐ vices,” and “organization and management.” An overwhelming majority of the empirical research articles employed a quantitative approach. Although the survey emerged as the most frequently used research strategy, there is evidence that the number and variety of research methodologies have been increased. There is also evidence that qualitative approaches are gaining increasing importance and have a role to play in LIS, while mixed methods have not yet gained enough recognition in LIS research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Collaborative Information Seeking: Art and Science of Achieving 1+1>2 in IR\n",
            "Authors: C. Shah\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Traditional IR techniques, systems, and methods that assume an individual searcher are often shown to be inadequate for addressing search problems that are multi-faceted and/or too complex or difficult for individuals. The next big leap in information seeking/retrieval could happen by considering social and collaborative aspects of search. In this half-day tutorial, this concept, along with some of the foundational works and latest developments in the field of collaborative information seeking (CIS) will be presented. Specifically, the course will introduce the student to theories, methodologies, and tools that focus on information retrieval/seeking in collaboration. The student will have an opportunity to learn about the social aspect of IR with a focus on collaborative search or CIS situations, systems, and evaluation techniques. The three hours will be divided as: (1) introduction to group-based IR models, approaches, and systems; (2) back-end of CIS systems with system-focused mediation and front-end with user-focused mediation; and (3) evaluation of CIS systems/approaches, prediction and recommendations with collaborative aspects of IR, and future directions. The attendees will be given a course-pack that will include a reference list, an annotated bibliography of seminal works in the field, and depictions of relevant models/frameworks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TREC Incident Streams: Finding Actionable Information on Social Media\n",
            "Authors: R. McCreadie, C. Buntain, I. Soboroff\n",
            "Year: 2019\n",
            "Venue: International Conference on Information Systems for Crisis Response and Management\n",
            "Abstract: The Text Retrieval Conference (TREC) Incident Streams track is a new initiative that aims to mature social \n",
            "media-based emergency response technology. This initiative advances the state of the art in this area through an \n",
            "evaluation challenge, which attracts researchers and developers from across the globe. The 2018 edition of the track \n",
            "provides a standardized evaluation methodology, an ontology of emergency-relevant social media information types, \n",
            "proposes a scale for information criticality, and releases a dataset containing fifteen test events and approximately \n",
            "20,000 labeled tweets. Analysis of this dataset reveals a significant amount of actionable information on social \n",
            "media during emergencies (> 10%). While this data is valuable for emergency response efforts, analysis of the \n",
            "39 state-of-the-art systems demonstrate a performance gap in identifying this data. We therefore find the current \n",
            "state-of-the-art is insufficient for emergency responders’ requirements, particularly for rare actionable information \n",
            "for which there is little prior training data available.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Hashing with Mutual Information\n",
            "Authors: Fatih Çakir, Kun He, Sarah Adel Bargal, S. Sclaroff\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "Abstract: Binary vector embeddings enable fast nearest neighbor retrieval in large databases of high-dimensional objects, and play an important role in many practical applications, such as image and video retrieval. We study the problem of learning binary vector embeddings under a supervised setting, also known as hashing. We propose a novel supervised hashing method based on optimizing an information-theoretic quantity, mutual information. We show that optimizing mutual information can reduce ambiguity in the induced neighborhood structure in the learned Hamming space, which is essential in obtaining high retrieval performance. To this end, we optimize mutual information in deep neural networks with minibatch stochastic gradient descent, with a formulation that maximally and efficiently utilizes available supervision. Experiments on four image retrieval benchmarks, including ImageNet, confirm the effectiveness of our method in learning high-quality binary embeddings for nearest neighbor retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Re-evaluation of learned information in Drosophila\n",
            "Authors: Johannes Felsenberg, Oliver Barnstedt, P. Cognigni, Suewei Lin, S. Waddell\n",
            "Year: 2017\n",
            "Venue: Nature\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Fashion IQ Dataset: Retrieving Images by Combining Side Information and Relative Natural Language Feedback\n",
            "Authors: Xiaoxiao Guo, Hui Wu, Yupeng Gao, Steven J. Rennie, R. Feris\n",
            "Year: 2019\n",
            "Venue: arXiv.org\n",
            "Abstract: We contribute a new dataset and a novel method for natural language based fashion image retrieval. Unlike previous fashion datasets, we provide natural language annotations to facilitate the training of interactive image retrieval systems, as well as the commonly used attribute based labels. We propose a novel approach and empirically demonstrate that combining natural language feedback with visual attribute information results in superior user feedback modeling and retrieval performance relative to using either of these modalities. We believe that our dataset can encourage further work on developing more natural and real-world applicable conversational shopping assistants.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Security Attacks in Information-Centric Networking\n",
            "Authors: Eslam G. AbdAllah, H. Hassanein, Mohammad Zulkernine\n",
            "Year: 2015\n",
            "Venue: IEEE Communications Surveys and Tutorials\n",
            "Abstract: Information-centric networking (ICN) is a new communication paradigm that focuses on content retrieval from a network regardless of the storage location or physical representation of this content. In ICN, securing the content itself is much more important than securing the infrastructure or the endpoints. To achieve the security goals in this new paradigm, it is crucial to have a comprehensive understanding of ICN attacks, their classification, and proposed solutions. In this paper, we provide a survey of attacks unique to ICN architectures and other generic attacks that have an impact on ICN. It also provides a taxonomy of these attacks in ICN, which are classified into four main categories, i.e., naming, routing, caching, and other miscellaneous related attacks. Furthermore, this paper shows the relation between ICN attacks and unique ICN attributes, and that between ICN attacks and security requirements, i.e., confidentiality, integrity, availability, and privacy. Finally, this paper presents the severity levels of ICN attacks and discusses the existing ICN security solutions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Answering Complex Questions Using Open Information Extraction\n",
            "Authors: Tushar Khot, Ashish Sabharwal, Peter Clark\n",
            "Year: 2017\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: While there has been substantial progress in factoid question-answering (QA), answering complex questions remains challenging, typically requiring both a large body of knowledge and inference techniques. Open Information Extraction (Open IE) provides a way to generate semi-structured knowledge for QA, but to date such knowledge has only been used to answer simple questions with retrieval-based methods. We overcome this limitation by presenting a method for reasoning with Open IE knowledge, allowing more complex questions to be handled. Using a recently proposed support graph optimization framework for QA, we develop a new inference model for Open IE, in particular one that can work effectively with multiple short facts, noise, and the relational structure of tuples. Our model significantly outperforms a state-of-the-art structured solver on complex questions of varying difficulty, while also removing the reliance on manually curated knowledge.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Green Information-Centric Networking: Research Issues and Challenges\n",
            "Authors: Chao Fang, Haipeng Yao, Zhuwei Wang, Wenjun Wu, Xiaoning Jin, F. Yu\n",
            "Year: 2015\n",
            "Venue: IEEE Communications Surveys and Tutorials\n",
            "Abstract: To better cope with the Internet usage shift from host-centric end-to-end communication to receiver-driven content retrieval, innovative information-centric networking (ICN) architectures have been proposed. With the explosive increase in global network traffic, the energy efficiency issue in ICN is a growing concern. A number of approaches have been proposed to address the energy-efficiency issue in ICN. However, several significant research challenges remain to be addressed before its widespread deployment, including shutdown, slowdown, mobility, and cloud computing. In this paper, we present a brief survey on some of the works that have been already done to achieve green ICN and discuss some research issues and challenges. We identify several important aspects of green ICN, i.e., overview, energy efficiency metrics, network planning, enabling technologies, and challenges. Finally, we explore some broader perspectives for green ICN.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Lost in the Middle: How Language Models Use Long Contexts\n",
            "Authors: Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, F. Petroni, Percy Liang\n",
            "Year: 2023\n",
            "Venue: Transactions of the Association for Computational Linguistics\n",
            "Abstract: While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: MIHash: Online Hashing with Mutual Information\n",
            "Authors: Fatih Çakir, Kun He, Sarah Adel Bargal, S. Sclaroff\n",
            "Year: 2017\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Learning-based hashing methods are widely used for nearest neighbor retrieval, and recently, online hashing methods have demonstrated good performance-complexity trade-offs by learning hash functions from streaming data. In this paper, we first address a key challenge for online hashing: the binary codes for indexed data must be recomputed to keep pace with updates to the hash functions. We propose an efficient quality measure for hash functions, based on an information-theoretic quantity, mutual information, and use it successfully as a criterion to eliminate unnecessary hash table updates. Next, we also show how to optimize the mutual information objective using stochastic gradient descent. We thus develop a novel hashing method, MIHash, that can be used in both online and batch settings. Experiments on image retrieval benchmarks (including a 2.5M image dataset) confirm the effectiveness of our formulation, both in reducing hash table recomputations and in learning high-quality hash functions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems\n",
            "Authors: Martín Abadi, Ashish Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. Corrado, Andy Davis, J. Dean, M. Devin, Sanjay Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Yangqing Jia, R. Józefowicz, Lukasz Kaiser, M. Kudlur, J. Levenberg, Dandelion Mané, R. Monga, Sherry Moore, D. Murray, C. Olah, M. Schuster, Jonathon Shlens, Benoit Steiner, I. Sutskever, Kunal Talwar, P. Tucker, Vincent Vanhoucke, Vijay Vasudevan, F. Viégas, O. Vinyals, Pete Warden, M. Wattenberg, M. Wicke, Yuan Yu, Xiaoqiang Zheng\n",
            "Year: 2016\n",
            "Venue: arXiv.org\n",
            "Abstract: TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Macaw: An Extensible Conversational Information Seeking Platform\n",
            "Authors: Hamed Zamani, Nick Craswell\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Conversational information seeking (CIS) has been recognized as a major emerging research area in information retrieval. Such research will require data and tools, to allow the implementation and study of conversational systems. This paper introduces Macaw, an open-source framework with a modular architecture for CIS research. Macaw supports multi-turn, multi-modal, and mixed-initiative interactions, and enables research for tasks such as document retrieval, question answering, recommendation, and structured data exploration. It has a modular design to encourage the study of new CIS algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. Macaw is distributed under the MIT License.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modeling Relational Data with Graph Convolutional Networks\n",
            "Authors: M. Schlichtkrull, Thomas Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, M. Welling\n",
            "Year: 2017\n",
            "Venue: Extended Semantic Web Conference\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Discovering Meta-Paths in Large Heterogeneous Information Networks\n",
            "Authors: Changping Meng, Reynold Cheng, Silviu Maniu, P. Senellart, Wangda Zhang\n",
            "Year: 2015\n",
            "Venue: The Web Conference\n",
            "Abstract: The Heterogeneous Information Network (HIN) is a graph data model in which nodes and edges are annotated with class and relationship labels. Large and complex datasets, such as Yago or DBLP, can be modeled as HINs. Recent work has studied how to make use of these rich information sources. In particular, meta-paths, which represent sequences of node classes and edge types between two nodes in a HIN, have been proposed for such tasks as information retrieval, decision making, and product recommendation. Current methods assume meta-paths are found by domain experts. However, in a large and complex HIN, retrieving meta-paths manually can be tedious and difficult. We thus study how to discover meta-paths automatically. Specifically, users are asked to provide example pairs of nodes that exhibit high proximity. We then investigate how to generate meta-paths that can best explain the relationship between these node pairs. Since this problem is computationally intractable, we propose a greedy algorithm to select the most relevant meta-paths. We also present a data structure to enable efficient execution of this algorithm. We further incorporate hierarchical relationships among node classes in our solutions. Extensive experiments on real-world HIN show that our approach captures important meta-paths in an efficient and scalable manner.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Accessing Real-Life Episodic Information from Minutes versus Hours Earlier Modulates Hippocampal and High-Order Cortical Dynamics.\n",
            "Authors: J. Chen, C. Honey, E. Simony, Michael Arcaro, K. Norman, U. Hasson\n",
            "Year: 2016\n",
            "Venue: Cerebral Cortex\n",
            "Abstract: It is well known that formation of new episodic memories depends on hippocampus, but in real-life settings (e.g., conversation), hippocampal amnesics can utilize information from several minutes earlier. What neural systems outside hippocampus might support this minutes-long retention? In this study, subjects viewed an audiovisual movie continuously for 25 min; another group viewed the movie in 2 parts separated by a 1-day delay. Understanding Part 2 depended on retrieving information from Part 1, and thus hippocampus was required in the day-delay condition. But is hippocampus equally recruited to access the same information from minutes earlier? We show that accessing memories from a few minutes prior elicited less interaction between hippocampus and default mode network (DMN) cortical regions than accessing day-old memories of identical events, suggesting that recent information was available with less reliance on hippocampal retrieval. Moreover, the 2 groups evinced reliable but distinct DMN activity timecourses, reflecting differences in information carried in these regions when Part 1 was recent versus distant. The timecourses converged after 4 min, suggesting a time frame over which the continuous-viewing group may have relied less on hippocampal retrieval. We propose that cortical default mode regions can intrinsically retain real-life episodic information for several minutes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal biomedical image indexing and retrieval using descriptive text and global feature mapping\n",
            "Authors: Matthew S. Simpson, Dina Demner-Fushman, Sameer Kiran Antani, G. Thoma\n",
            "Year: 2014\n",
            "Venue: Information retrieval (Boston)\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: MISC: A data set of information-seeking conversations\n",
            "Authors: Paul Thomas, Daniel J. McDuff, M. Czerwinski, Nick Craswell\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: Conversational interfaces to information retrieval systems, via software agents such as Siri or Cortana, are of commercial and research interest. To build or evaluate these software interfaces it is natural to consider how people act in the same role, but there is little public, fine-grained, data on interactions with intermediaries for web tasks. We introduce the Microsoft Information-Seeking Conversation data (MISC), a set of recordings of information-seeking conversations between human “seekers” and “intermediaries”. MISC includes audio and video signals; transcripts of conversation; affectual and physiological signals; recordings of search and other computer use; and post-task surveys on emotion, success, and effort. We hope that these recordings will support conversational retrieval interfaces both in engineering (how can we make “natural” systems?) and evaluation (what does a “good” conversation look like?).\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Notion of Relevance in Information Science: Everybody knows what relevance is. But, what is it really?\n",
            "Authors: T. Saracevic\n",
            "Year: 2016\n",
            "Venue: The Notion of Relevance in Information Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Comparison of Deep Learning Based Query Expansion with Pseudo-Relevance Feedback and Mutual Information\n",
            "Authors: M. Almasri, C. Berrut, J. Chevallet\n",
            "Year: 2016\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: ENT Rank: Retrieving Entities for Topical Information Needs through Entity-Neighbor-Text Relations\n",
            "Authors: Laura Dietz\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Related work has demonstrated the helpfulness of utilizing information about entities in text retrieval; here we explore the converse: Utilizing information about text in entity retrieval. We model the relevance of Entity-Neighbor-Text (ENT) relations to derive a learning-to-rank-entities model. We focus on the task of retrieving (multiple) relevant entities in response to a topical information need such as \"Zika fever\". The ENT Rank model is designed to exploit semi-structured knowledge resources such as Wikipedia for entity retrieval. The ENT Rank model combines (1) established features of entity-relevance, with (2) information from neighboring entities (co-mentioned or mentioned-on-page) through (3) relevance scores of textual contexts through traditional retrieval models such as BM25 and RM3.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SHIHbot: A Facebook chatbot for Sexual Health Information on HIV/AIDS\n",
            "Authors: Jacqueline Brixey, Rens Hoegen, Wei Lan, Joshua A Rusow, Karan Singla, Xusen Yin, Ron Artstein, Anton Leuski\n",
            "Year: 2017\n",
            "Venue: SIGDIAL Conference\n",
            "Abstract: We present the implementation of an autonomous chatbot, SHIHbot, deployed on Facebook, which answers a wide variety of sexual health questions on HIV/AIDS. The chatbot’s response database is com-piled from professional medical and public health resources in order to provide reliable information to users. The system’s backend is NPCEditor, a response selection platform trained on linked questions and answers; to our knowledge this is the first retrieval-based chatbot deployed on a large public social network.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evolution of library and information science, 1965–2005: Content analysis of journal articles\n",
            "Authors: Otto Tuomaala, K. Järvelin, P. Vakkari\n",
            "Year: 2014\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: This article first analyzes library and information science (LIS) research articles published in core LIS journals in 2005. It also examines the development of LIS from 1965 to 2005 in light of comparable data sets for 1965, 1985, and 2005. In both cases, the authors report (a) how the research articles are distributed by topic and (b) what approaches, research strategies, and methods were applied in the articles. In 2005, the largest research areas in LIS by this measure were information storage and retrieval, scientific communication, library and information‐service activities, and information seeking. The same research areas constituted the quantitative core of LIS in the previous years since 1965. Information retrieval has been the most popular area of research over the years. The proportion of research on library and information‐service activities decreased after 1985, but the popularity of information seeking and of scientific communication grew during the period studied. The viewpoint of research has shifted from library and information organizations to end users and development of systems for the latter. The proportion of empirical research strategies was high and rose over time, with the survey method being the single most important method. However, attention to evaluation and experiments increased considerably after 1985. Conceptual research strategies and system analysis, description, and design were quite popular, but declining. The most significant changes from 1965 to 2005 are the decreasing interest in library and information‐service activities and the growth of research into information seeking and scientific communication.\n",
            "\n",
            "---\n",
            "\n",
            "Title: FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation\n",
            "Authors: Sewon Min, Kalpesh Krishna, Xinxi Lyu, M. Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, Hannaneh Hajishirzi\n",
            "Year: 2023\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Evaluating the factuality of long-form text generated by large language models (LMs) is non-trivial because (1) generations often contain a mixture of supported and unsupported pieces of information, making binary judgments of quality inadequate, and (2) human evaluation is time-consuming and costly. In this paper, we introduce FACTSCORE, a new evaluation that breaks a generation into a series of atomic facts and computes the percentage of atomic facts supported by a reliable knowledge source. We conduct an extensive human evaluation to obtain FACTSCOREs of people biographies generated by several state-of-the-art commercial LMs -- InstructGPT, ChatGPT, and the retrieval-augmented PerplexityAI -- and report new analysis demonstrating the need for such a fine-grained score (e.g., ChatGPT only achieves 58%). Since human evaluation is costly, we also introduce an automated model that estimates FACTSCORE using retrieval and a strong language model, with less than a 2% error rate. Finally, we use this automated metric to evaluate 6,500 generations from a new set of 13 recent LMs that would have cost $26K if evaluated by humans, with various findings: GPT-4 and ChatGPT are more factual than public models, and Vicuna and Alpaca are some of the best public models. FACTSCORE is available for public use via `pip install factscore`.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge\n",
            "Authors: Yunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steven Jiang, You Zhang\n",
            "Year: 2023\n",
            "Venue: Cureus\n",
            "Abstract: Objective The primary aim of this research was to address the limitations observed in the medical knowledge of prevalent large language models (LLMs) such as ChatGPT, by creating a specialized language model with enhanced accuracy in medical advice. Methods We achieved this by adapting and refining the large language model meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform. These conversations were cleaned and anonymized to respect privacy concerns. In addition to the model refinement, we incorporated a self-directed information retrieval mechanism, allowing the model to access and utilize real-time information from online sources like Wikipedia and data from curated offline medical databases. Results The fine-tuning of the model with real-world patient-doctor interactions significantly improved the model's ability to understand patient needs and provide informed advice. By equipping the model with self-directed information retrieval from reliable online and offline sources, we observed substantial improvements in the accuracy of its responses. Conclusion Our proposed ChatDoctor, represents a significant advancement in medical LLMs, demonstrating a significant improvement in understanding patient inquiries and providing accurate advice. Given the high stakes and low error tolerance in the medical field, such enhancements in providing accurate and reliable information are not only beneficial but essential.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Learning: Methods and Applications\n",
            "Authors: L. Deng, Dong Yu\n",
            "Year: 2014\n",
            "Venue: Foundations and Trends® in Signal Processing\n",
            "Abstract: This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Emergence of Knowledge and How it Supports the Memory for Novel Related Information\n",
            "Authors: T. Sommer\n",
            "Year: 2016\n",
            "Venue: Cerebral Cortex\n",
            "Abstract: Abstract Current theories suggest that memories for novel information and events, over time and with repeated retrieval, lose the association to their initial learning context. They are consolidated into a more stable form and transformed into semantic knowledge, that is, semanticized. Novel, related information can then be rapidly integrated into such knowledge, leading to superior memory. We tested these hypotheses in a longitudinal, 302‐day, human functional magnetic resonance imaging study in which participants first overlearned and consolidated associative structures. This phase was associated with a shift from hippocampal‐ to ventrolateral prefrontal cortex (vlPFC)‐mediated retrieval, consistent with semanticization. Next, participants encoded novel, related information whose encoding into the already acquired knowledge was orchestrated by the ventromedial prefrontal cortex. Novel related information exhibited reduced forgetting compared with novel control information, which corresponded to a faster shift from hippocampal‐ to vlPFC‐mediated retrieval. In sum, the current results suggest that memory for novel information can be enhanced by anchoring it to prior knowledge via acceleration of the processes observed during semanticization.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Visual working memory buffers information retrieved from visual long-term memory\n",
            "Authors: Keisuke Fukuda, G. Woodman\n",
            "Year: 2017\n",
            "Venue: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Abstract: Significance How do we retrieve long-term memory? Here, we show that by measuring subjects’ electroencephalogram (EEG), we can directly observe the dynamic process of long-term memory retrieval. Our findings suggest that retrieved information becomes consciously available by being represented in a working-memory format that is similar to that used to represent new perceptual inputs. Furthermore, we show that our EEG measures can track the process of retrieving and combining two long-term memories acquired separately (e.g., image of a horse and a pair of wings) into one working-memory representation (e.g., a Pegasus). Thus, our results not only provide direct neural support for a long-assumed theory of memory retrieval but also demonstrate how flexible retrieval allows for creative thought. Human memory is thought to consist of long-term storage and short-term storage mechanisms, the latter known as working memory. Although it has long been assumed that information retrieved from long-term memory is represented in working memory, we lack neural evidence for this and need neural measures that allow us to watch this retrieval into working memory unfold with high temporal resolution. Here, we show that human electrophysiology can be used to track information as it is brought back into working memory during retrieval from long-term memory. Specifically, we found that the retrieval of information from long-term memory was limited to just a few simple objects’ worth of information at once, and elicited a pattern of neurophysiological activity similar to that observed when people encode new information into working memory. Our findings suggest that working memory is where information is buffered when being retrieved from long-term memory and reconcile current theories of memory retrieval with classic notions about the memory mechanisms involved.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Neural Networks for YouTube Recommendations\n",
            "Authors: Paul Covington, Jay K. Adams, Emre Sargin\n",
            "Year: 2016\n",
            "Venue: ACM Conference on Recommender Systems\n",
            "Abstract: YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.\n",
            "\n",
            "---\n",
            "\n",
            "Title: librosa: Audio and Music Signal Analysis in Python\n",
            "Authors: Brian McFee, Colin Raffel, Dawen Liang, D. Ellis, Matt McVicar, Eric Battenberg, Oriol Nieto\n",
            "Year: 2015\n",
            "Venue: SciPy\n",
            "Abstract: This document describes version 0.4.0 of librosa: a Python pack- age for audio and music signal processing. At a high level, librosa provides implementations of a variety of common functions used throughout the field of music information retrieval. In this document, a brief overview of the library's functionality is provided, along with explanations of the design goals, software development practices, and notational conventions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Critical Review of Recurrent Neural Networks for Sequence Learning\n",
            "Authors: Zachary Chase Lipton\n",
            "Year: 2015\n",
            "Venue: arXiv.org\n",
            "Abstract: Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been dicult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades rst yielded and then made practical these powerful learning models. When appropriate, we reconcile conicting notation and nomenclature. Our goal is to provide a selfcontained explication of the state of the art together with a historical perspective and references to primary research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Mapping recent information behavior research: an analysis of co-authorship and co-citation networks\n",
            "Authors: A. González-Teruel, G. González-Alcaide, Maite Barrios, M. Abad-García\n",
            "Year: 2015\n",
            "Venue: Scientometrics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Metric Learning Using Triplet Network\n",
            "Authors: Elad Hoffer, Nir Ailon\n",
            "Year: 2014\n",
            "Venue: International Workshop on Similarity-Based Pattern Recognition\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\n",
            "Authors: O. Khattab, M. Zaharia\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Recent progress in Natural Language Understanding (NLU) is driving fast-paced advances in Information Retrieval (IR), largely owed to fine-tuning deep language models (LMs) for document ranking. While remarkably effective, the ranking models based on these LMs increase computational cost by orders of magnitude over prior approaches, particularly as they must feed each query-document pair through a massive neural network to compute a single relevance score. To tackle this, we present ColBERT, a novel ranking model that adapts deep LMs (in particular, BERT) for efficient retrieval. ColBERT introduces a late interaction architecture that independently encodes the query and the document using BERT and then employs a cheap yet powerful interaction step that models their fine-grained similarity. By delaying and yet retaining this fine-granular interaction, ColBERT can leverage the expressiveness of deep LMs while simultaneously gaining the ability to pre-compute document representations offline, considerably speeding up query processing. Crucially, ColBERT's pruning-friendly interaction mechanism enables leveraging vector-similarity indexes for end-to-end retrieval directly from millions of documents. We extensively evaluate ColBERT using two recent passage search datasets. Results show that ColBERT's effectiveness is competitive with existing BERT-based models (and outperforms every non-BERT baseline), while executing two orders-of-magnitude faster and requiring up to four orders-of-magnitude fewer FLOPs per query.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CodeSearchNet Challenge: Evaluating the State of Semantic Code Search\n",
            "Authors: Hamel Husain, Hongqiu Wu, Tiferet Gazit, Miltiadis Allamanis, Marc Brockschmidt\n",
            "Year: 2019\n",
            "Venue: arXiv.org\n",
            "Abstract: Semantic code search is the task of retrieving relevant code given a natural language query. While related to other information retrieval tasks, it requires bridging the gap between the language used in code (often abbreviated and highly technical) and natural language more suitable to describe vague concepts and ideas. \n",
            "To enable evaluation of progress on code search, we are releasing the CodeSearchNet Corpus and are presenting the CodeSearchNet Challenge, which consists of 99 natural language queries with about 4k expert relevance annotations of likely results from CodeSearchNet Corpus. The corpus contains about 6 million functions from open-source code spanning six programming languages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet Corpus also contains automatically generated query-like natural language for 2 million functions, obtained from mechanically scraping and preprocessing associated function documentation. In this article, we describe the methodology used to obtain the corpus and expert labels, as well as a number of simple baseline solutions for the task. \n",
            "We hope that CodeSearchNet Challenge encourages researchers and practitioners to study this interesting task further and will host a competition and leaderboard to track the progress on the challenge. We are also keen on extending CodeSearchNet Challenge to more queries and programming languages in the future.\n",
            "\n",
            "---\n",
            "\n",
            "Title: AcousticBrainz: A Community Platform for Gathering Music Information Obtained from Audio\n",
            "Authors: Alastair Porter, D. Bogdanov, R. Kaye, R. Tsukanov, Xavier Serra\n",
            "Year: 2015\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada a la 16th International Society for Music Information Retrieval Conference (ISMIR 2015), celebrada els dies 26 a 30 d'octubre de 2015 a Malaga, Espanya.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Understanding Information Need: An fMRI Study\n",
            "Authors: Yashar Moshfeghi, P. Triantafillou, F. Pollick\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The raison d'etre of IR is to satisfy human information need. But, do we really understand information need? Despite advances in the past few decades in both the IR and relevant scientific communities, this question is largely unanswered. We do not really understand how an information need emerges and how it is physically manifested. Information need refers to a complex concept: at the very initial state of the phenomenon (i.e. at a visceral level), even the searcher may not be aware of its existence. This renders the measuring of this concept (using traditional behaviour studies) nearly impossible. In this paper, we investigate the connection between an information need and brain activity. Using functional Magnetic Resonance Imaging (fMRI), we measured the brain activity of twenty four participants while they performed a Question Answering (Q/A) Task, where the questions were carefully selected and developed from TREC-8 and TREC 2001 Q/A Track. The results of this experiment revealed a distributed network of brain regions commonly associated with activities related to information need and retrieval and differing brain activity in processing scenarios when participants knew the answer to a given question and when they did not and needed to search. We believe our study and conclusions constitute an important step in unravelling the nature of information need and therefore better satisfying it.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploring the Space of Topic Coherence Measures\n",
            "Authors: Michael Röder, A. Both, Alexander Hinneburg\n",
            "Year: 2015\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CORD-19: The Covid-19 Open Research Dataset\n",
            "Authors: Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Darrin Eide, Kathryn Funk, Rodney Michael Kinney, Ziyang Liu, William Merrill, P. Mooney, D. Murdick, Devvret Rishi, J. Sheehan, Zhihong Shen, Brandon Stilson, Alex D Wade, Kuansan Wang, Christopher Wilhelm, Boya Xie, Douglas A. Raymond, Daniel S. Weld, Oren Etzioni, Sebastian Kohlmeier\n",
            "Year: 2020\n",
            "Venue: NLPCOVID19\n",
            "Abstract: The COVID-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on COVID-19 and related historical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information retrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19 has been downloaded over 200K times and has served as the basis of many COVID-19 text mining and discovery systems. In this article, we describe the mechanics of dataset construction, highlighting challenges and key design decisions, provide an overview of how CORD-19 has been used, and describe several shared tasks built around the dataset. We hope this resource will continue to bring together the computing community, biomedical experts, and policy makers in the search for effective treatments and management policies for COVID-19.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Transformer Memory as a Differentiable Search Index\n",
            "Authors: Yi Tay, Vinh Q. Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, Tal Schuster, William W. Cohen, Donald Metzler\n",
            "Year: 2022\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: In this paper, we demonstrate that information retrieval can be accomplished with a single Transformer, in which all information about the corpus is encoded in the parameters of the model. To this end, we introduce the Differentiable Search Index (DSI), a new paradigm that learns a text-to-text model that maps string queries directly to relevant docids; in other words, a DSI model answers queries directly using only its parameters, dramatically simplifying the whole retrieval process. We study variations in how documents and their identifiers are represented, variations in training procedures, and the interplay between models and corpus sizes. Experiments demonstrate that given appropriate design choices, DSI significantly outperforms strong baselines such as dual encoder models. Moreover, DSI demonstrates strong generalization capabilities, outperforming a BM25 baseline in a zero-shot setup.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Relating Brain Structures To Open-Ended Descriptions Of Cognition\n",
            "Authors: Jérôme Dockès, O. Grisel, Joan Massich, Fabian M. Suchanek, B. Thirion, G. Varoquaux\n",
            "Year: 2017\n",
            "Venue: \n",
            "Abstract: Finding correspondences between mental processes and brain structures is a central goal in cognitive neuroscience. Neuroimaging provides brain-activity maps associated with cognitive task, however each study explores only a handful of mental processes. Here we use literature mining to bridge results across studies, establishing a bidirectional mapping between brain and mind. Our goal is to work on an open-ended set of terms describing cognitive processes. Moreover we introduce a validation framework using information retrieval met-rics to ensure the accuracy of such correspondences, with a clear focus on relative frequencies, ignored in previous studies , to capture the relative importance of cognitive concepts. We show that this approach enables open-ended encoding and decoding.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Neural Network Approach to Context-Sensitive Generation of Conversational Responses\n",
            "Authors: Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, W. Dolan\n",
            "Year: 2015\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information content and sensitivity of the 3 β + 2 α lidar measurement system for aerosol microphysical retrievals\n",
            "Authors: S. Burton, E. Chemyakin, Xu Liu, K. Knobelspiesse, S. Stamnes, P. Sawamura, R. Moore, C. Hostetler, R. Ferrare\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Abstract. There is considerable interest in retrieving profiles of aerosol effective radius, total number concentration, and complex refractive index from lidar measurements of extinction and backscatter at several wavelengths. The combination of three backscatter channels plus two extinction channels (3β + 2α) is particularly important since it is believed to be the minimum configuration necessary for the retrieval of aerosol microphysical properties and because the technological readiness of lidar systems permits this configuration on both an airborne and future spaceborne instrument. The second-generation NASA Langley airborne High Spectral Resolution Lidar (HSRL-2) has been making 3β + 2α measurements since 2012. The planned NASA Aerosol/Clouds/Ecosystems (ACE) satellite mission also recommends the 3β + 2α combination. Here we develop a deeper understanding of the information content and sensitivities of the 3β + 2α system in terms of aerosol microphysical parameters of interest. We use a retrieval-free methodology to determine the basic sensitivities of the measurements independent of retrieval assumptions and constraints. We calculate information content and uncertainty metrics using tools borrowed from the optimal estimation methodology based on Bayes' theorem, using a simplified forward model look-up table, with no explicit inversion. The forward model is simplified to represent spherical particles, monomodal log-normal size distributions, and wavelength-independent refractive indices. Since we only use the forward model with no retrieval, the given simplified aerosol scenario is applicable as a best case for all existing retrievals in the absence of additional constraints. Retrieval-dependent errors due to mismatch between retrieval assumptions and true atmospheric aerosols are not included in this sensitivity study, and neither are retrieval errors that may be introduced in the inversion process. The choice of a simplified model adds clarity to the understanding of the uncertainties in such retrievals, since it allows for separately assessing the sensitivities and uncertainties of the measurements alone that cannot be corrected by any potential or theoretical improvements to retrieval methodology but must instead be addressed by adding information content. The sensitivity metrics allow for identifying (1) information content of the measurements vs. a priori information; (2) error bars on the retrieved parameters; and (3) potential sources of cross-talk or \"compensating\" errors wherein different retrieval parameters are not independently captured by the measurements. The results suggest that the 3β + 2α measurement system is underdetermined with respect to the full suite of microphysical parameters considered in this study and that additional information is required, in the form of additional coincident measurements (e.g., sun-photometer or polarimeter) or a priori retrieval constraints. A specific recommendation is given for addressing cross-talk between effective radius and total number concentration.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Transduction of DNA information through water and electromagnetic waves\n",
            "Authors: L. Montagnier, E. del Giudice, Jamal Aïssa, C. Lavallée, S. Motschwiller, A. Capolupo, A. Polcari, P. Romano, A. Tedeschi, G. Vitiello\n",
            "Year: 2014\n",
            "Venue: Electromagnetic Biology and Medicine\n",
            "Abstract: Abstract The experimental conditions by which electromagnetic signals (EMS) of low frequency can be emitted by diluted aqueous solutions of some bacterial and viral DNAs are described. That the recorded EMS and nanostructures induced in water carry the DNA information (sequence) is shown by retrieval of that same DNA by classical PCR amplification using the TAQ polymerase, including both primers and nucleotides. Moreover, such a transduction process has also been observed in living human cells exposed to EMS irradiation. These experiments suggest that coherent long-range molecular interaction must be present in water to observe the above-mentioned features. The quantum field theory analysis of the phenomenon is presented in this article.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Natural Language Processing and Information Systems\n",
            "Authors: Elisabeth Métais, Mathieu Roche, M. Teisseire\n",
            "Year: 2014\n",
            "Venue: Lecture Notes in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Differential Representations of Perceived and Retrieved Visual Information in Hippocampus and Cortex.\n",
            "Authors: Sue-Hyun Lee, Dwight J. Kravitz, C. Baker\n",
            "Year: 2018\n",
            "Venue: Cerebral Cortex\n",
            "Abstract: Memory retrieval is thought to depend on interactions between hippocampus and cortex, but the nature of representation in these regions and their relationship remains unclear. Here, we performed an ultra-high field fMRI (7T) experiment, comprising perception, learning and retrieval sessions. We observed a fundamental difference between representations in hippocampus and high-level visual cortex during perception and retrieval. First, while object-selective posterior fusiform cortex showed consistent responses that allowed us to decode object identity across both perception and retrieval one day after learning, object decoding in hippocampus was much stronger during retrieval than perception. Second, in visual cortex but not hippocampus, there was consistency in response patterns between perception and retrieval, suggesting that substantial neural populations are shared for both perception and retrieval. Finally, the decoding in hippocampus during retrieval was not observed when retrieval was tested on the same day as learning suggesting that the retrieval process itself is not sufficient to elicit decodable object representations. Collectively, these findings suggest that while cortical representations are stable between perception and retrieval, hippocampal representations are much stronger during retrieval, implying some form of reorganization of the representations between perception and retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: ShinyGO: a graphical gene-set enrichment tool for animals and plants\n",
            "Authors: S. X. Ge, Dongmin Jung, Runan Yao\n",
            "Year: 2019\n",
            "Venue: Bioinform.\n",
            "Abstract: MOTIVATION\n",
            "Gene lists are routinely produced from various genome-wide studies. Enrichment analysis can link these gene lists with underlying molecular pathways and functional categories such as gene ontology (GO) and other databases.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "To complement existing tools, we developed ShinyGO based on a large annotation database derived from Ensembl and STRING-db for 59 plant, 256 animal, 115 archaeal, and 1678 bacterial species. ShinyGO's novel features include graphical visualization of enrichment results and gene characteristics, and application program interface (API) access to KEGG and STRING for the retrieval of pathway diagrams and protein-protein interaction networks. ShinyGO is an intuitive, graphical web application that can help researchers gain actionable insights from gene lists.\n",
            "\n",
            "\n",
            "AVAILABILITY\n",
            "http://ge-lab.org/go/.\n",
            "\n",
            "\n",
            "SUPPLEMENTARY INFORMATION\n",
            "Supplementary data are available at Bioinformatics online.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks\n",
            "Authors: Aliaksei Severyn, Alessandro Moschitti\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Learning a similarity function between pairs of objects is at the core of learning to rank approaches. In information retrieval tasks we typically deal with query-document pairs, in question answering -- question-answer pairs. However, before learning can take place, such pairs needs to be mapped from the original space of symbolic words into some feature space encoding various aspects of their relatedness, e.g. lexical, syntactic and semantic. Feature engineering is often a laborious task and may require external knowledge sources that are not always available or difficult to obtain. Recently, deep learning approaches have gained a lot of attention from the research community and industry for their ability to automatically learn optimal feature representation for a given task, while claiming state-of-the-art performance in many tasks in computer vision, speech recognition and natural language processing. In this paper, we present a convolutional neural network architecture for reranking pairs of short texts, where we learn the optimal representation of text pairs and a similarity function to relate them in a supervised way from the available training data. Our network takes only words in the input, thus requiring minimal preprocessing. In particular, we consider the task of reranking short text pairs where elements of the pair are sentences. We test our deep learning system on two popular retrieval tasks from TREC: Question Answering and Microblog Retrieval. Our model demonstrates strong performance on the first task beating previous state-of-the-art systems by about 3\\% absolute points in both MAP and MRR and shows comparable results on tweet reranking, while enjoying the benefits of no manual feature engineering and no additional syntactic parsers.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of the FIRE 2016 Microblog track: Information Extraction from Microblogs Posted during Disasters\n",
            "Authors: Saptarshi Ghosh, Kripabandhu Ghosh\n",
            "Year: 2016\n",
            "Venue: Fire\n",
            "Abstract: The FIRE 2016 Microblog track focused on retrieval of microblogs (tweets posted on Twitter) during disaster events. A collection of about 50,000 microblogs posted during a recent disaster event was made available to the participants, along with a set of seven practical information needs during a disaster situation. The task was to retrieve microblogs relevant to these needs. 10 teams participated in the task, submitting a total of 15 runs. The task resulted in comparison among performances of various microblog retrieval strategies over a benchmark collection, and brought out the challenges in microblog retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond short snippets: Deep networks for video classification\n",
            "Authors: Joe Yue-Hei Ng, Matthew J. Hausknecht, Sudheendra Vijayanarasimhan, O. Vinyals, R. Monga, G. Toderici\n",
            "Year: 2015\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Convolutional neural networks (CNNs) have been extensively applied for image recognition problems giving state-of-the-art results on recognition, detection, segmentation and retrieval. In this work we propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted. We propose two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose we employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN. Our best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101 datasets with (88.6% vs. 88.0%) and without additional optical flow information (82.6% vs. 73.0%).\n",
            "\n",
            "---\n",
            "\n",
            "Title: The NarrativeQA Reading Comprehension Challenge\n",
            "Authors: Tomás Kociský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, Edward Grefenstette\n",
            "Year: 2017\n",
            "Venue: Transactions of the Association for Computational Linguistics\n",
            "Abstract: Reading comprehension (RC)—in contrast to information retrieval—requires integrating information and reasoning about events, entities, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read. However, existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency); they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here. We provide an analysis of the dataset and the challenges it presents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information resilience through user-assisted caching in disruptive Content-Centric Networks\n",
            "Authors: Vasilis Sourlas, L. Tassiulas, I. Psaras, G. Pavlou\n",
            "Year: 2015\n",
            "Venue: 2015 IFIP Networking Conference (IFIP Networking)\n",
            "Abstract: We investigate an information-resilience scheme in the context of Content-Centric Networks (CCN) for the retrieval of content in disruptive, fragmented networks cases. To resolve and fetch content when the origin is not available due to fragmentation, we exploit content cached both in in-network caches and in end-users' devices. Initially, we present the required modifications in the CCN architecture to support the proposed resilience scheme. We also present the family of policies that enable the retrieval of cached content and we derive an analytical expression/lower bound of the probability that an information item will disappear from the network (be absorbed) and the time to absorption when the origin of the item is not reachable. Extensive simulations indicate that the proposed resilience scheme is a valid tool for the retrieval of cached content in disruptive scenarios, since it allows the retrieval of content for a long period after the fragmentation of the network and the “disappearance” of the content origin.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Affective Computing and Sentiment Analysis\n",
            "Authors: E. Cambria\n",
            "Year: 2016\n",
            "Venue: IEEE Intelligent Systems\n",
            "Abstract: Understanding emotions is an important aspect of personal development and growth, and as such it is a key tile for the emulation of human intelligence. Besides being important for the advancement of AI, emotion processing is also important for the closely related task of polarity detection. The opportunity to automatically capture the general public's sentiments about social events, political movements, marketing campaigns, and product preferences has raised interest in both the scientific community, for the exciting open challenges, and the business world, for the remarkable fallouts in marketing and financial market prediction. This has led to the emerging fields of affective computing and sentiment analysis, which leverage human-computer interaction, information retrieval, and multimodal signal processing for distilling people's sentiments from the ever-growing amount of online social data.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Learning Based Recommender System\n",
            "Authors: Shuai Zhang, Lina Yao, Aixin Sun, Yi Tay, Shuai Zhang, Lina Yao, Aixin Sun\n",
            "Year: 2017\n",
            "Venue: ACM Computing Surveys\n",
            "Abstract: With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions\n",
            "Authors: Wei Shen, Jianyong Wang, Jiawei Han\n",
            "Year: 2015\n",
            "Venue: IEEE Transactions on Knowledge and Data Engineering\n",
            "Abstract: The large number of potential applications from bridging web data with knowledge bases have led to an increase in the entity linking research. Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base. Potential applications include information extraction, information retrieval, and knowledge base population. However, this task is challenging due to name variations and entity ambiguity. In this survey, we present a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The effect of testing versus restudy on retention: a meta-analytic review of the testing effect.\n",
            "Authors: Christopher A. Rowland\n",
            "Year: 2014\n",
            "Venue: Psychological bulletin\n",
            "Abstract: Engaging in a test over previously studied information can serve as a potent learning event, a phenomenon referred to as the testing effect. Despite a surge of research in the past decade, existing theories have not yet provided a cohesive account of testing phenomena. The present study uses meta-analysis to examine the effects of testing versus restudy on retention. Key results indicate support for the role of effortful processing as a contributor to the testing effect, with initial recall tests yielding larger testing benefits than recognition tests. Limited support was found for existing theoretical accounts attributing the testing effect to enhanced semantic elaboration, indicating that consideration of alternative mechanisms is warranted in explaining testing effects. Future theoretical accounts of the testing effect may benefit from consideration of episodic and contextually derived contributions to retention resulting from memory retrieval. Additionally, the bifurcation model of the testing effect is considered as a viable framework from which to characterize the patterns of results present across the literature.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Process of Question Answering\n",
            "Authors: W. Lehnert\n",
            "Year: 2022\n",
            "Venue: \n",
            "Abstract: Abstract : Problems in computational question answering assume a new perspective when question answering is viewed as a problem in natural language processing. A theory of question answering has been proposed which relies on ideas in conceptual information processing and theories of human memory organization. This theory of question answering has been implemented in a computer program, QUALM, currently being used by two story understanding systems to complete a natural language processing system which reads stories and answers questions about what was read. The processes in QUALM are divided into 4 phases: (1) Conceptual categorization which guides subsequent processing by dictating which specific inference mechanisms and memory retrieval strategies should be invoked in the course of answering a question; (2) Inferential analysis which is responsible for understanding what the questioner really meant when a question should not be taken literally; (3) Content specification which determines how much of an answer should be returned in terms of detail and elaborations, and (4) Retrieval heuristics which do the actual digging to extract an answer from memory.\n",
            "\n",
            "---\n",
            "\n",
            "Title: International Code of Nomenclature for algae, fungi, and plants\n",
            "Authors: N. Turland, J. Wiersema, F. Barrie, Werner Greuter, D. L. Hawksworth, P. Herendeen, Sandra Knapp, Wolf-Henning Kusber, De-Zhu Li, Karol Marhold, Tom W. May, J. McNeill, A. Monro, Jefferson Prado, Michelle J. Price, Gideon F. Smith\n",
            "Year: 2018\n",
            "Venue: Regnum Vegetabile\n",
            "Abstract: © 2018, International Association for Plant Taxonomy. All rights reserved. No part of this book may be reproduced or utilized in any form or by any means, electronic or mechanical, including photocopying, recording, or by any information storage and retrieval system, or be translated into any other language, without written permission from the copyright holder. https://www.iapt-taxon.org/nomen/main.php\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Deep Representations of Fine-Grained Visual Descriptions\n",
            "Authors: Scott E. Reed, Zeynep Akata, Honglak Lee, B. Schiele\n",
            "Year: 2016\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: State-of-the-art methods for zero-shot visual recognition formulate learning as a joint embedding problem of images and side information. In these formulations the current best complement to visual features are attributes: manually-encoded vectors describing shared characteristics among categories. Despite good performance, attributes have limitations: (1) finer-grained recognition requires commensurately more attributes, and (2) attributes do not provide a natural language interface. We propose to overcome these limitations by training neural language models from scratch, i.e. without pre-training and only consuming words and characters. Our proposed models train end-to-end to align with the fine-grained and category-specific content of images. Natural language provides a flexible and compact way of encoding only the salient visual aspects for distinguishing categories. By training on raw text, our model can do inference on raw text as well, providing humans a familiar mode both for annotation and retrieval. Our model achieves strong performance on zero-shot text-based image retrieval and significantly outperforms the attribute-based state-of-the-art for zero-shot classification on the Caltech-UCSD Birds 200-2011 dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Feature Learning Based Deep Supervised Hashing with Pairwise Labels\n",
            "Authors: Wu-Jun Li, Sheng Wang, Wang-Cheng Kang\n",
            "Year: 2015\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract: Recent years have witnessed wide application of hashing for large-scale image retrieval. However, most existing hashing methods are based on handcrafted features which might not be optimally compatible with the hashing procedure. Recently, deep hashing methods have been proposed to perform simultaneous feature learning and hash-code learning with deep neural networks, which have shown better performance than traditional hashing methods with hand-crafted features. Most of these deep hashing methods are supervised whose supervised information is given with triplet labels. For another common application scenario with pairwise labels, there have not existed methods for simultaneous feature learning and hash-code learning. In this paper, we propose a novel deep hashing method, called deep pairwise-supervised hashing (DPSH), to perform simultaneous feature learning and hashcode learning for applications with pairwise labels. Experiments on real datasets show that our DPSH method can outperform other methods to achieve the state-of-the-art performance in image retrieval applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Convex Optimization Algorithms\n",
            "Authors: D. Bertsekas\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: c 2015 Dimitri P. Bertsekas All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.\n",
            "\n",
            "---\n",
            "\n",
            "Title: RealTime QA: What's the Answer Right Now?\n",
            "Authors: Jungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi, Ronan Le Bras, Akari Asai, Xinyan Velocity Yu, Dragomir R. Radev, Noah A. Smith, Yejin Choi, Kentaro Inui\n",
            "Year: 2022\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: We introduce REALTIME QA, a dynamic question answering (QA) platform that announces questions and evaluates systems on a regular basis (weekly in this version). REALTIME QA inquires about the current world, and QA systems need to answer questions about novel events or information. It therefore challenges static, conventional assumptions in open-domain QA datasets and pursues instantaneous applications. We build strong baseline models upon large pretrained language models, including GPT-3 and T5. Our benchmark is an ongoing effort, and this paper presents real-time evaluation results over the past year. Our experimental results show that GPT-3 can often properly update its generation results, based on newly-retrieved documents, highlighting the importance of up-to-date information retrieval. Nonetheless, we find that GPT-3 tends to return outdated answers when retrieved documents do not provide sufficient information to find an answer. This suggests an important avenue for future research: can an open-domain QA system identify such unanswerable cases and communicate with the user or even the retrieval module to modify the retrieval results? We hope that REALTIME QA will spur progress in instantaneous applications of question answering and beyond.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information-centric delay-tolerant mobile ad-hoc networks\n",
            "Authors: You Lu, Xiao Li, Yu-Ting Yu, M. Gerla\n",
            "Year: 2014\n",
            "Venue: Conference on Computer Communications Workshops\n",
            "Abstract: Information-centric networks have recently been drawing increasing attention in academia as well as in industry. Information and content retrieval is a critical service for mobile ad-hoc networks. It relies on other resources and tools, such as internal storage, content searching and sharing, delay-tolerant delivery, etc. Previous studies have shown that social networking can assist delay-tolerant routing design in many respects. In this paper, we specifically address content retrieval in delay-tolerant mobile ad-hoc networks. We propose a social-tie based content retrieval scheme to support the delay-tolerant MANET. The social hierarchy is structured using balanced connectivity criteria and a K-mean clustering algorithm. The proposed scheme has been evaluated and validated on a real social network dataset.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Contextual Information Drives the Reconsolidation-Dependent Updating of Retrieved Fear Memories\n",
            "Authors: Timothy J. Jarome, Nicole C. Ferrara, Janine L. Kwapis, F. J. Helmstetter\n",
            "Year: 2015\n",
            "Venue: Neuropsychopharmacology\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Novel Neural Source Code Representation Based on Abstract Syntax Tree\n",
            "Authors: Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, Xudong Liu\n",
            "Year: 2019\n",
            "Venue: International Conference on Software Engineering\n",
            "Abstract: Exploiting machine learning techniques for analyzing programs has attracted much attention. One key problem is how to represent code fragments well for follow-up analysis. Traditional information retrieval based methods often treat programs as natural language texts, which could miss important semantic information of source code. Recently, state-of-the-art studies demonstrate that abstract syntax tree (AST) based neural models can better represent source code. However, the sizes of ASTs are usually large and the existing models are prone to the long-term dependency problem. In this paper, we propose a novel AST-based Neural Network (ASTNN) for source code representation. Unlike existing models that work on entire ASTs, ASTNN splits each large AST into a sequence of small statement trees, and encodes the statement trees to vectors by capturing the lexical and syntactical knowledge of statements. Based on the sequence of statement vectors, a bidirectional RNN model is used to leverage the naturalness of statements and finally produce the vector representation of a code fragment. We have applied our neural network based source code representation method to two common program comprehension tasks: source code classification and code clone detection. Experimental results on the two tasks indicate that our model is superior to state-of-the-art approaches.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey on Recent Advances in Named Entity Recognition from Deep Learning models\n",
            "Authors: Vikas Yadav, Steven Bethard\n",
            "Year: 2018\n",
            "Venue: International Conference on Computational Linguistics\n",
            "Abstract: Named Entity Recognition (NER) is a key component in NLP systems for question answering, information retrieval, relation extraction, etc. NER systems have been studied and developed widely for decades, but accurate systems using deep neural networks (NN) have only been introduced in the last few years. We present a comprehensive survey of deep neural network architectures for NER, and contrast them with previous approaches to NER based on feature engineering and other supervised or semi-supervised learning algorithms. Our results highlight the improvements achieved by neural networks, and show how incorporating some of the lessons learned from past work on feature-based NER systems can yield further improvements.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of NTCIR-11 Temporal Information Access (Temporalia) Task\n",
            "Authors: Hideo Joho, A. Jatowt, Roi Blanco, Hajime Naka, Shuhei Yamamoto\n",
            "Year: 2014\n",
            "Venue: NTCIR Conference on Evaluation of Information Access Technologies\n",
            "Abstract: This paper describes the overview of NTCIR-11 Temporal Information Access (Temporalia) task. This pilot task aims to foster research in temporal aspects of information retrieval and search. Temporalia is composed of two subtasks: Temporal Query Intent Classication (TQIC) and Temporal Information Retrieval (TIR) subtask. TQIC attracted 6 teams which submitted a total of 17 runs, while 6 teams took part in TIR proposing 18 runs. In this paper we describe both subtasks, datasets, evaluation methods and results of meta analyses.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploiting Privileged Information from Web Data for Image Categorization\n",
            "Authors: Wen Li, Li Niu, Dong Xu\n",
            "Year: 2014\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents\n",
            "Authors: Thomas Wolf, Victor Sanh, Julien Chaumond, Clement Delangue\n",
            "Year: 2019\n",
            "Venue: arXiv.org\n",
            "Abstract: We introduce a new approach to generative data-driven dialogue systems (e.g. chatbots) called TransferTransfo which is a combination of a Transfer learning based training scheme and a high-capacity Transformer model. Fine-tuning is performed by using a multi-task objective which combines several unsupervised prediction tasks. The resulting fine-tuned model shows strong improvements over the current state-of-the-art end-to-end conversational models like memory augmented seq2seq and information-retrieval models. On the privately held PERSONA-CHAT dataset of the Conversational Intelligence Challenge 2, this approach obtains a new state-of-the-art, with respective perplexity, Hits@1 and F1 metrics of 16.28 (45 % absolute improvement), 80.7 (46 % absolute improvement) and 19.5 (20 % absolute improvement).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Challenges of Mathematical Information Retrievalin the NTCIR-11 Math Wikipedia Task\n",
            "Authors: M. Schubotz, Abdou Youssef, V. Markl, H. Cohl\n",
            "Year: 2015\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Mathematical Information Retrieval concerns retrieving information related to a particular mathematical concept. The NTCIR-11 Math Task develops an evaluation test collection for document sections retrieval of scientific articles based on human generated topics. Those topics involve a combination of formula patterns and keywords. In addition, the optional Wikipedia Task provides a test collection for retrieval of individual mathematical formula from Wikipedia based on search topics that contain exactly one formula pattern. We developed a framework for automatic query generation and immediate evaluation. This paper discusses our dataset preparation, topic generation and evaluation methods, and summarizes the results of the participants, with a special focus on the Wikipedia Task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: End-to-End Open-Domain Question Answering with BERTserini\n",
            "Authors: Wei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen Tan, Kun Xiong, Ming Li, Jimmy J. Lin\n",
            "Year: 2019\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: We demonstrate an end-to-end question answering system that integrates BERT with the open-source Anserini information retrieval toolkit. In contrast to most question answering and reading comprehension models today, which operate over small amounts of input text, our system integrates best practices from IR with a BERT-based reader to identify answers from a large corpus of Wikipedia articles in an end-to-end fashion. We report large improvements over previous results on a standard benchmark test collection, showing that fine-tuning pretrained BERT with SQuAD is sufficient to achieve high accuracy in identifying answer spans.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Collaborative information seeking\n",
            "Authors: Chirag Shah\n",
            "Year: 2014\n",
            "Venue: J. Assoc. Inf. Sci. Technol.\n",
            "Abstract: The notions that information seeking is not always a solitary activity and that people working in collaboration for information intensive tasks should be studied and supported have become more prevalent in recent years. Several new research questions, methodologies, and systems have emerged around these notions that may prove to be useful beyond the field of collaborative information seeking (CIS), with relevance to the broader area of information seeking and behavior. This article provides an overview of such key research work from a variety of domains, including library and information science, computer‐supported cooperative work, human‐computer interaction, and information retrieval. It starts with explanations of collaboration and how CIS fits in different contexts, emphasizing the interactive, intentional, and mutually beneficial nature of CIS activities. Relations to similar and related fields such as collaborative information retrieval, collaborative information behavior, and collaborative filtering are also clarified. Next, the article presents a synthesis of various frameworks and models that exist in the field today, along with a new synthesis of 12 different dimensions of group activities. A discussion on issues and approaches relating to evaluating various parameters in CIS follows. Finally, a list of known issues and challenges is presented to provide an overview of research opportunities in this field.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning semantic representations using convolutional neural networks for web search\n",
            "Authors: Yelong Shen, Xiaodong He, Jianfeng Gao, L. Deng, Grégoire Mesnil\n",
            "Year: 2014\n",
            "Venue: The Web Conference\n",
            "Abstract: This paper presents a series of new latent semantic models based on a convolutional neural network (CNN) to learn low-dimensional semantic vectors for search queries and Web documents. By using the convolution-max pooling operation, local contextual information at the word n-gram level is modeled first. Then, salient local fea-tures in a word sequence are combined to form a global feature vector. Finally, the high-level semantic information of the word sequence is extracted to form a global vector representation. The proposed models are trained on clickthrough data by maximizing the conditional likelihood of clicked documents given a query, us-ing stochastic gradient ascent. The new models are evaluated on a Web document ranking task using a large-scale, real-world data set. Results show that our model significantly outperforms other se-mantic models, which were state-of-the-art in retrieval performance prior to this work.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Collective Matrix Factorization Hashing for Multimodal Data\n",
            "Authors: Guiguang Ding, Yuchen Guo, J. Zhou\n",
            "Year: 2014\n",
            "Venue: 2014 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: Nearest neighbor search methods based on hashing have attracted considerable attention for effective and efficient large-scale similarity search in computer vision and information retrieval community. In this paper, we study the problems of learning hash functions in the context of multimodal data for cross-view similarity search. We put forward a novel hashing method, which is referred to Collective Matrix Factorization Hashing (CMFH). CMFH learns unified hash codes by collective matrix factorization with latent factor model from different modalities of one instance, which can not only supports cross-view search but also increases the search accuracy by merging multiple view information sources. We also prove that CMFH, a similarity-preserving hashing learning method, has upper and lower boundaries. Extensive experiments verify that CMFH significantly outperforms several state-of-the-art methods on three different datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Random access in large-scale DNA data storage\n",
            "Authors: Lee Organick, S. Ang, Yuan-Jyue Chen, Randolph Lopez, S. Yekhanin, K. Makarychev, Miklós Z. Rácz, G. Kamath, Parikshit Gopalan, Bichlien H. Nguyen, Christopher N. Takahashi, Sharon Newman, Hsing-Yeh Parker, Cyrus Rashtchian, Kendall Stewart, Gagan Gupta, Robert Carlson, J. Mulligan, Douglas M. Carmean, Georg Seelig, L. Ceze, K. Strauss\n",
            "Year: 2018\n",
            "Venue: Nature Biotechnology\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking\n",
            "Authors: Thibault Formal, Benjamin Piwowarski, S. Clinchant\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: In neural Information Retrieval, ongoing research is directed towards improving the first retriever in ranking pipelines. Learning dense embeddings to conduct retrieval using efficient approximate nearest neighbors methods has proven to work well. Meanwhile, there has been a growing interest in learning sparse representations for documents and queries, that could inherit from the desirable properties of bag-of-words models such as the exact matching of terms and the efficiency of inverted indexes. In this work, we present a new first-stage ranker based on explicit sparsity regularization and a log-saturation effect on term weights, leading to highly sparse representations and competitive results with respect to state-of-the-art dense and sparse methods. Our approach is simple, trained end-to-end in a single stage. We also explore the trade-off between effectiveness and efficiency, by controlling the contribution of the sparsity regularization.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Hippocampal-prefrontal input supports spatial encoding in working memory\n",
            "Authors: T. Spellman, Mattia Rigotti, S. Ahmari, Stefano Fusi, J. Gogos, J. Gordon\n",
            "Year: 2015\n",
            "Venue: Nature\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Ultrasensitive hyperspectral imaging and biodetection enabled by dielectric metasurfaces\n",
            "Authors: F. Yesilkoy, Eduardo Arvelo, Yasaman Jahani, Mingkai Liu, Andreas Tittl, V. Cevher, Y. Kivshar, H. Altug\n",
            "Year: 2019\n",
            "Venue: Nature Photonics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning\n",
            "Authors: Krishna Srinivasan, K. Raman, Jiecao Chen, Michael Bendersky, Marc Najork\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The milestone improvements brought about by deep representation learning and pre-training techniques have led to large performance gains across downstream NLP, IR and Vision tasks. Multimodal modeling techniques aim to leverage large high-quality visio-linguistic datasets for learning complementary information across image and text modalities. In this paper, we introduce the Wikipedia-based Image Text (WIT) Dataset to better facilitate multimodal, multilingual learning. WIT is composed of a curated set of 37.5 million entity rich image-text examples with 11.5 million unique images across 108 Wikipedia languages. Its size enables WIT to be used as a pretraining dataset for multimodal models, as we show when applied to downstream tasks such as image-text retrieval. WIT has four main and unique advantages. First, WIT is the largest multimodal dataset by the number of image-text examples by 3x (at the time of writing). Second, WIT is massively multilingual (first of its kind) with coverage over 100+ languages (each of which has at least 12K examples) and provides cross-lingual texts for many images. Third, WIT represents a more diverse set of concepts and real world entities relative to what previous datasets cover. Lastly, WIT provides a very challenging real-world test set, as we empirically illustrate using an image-text retrieval task as an example. WIT Dataset is available for download and use via a Creative Commons license here: https://github.com/google-research-datasets/wit.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Social Information Seeking\n",
            "Authors: C. Shah\n",
            "Year: 2017\n",
            "Venue: The Information Retrieval Series\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Passage Impacts for Inverted Indexes\n",
            "Authors: Antonio Mallia, O. Khattab, N. Tonellotto, Torsten Suel\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Neural information retrieval systems typically use a cascading pipeline, in which a first-stage model retrieves a candidate set of documents and one or more subsequent stages re-rank this set using contextualized language models such as BERT. In this paper, we propose DeepImpact, a new document term-weighting scheme suitable for efficient retrieval using a standard inverted index. Compared to existing methods, DeepImpact improves impact-score modeling and tackles the vocabulary-mismatch problem. In particular, DeepImpact leverages DocT5Query to enrich the document collection and, using a contextualized language model, directly estimates the semantic importance of tokens in a document, producing a single-value representation for each token in each document. Our experiments show that DeepImpact significantly outperforms prior first-stage retrieval approaches by up to 17% on effectiveness metrics w.r.t. DocT5Query, and, when deployed in a re-ranking scenario, can reach the same effectiveness of state-of-the-art approaches with up to 5.1x speedup in efficiency.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Visual Semantic Reasoning for Image-Text Matching\n",
            "Authors: Kunpeng Li, Yulun Zhang, K. Li, Yuanyuan Li, Y. Fu\n",
            "Year: 2019\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Image-text matching has been a hot research topic bridging the vision and language areas. It remains challenging because the current representation of image usually lacks global semantic concepts as in its corresponding text caption. To address this issue, we propose a simple and interpretable reasoning model to generate visual representation that captures key objects and semantic concepts of a scene. Specifically, we first build up connections between image regions and perform reasoning with Graph Convolutional Networks to generate features with semantic relationships. Then, we propose to use the gate and memory mechanism to perform global semantic reasoning on these relationship-enhanced features, select the discriminative information and gradually generate the representation for the whole scene. Experiments validate that our method achieves a new state-of-the-art for the image-text matching on MS-COCO and Flickr30K datasets. It outperforms the current best method by 6.8% relatively for image retrieval and 4.8% relatively for caption retrieval on MS-COCO (Recall@1 using 1K test set). On Flickr30K, our model improves image retrieval by 12.6% relatively and caption retrieval by 5.8% relatively (Recall@1).\n",
            "\n",
            "---\n",
            "\n",
            "Title: ICE: Item Concept Embedding via Textual Information\n",
            "Authors: Chuan-Ju Wang, Ting-Hsiang Wang, Hsiu-Wei Yang, Boyu Chang, Ming-Feng Tsai\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This paper proposes an item concept embedding (ICE) framework to model item concepts via textual information. Specifically, in the proposed framework there are two stages: graph construction and embedding learning. In the first stage, we propose a generalized network construction method to build a network involving heterogeneous nodes and a mixture of both homogeneous and heterogeneous relations. The second stage leverages the concept of neighborhood proximity to learn the embeddings of both items and words. With the proposed carefully designed ICE networks, the resulting embedding facilitates both homogeneous and heterogeneous retrieval, including item-to-item and word-to-item retrieval. Moreover, as a distributed embedding approach, the proposed ICE approach not only generates related retrieval results but also delivers more diverse results than traditional keyword-matching-based approaches. As our experiments on two real-world datasets show, ICE encodes useful textual information and thus outperforms traditional methods in various item classification and retrieval tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Unobtrusive Sensing and Wearable Devices for Health Informatics\n",
            "Authors: Yali Zheng, Xiaorong Ding, Carmen C. Y. Poon, Benny P. L. Lo, Heye Zhang, Xiao-Lin Zhou, Guang-Zhong Yang, Ni Zhao, Yuan-ting Zhang\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Biomedical Engineering\n",
            "Abstract: The aging population, prevalence of chronic diseases, and outbreaks of infectious diseases are some of the major challenges of our present-day society. To address these unmet healthcare needs, especially for the early prediction and treatment of major diseases, health informatics, which deals with the acquisition, transmission, processing, storage, retrieval, and use of health information, has emerged as an active area of interdisciplinary research. In particular, acquisition of health-related information by unobtrusive sensing and wearable technologies is considered as a cornerstone in health informatics. Sensors can be weaved or integrated into clothing, accessories, and the living environment, such that health information can be acquired seamlessly and pervasively in daily living. Sensors can even be designed as stick-on electronic tattoos or directly printed onto human skin to enable long-term health monitoring. This paper aims to provide an overview of four emerging unobtrusive and wearable technologies, which are essential to the realization of pervasive health information acquisition, including: 1) unobtrusive sensing methods, 2) smart textile technology, 3) flexible-stretchable-printable electronics, and 4) sensor fusion, and then to identify some future directions of research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Fashion IQ: A New Dataset Towards Retrieving Images by Natural Language Feedback\n",
            "Authors: Xiaoxiao Guo, Hui Wu, Yupeng Gao, Steven J. Rennie, R. Feris\n",
            "Year: 2021\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Conversational interfaces for the detail-oriented retail fashion domain are more natural, expressive, and user friendly than classical keyword-based search interfaces. In this paper, we introduce the Fashion IQ dataset to support and advance research on interactive fashion image retrieval. Fashion IQ is the first fashion dataset to provide human-generated captions that distinguish similar pairs of garment images together with side-information consisting of real-world product descriptions and derived visual attribute labels for these images. We provide a detailed analysis of the characteristics of the Fashion IQ data, and present a transformer-based user simulator and interactive image retriever that can seamlessly integrate visual attributes with image features, user feedback, and dialog history, leading to improved performance over the state of the art in dialog-based image retrieval. We believe that our dataset will encourage further work on developing more natural and real-world applicable conversational shopping assistants. 1\n",
            "\n",
            "---\n",
            "\n",
            "Title: ActBERT: Learning Global-Local Video-Text Representations\n",
            "Authors: Linchao Zhu, Yi Yang\n",
            "Year: 2020\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: In this paper, we introduce ActBERT for self-supervised learning of joint video-text representations from unlabeled data. First, we leverage global action information to catalyze the mutual interactions between linguistic texts and local regional objects. It uncovers global and local visual clues from paired video sequences and text descriptions for detailed visual and text relation modeling. Second, we introduce an ENtangled Transformer block (ENT) to encode three sources of information, i.e., global actions, local regional objects, and linguistic descriptions. Global-local correspondences are discovered via judicious clues extraction from contextual information. It enforces the joint videotext representation to be aware of fine-grained objects as well as global human intention. We validate the generalization capability of ActBERT on downstream video-and language tasks, i.e., text-video clip retrieval, video captioning, video question answering, action segmentation, and action step localization. ActBERT significantly outperform the state-of-the-arts, demonstrating its superiority in video-text representation learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Self-supervised Co-training for Video Representation Learning\n",
            "Authors: Tengda Han, Weidi Xie, Andrew Zisserman\n",
            "Year: 2020\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: The objective of this paper is visual-only self-supervised video representation learning. We make the following contributions: (i) we investigate the benefit of adding semantic-class positives to instance-based Info Noise Contrastive Estimation (InfoNCE) training, showing that this form of supervised contrastive learning leads to a clear improvement in performance; (ii) we propose a novel self-supervised co-training scheme to improve the popular infoNCE loss, exploiting the complementary information from different views, RGB streams and optical flow, of the same data source by using one view to obtain positive class samples for the other; (iii) we thoroughly evaluate the quality of the learnt representation on two different downstream tasks: action recognition and video retrieval. In both cases, the proposed approach demonstrates state-of-the-art or comparable performance with other self-supervised approaches, whilst being significantly more efficient to train, i.e. requiring far less training data to achieve similar performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Pose-Sensitive Embedding for Person Re-identification with Expanded Cross Neighborhood Re-ranking\n",
            "Authors: M. Sarfraz, Arne Schumann, Andreas Eberle, R. Stiefelhagen\n",
            "Year: 2017\n",
            "Venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: Person re-identification is a challenging retrieval task that requires matching a person's acquired image across non-overlapping camera views. In this paper we propose an effective approach that incorporates both the fine and coarse pose information of the person to learn a discriminative embedding. In contrast to the recent direction of explicitly modeling body parts or correcting for misalignment based on these, we show that a rather straightforward inclusion of acquired camera view and/or the detected joint locations into a convolutional neural network helps to learn a very effective representation. To increase retrieval performance, re-ranking techniques based on computed distances have recently gained much attention. We propose a new unsupervised and automatic re-ranking framework that achieves state-of-the-art re-ranking performance. We show that in contrast to the current state-of-the-art re-ranking methods our approach does not require to compute new rank lists for each image pair (e.g., based on reciprocal neighbors) and performs well by using simple direct rank list based comparison or even by just using the already computed euclidean distances between the images. We show that both our learned representation and our re-ranking method achieve state-of-the-art performance on a number of challenging surveillance image and video datasets. Code is available at https://github.com/pse-ecn.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Theoretical Framework for Conversational Search\n",
            "Authors: Filip Radlinski, Nick Craswell\n",
            "Year: 2017\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: This paper studies conversational approaches to information retrieval, presenting a theory and model of information interaction in a chat setting. In particular, we consider the question of what properties would be desirable for a conversational information retrieval system so that the system can allow users to answer a variety of information needs in a natural and efficient manner. We study past work on human conversations, and propose a small set of properties that taken together could measure the extent to which a system is conversational. Following this, we present a theoretical model of a conversational system that implements the properties. We describe how this system could be implemented, making the action space of an conversational search agent explicit. Our analysis of this model shows that while theoretical, the model could be practically implemented to satisfy the desirable properties presented. In doing so, we show that the properties are also feasible.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations\n",
            "Authors: Shengxian Wan, Yanyan Lan, J. Guo, Jun Xu, Liang Pang, Xueqi Cheng\n",
            "Year: 2015\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " Matching natural language sentences is central for many applications such as information retrieval and question answering. Existing deep models rely on a single sentence representation or multiple granularity representations for matching. However, such methods cannot well capture the contextualized local information in the matching process. To tackle this problem, we present a new deep architecture to match two sentences with multiple positional sentence representations. Specifically, each positional sentence representation is a sentence representation at this position, generated by a bidirectional long short term memory (Bi-LSTM). The matching score is finally produced by aggregating interactions between these different positional sentence representations, through k-Max pooling and a multi-layer perceptron. Our model has several advantages: (1) By using Bi-LSTM, rich context of the whole sentence is leveraged to capture the contextualized local information in each positional sentence representation; (2) By matching with multiple positional sentence representations, it is flexible to aggregate different important contextualized local information in a sentence to support the matching; (3) Experiments on different tasks such as question answering and sentence completion demonstrate the superiority of our model.\n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: A New Chatbot for Customer Service on Social Media\n",
            "Authors: Anbang Xu, Zhe Liu, Yufan Guo, Vibha Sinha, R. Akkiraju\n",
            "Year: 2017\n",
            "Venue: International Conference on Human Factors in Computing Systems\n",
            "Abstract: Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.\n",
            "\n",
            "---\n",
            "\n",
            "Title: MIR_EVAL: A Transparent Implementation of Common MIR Metrics\n",
            "Authors: Colin Raffel, Brian McFee, Eric J. Humphrey, J. Salamon, Oriol Nieto, Dawen Liang, D. Ellis\n",
            "Year: 2014\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Central to the field of MIR research is the evaluation of algorithms used to extract information from music data. We present mir_eval, an open source software library which provides a transparent and easy-to-use implementation of the most common metrics used to measure the performance of MIR algorithms. In this paper, we enumerate the metrics implemented by mir_eval and quantitatively compare each to existing implementations. When the scores reported by mir_eval differ substantially from the reference, we detail the differences in implementation. We also provide a brief overview of mir_eval’s architecture, design, and intended use. 1. EVALUATING MIR ALGORITHMS Much of the research in Music Information Retrieval (MIR) involves the development of systems that process raw music data to produce semantic information. The goal of these systems is frequently defined as attempting to duplicate the performance of a human listener given the same task [5]. A natural way to determine a system’s effectiveness might be for a human to study the output produced by the system and judge its correctness. However, this would yield only subjective ratings, and would also be extremely timeconsuming when evaluating a system’s output over a large corpus of music. Instead, objective metrics are developed to provide a well-defined way of computing a score which indicates each system’s output’s correctness. These metrics typically involve a heuristically-motivated comparison of the system’s output to a reference which is known to be correct. Over time, certain metrics have become standard for each ∗Please direct correspondence to craffel@gmail.com c © Colin Raffel, Brian McFee, Eric J. Humphrey, Justin Salamon, Oriol Nieto, Dawen Liang, Daniel P. W. Ellis. Licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). Attribution: Colin Raffel, Brian McFee, Eric J. Humphrey, Justin Salamon, Oriol Nieto, Dawen Liang, Daniel P. W. Ellis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: OpenKE: An Open Toolkit for Knowledge Embedding\n",
            "Authors: Xu Han, Shulin Cao, Xin Lv, Yankai Lin, Zhiyuan Liu, Maosong Sun, Juan-Zi Li\n",
            "Year: 2018\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: We release an open toolkit for knowledge embedding (OpenKE), which provides a unified framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes operational efficiency to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufficient modularity and extensibility to easily incorporate new models into the framework. Besides the toolkit, the embeddings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available, which can be directly applied for many applications including information retrieval, personalized recommendation and question answering. The toolkit, documentation, and pre-trained embeddings are all released on http://openke.thunlp.org/.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Visible-Infrared Person Re-Identification via Homogeneous Augmented Tri-Modal Learning\n",
            "Authors: Mang Ye, Jianbing Shen, Ling Shao\n",
            "Year: 2021\n",
            "Venue: IEEE Transactions on Information Forensics and Security\n",
            "Abstract: Matching person images between the daytime visible modality and night-time infrared modality (VI-ReID) is a challenging cross-modality pedestrian retrieval problem. Existing methods usually learn the multi-modality features in raw image, ignoring the image-level discrepancy. Some methods apply GAN technique to generate the cross-modality images, but it destroys the local structure and introduces unavoidable noise. In this paper, we propose a Homogeneous Augmented Tri-Modal (HAT) learning method for VI-ReID, where an auxiliary grayscale modality is generated from their homogeneous visible images, without additional training process. It preserves the structure information of visible images and approximates the image style of infrared modality. Learning with the grayscale visible images enforces the network to mine structure relations across multiple modalities, making it robust to color variations. Specifically, we solve the tri-modal feature learning from both multi-modal classification and multi-view retrieval perspectives. For multi-modal classification, we learn a multi-modality sharing identity classifier with a parameter-sharing network, trained with a homogeneous and heterogeneous identification loss. For multi-view retrieval, we develop a weighted tri-directional ranking loss to optimize the relative distance across multiple modalities. Incorporated with two invariant regularizers, HAT simultaneously minimizes multiple modality variations. In-depth analysis demonstrates the homogeneous grayscale augmentation significantly outperforms the current state-of-the-art by a large margin.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Preprocessing Techniques for Text Mining-An Overview Dr\n",
            "Authors: .. S. Vijayarani, Ms. J. Ilamathi, Mrs. N. S. Nithya\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: Data mining is used for finding the useful information from the large amount of data. Data mining techniques are used to implement and solve different types of research problems. The research related areas in data mining are text mining, web mining, image mining, sequential pattern mining, spatial mining, medical mining, multimedia mining, structure mining and graph mining. This paper discussed about the text mining and its preprocessing techniques. Text mining is the process of mining the useful information from the text documents. It is also called knowledge discovery in text (KDT) or knowledge of intelligent text analysis. Text mining is a technique which extracts information from both structured and unstructured data and also finding patterns. Text mining techniques are used in various types of research domains like natural language processing, information retrieval, text classification and text clustering.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Farasa: A Fast and Furious Segmenter for Arabic\n",
            "Authors: Ahmed Abdelali, Kareem Darwish, Nadir Durrani, Hamdy Mubarak\n",
            "Year: 2016\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: In this paper, we present Farasa, a fast and accurate Arabic segmenter. Our approach is based on SVM-rank using linear kernels. We measure the performance of the seg-menter in terms of accuracy and efﬁciency, in two NLP tasks, namely Machine Translation (MT) and Information Retrieval (IR). Farasa outperforms or is at par with the state-of-the-art Arabic segmenters (Stanford and MADAMIRA), while being more than one order of magnitude faster.\n",
            "\n",
            "---\n",
            "\n",
            "Title: MedBlock: Efficient and Secure Medical Data Sharing Via Blockchain\n",
            "Authors: K. Fan, Shangyang Wang, Yanhui Ren, Hui Li, Yintang Yang\n",
            "Year: 2018\n",
            "Venue: Journal of medical systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploiting Subspace Relation in Semantic Labels for Cross-Modal Hashing\n",
            "Authors: Heng Tao Shen, Luchen Liu, Yang Yang, Xing Xu, Zi Huang, Fumin Shen, Richang Hong\n",
            "Year: 2021\n",
            "Venue: IEEE Transactions on Knowledge and Data Engineering\n",
            "Abstract: Hashing methods have been extensively applied to efficient multimedia data indexing and retrieval on account of the explosion of multimedia data. Cross-modal hashing usually learns binary codes by mapping multi-modal data into a common Hamming space. Most supervised methods utilize relation information like class labels as pairwise similarities of cross-modal data pair to narrow intra-modal and inter-modal gap. In this paper, we propose a novel supervised cross-modal hashing method dubbed Subspace Relation Learning for Cross-modal Hashing (SRLCH), which exploits relation information of labels in semantic space to make similar data from different modalities closer in the low-dimension Hamming subspace. SRLCH preserves the modality relationships, the discrete constraints and nonlinear structures, while admitting a closed-form binary codes solution, which effectively enhances the training efficiency. An iterative alternative optimization algorithm is developed to simultaneously learn both hash functions and unified binary codes. With these binary codes and hash functions, we can index multimedia data and search them in an efficient way. Evaluations in two cross-modal retrieval tasks on several widely-used datasets show that the proposed SRLCH outperforms most cross-modal hashing methods. Theoretical analysis also illustrates reasons for our method’s promotion in subspace relation learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering\n",
            "Authors: Devendra Singh Sachan, Siva Reddy, William Hamilton, Chris Dyer, Dani Yogatama\n",
            "Year: 2021\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: We present an end-to-end differentiable training method for retrieval-augmented open-domain question answering systems that combine information from multiple retrieved documents when generating answers. We model retrieval decisions as latent variables over sets of relevant documents. Since marginalizing over sets of retrieved documents is computationally hard, we approximate this using an expectation-maximization algorithm. We iteratively estimate the value of our latent variable (the set of relevant documents for a given question) and then use this estimate to update the retriever and reader parameters. We hypothesize that such end-to-end training allows training signals to flow to the reader and then to the retriever better than staged-wise training. This results in a retriever that is able to select more relevant documents for a question and a reader that is trained on more accurate documents to generate an answer. Experiments on three benchmark datasets demonstrate that our proposed method outperforms all existing approaches of comparable size by 2-3% absolute exact match points, achieving new state-of-the-art results. Our results also demonstrate the feasibility of learning to retrieve to improve answer generation without explicit supervision of retrieval decisions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: End-to-end learning for music audio\n",
            "Authors: S. Dieleman, B. Schrauwen\n",
            "Year: 2014\n",
            "Venue: IEEE International Conference on Acoustics, Speech, and Signal Processing\n",
            "Abstract: Content-based music information retrieval tasks have traditionally been solved using engineered features and shallow processing architectures. In recent years, there has been increasing interest in using feature learning and deep architectures instead, thus reducing the required engineering effort and the need for prior knowledge. However, this new approach typically still relies on mid-level representations of music audio, e.g. spectrograms, instead of raw audio signals. In this paper, we investigate whether it is possible to apply feature learning directly to raw audio signals. We train convolutional neural networks using both approaches and compare their performance on an automatic tagging task. Although they do not outperform a spectrogram-based approach, the networks are able to autonomously discover frequency decompositions from raw audio, as well as phase-and translation-invariant feature representations.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Latent semantic sparse hashing for cross-modal similarity search\n",
            "Authors: J. Zhou, Guiguang Ding, Yuchen Guo\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Similarity search methods based on hashing for effective and efficient cross-modal retrieval on large-scale multimedia databases with massive text and images have attracted considerable attention. The core problem of cross-modal hashing is how to effectively construct correlation between multi-modal representations which are heterogeneous intrinsically in the process of hash function learning. Analogous to Canonical Correlation Analysis (CCA), most existing cross-modal hash methods embed the heterogeneous data into a joint abstraction space by linear projections. However, these methods fail to bridge the semantic gap more effectively, and capture high-level latent semantic information which has been proved that it can lead to better performance for image retrieval. To address these challenges, in this paper, we propose a novel Latent Semantic Sparse Hashing (LSSH) to perform cross-modal similarity search by employing Sparse Coding and Matrix Factorization. In particular, LSSH uses Sparse Coding to capture the salient structures of images, and Matrix Factorization to learn the latent concepts from text. Then the learned latent semantic features are mapped to a joint abstraction space. Moreover, an iterative strategy is applied to derive optimal solutions efficiently, and it helps LSSH to explore the correlation between multi-modal representations efficiently and automatically. Finally, the unified hashcodes are generated through the high level abstraction space by quantization. Extensive experiments on three different datasets highlight the advantage of our method under cross-modal scenarios and show that LSSH significantly outperforms several state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Supervised Discrete Hashing\n",
            "Authors: Qi Li, Zhenan Sun, R. He, T. Tan\n",
            "Year: 2017\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: With the rapid growth of image and video data on the web, hashing has been extensively studied for image or video search in recent years. Benefit from recent advances in deep learning, deep hashing methods have achieved promising results for image retrieval. However, there are some limitations of previous deep hashing methods (e.g., the semantic information is not fully exploited). In this paper, we develop a deep supervised discrete hashing algorithm based on the assumption that the learned binary codes should be ideal for classification. Both the pairwise label information and the classification information are used to learn the hash codes within one stream framework. We constrain the outputs of the last layer to be binary codes directly, which is rarely investigated in deep hashing algorithm. Because of the discrete nature of hash codes, an alternating minimization method is used to optimize the objective function. Experimental results have shown that our method outperforms current state-of-the-art methods on benchmark datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Trust and Mistrust in International Relations\n",
            "Authors: Andrew H. Kydd\n",
            "Year: 2018\n",
            "Venue: \n",
            "Abstract: is published by Princeton University Press and copyrighted, © 2005, by Princeton University Press. All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher, except for reading and browsing via the World Wide Web. Users are not permitted to mount this file on any network servers.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pre-training via Paraphrasing\n",
            "Authors: M. Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida I. Wang, Luke Zettlemoyer\n",
            "Year: 2020\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.\n",
            "\n",
            "---\n",
            "\n",
            "Title: How Context Affects Language Models' Factual Predictions\n",
            "Authors: F. Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H. Miller, Sebastian Riedel\n",
            "Year: 2020\n",
            "Venue: Conference on Automated Knowledge Base Construction\n",
            "Abstract: When pre-trained on large unsupervised textual corpora, language models are able to store and retrieve factual knowledge to some extent, making it possible to use them directly for zero-shot cloze-style question answering. However, storing factual knowledge in a fixed number of weights of a language model clearly has limitations. Previous approaches have successfully provided access to information outside the model weights using supervised architectures that combine an information retrieval system with a machine reading component. In this paper, we go a step further and integrate information from a retrieval system with a pre-trained language model in a purely unsupervised way. We report that augmenting pre-trained language models in this way dramatically improves performance and that the resulting system, despite being unsupervised, is competitive with a supervised machine reading baseline. Furthermore, processing query and context with different segment tokens allows BERT to utilize its Next Sentence Prediction pre-trained classifier to determine whether the context is relevant or not, substantially improving BERT's zero-shot cloze-style question-answering performance and making its predictions robust to noisy contexts.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Searching for qualitative research for inclusion in systematic reviews: a structured methodological review\n",
            "Authors: A. Booth\n",
            "Year: 2016\n",
            "Venue: Systematic Reviews\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multimodal Convolutional Neural Networks for Matching Image and Sentence\n",
            "Authors: Lin Ma, Zhengdong Lu, Lifeng Shang, Hang Li\n",
            "Year: 2015\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: In this paper, we propose multimodal convolutional neural networks (m-CNNs) for matching image and sentence. Our m-CNN provides an end-to-end framework with convolutional architectures to exploit image representation, word composition, and the matching relations between the two modalities. More specifically, it consists of one image CNN encoding the image content and one matching CNN modeling the joint representation of image and sentence. The matching CNN composes different semantic fragments from words and learns the inter-modal relations between image and the composed fragments at different levels, thus fully exploit the matching relations between image and sentence. Experimental results demonstrate that the proposed m-CNNs can effectively capture the information necessary for image and sentence matching. More specifically, our proposed m-CNNs significantly outperform the state-of-the-art approaches for bidirectional image and sentence retrieval on the Flickr8K and Flickr30K datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: LifeLogging: Personal Big Data\n",
            "Authors: C. Gurrin, A. Smeaton, A. Doherty\n",
            "Year: 2014\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: We have recently observed a convergence of technologies to foster the emergence of lifelogging as a mainstream activity. Computer storage has become significantly cheaper, and advancements in sensing technology allows for the efficient sensing of personal activities, locations and the environment. This is best seen in the growing popularity of the quantified self movement, in which life activities are tracked using wearable sensors in the hope of better understanding human performance in a variety of tasks. This review aims to provide a comprehensive summary of lifelogging, to cover its research history, current technologies, and applications. Thus far, most of the lifelogging research has focused predominantly on visual lifelogging, hence we maintain this focus in this review. However, we also reflect on the challenges lifelogging poses for information access and retrieval in general. This review is a suitable reference for those seeking an information retrieval scientist's perspective on lifelogging and the quantified self.\n",
            "\n",
            "---\n",
            "\n",
            "Title: DGL-KE: Training Knowledge Graph Embeddings at Scale\n",
            "Authors: Da Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, G. Karypis\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Knowledge graphs have emerged as a key abstraction for organizing information in diverse domains and their embeddings are increasingly used to harness their information in various information retrieval and machine learning tasks. However, the ever growing size of knowledge graphs requires computationally efficient algorithms capable of scaling to graphs with millions of nodes and billions of edges. This paper presents DGL-KE, an open-source package to efficiently compute knowledge graph embeddings. DGL-KE introduces various novel optimizations that accelerate training on knowledge graphs with millions of nodes and billions of edges using multi-processing, multi-GPU, and distributed parallelism. These optimizations are designed to increase data locality, reduce communication overhead, overlap computations with memory accesses, and achieve high operation efficiency. Experiments on knowledge graphs consisting of over 86M nodes and 338M edges show that DGL-KE can compute embeddings in 100 minutes on an EC2 instance with 8 GPUs and 30 minutes on an EC2 cluster with 4 machines with 48 cores/machine. These results represent a 2× ~ 5× speedup over the best competing approaches. DGL-KE is available on https://github.com/awslabs/dgl-ke.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Simplified Data Wrangling with ir_datasets\n",
            "Authors: Sean MacAvaney, Andrew Yates, Sergey Feldman, Doug Downey, Arman Cohan, Nazli Goharian\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Managing the data for Information Retrieval (IR) experiments can be challenging. Dataset documentation is scattered across the Internet and once one obtains a copy of the data, there are numerous different data formats to work with. Even basic formats can have subtle dataset-specific nuances that need to be considered for proper use. To help mitigate these challenges, we introduce a new robust and lightweight tool (ir_datasets) for acquiring, managing, and performing typical operations over datasets used in IR. We primarily focus on textual datasets used for ad-hoc search. This tool provides both a Python and command line interface to numerous IR datasets and benchmarks. To our knowledge, this is the most extensive tool of its kind. Integrations with popular IR indexing and experimentation toolkits demonstrate the tool's utility. We also provide documentation of these datasets through the \\sys catalog: https://ir-datasets.com/. The catalog acts as a hub for information on datasets used in IR, providing core information about what data each benchmark provides as well as links to more detailed information. We welcome community contributions and intend to continue to maintain and grow this tool.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluating Stochastic Rankings with Expected Exposure\n",
            "Authors: Fernando Diaz, Bhaskar Mitra, Michael D. Ekstrand, Asia J. Biega, Ben Carterette\n",
            "Year: 2020\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: We introduce the concept of expected exposure as the average attention ranked items receive from users over repeated samples of the same query. Furthermore, we advocate for the adoption of the principle of equal expected exposure: given a fixed information need, no item should receive more or less expected exposure than any other item of the same relevance grade. We argue that this principle is desirable for many retrieval objectives and scenarios, including topical diversity and fair ranking. %Leveraging user models from existing retrieval metrics, we propose a general evaluation methodology based on expected exposure and draw connections to related metrics in information retrieval evaluation. Importantly, this methodology relaxes classic information retrieval assumptions, allowing a system, in response to a query, to produce a distribution over rankings instead of a single fixed ranking. We study the behavior of the expected exposure metric and stochastic rankers across a variety of information access conditions, including ad hoc retrieval and recommendation. %We believe that measuring and optimizing expected exposure metrics using randomization opens a new area for retrieval algorithm development and progress.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey on Application of Knowledge Graph\n",
            "Authors: Xiaohan Zou\n",
            "Year: 2020\n",
            "Venue: Journal of Physics: Conference Series\n",
            "Abstract: Knowledge graphs, representation of information as a semantic graph, have caused wide concern in both industrial and academic world. Their property of providing semantically structured information has brought important possible solutions for many tasks including question answering, recommendation and information retrieval, and is considered to offer great promise for building more intelligent machines by many researchers. Although knowledge graphs have already supported multiple “Big Data” applications in all sorts of commercial and scientific domains since Google coined this term in 2012, there was no previous study give a systemically review of the application of knowledge graphs. Therefore, unlike other related work which focuses on the construction techniques of knowledge graphs, this present paper aims at providing a first survey on these applications stemming from different domains. This paper also points out that while important advancements of applying knowledge graphs’ great ability of providing semantically structured information into specific domains have been made in recent years, several aspects still remain to be explored.\n",
            "\n",
            "---\n",
            "\n",
            "Title: BERT with History Answer Embedding for Conversational Question Answering\n",
            "Authors: Chen Qu, Liu Yang, Minghui Qiu, W. Bruce Croft, Yongfeng Zhang, Mohit Iyyer\n",
            "Year: 2019\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Conversational search is an emerging topic in the information retrieval community. One of the major challenges to multi-turn conversational search is to model the conversation history to answer the current question. Existing methods either prepend history turns to the current question or use complicated attention mechanisms to model the history. We propose a conceptually simple yet highly effective approach referred to as history answer embedding. It enables seamless integration of conversation history into a conversational question answering (ConvQA) model built on BERT (Bidirectional Encoder Representations from Transformers). We first explain our view that ConvQA is a simplified but concrete setting of conversational search, and then we provide a general framework to solve ConvQA. We further demonstrate the effectiveness of our approach under this framework. Finally, we analyze the impact of different numbers of history turns under different settings to provide new insights into conversation history modeling in ConvQA.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Collaborative Embedding for Social Image Understanding\n",
            "Authors: Zechao Li, Jinhui Tang, Tao Mei\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "Abstract: In this work, we investigate the problem of learning knowledge from the massive community-contributed images with rich weakly-supervised context information, which can benefit multiple image understanding tasks simultaneously, such as social image tag refinement and assignment, content-based image retrieval, tag-based image retrieval and tag expansion. Towards this end, we propose a Deep Collaborative Embedding (DCE) model to uncover a unified latent space for images and tags. The proposed method incorporates the end-to-end learning and collaborative factor analysis in one unified framework for the optimal compatibility of representation learning and latent space discovery. A nonnegative and discrete refined tagging matrix is learned to guide the end-to-end learning. To collaboratively explore the rich context information of social images, the proposed method integrates the weakly-supervised image-tag correlation, image correlation and tag correlation simultaneously and seamlessly. The proposed model is also extended to embed new tags in the uncovered space. To verify the effectiveness of the proposed method, extensive experiments are conducted on two widely-used social image benchmarks for multiple social image understanding tasks. The encouraging performance of the proposed method over the state-of-the-art approaches demonstrates its superiority.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Neural Network for Factoid Question Answering over Paragraphs\n",
            "Authors: Mohit Iyyer, Jordan L. Boyd-Graber, L. Claudino, R. Socher, Hal Daumé\n",
            "Year: 2014\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: Text classification methods for tasks like factoid question answering typically use manually defined string matching rules or bag of words representations. These methods are ineective when question text contains very few individual words (e.g., named entities) that are indicative of the answer. We introduce a recursive neural network (rnn) model that can reason over such input by modeling textual compositionality. We apply our model, qanta, to a dataset of questions from a trivia competition called quiz bowl. Unlike previous rnn models, qanta learns word and phrase-level representations that combine across sentences to reason about entities. The model outperforms multiple baselines and, when combined with information retrieval methods, rivals the best human players.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Query Expansion with Locally-Trained Word Embeddings\n",
            "Authors: Fernando Diaz, Bhaskar Mitra, Nick Craswell\n",
            "Year: 2016\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: Continuous space word embeddings have received a great deal of attention in the natural language processing and machine learning communities for their ability to model term similarity and other relationships. We study the use of term relatedness in the context of query expansion for ad hoc information retrieval. We demonstrate that word embeddings such as word2vec and GloVe, when trained globally, underperform corpus and query specific embeddings for retrieval tasks. These results suggest that other tasks benefiting from global embeddings may also benefit from local embeddings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Stress, glucocorticoids and memory: implications for treating fear-related disorders\n",
            "Authors: D. D. Quervain, L. Schwabe, B. Roozendaal\n",
            "Year: 2016\n",
            "Venue: Nature Reviews Neuroscience\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of the ShARe/CLEF eHealth Evaluation Lab 2014\n",
            "Authors: Liadh Kelly, Lorraine Goeuriot, H. Suominen, Tobias Schreck, Gondy Leroy, D. Mowery, S. Velupillai, W. Chapman, David Martínez, G. Zuccon, João Palotti\n",
            "Year: 2014\n",
            "Venue: Conference and Labs of the Evaluation Forum\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Dataset search: a survey\n",
            "Authors: Adriane P. Chapman, E. Simperl, Laura Koesten, G. Konstantinidis, L. Ibáñez, Emilia Kacprzak, Paul Groth\n",
            "Year: 2019\n",
            "Venue: The VLDB journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Core techniques of question answering systems over knowledge bases: a survey\n",
            "Authors: Dennis Diefenbach, V. López, K. Singh, P. Maret\n",
            "Year: 2017\n",
            "Venue: Knowledge and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Software traceability: trends and future directions\n",
            "Authors: J. Cleland-Huang, O. Gotel, J. Hayes, Patrick Mäder, A. Zisman\n",
            "Year: 2014\n",
            "Venue: FOSE\n",
            "Abstract: Software traceability is a sought-after, yet often elusive quality in software-intensive systems. Required in safety-critical systems by many certifying bodies, such as the USA Federal Aviation Authority, software traceability is an essential element of the software development process. In practice, traceability is often conducted in an ad-hoc, after-the-fact manner and, therefore, its benefits are not always fully realized. Over the past decade, researchers have focused on specific areas of the traceability problem, developing more sophisticated tooling, promoting strategic planning, applying information retrieval techniques capable of semi-automating the trace creation and maintenance process, developing new trace query languages and visualization techniques that use trace links, and applying traceability in specific domains such as Model Driven Development, product line systems, and agile project environments. In this paper, we build upon a prior body of work to highlight the state-of-the-art in software traceability, and to present compelling areas of research that need to be addressed.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A stable multi-scale kernel for topological machine learning\n",
            "Authors: Jan Reininghaus, S. Huber, Ulrich Bauer, R. Kwitt\n",
            "Year: 2014\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Topological data analysis offers a rich source of valuable information to study vision problems. Yet, so far we lack a theoretically sound connection to popular kernel-based learning techniques, such as kernel SVMs or kernel PCA. In this work, we establish such a connection by designing a multi-scale kernel for persistence diagrams, a stable summary representation of topological features in data. We show that this kernel is positive definite and prove its stability with respect to the 1-Wasserstein distance. Experiments on two benchmark datasets for 3D shape classification/retrieval and texture recognition show considerable performance gains of the proposed method compared to an alternative approach that is based on the recently introduced persistence landscapes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: StarSpace: Embed All The Things!\n",
            "Authors: Ledell Yu Wu, Adam Fisch, S. Chopra, Keith Adams, Antoine Bordes, J. Weston\n",
            "Year: 2017\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification,ranking tasks such as information retrieval/web search,collaborative filtering-based  or content-based recommendation,embedding of multi-relational graphs, and learning word, sentence or document level embeddings.In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task.Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.\n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework\n",
            "Authors: Ran Xu, Caiming Xiong, Wei Chen, Jason J. Corso\n",
            "Year: 2015\n",
            "Venue: AAAI Conference on Artificial Intelligence\n",
            "Abstract: \n",
            " \n",
            " Recently, joint video-language modeling has been attracting more and more attention. However, most existing approaches focus on exploring the language model upon on a fixed visual model. In this paper, we propose a unified framework that jointly models video and the corresponding text sentences. The framework consists of three parts: a compositional semantics language model, a deep video model and a joint embedding model. In our language model, we propose a dependency-tree structure model that embeds sentence into a continuous vector space, which preserves visually grounded meanings and word order. In the visual model, we leverage deep neural networks to capture essential semantic information from videos. In the joint embedding model, we minimize the distance of the outputs of the deep video model and compositional language model in the joint space, and update these two models jointly. Based on these three parts, our system is able to accomplish three tasks: 1) natural language generation, and 2) video retrieval and 3) language retrieval. In the experiments, the results show our approach outperforms SVM, CRF and CCA baselines in predicting Subject-Verb-Object triplet and natural sentence generation, and is better than CCA in video retrieval and language retrieval tasks. \n",
            " \n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: Riposte: An Anonymous Messaging System Handling Millions of Users\n",
            "Authors: Henry Corrigan-Gibbs, D. Boneh, David Mazières\n",
            "Year: 2015\n",
            "Venue: IEEE Symposium on Security and Privacy\n",
            "Abstract: This paper presents Riposte, a new system for anonymous broadcast messaging. Riposte is the first such system, to our knowledge, that simultaneously protects against traffic-analysis attacks, prevents anonymous denial-of-service by malicious clients, and scales to million-user anonymity sets. To achieve these properties, Riposte makes novel use of techniques used in systems for private information retrieval and secure multi-party computation. For latency-tolerant workloads with many more readers than writers (e.g. Twitter, Wikileaks), we demonstrate that a three-server Riposte cluster can build an anonymity set of 2,895,216 users in 32 hours.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Auto-ReID: Searching for a Part-Aware ConvNet for Person Re-Identification\n",
            "Authors: Ruijie Quan, Xuanyi Dong, Yuehua Wu, Linchao Zhu, Yi Yang\n",
            "Year: 2019\n",
            "Venue: IEEE International Conference on Computer Vision\n",
            "Abstract: Prevailing deep convolutional neural networks (CNNs) for person re-IDentification (reID) are usually built upon ResNet or VGG backbones, which were originally designed for classification. Because reID is different from classification, the architecture should be modified accordingly. We propose to automatically search for a CNN architecture that is specifically suitable for the reID task. There are three aspects to be tackled. First, body structural information plays an important role in reID but it is not encoded in backbones. Second, Neural Architecture Search (NAS) automates the process of architecture design without human effort, but no existing NAS methods incorporate the structure information of input images. Third, reID is essentially a retrieval task but current NAS algorithms are merely designed for classification. To solve these problems, we propose a retrieval-based search algorithm over a specifically designed reID search space, named Auto-ReID. Our Auto-ReID enables the automated approach to find an efficient and effective CNN architecture for reID. Extensive experiments demonstrate that the searched architecture achieves state-of-the-art performance while reducing 50% parameters and 53% FLOPs compared to others.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Four Ways of Considering Emotion in Cognitive Load Theory\n",
            "Authors: J. Plass, Slava Kalyuga\n",
            "Year: 2019\n",
            "Venue: Educational Psychology Review\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Assessing the Impact of OCR Quality on Downstream NLP Tasks\n",
            "Authors: Daniel Alexander van Strien, K. Beelen, Mariona Coll Ardanuy, Kasra Hosseini, Barbara McGillivray, Giovanni Colavizza\n",
            "Year: 2020\n",
            "Venue: International Conference on Agents and Artificial Intelligence\n",
            "Abstract: : A growing volume of heritage data is being digitized and made available as text via optical character recognition (OCR). Scholars and libraries are increasingly using OCR-generated text for retrieval and analysis. However, the process of creating text through OCR introduces varying degrees of error to the text. The impact of these errors on natural language processing (NLP) tasks has only been partially studied. We perform a series of extrinsic assessment tasks — sentence segmentation, named entity recognition, dependency parsing, information retrieval, topic modelling and neural language model ﬁne-tuning — using popular, out-of-the-box tools in order to quantify the impact of OCR quality on these tasks. We ﬁnd a consistent impact resulting from OCR errors on our downstream tasks with some tasks more irredeemably harmed by OCR errors. Based on these results, we offer some preliminary guidelines for working with text produced through OCR.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Comprehensive Assessment of Spoken Language\n",
            "Authors: R. Dumont, John O. Willis, Kathleen D. Viezel, Jamie Zibulsky\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Classification: Supplemental: Mitochondrial Disease (Mito) and Traumatic Brain Injury (TBI) Short Description of Instrument: The Comprehensive Assessment of Spoken Language (CASL) provides an oral language assessment for individuals ages 3 through 21. The battery includes 15 tests to measure language processing skills (comprehension, expression and retrieval) in four language structure categories (Lexical/Semantic, Syntactic, Superlinguistic, and Pragmatic. Each test has been classified by the authors as either Core or Supplementary; the core tests provide a global language composite and the supplementary tests provide additional information and index scores. A verbal or nonverbal response is required; however, reading or writing ability is not needed to complete this measure.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning a Deep Listwise Context Model for Ranking Refinement\n",
            "Authors: Qingyao Ai, Keping Bi, J. Guo, W. Bruce Croft\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Learning to rank has been intensively studied and widely applied in information retrieval. Typically, a global ranking function is learned from a set of labeled data, which can achieve good performance on average but may be suboptimal for individual queries by ignoring the fact that relevant documents for different queries may have different distributions in the feature space. Inspired by the idea of pseudo relevance feedback where top ranked documents, which we refer as the local ranking context, can provide important information about the query's characteristics, we propose to use the inherent feature distributions of the top results to learn a Deep Listwise Context Model that helps us fine tune the initial ranked list. Specifically, we employ a recurrent neural network to sequentially encode the top results using their feature vectors, learn a local context model and use it to re-rank the top results. There are three merits with our model: (1) Our model can capture the local ranking context based on the complex interactions between top results using a deep neural network; (2) Our model can be built upon existing learning-to-rank methods by directly using their extracted feature vectors; (3) Our model is trained with an attention-based loss function, which is more effective and efficient than many existing listwise methods. Experimental results show that the proposed model can significantly improve the state-of-the-art learning to rank methods on benchmark retrieval corpora.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Societal Biases in Retrieved Contents: Measurement Framework and Adversarial Mitigation of BERT Rankers\n",
            "Authors: Navid Rekabsaz, Simone Kopeinik, M. Schedl\n",
            "Year: 2021\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Societal biases resonate in the retrieved contents of information retrieval (IR) systems, resulting in reinforcing existing stereotypes. Approaching this issue requires established measures of fairness in respect to the representation of various social groups in retrieval results, as well as methods to mitigate such biases, particularly in the light of the advances in deep ranking models. In this work, we first provide a novel framework to measure the fairness in the retrieved text contents of ranking models. Introducing a ranker-agnostic measurement, the framework also enables the disentanglement of the effect on fairness of collection from that of rankers. To mitigate these biases, we propose AdvBert, a ranking model achieved by adapting adversarial bias mitigation for IR, which jointly learns to predict relevance and remove protected attributes. We conduct experiments on two passage retrieval collections (MSMARCO Passage Re-ranking and TREC Deep Learning 2019 Passage Re-ranking), which we extend by fairness annotations of a selected subset of queries regarding gender attributes. Our results on the MSMARCO benchmark show that, (1) all ranking models are less fair in comparison with ranker-agnostic baselines, and (2) the fairness of Bert rankers significantly improves when using the proposed AdvBert models. Lastly, we investigate the trade-off between fairness and utility, showing that we can maintain the significant improvements in fairness without any significant loss in utility.\n",
            "\n",
            "---\n",
            "\n",
            "Title: WWW'18 Open Challenge: Financial Opinion Mining and Question Answering\n",
            "Authors: Macedo Maia, S. Handschuh, A. Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, A. Balahur\n",
            "Year: 2018\n",
            "Venue: The Web Conference\n",
            "Abstract: The growing maturity of Natural Language Processing (NLP) techniques and resources is dramatically changing the landscape of many application domains which are dependent on the analysis of unstructured data at scale. The finance domain, with its reliance on the interpretation of multiple unstructured and structured data sources and its demand for fast and comprehensive decision making is already emerging as a primary ground for the experimentation of NLP, Web Mining and Information Retrieval (IR) techniques for the automatic analysis of financial news and opinions online. This challenge focuses on advancing the state-of-the-art of aspect-based sentiment analysis and opinion-based Question Answering for the financial domain.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Combining Language and Vision with a Multimodal Skip-gram Model\n",
            "Authors: Angeliki Lazaridou, N. Pham, Marco Baroni\n",
            "Year: 2015\n",
            "Venue: North American Chapter of the Association for Computational Linguistics\n",
            "Abstract: We extend the SKIP-GRAM model of Mikolov et al. (2013a) by taking visual information into account. Like SKIP-GRAM, our multimodal models (MMSKIP-GRAM) build vector-based word representations by learning to predict linguistic contexts in text corpora. However, for a restricted set of words, the models are also exposed to visual representations of the objects they denote (extracted from natural images), and must predict linguistic and visual features jointly. The MMSKIP-GRAM models achieve good performance on a variety of semantic benchmarks. Moreover, since they propagate visual information to all words, we use them to improve image labeling and retrieval in the zero-shot setup, where the test concepts are never seen during model training. Finally, the MMSKIP-GRAM models discover intriguing visual properties of abstract words, paving the way to realistic implementations of embodied theories of meaning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: In search of the focus of attention in working memory: 13 years of the retro-cue effect\n",
            "Authors: Alessandra S. Souza, K. Oberauer\n",
            "Year: 2016\n",
            "Venue: Attention, perception & psychophysics\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Image Captioning with Deep Bidirectional LSTMs\n",
            "Authors: Cheng Wang, Haojin Yang, Christian Bartz, C. Meinel\n",
            "Year: 2016\n",
            "Venue: ACM Multimedia\n",
            "Abstract: This work presents an end-to-end trainable deep bidirectional LSTM (Long-Short Term Memory) model for image captioning. Our model builds on a deep convolutional neural network (CNN) and two separate LSTM networks. It is capable of learning long term visual-language interactions by making use of history and future context information at high level semantic space. Two novel deep bidirectional variant models, in which we increase the depth of nonlinearity transition in different way, are proposed to learn hierarchical visual-language embeddings. Data augmentation techniques such as multi-crop, multi-scale and vertical mirror are proposed to prevent overfitting in training deep models. We visualize the evolution of bidirectional LSTM internal states over time and qualitatively analyze how our models \"translate\" image to sentence. Our proposed models are evaluated on caption generation and image-sentence retrieval tasks with three benchmark datasets: Flickr8K, Flickr30K and MSCOCO datasets. We demonstrate that bidirectional LSTM models achieve highly competitive performance to the state-of-the-art results on caption generation even without integrating additional mechanism (e.g. object detection, attention model etc.) and significantly outperform recent methods on retrieval task\n",
            "\n",
            "---\n",
            "\n",
            "Title: AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\n",
            "Authors: Andrew Rouditchenko, Angie Boggust, David F. Harwath, D. Joshi, Samuel Thomas, Kartik Audhkhasi, R. Feris, Brian Kingsbury, M. Picheny, A. Torralba, James R. Glass\n",
            "Year: 2020\n",
            "Venue: Interspeech\n",
            "Abstract: Current methods for learning visually grounded language from videos often rely on time-consuming and expensive data collection, such as human annotated textual summaries or machine generated automatic speech recognition transcripts. In this work, we introduce Audio-Video Language Network (AVLnet), a self-supervised network that learns a shared audio-visual embedding space directly from raw video inputs. We circumvent the need for annotation and instead learn audio-visual language representations directly from randomly segmented video clips and their raw audio waveforms. We train AVLnet on publicly available instructional videos and evaluate our model on video clip and language retrieval tasks on three video datasets. Our proposed model outperforms several state-of-the-art text-video baselines by up to 11.8% in a video clip retrieval task, despite operating on the raw audio instead of manually annotated text captions. Further, we show AVLnet is capable of integrating textual information, increasing its modularity and improving performance by up to 20.3% on the video clip retrieval task. Finally, we perform analysis of AVLnet's learned representations, showing our model has learned to relate visual objects with salient words and natural sounds.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Time cells in the human hippocampus and entorhinal cortex support episodic memory\n",
            "Authors: Gray Umbach, Pranish A. Kantak, J. Jacobs, M. Kahana, Brad E. Pfeiffer, M. Sperling, B. Lega\n",
            "Year: 2020\n",
            "Venue: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Abstract: Significance Time cells are neurons in the hippocampus and entorhinal cortex that fire at specific moments within a cognitive task or experience. While many prominent theories of memory encoding offer time cells as the source of the temporal component to memory, they have never been observed in human recordings. We identify time cell populations in the medial temporal lobe of humans during memory encoding and retrieval. Further, we demonstrate that the stability of the time signal provided by time cells during encoding influences the ability to temporally order memories at time of retrieval. The organization of temporal information is critical for the encoding and retrieval of episodic memories. In the rodent hippocampus and entorhinal cortex, evidence accumulated over the last decade suggests that populations of “time cells” in the hippocampus encode temporal information. We identify time cells in humans using intracranial microelectrode recordings obtained from 27 human epilepsy patients who performed an episodic memory task. We show that time cell activity predicts the temporal organization of retrieved memory items. We also uncover evidence of ramping cell activity in humans, which represents a complementary type of temporal information. These findings establish a cellular mechanism for the representation of temporal information in the human brain needed to form episodic memories.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Anserini\n",
            "Authors: Peilin Yang, Hui Fang, Jimmy J. Lin\n",
            "Year: 2018\n",
            "Venue: ACM Journal of Data and Information Quality\n",
            "Abstract: This work tackles the perennial problem of reproducible baselines in information retrieval research, focusing on bag-of-words ranking models. Although academic information retrieval researchers have a long history of building and sharing systems, they are primarily designed to facilitate the publication of research papers. As such, these systems are often incomplete, inflexible, poorly documented, difficult to use, and slow, particularly in the context of modern web-scale collections. Furthermore, the growing complexity of modern software ecosystems and the resource constraints most academic research groups operate under make maintaining open-source systems a constant struggle. However, except for a small number of companies (mostly commercial web search engines) that deploy custom infrastructure, Lucene has become the de facto platform in industry for building search applications. Lucene has an active developer base, a large audience of users, and diverse capabilities to work with heterogeneous collections at scale. However, it lacks systematic support for ad hoc experimentation using standard test collections. We describe Anserini, an information retrieval toolkit built on Lucene that fills this gap. Our goal is to simplify ad hoc experimentation and allow researchers to easily reproduce results with modern bag-of-words ranking models on diverse test collections. With Anserini, we demonstrate that Lucene provides a suitable framework for supporting information retrieval research. Experiments show that our system efficiently indexes large web collections, provides modern ranking models that are on par with research implementations in terms of effectiveness, and supports low-latency query evaluation to facilitate rapid experimentation\n",
            "\n",
            "---\n",
            "\n",
            "Title: From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing\n",
            "Authors: Hamed Zamani, Mostafa Dehghani, W. Bruce Croft, E. Learned-Miller, J. Kamps\n",
            "Year: 2018\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: The availability of massive data and computing power allowing for effective data driven neural approaches is having a major impact on machine learning and information retrieval research, but these models have a basic problem with efficiency. Current neural ranking models are implemented as multistage rankers: for efficiency reasons, the neural model only re-ranks the top ranked documents retrieved by a first-stage efficient ranker in response to a given query. Neural ranking models learn dense representations causing essentially every query term to match every document term, making it highly inefficient or intractable to rank the whole collection. The reliance on a first stage ranker creates a dual problem: First, the interaction and combination effects are not well understood. Second, the first stage ranker serves as a \"gate-keeper\" or filter, effectively blocking the potential of neural models to uncover new relevant documents. In this work, we propose a standalone neural ranking model (SNRM) by introducing a sparsity property to learn a latent sparse representation for each query and document. This representation captures the semantic relationship between the query and documents, but is also sparse enough to enable constructing an inverted index for the whole collection. We parameterize the sparsity of the model to yield a retrieval model as efficient as conventional term based models. Our model gains in efficiency without loss of effectiveness: it not only outperforms the existing term matching baselines, but also performs similarly to the recent re-ranking based neural models with dense representations. Our model can also take advantage of pseudo-relevance feedback for further improvements. More generally, our results demonstrate the importance of sparsity in neural IR models and show that dense representations can be pruned effectively, giving new insights about essential semantic features and their distributions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Freesound Datasets: A Platform for the Creation of Open Audio Datasets\n",
            "Authors: Eduardo Fonseca, Jordi Pons, Xavier Favory, F. Font, D. Bogdanov, Andrés Ferraro, Sergio Oramas, Alastair Porter, Xavier Serra\n",
            "Year: 2017\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada al 18th International Society for Music Information Retrieval Conference celebrada a Suzhou, Xina, del 23 al 27 d'cotubre de 2017.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Cross-Media Joint Representation With Sparse and Semisupervised Regularization\n",
            "Authors: Xiaohua Zhai, Yuxin Peng, Jianguo Xiao\n",
            "Year: 2014\n",
            "Venue: IEEE transactions on circuits and systems for video technology (Print)\n",
            "Abstract: Cross-media retrieval has become a key problem in both research and application, in which users can search results across all of the media types (text, image, audio, video, and 3-D) by submitting a query of any media type. How to measure the content similarity among different media is the key challenge. Existing cross-media retrieval methods usually focus on modeling the pairwise correlation or semantic information separately. In fact, these two kinds of information are complementary to each other and optimizing them simultaneously can further improve the accuracy. In this paper, we propose a novel feature learning algorithm for cross-media data, called joint representation learning (JRL), which is able to explore jointly the correlation and semantic information in a unified optimization framework. JRL integrates the sparse and semisupervised regularization for different media types into one unified optimization problem, while existing feature learning methods generally focus on a single media type. On one hand, JRL learns sparse projection matrix for different media simultaneously, so different media can align with each other, which is robust to the noise. On the other hand, both the labeled data and unlabeled data of different media types are explored. Unlabeled examples of different media types increase the diversity of training data and boost the performance of joint representation learning. Furthermore, JRL can not only reduce the dimension of the original features, but also incorporate the cross-media correlation into the final representation, which further improves the performance of both cross-media retrieval and single-media retrieval. Experiments on two datasets with up to five media types show the effectiveness of our proposed approach, as compared with the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Self-Supervised Video Hashing With Hierarchical Binary Auto-Encoder\n",
            "Authors: Jingkuan Song, Hanwang Zhang, Xiangpeng Li, Lianli Gao, M. Wang, Richang Hong\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Existing video hash functions are built on three isolated stages: frame pooling, relaxed learning, and binarization, which have not adequately explored the temporal order of video frames in a joint binary optimization model, resulting in severe information loss. In this paper, we propose a novel unsupervised video hashing framework dubbed self-supervised video hashing (SSVH), which is able to capture the temporal nature of videos in an end-to-end learning to hash fashion. We specifically address two central problems: 1) how to design an encoder–decoder architecture to generate binary codes for videos and 2) how to equip the binary codes with the ability of accurate video retrieval. We design a hierarchical binary auto-encoder to model the temporal dependencies in videos with multiple granularities, and embed the videos into binary codes with less computations than the stacked architecture. Then, we encourage the binary codes to simultaneously reconstruct the visual content and neighborhood structure of the videos. Experiments on two real-world data sets show that our SSVH method can significantly outperform the state-of-the-art methods and achieve the current best performance on the task of unsupervised video retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Image-to-image translation for cross-domain disentanglement\n",
            "Authors: Abel Gonzalez-Garcia, Joost van de Weijer, Yoshua Bengio\n",
            "Year: 2018\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Deep image translation methods have recently shown excellent results, outputting high-quality images covering multiple modes of the data distribution. There has also been increased interest in disentangling the internal representations learned by deep methods to further improve their performance and achieve a finer control. In this paper, we bridge these two objectives and introduce the concept of cross-domain disentanglement. We aim to separate the internal representation into three parts. The shared part contains information for both domains. The exclusive parts, on the other hand, contain only factors of variation that are particular to each domain. We achieve this through bidirectional image translation based on Generative Adversarial Networks and cross-domain autoencoders, a novel network component. Our model offers multiple advantages. We can output diverse samples covering multiple modes of the distributions of both domains, perform domain-specific image transfer and interpolation, and cross-domain retrieval without the need of labeled data, only paired images. We compare our model to the state-of-the-art in multi-modal image translation and achieve better results for translation on challenging datasets as well as for cross-domain retrieval on realistic datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Rethinking search\n",
            "Authors: Donald Metzler, Yi Tay, Dara Bahri\n",
            "Year: 2021\n",
            "Venue: SIGIR Forum\n",
            "Abstract: When experiencing an information need, users want to engage with a domain expert, but often turn to an information retrieval system, such as a search engine, instead. Classical information retrieval systems do not answer information needs directly, but instead provide references to (hopefully authoritative) answers. Successful question answering systems offer a limited corpus created on-demand by human experts, which is neither timely nor scalable. Pre-trained language models, by contrast, are capable of directly generating prose that may be responsive to an information need, but at present they are dilettantes rather than domain experts - they do not have a true understanding of the world, they are prone to hallucinating, and crucially they are incapable of justifying their utterances by referring to supporting documents in the corpus they were trained over. This paper examines how ideas from classical information retrieval and pre-trained language models can be synthesized and evolved into systems that truly deliver on the promise of domain expert advice.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Applications of Topic Models\n",
            "Authors: Jordan L. Boyd-Graber, Yuening Hu, David Mimno\n",
            "Year: 2017\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: How can a single person understand what’s going on in a collection of millions of documents? This is an increasingly widespread problem: sifting through an organization’s e-mails, understanding a decade worth of newspapers, or characterizing a scientific field’s research. This monograph explores the ways that humans and computers make sense of document collections through tools called topic models. Topic models are a statistical framework that help users understand large document collections; not just to find individual documents but to understand the general themes present in the collection. Applications of Topic Models describes the recent academic and industrial applications of topic models. In addition to topic models’ effective application to traditional problems like information retrieval, visualization, statistical inference, multilingual modeling, and linguistic understanding, Applications of Topic Models also reviews topic models’ ability to unlock large text collections for qualitative analysis. It reviews their successful use by researchers to help understand fiction, non-fiction, scientific publications, and political texts. Applications of Topic Models is aimed at the reader with some knowledge of document processing, basic understanding of some probability, and interested in many application domains. It discusses the information needs of each application area, and how those specific needs affect models, curation procedures, and interpretations. By the end of the monograph, it is hoped that readers will be excited enough to attempt to embark on building their own topic models. It should also be of interest to topic model experts as the coverage of diverse applications may expose models and approaches they had not seen before.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Interference Model of Visual Working Memory\n",
            "Authors: K. Oberauer, Hsuan-Yu Lin\n",
            "Year: 2017\n",
            "Venue: Psychology Review\n",
            "Abstract: The article introduces an interference model of working memory for information in a continuous similarity space, such as the features of visual objects. The model incorporates the following assumptions: (a) Probability of retrieval is determined by the relative activation of each retrieval candidate at the time of retrieval; (b) activation comes from 3 sources in memory: cue-based retrieval using context cues, context-independent memory for relevant contents, and noise; (c) 1 memory object and its context can be held in the focus of attention, where it is represented with higher precision, and partly shielded against interference. The model was fit to data from 4 continuous-reproduction experiments testing working memory for colors or orientations. The experiments involved variations of set size, kind of context cues, precueing, and retro-cueing of the to-be-tested item. The interference model fit the data better than 2 competing models, the Slot-Averaging model and the Variable-Precision resource model. The interference model also fared well in comparison to several new models incorporating alternative theoretical assumptions. The experiments confirm 3 novel predictions of the interference model: (a) Nontargets intrude in recall to the extent that they are close to the target in context space; (b) similarity between target and nontarget features improves recall, and (c) precueing—but not retro-cueing—the target substantially reduces the set-size effect. The success of the interference model shows that working memory for continuous visual information works according to the same principles as working memory for more discrete (e.g., verbal) contents. Data and model codes are available at https://osf.io/wgqd5/.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Salience Representations for F0 Estimation in Polyphonic Music\n",
            "Authors: Rachel M. Bittner, Brian McFee, J. Salamon, P. Li, J. Bello\n",
            "Year: 2017\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Estimating fundamental frequencies in polyphonic music remains a notoriously difﬁcult task in Music Information Retrieval. While other tasks, such as beat tracking and chord recognition have seen improvement with the application of deep learning models, little work has been done to apply deep learning methods to fundamental frequency related tasks including multi-f 0 and melody tracking, primarily due to the scarce availability of labeled data. In this work, we describe a fully convolutional neural network for learning salience representations for estimating fundamental frequencies, trained using a large, semi-automatically generated f 0 dataset. We demonstrate the effectiveness of our model for learning salience representations for both multi-f 0 and melody tracking in polyphonic audio, and show that our models achieve state-of-the-art performance on several multi-f 0 and melody datasets. We conclude with directions for future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TREC 2020 Podcasts Track Overview\n",
            "Authors: R. Jones, Ben Carteree, Ann Clion, Maria Eskevich, G. Jones, Jussi Karlgren, Aasish Pappu, S. Reddy, Yongze Yu\n",
            "Year: 2021\n",
            "Venue: Text Retrieval Conference\n",
            "Abstract: The Podcast Track is new at the Text Retrieval Conference (TREC) in 2020. The podcast track was designed to encourage research into podcasts in the information retrieval and NLP research communities. The track consisted of two shared tasks: segment retrieval and summarization, both based on a dataset of over 100,000 podcast episodes (metadata, audio, and automatic transcripts) which was released concurrently with the track. The track generated considerable interest, attracted hundreds of new registrations to TREC and fifteen teams, mostly disjoint between search and summarization, made final submissions for assessment. Deep learning was the dominant experimental approach for both search experiments and summarization. This paper gives an overview of the tasks and the results of the participants' experiments. The track will return to TREC 2021 with the same two tasks, incorporating slight modifications in response to participant feedback.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Associative Memories via Predictive Coding\n",
            "Authors: Tommaso Salvatori, Yuhang Song, Yujian Hong, Simon Frieder, Lei Sha, Zhenghua Xu, R. Bogacz, Thomas Lukasiewicz\n",
            "Year: 2021\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Associative memories in the brain receive and store patterns of activity registered by the sensory neurons, and are able to retrieve them when necessary. Due to their importance in human intelligence, computational models of associative memories have been developed for several decades now. In this paper, we present a novel neural model for realizing associative memories, which is based on a hierarchical generative network that receives external stimuli via sensory neurons. It is trained using predictive coding, an error-based learning algorithm inspired by information processing in the cortex. To test the model's capabilities, we perform multiple retrieval experiments from both corrupted and incomplete data points. In an extensive comparison, we show that this new model outperforms in retrieval accuracy and robustness popular associative memory models, such as autoencoders trained via backpropagation, and modern Hopfield networks. In particular, in completing partial data points, our model achieves remarkable results on natural image datasets, such as ImageNet, with a surprisingly high accuracy, even when only a tiny fraction of pixels of the original images is presented. Our model provides a plausible framework to study learning and retrieval of memories in the brain, as it closely mimics the behavior of the hippocampus as a memory index and generative model.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving algorithms and uncertainty estimates for satellite NO2 retrievals: results from the quality assurance for the essential climate variables (QA4ECV) project\n",
            "Authors: K. F. Boersma, H. Eskes, A. Richter, I. de Smedt, A. Lorente, S. Beirle, J. van Geffen, Marina Zara, E. Peters, M. Van Roozendael, T. Wagner, J. Maasakkers, R. van der A, J. Nightingale, Anne De Rudder, H. Irie, G. Pinardi, J. Lambert, S. Compernolle\n",
            "Year: 2018\n",
            "Venue: Atmospheric Measurement Techniques\n",
            "Abstract: Abstract. Global observations of tropospheric nitrogen dioxide (NO2) columns have been shown to be feasible from space, but consistent multi-sensor records do not yet exist, nor are they covered by planned activities at the international level. Harmonised, multi-decadal records of NO2 columns and their associated uncertainties can provide crucial information on how the emissions and concentrations of nitrogen oxides evolve over time. Here we describe the development of a new, community best-practice NO2 retrieval algorithm based on a synthesis of existing approaches. Detailed comparisons of these approaches led us to implement an enhanced spectral fitting method for NO2, a 1°  ×  1° TM5-MP data assimilation scheme to estimate the stratospheric background and improve air mass factor calculations. Guided by the needs expressed by data users, producers, and WMO GCOS guidelines, we incorporated detailed per-pixel uncertainty information in the data product, along with easily traceable information on the relevant quality aspects of the retrieval. We applied the improved QA4ECV NO2 algorithm to the most current level-1 data sets to produce a complete 22-year data record that includes GOME (1995–2003), SCIAMACHY (2002–2012), GOME-2(A) (2007 onwards) and OMI (2004 onwards). The QA4ECV NO2 spectral fitting recommendations and TM5-MP stratospheric column and air mass factor approach are currently also applied to S5P-TROPOMI. The uncertainties in the QA4ECV tropospheric NO2 columns amount to typically 40 % over polluted scenes. The first validation results of the QA4ECV OMI NO2 columns and their uncertainties over Tai'an, China, in June 2006 suggest a small bias (−2 %) and better precision than suggested by uncertainty propagation. We conclude that our improved QA4ECV NO2 long-term data record is providing valuable information to quantitatively constrain emissions, deposition, and trends in nitrogen oxides on a global scale.\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Title: RelocNet: Continuous Metric Learning Relocalisation Using Neural Nets\n",
            "Authors: Vassileios Balntas, Shuda Li, V. Prisacariu\n",
            "Year: 2018\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Secure Data Storage and Searching for Industrial IoT by Integrating Fog Computing and Cloud Computing\n",
            "Authors: Jun-Song Fu, Yun Liu, H. Chao, B. Bhargava, Zhenjiang Zhang\n",
            "Year: 2018\n",
            "Venue: IEEE Transactions on Industrial Informatics\n",
            "Abstract: With the fast development of industrial Internet of things (IIoT), a large amount of data is being generated continuously by different sources. Storing all the raw data in the IIoT devices locally is unwise considering that the end devices’ energy and storage spaces are strictly limited. In addition, the devices are unreliable and vulnerable to many threats because the networks may be deployed in remote and unattended areas. In this paper, we discuss the emerging challenges in the aspects of data processing, secure data storage, efficient data retrieval and dynamic data collection in IIoT. Then, we design a flexible and economical framework to solve the problems above by integrating the fog computing and cloud computing. Based on the time latency requirements, the collected data are processed and stored by the edge server or the cloud server. Specifically, all the raw data are first preprocessed by the edge server and then the time-sensitive data (e.g., control information) are used and stored locally. The non-time-sensitive data (e.g., monitored data) are transmitted to the cloud server to support data retrieval and mining in the future. A series of experiments and simulation are conducted to evaluate the performance of our scheme. The results illustrate that the proposed framework can greatly improve the efficiency and security of data storage and retrieval in IIoT.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Modal and Hierarchical Modeling of Video and Text\n",
            "Authors: Bowen Zhang, Hexiang Hu, Fei Sha\n",
            "Year: 2018\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Cross-Modal Embeddings With Adversarial Networks for Cooking Recipes and Food Images\n",
            "Authors: Hao Wang, Doyen Sahoo, Chenghao Liu, Ee-Peng Lim, S. Hoi\n",
            "Year: 2019\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Food computing is playing an increasingly important role in human daily life, and has found tremendous applications in guiding human behavior towards smart food consumption and healthy lifestyle. An important task under the food-computing umbrella is retrieval, which is particularly helpful for health related applications, where we are interested in retrieving important information about food (e.g., ingredients, nutrition, etc.). In this paper, we investigate an open research task of cross-modal retrieval between cooking recipes and food images, and propose a novel framework Adversarial Cross-Modal Embedding (ACME) to resolve the cross-modal retrieval task in food domains. Specifically, the goal is to learn a common embedding feature space between the two modalities, in which our approach consists of several novel ideas: (i) learning by using a new triplet loss scheme together with an effective sampling strategy, (ii) imposing modality alignment using an adversarial learning strategy, and (iii) imposing cross-modal translation consistency such that the embedding of one modality is able to recover some important information of corresponding instances in the other modality. ACME achieves the state-of-the-art performance on the benchmark Recipe1M dataset, validating the efficacy of the proposed technique.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PACRR: A Position-Aware Neural IR Model for Relevance Matching\n",
            "Authors: Kai Hui, Andrew Yates, K. Berberich, Gerard de Melo\n",
            "Year: 2017\n",
            "Venue: Conference on Empirical Methods in Natural Language Processing\n",
            "Abstract: In order to adopt deep learning for information retrieval, models are needed that can capture all relevant information required to assess the relevance of a document to a given user query. While previous works have successfully captured unigram term matches, how to fully employ position-dependent information such as proximity and term dependencies has been insufficiently explored. In this work, we propose a novel neural IR model named PACRR aiming at better modeling position-dependent interactions between a query and a document. Extensive experiments on six years’ TREC Web Track data confirm that the proposed model yields better results under multiple benchmarks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Machine learning approach for text and document mining\n",
            "Authors: Vishwanath Bijalwan, P. Kumari, Jordán Pascual Espada, Vijay Bhaskar Semwal\n",
            "Year: 2014\n",
            "Venue: arXiv.org\n",
            "Abstract: Text Categorization (TC), also known as Text Classification, is the task of automatically classifying a set of text documents into different categories from a predefined set. If a document belongs to exactly one of the categories, it is a single-label classification task; otherwise, it is a multi-label classification task. TC uses several tools from Information Retrieval (IR) and Machine Learning (ML) and has received much attention in the last years from both researchers in the academia and industry developers. In this paper, we first categorize the documents using KNN based machine learning approach and then return the most relevant documents.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluation Metrics and Evaluation\n",
            "Authors: H. Dalianis\n",
            "Year: 2018\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: AliMe Chat: A Sequence to Sequence and Rerank based Chatbot Engine\n",
            "Authors: Minghui Qiu, Feng-Lin Li, Siyu Wang, Xing Gao, Yan Chen, Weipeng Zhao, Haiqing Chen, Jun Huang, Wei Chu\n",
            "Year: 2017\n",
            "Venue: Annual Meeting of the Association for Computational Linguistics\n",
            "Abstract: We propose AliMe Chat, an open-domain chatbot engine that integrates the joint results of Information Retrieval (IR) and Sequence to Sequence (Seq2Seq) based generation models. AliMe Chat uses an attentive Seq2Seq based rerank model to optimize the joint results. Extensive experiments show our engine outperforms both IR and generation based models. We launch AliMe Chat for a real-world industrial application and observe better results than another public chatbot.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep learning in law: early adaptation and legal word embeddings trained on large corpora\n",
            "Authors: Ilias Chalkidis, Dimitrios Kampas\n",
            "Year: 2018\n",
            "Venue: Artificial Intelligence and Law\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Relevance-based Word Embedding\n",
            "Authors: Hamed Zamani, W. Bruce Croft\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Learning a high-dimensional dense representation for vocabulary terms, also known as a word embedding, has recently attracted much attention in natural language processing and information retrieval tasks. The embedding vectors are typically learned based on term proximity in a large corpus. This means that the objective in well-known word embedding algorithms, e.g., word2vec, is to accurately predict adjacent word(s) for a given word or context. However, this objective is not necessarily equivalent to the goal of many information retrieval (IR) tasks. The primary objective in various IR tasks is to capture relevance instead of term proximity, syntactic, or even semantic similarity. This is the motivation for developing unsupervised relevance-based word embedding models that learn word representations based on query-document relevance information. In this paper, we propose two learning models with different objective functions; one learns a relevance distribution over the vocabulary set for each query, and the other classifies each term as belonging to the relevant or non-relevant class for each query. To train our models, we used over six million unique queries and the top ranked documents retrieved in response to each query, which are assumed to be relevant to the query. We extrinsically evaluate our learned word representation models using two IR tasks: query expansion and query classification. Both query expansion experiments on four TREC collections and query classification experiments on the KDD Cup 2005 dataset suggest that the relevance-based word embedding models significantly outperform state-of-the-art proximity-based embedding models, such as word2vec and GloVe.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Introduction To Complex Analysis\n",
            "Authors: Anke Schmid\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: c © W W L Chen, 1986, 2008. This chapter originates from material used by the author at Imperial College, University of London, between 1981 and 1990. It is available free to all individuals, on the understanding that it is not to be used for financial gain, and may be downloaded and/or photocopied, with or without permission from the author. However, this document may not be kept on any information storage and retrieval system without permission from the author, unless such system is not accessible to any individuals other than its owners.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Media Shared Representation by Hierarchical Learning with Multiple Deep Networks\n",
            "Authors: Yuxin Peng, Xin Huang, Jinwei Qi\n",
            "Year: 2016\n",
            "Venue: International Joint Conference on Artificial Intelligence\n",
            "Abstract: Inspired by the progress of deep neural network (DNN) in single-media retrieval, the researchers have applied the DNN to cross-media retrieval. These methods are mainly two-stage learning: the first stage is to generate the separate representation for each media type, and the existing methods only model the intra-media information but ignore the inter-media correlation with the rich complementary context to the intra-media information. The second stage is to get the shared representation by learning the cross-media correlation, and the existing methods learn the shared representation through a shallow network structure, which cannot fully capture the complex cross-media correlation. For addressing the above problems, we propose the cross-media multiple deep network (CMDN) to exploit the complex cross-media correlation by hierarchical learning. In the first stage, CMDN jointly models the intra-media and intermedia information for getting the complementary separate representation of each media type. In the second stage, CMDN hierarchically combines the inter-media and intra-media representations to further learn the rich cross-media correlation by a deeper two-level network strategy, and finally get the shared representation by a stacked network style. Experiment results show that CMDN achieves better performance comparing with several state-of-the-art methods on 3 extensively used cross-media datasets.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The contribution of the human posterior parietal cortex to episodic memory\n",
            "Authors: C. Sestieri, G. Shulman, M. Corbetta\n",
            "Year: 2017\n",
            "Venue: Nature Reviews Neuroscience\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Machine learning and its applications: A review\n",
            "Authors: Sheena Angra, S. Ahuja\n",
            "Year: 2017\n",
            "Venue: 2017 International Conference on Big Data Analytics and Computational Intelligence (ICBDAC)\n",
            "Abstract: Nowadays, large amount of data is available everywhere. Therefore, it is very important to analyze this data in order to extract some useful information and to develop an algorithm based on this analysis. This can be achieved through data mining and machine learning. Machine learning is an integral part of artificial intelligence, which is used to design algorithms based on the data trends and historical relationships between data. Machine learning is used in various fields such as bioinformatics, intrusion detection, Information retrieval, game playing, marketing, malware detection, image deconvolution and so on. This paper presents the work done by various authors in the field of machine learning in various application areas.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Observation of Critical Phenomena in Parity-Time-Symmetric Quantum Dynamics.\n",
            "Authors: Lei Xiao, Kunkun Wang, Xiang Zhan, Zhi-Hao Bian, K. Kawabata, Masahito Ueda, W. Yi, P. Xue\n",
            "Year: 2018\n",
            "Venue: Physical Review Letters\n",
            "Abstract: We experimentally simulate nonunitary quantum dynamics using a single-photon interferometric network and study the information flow between a parity-time- (PT-)symmetric non-Hermitian system and its environment. We observe oscillations of quantum-state distinguishability and complete information retrieval in the PT-symmetry-unbroken regime. We then characterize in detail critical phenomena of the information flow near the exceptional point separating the PT-unbroken and PT-broken regimes, and demonstrate power-law behavior in key quantities such as the distinguishability and the recurrence time. We also reveal how the critical phenomena are affected by symmetry and initial conditions. Finally, introducing an ancilla as an environment and probing quantum entanglement between the system and the environment, we confirm that the observed information retrieval is induced by a finite-dimensional entanglement partner in the environment. Our work constitutes the first experimental characterization of critical phenomena in PT-symmetric nonunitary quantum dynamics.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Associative Long Short-Term Memory\n",
            "Authors: Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, Alex Graves\n",
            "Year: 2016\n",
            "Venue: International Conference on Machine Learning\n",
            "Abstract: We investigate a new method to augment recurrent neural networks with extra memory without increasing the number of network parameters. The system has an associative memory based on complex-valued vectors and is closely related to Holographic Reduced Representations and Long Short-Term Memory networks. Holographic Reduced Representations have limited capacity: as they store more information, each retrieval becomes noisier due to interference. Our system in contrast creates redundant copies of stored information, which enables retrieval with reduced noise. Experiments demonstrate faster learning on multiple memorization tasks.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Joint embeddings of shapes and images via CNN image purification\n",
            "Authors: Yangyan Li, Hao Su, C. Qi, N. Fish, D. Cohen-Or, L. Guibas\n",
            "Year: 2015\n",
            "Venue: ACM Transactions on Graphics\n",
            "Abstract: Both 3D models and 2D images contain a wealth of information about everyday objects in our environment. However, it is difficult to semantically link together these two media forms, even when they feature identical or very similar objects. We propose a joint embedding space populated by both 3D shapes and 2D images of objects, where the distances between embedded entities reflect similarity between the underlying objects. This joint embedding space facilitates comparison between entities of either form, and allows for cross-modality retrieval. We construct the embedding space using 3D shape similarity measure, as 3D shapes are more pure and complete than their appearance in images, leading to more robust distance metrics. We then employ a Convolutional Neural Network (CNN) to \"purify\" images by muting distracting factors. The CNN is trained to map an image to a point in the embedding space, so that it is close to a point attributed to a 3D model of a similar object to the one depicted in the image. This purifying capability of the CNN is accomplished with the help of a large amount of training data consisting of images synthesized from 3D shapes. Our joint embedding allows cross-view image retrieval, image-based shape retrieval, as well as shape-based image retrieval. We evaluate our method on these retrieval tasks and show that it consistently out-performs state-of-the-art methods, and demonstrate the usability of a joint embedding in a number of additional applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Journal of Experimental Psychology: Learning, Memory, and Cognition\n",
            "Authors: Melanie Labusch, Stéphanie Massol, Ana Marcet, Manuel Perea\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Abstract: Previous studies have shown that speakers of languages such as German, Spanish and French reactivate the syntactic gender of the antecedent of a pronoun in order to license gender agreement. As syntactic gender information is assumed to be stored in the lexicon, this has motivated the claim that pronouns in these languages reactivate the lexical entry of their antecedent noun. In contrast, in languages without syntactic gender such as English, lexical retrieval might be unnecessary. Using eye-tracking while reading, we examined whether antecedent retrieval involves rapid semantic and phonological reactivation. We compared German and English. In German, we found early sensitivity to the semantic, but not to the phonological features of the pronoun's antecedent. In English, readers did not immediately show either semantic or phonological effects specific to coreference. We propose that early semantic facilitation arises due to syntactic gender reactivation, and that antecedent retrieval varies crosslinguistically depending on the type of information relevant to the grammar of each language.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Boosting Bug-Report-Oriented Fault Localization with Segmentation and Stack-Trace Analysis\n",
            "Authors: Chu-Pan Wong, Yingfei Xiong, Hongyu Zhang, Dan Hao, Lu Zhang, Hong Mei\n",
            "Year: 2014\n",
            "Venue: IEEE International Conference on Software Maintenance and Evolution\n",
            "Abstract: To deal with post-release bugs, many software projects set up public bug repositories for users all over the world to report bugs that they have encountered. Recently, researchers have proposed various information retrieval based approaches to localizing faults based on bug reports. In these approaches, source files are processed as single units, where noise in large files may affect the accuracy of fault localization. Furthermore, bug reports often contain stack-trace information, but existing approaches often treat this information as plain text. In this paper, we propose to use segmentation and stack-trace analysis to improve the performance of bug localization. Specifically, given a bug report, we divide each source code file into a series of segments and use the segment most similar to the bug report to represent the file. We also analyze the bug report to identify possible faulty files in a stack trace and favor these files in our retrieval. According to our empirical results, our approach is able to significantly improve Bug Locator, a representative fault localization approach, on all the three software projects (i.e., Eclipse, AspectJ, and SWT) used in our empirical evaluation. Furthermore, segmentation and stack-trace analysis are complementary to each other for boosting the performance of bug-report-oriented fault localization.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Do Neural Ranking Models Intensify Gender Bias?\n",
            "Authors: Navid Rekabsaz, M. Schedl\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Concerns regarding the footprint of societal biases in information retrieval (IR) systems have been raised in several previous studies. In this work, we examine various recent IR models from the perspective of the degree of gender bias in their retrieval results. To this end, we first provide a bias measurement framework which includes two metrics to quantify the degree of the unbalanced presence of gender-related concepts in a given IR model's ranking list. To examine IR models by means of the framework, we create a dataset of non-gendered queries, selected by human annotators. Applying these queries to the MS MARCO Passage retrieval collection, we then measure the gender bias of a BM25 model and several recent neural ranking models. The results show that while all models are strongly biased toward male, the neural models, and in particular the ones based on contextualized embedding models, significantly intensify gender bias. Our experiments also show an overall increase in the gender bias of neural models when they exploit transfer learning, namely when they use (already biased) pre-trained embeddings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bidirectional prefrontal-hippocampal interactions support context-guided memory\n",
            "Authors: Ryan Place, A. Farovik, Marco D. Brockmann, H. Eichenbaum\n",
            "Year: 2016\n",
            "Venue: Nature Neuroscience\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Guided Transformer: Leveraging Multiple External Sources for Representation Learning in Conversational Search\n",
            "Authors: Helia Hashemi, Hamed Zamani, W. Bruce Croft\n",
            "Year: 2020\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Asking clarifying questions in response to ambiguous or faceted queries has been recognized as a useful technique for various information retrieval systems, especially conversational search systems with limited bandwidth interfaces. Analyzing and generating clarifying questions have been studied recently but the accurate utilization of user responses to clarifying questions has been relatively less explored. In this paper, we enrich the representations learned by Transformer networks using a novel attention mechanism from external information sources that weights each term in the conversation. We evaluate this Guided Transformer model in a conversational search scenario that includes clarifying questions. In our experiments, we use two separate external sources, including the top retrieved documents and a set of different possible clarifying questions for the query. We implement the proposed representation learning model for two downstream tasks in conversational search; document retrieval and next clarifying question selection. Our experiments use a public dataset for search clarification and demonstrate significant improvements compared to competitive baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Successful Remembering Elicits Event-Specific Activity Patterns in Lateral Parietal Cortex\n",
            "Authors: Brice A. Kuhl, M. Chun\n",
            "Year: 2014\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Remembering a past event involves reactivation of content-specific patterns of neural activity in high-level perceptual regions (e.g., ventral temporal cortex, VTC). In contrast, the subjective experience of vivid remembering is typically associated with increased activity in lateral parietal cortex (LPC)—“retrieval success effects” that are thought to generalize across content types. However, the functional significance of LPC activation during memory retrieval remains a subject of active debate. In particular, theories are divided with respect to whether LPC actively represents retrieved content or if LPC activity only scales with content reactivation elsewhere (e.g., VTC). Here, we report a human fMRI study of visual memory recall (faces vs scenes) in which complementary forms of multivoxel pattern analysis were used to test for and compare content reactivation within LPC and VTC. During recall of visual images, we observed robust reactivation of broad category information (face vs scene) in both VTC and LPC. Moreover, recall-related activity patterns in LPC, but not VTC, differentiated between individual events. Importantly, these content effects were particularly evident in areas of LPC (namely, angular gyrus) in which activity scaled with subjective reports of recall vividness. These findings provide striking evidence that LPC not only signals that memories have been successfully recalled, but actively represents what is being remembered.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Embedding-based Query Language Models\n",
            "Authors: Hamed Zamani, W. Bruce Croft\n",
            "Year: 2016\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Word embeddings, which are low-dimensional vector representations of vocabulary terms that capture the semantic similarity between them, have recently been shown to achieve impressive performance in many natural language processing tasks. The use of word embeddings in information retrieval, however, has only begun to be studied. In this paper, we explore the use of word embeddings to enhance the accuracy of query language models in the ad-hoc retrieval task. To this end, we propose to use word embeddings to incorporate and weight terms that do not occur in the query, but are semantically related to the query terms. We describe two embedding-based query expansion models with different assumptions. Since pseudo-relevance feedback methods that use the top retrieved documents to update the original query model are well-known to be effective, we also develop an embedding-based relevance model, an extension of the effective and robust relevance model approach. In these models, we transform the similarity values obtained by the widely-used cosine similarity with a sigmoid function to have more discriminative semantic similarity values. We evaluate our proposed methods using three TREC newswire and web collections. The experimental results demonstrate that the embedding-based methods significantly outperform competitive baselines in most cases. The embedding-based methods are also shown to be more robust than the baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Randomized Ensembles for Metric Learning\n",
            "Authors: Hong Xuan, Richard Souvenir, Robert Pless\n",
            "Year: 2018\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: GRASP: a versatile algorithm for characterizing the atmosphere\n",
            "Authors: O. Dubovik, Tatyana Lapyonok, P. Litvinov, M. Herman, D. Fuertes, F. Ducos, B. Torres, Y. Derimian, Xin Huang, A. Lopatin, A. Chaikovsky, M. Aspetsberger, C. Federspiel\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: GRASP (Generalized Retrieval of Aerosol and Surface Properties) is the first unified algorithm to be developed for characterizing atmospheric properties gathered from a variety of remote sensing observations (an introductory video is available elsewhere1). GRASP is based on a recent algorithm2 created to improve aerosol retrieval from the French Space Agency’s PARASOL3 imager over bright surfaces like deserts where high surface reflectance dwarfs the signal from aerosols. Moreover, GRASP relies on the heritage of retrieval advances4–7 implemented for AERONET,8 a worldwide network of over 200 radiometer sites that generate the data used to validate nearly all satellite observations of atmospheric aerosols. The AERONET retrievals derive detailed aerosol properties,6 including absorption, providing information of vital importance for reducing uncertainty in assessments of climate change. GRASP is based on several generalization principles with the idea of developing a scientifically rigorous, versatile, practically efficient, transparent, and accessible algorithm. There are two main independent modules. The first, numerical inversion, includes general mathematical operations not related to the particular physical nature of the inverted data (in this case, remote sensing observations). The second module, the forward model, was developed to simulate various atmospheric remote sensing observations. Numerical inversion is implemented as a statistically optimized fitting of observations following the multi-term least squares method (LSM) strategy, which combines9 the advantages of a variety of approaches and provides transparency and flexibility in developing algorithms that invert passive and/or active observations and derive several groups of Figure 1. Diagram illustrating the principle of combined synergetic processing of complementary observations using a multi-pixel2 retrieval approach. CALIPSO is a joint lidar mission of NASA and the French Space Agency, which also manages the PARASOL imager. AERONET is a worldwide network of radiometer sites.\n",
            "\n",
            "---\n",
            "\n",
            "Title: PISA: Performant Indexes and Search for Academia\n",
            "Authors: Antonio Mallia, Michal Siedlaczek, J. Mackenzie, Torsten Suel\n",
            "Year: 2019\n",
            "Venue: OSIRRC@SIGIR\n",
            "Abstract: Performant Indexes and Search for Academia ( PISA ) is an experimental search engine that focuses on efficient implementations of state-of-the-art representations and algorithms for text retrieval. In this work, we outline our effort in creating a replicable search run from PISA for the 2019 Open Source Information Retrieval Replicability Challenge , which encourages the information retrieval community to produce replicable systems through the use of a containerized, Docker-based infrastructure. We also discuss the origins, current functionality, and future direction and challenges for the PISA sys-tem.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning a Joint Search and Recommendation Model from User-Item Interactions\n",
            "Authors: Hamed Zamani\n",
            "Year: 2020\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: Existing learning to rank models for information retrieval are trained based on explicit or implicit query-document relevance information. In this paper, we study the task of learning a retrieval model based on user-item interactions. Our model has potential applications to the systems with rich user-item interaction data, such as browsing and recommendation, in which having an accurate search engine is desired. This includes media streaming services and e-commerce websites among others. Inspired by the neural approaches to collaborative filtering and the language modeling approaches to information retrieval, our model is jointly optimized to predict user-item interactions and reconstruct the item textual descriptions. In more details, our model learns user and item representations such that they can accurately predict future user-item interactions, while generating an effective unigram language model for each item. Our experiments on four diverse datasets in the context of movie and product search and recommendation demonstrate that our model substantially outperforms competitive retrieval baselines, in addition to providing comparable performance to state-of-the-art hybrid recommendation models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Recommender Systems: Issues, Challenges, and Research Opportunities\n",
            "Authors: Shah Khusro, Z. Ali, Irfan Ullah\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: ANTIQUE: A Non-factoid Question Answering Benchmark\n",
            "Authors: Helia Hashemi, Mohammad Aliannejadi, Hamed Zamani, W. Bruce Croft\n",
            "Year: 2019\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Question Answering Systems : A Survey .\n",
            "Authors: Ali Mohamed Nabil Allam, Mohamed H. Haggag\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Question Answering (QA) is a specialized area in the field of Information Retrieval (IR). The QA systems are concerned with providing relevant answers in response to questions proposed in natural language. QA is therefore composed of three distinct modules, each of which has a core component beside other supplementary components. These three core components are: question classification, information retrieval, and answer extraction. Question classification plays an essential role in QA systems by classifying the submitted question according to its type. Information retrieval is very important for question answering, because if no correct answers are present in a document, no further processing could be carried out to find an answer. Finally, answer extraction aims to retrieve the answer for a question asked by the user. This survey paper provides an overview of Question-Answering and its system architecture, as well as the previous related work comparing each research against the others with respect to the components that were covered and the approaches that were followed. At the end, the survey provides an analytical discussion of the proposed QA models, along with their main contributions, experimental results, and limitations.\n",
            "\n",
            "---\n",
            "\n",
            "Title: EXS: Explainable Search Using Local Model Agnostic Interpretability\n",
            "Authors: Jaspreet Singh, Avishek Anand\n",
            "Year: 2018\n",
            "Venue: Web Search and Data Mining\n",
            "Abstract: Retrieval models in information retrieval are used to rank documents for typically under-specified queries. Today machine learning is used to learn retrieval models from click logs and/or relevance judgments that maximizes an objective correlated with user satisfaction. As these models become increasingly powerful and sophisticated, they also become harder to understand. Consequently, it is hard for to identify artifacts in training, data specific biases and intents from a complex trained model like neural rankers even if trained purely on text features. EXS is a search system designed specifically to provide its users with insight into the following questions: \"What is the intent of the query according to the ranker?'', \"Why is this document ranked higher than another?'' and \"Why is this document relevant to the query?''. EXS uses a version of a popular posthoc explanation method for classifiers -- LIME, adapted specifically to answer these questions. We show how such a system can effectively help a user understand the results of neural rankers and highlight areas of improvement.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Assessing ranking metrics in top-N recommendation\n",
            "Authors: Daniel Valcarce, Alejandro Bellogín, Javier Parapar, P. Castells\n",
            "Year: 2020\n",
            "Venue: Information Retrieval Journal\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Generous Interfaces for Digital Cultural Collections\n",
            "Authors: M. Whitelaw\n",
            "Year: 2015\n",
            "Venue: Digital Humanities Quarterly\n",
            "Abstract: Decades of digitisation have made a wealth of digital cultural material available online. Yet search — the dominant interface to these collections — is incapable of representing this abundance. Search is ungenerous: it withholds information, and demands a query. This paper argues for a more generous alternative: rich, browsable interfaces that reveal the scale and complexity of digital heritage collections. Drawing on related work and precedents from information retrieval and visualisation, as well as critical humanistic approaches to the interface, this paper documents and analyses practical experiments in generous interfaces developed in collaboration with Australian cultural institutions. Imagine yourself\n",
            "\n",
            "---\n",
            "\n",
            "Title: Homomorphic Encryption and Applications\n",
            "Authors: X. Yi, Russell Paulet, E. Bertino\n",
            "Year: 2014\n",
            "Venue: SpringerBriefs in Computer Science\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Capacity of Private Computation\n",
            "Authors: Hua Sun, S. Jafar\n",
            "Year: 2017\n",
            "Venue: IEEE Transactions on Information Theory\n",
            "Abstract: We introduce the problem of private computation, comprised of <inline-formula> <tex-math notation=\"LaTeX\">$ {N}$ </tex-math></inline-formula> distributed and non-colluding servers, <inline-formula> <tex-math notation=\"LaTeX\">$ {K}$ </tex-math></inline-formula> independent datasets, and a user who wants to compute a function of the datasets privately, i.e., without revealing which function he wants to compute, to any individual server. This private computation problem is a strict generalization of the private information retrieval (PIR) problem, obtained by expanding the PIR message set (which consists of only independent messages) to also include functions of those messages. The capacity of private computation, <inline-formula> <tex-math notation=\"LaTeX\">$ {C}$ </tex-math></inline-formula>, is defined as the maximum number of bits of the desired function that can be retrieved per bit of total download from all servers. We characterize the capacity of private computation, for <inline-formula> <tex-math notation=\"LaTeX\">$ {N}$ </tex-math></inline-formula> servers and <inline-formula> <tex-math notation=\"LaTeX\">$ {K}$ </tex-math></inline-formula> independent datasets that are replicated at each server, when the functions to be computed are arbitrary linear combinations of the datasets. Surprisingly, the capacity, <inline-formula> <tex-math notation=\"LaTeX\">$ {C}=\\left ({1+1/ {N}+\\cdots +1/ {N}^{ {K}-1}}\\right)^{-1}$ </tex-math></inline-formula>, matches the capacity of PIR with <inline-formula> <tex-math notation=\"LaTeX\">$ {N}$ </tex-math></inline-formula> servers and <inline-formula> <tex-math notation=\"LaTeX\">$ {K}$ </tex-math></inline-formula> messages. Thus, allowing arbitrary linear computations does not reduce the communication rate compared to pure dataset retrieval. The same insight is shown to hold even for arbitrary non-linear computations when the number of datasets <inline-formula> <tex-math notation=\"LaTeX\">$ {K}\\rightarrow \\infty $ </tex-math></inline-formula>.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Rethinking Query Expansion for BERT Reranking\n",
            "Authors: Ramith Padaki, Zhuyun Dai, Jamie Callan\n",
            "Year: 2020\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: TRECVID 2018: Benchmarking Video Activity Detection, Video Captioning and Matching, Video Storytelling Linking and Video Search\n",
            "Authors: G. Awad, A. Butt, Keith Curtis, Yooyoung Lee, Jonathan G. Fiscus, Afzad Godil, David Joy, Andrew Delgado, A. Smeaton, Yvette Graham, Wessel Kraaij, G. Quénot, João Magalhães, David Semedo, Saverio G. Blasi\n",
            "Year: 2018\n",
            "Venue: TREC Video Retrieval Evaluation\n",
            "Abstract: The TREC Video Retrieval Evaluation (TRECVID) 2018 was a TREC-style video analysis and retrieval evaluation, the goal of which remains to promote progress in research and development of contentbased exploitation and retrieval of information from digital video via open, metrics-based evaluation. Over the last eighteen years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID is funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addi-\n",
            "\n",
            "---\n",
            "\n",
            "Title: Medical Semantic Similarity with a Neural Language Model\n",
            "Authors: Lance De Vine, G. Zuccon, B. Koopman, Laurianne Sitbon, P. Bruza\n",
            "Year: 2014\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Advances in neural network language models have demonstrated that these models can effectively learn representations of words meaning. In this paper, we explore a variation of neural language models that can learn on concepts taken from structured ontologies and extracted from free-text, rather than directly from terms in free-text. This model is employed for the task of measuring semantic similarity between medical concepts, a task that is central to a number of techniques in medical informatics and information retrieval. The model is built with two medical corpora (journal abstracts and patient records) and empirically validated on two ground-truth datasets of human-judged concept pairs assessed by medical professionals. Empirically, our approach correlates closely with expert human assessors (≈0.9) and outperforms a number of state-of-the-art benchmarks for medical semantic similarity. The demonstrated superiority of this model for providing an effective semantic similarity measure is promising in that this may translate into effectiveness gains for techniques in medical information retrieval and medical informatics (e.g., query expansion and literature-based discovery).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving IR-based bug localization with context-aware query reformulation\n",
            "Authors: M. M. Rahman, C. Roy\n",
            "Year: 2018\n",
            "Venue: ESEC/SIGSOFT FSE\n",
            "Abstract: Recent findings suggest that Information Retrieval (IR)-based bug localization techniques do not perform well if the bug report lacks rich structured information (e.g., relevant program entity names). Conversely, excessive structured information (e.g., stack traces) in the bug report might not always help the automated localization either. In this paper, we propose a novel technique--BLIZZARD-- that automatically localizes buggy entities from project source using appropriate query reformulation and effective information retrieval. In particular, our technique determines whether there are excessive program entities or not in a bug report (query), and then applies appropriate reformulations to the query for bug localization. Experiments using 5,139 bug reports show that our technique can localize the buggy source documents with 7%--56% higher Hit@10, 6%--62% higher MAP@10 and 6%--62% higher MRR@10 than the baseline technique. Comparison with the state-of-the-art techniques and their variants report that our technique can improve 19% in MAP@10 and 20% in MRR@10 over the state-of-the-art, and can improve 59% of the noisy queries and 39% of the poor queries.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploring Data Augmentation for Improved Singing Voice Detection with Neural Networks\n",
            "Authors: Jan Schlüter, Thomas Grill\n",
            "Year: 2015\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: In computer vision, state-of-the-art object recognition systems rely on label-preserving image transformations such as scaling and rotation to augment the training datasets. The additional training examples help the system to learn invariances that are difficult to build into the model, and improve generalization to unseen data. To the best of our knowledge, this approach has not been systematically explored for music signals. Using the problem of singing voice detection with neural networks as an example, we apply a range of label-preserving audio transformations to assess their utility for music data augmentation. In line with recent research in speech recognition, we find pitch shifting to be the most helpful augmentation method. Combined with time stretching and random frequency filtering, we achieve a reduction in classification error between 10 and 30%, reaching the state of the art on two public datasets. We expect that audio data augmentation would yield significant gains for several other sequence labelling and event detection tasks in music information retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Detect-To-Retrieve: Efficient Regional Aggregation for Image Search\n",
            "Authors: Marvin Teichmann, A. Araújo, Menglong Zhu, Jack Sim\n",
            "Year: 2018\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: Retrieving object instances among cluttered scenes efficiently requires compact yet comprehensive regional image representations. Intuitively, object semantics can help build the index that focuses on the most relevant regions. However, due to the lack of bounding-box datasets for objects of interest among retrieval benchmarks, most recent work on regional representations has focused on either uniform or class-agnostic region selection. In this paper, we first fill the void by providing a new dataset of landmark bounding boxes, based on the Google Landmarks dataset, that includes 94k images with manually curated boxes from 15k unique landmarks. Then, we demonstrate how a trained landmark detector, using our new dataset, can be leveraged to index image regions and improve retrieval accuracy while being much more efficient than existing regional methods. In addition, we introduce a novel regional aggregated selective match kernel (R-ASMK) to effectively combine information from detected regions into an improved holistic image representation. R-ASMK boosts image retrieval accuracy substantially with no dimensionality increase, while even outperforming systems that index image regions independently. Our complete image retrieval system improves upon the previous state-of-the-art by significant margins on the Revisited Oxford and Paris datasets. Code and data will be released.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Interactions with Search Systems\n",
            "Authors: Ryen W. White\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: Information seeking is a fundamental human activity. In the modern world it is frequently conducted through interactions with search systems. The retrieval and comprehension of information returned by these systems is a key part of decision making and action in a broad range of settings. Advances in data availability, coupled with new interaction paradigms and mobile and cloud computing capabilities, have created a diverse set of new opportunities for information access and use. In this comprehensive book for professionals, researchers, and students involved in search system design and evaluation, search expert Ryen White discusses how search systems can capitalize on these new capabilities, and how next-generation search systems must support higher-order search activities such as task completion, learning, and decision making. He outlines the implications of these changes for the evolution of search evaluation, as well as related challenges that extend beyond search systems in areas such as privacy and societal benefit.\n",
            "\n",
            "---\n",
            "\n",
            "Title: HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN\n",
            "Authors: Yue Cao, Bin Liu, Mingsheng Long, Jianmin Wang\n",
            "Year: 2018\n",
            "Venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: Deep learning to hash improves image retrieval performance by end-to-end representation learning and hash coding from training data with pairwise similarity information. Subject to the scarcity of similarity information that is often expensive to collect for many application domains, existing deep learning to hash methods may overfit the training data and result in substantial loss of retrieval quality. This paper presents HashGAN, a novel architecture for deep learning to hash, which learns compact binary hash codes from both real images and diverse images synthesized by generative models. The main idea is to augment the training data with nearly real images synthesized from a new Pair Conditional Wasserstein GAN (PC-WGAN) conditioned on the pairwise similarity information. Extensive experiments demonstrate that HashGAN can generate high-quality binary hash codes and yield state-of-the-art image retrieval performance on three benchmarks, NUS-WIDE, CIFAR-10, and MS-COCO.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SearchGazer: Webcam Eye Tracking for Remote Studies of Web Search\n",
            "Authors: Alexandra Papoutsaki, James Laskey, Jeff Huang\n",
            "Year: 2017\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: We introduce SearchGazer, a web-based eye tracker for remote web search studies using common webcams already present in laptops and some desktop computers. SearchGazer is a pure JavaScript library that infers the gaze behavior of searchers in real time. The eye tracking model self-calibrates by watching searchers interact with the search pages and trains a mapping of eye features to gaze locations and search page elements on the screen. Contrary to typical eye tracking studies in information retrieval, this approach does not require the purchase of any additional specialized equipment, and can be done remotely in a user's natural environment, leading to cheaper and easier visual attention studies. While SearchGazer is not intended to be as accurate as specialized eye trackers, it is able to replicate many of the research findings of three seminal information retrieval papers: two that used eye tracking devices, and one that used the mouse cursor as a restricted focus viewer. Charts and heatmaps from those original papers are plotted side-by-side with SearchGazer results. While the main results are similar, there are some notable differences, which we hypothesize derive from improvements in the latest ranking technologies used by current versions of search engines and diligence by remote users. As part of this paper, we also release SearchGazer as a library that can be integrated into any search page.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Spaceborne GNSS-R Minimum Variance Wind Speed Estimator\n",
            "Authors: M. Clarizia, C. Ruf, P. Jales, C. Gommenginger\n",
            "Year: 2014\n",
            "Venue: IEEE Transactions on Geoscience and Remote Sensing\n",
            "Abstract: A Minimum Variance (MV) wind speed estimator for Global Navigation Satellite System-Reflectometry (GNSS-R) is presented. The MV estimator is a composite of wind estimates obtained from five different observables derived from GNSS-R Delay-Doppler Maps (DDMs). Regression-based wind retrievals are developed for each individual observable using empirical geophysical model functions that are derived from NDBC buoy wind matchups with collocated overpass measurements made by the GNSS-R sensor on the United Kingdom-Disaster Monitoring Constellation (UK-DMC) satellite. The MV estimator exploits the partial decorrelation that is present between residual errors in the five individual wind retrievals. In particular, the RMS error in the MV estimator, at 1.65 m/s, is lower than that of each of the individual retrievals. Although they are derived from the same DDM, the partial decorrelation between their retrieval errors demonstrates that there is some unique information contained in them. The MV estimator is applied here to UK-DMC data, but it can be easily adapted to retrieve wind speed for forthcoming GNSS-R missions, including the UK's TechDemoSat-1 (TDS-1) and NASA's Cyclone Global Navigation Satellite System (CYGNSS).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Query Expansion with Freebase\n",
            "Authors: Chenyan Xiong, Jamie Callan\n",
            "Year: 2015\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Large knowledge bases are being developed to describe entities, their attributes, and their relationships to other entities. Prior research mostly focuses on the construction of knowledge bases, while how to use them in information retrieval is still an open problem. This paper presents a simple and effective method of using one such knowledge base, Freebase, to improve query expansion, a classic and widely studied information retrieval task. It investigates two methods of identifying the entities associated with a query, and two methods of using those entities to perform query expansion. A supervised model combines information derived from Freebase descriptions and categories to select terms that are effective for query expansion. Experiments on the ClueWeb09 dataset with TREC Web Track queries demonstrate that these methods are almost 30% more effective than strong, state-of-the-art query expansion algorithms. In addition to improving average performance, some of these methods have better win/loss ratios than baseline algorithms, with 50% fewer queries damaged.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Context Driven Scene Parsing with Attention to Rare Classes\n",
            "Authors: Jimei Yang, Brian L. Price, Scott D. Cohen, Ming-Hsuan Yang\n",
            "Year: 2014\n",
            "Venue: 2014 IEEE Conference on Computer Vision and Pattern Recognition\n",
            "Abstract: This paper presents a scalable scene parsing algorithm based on image retrieval and superpixel matching. We focus on rare object classes, which play an important role in achieving richer semantic understanding of visual scenes, compared to common background classes. Towards this end, we make two novel contributions: rare class expansion and semantic context description. First, considering the long-tailed nature of the label distribution, we expand the retrieval set by rare class exemplars and thus achieve more balanced superpixel classification results. Second, we incorporate both global and local semantic context information through a feedback based mechanism to refine image retrieval and superpixel matching. Results on the SIFTflow and LMSun datasets show the superior performance of our algorithm, especially on the rare classes, without sacrificing overall labeling accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Highly-efficient quantum memory for polarization qubits in a spatially-multiplexed cold atomic ensemble\n",
            "Authors: P. Vernaz-Gris, Kun Huang, M. Cao, A. Sheremet, J. Laurat\n",
            "Year: 2017\n",
            "Venue: Nature Communications\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Directional coupling of slow and fast hippocampal gamma with neocortical alpha/beta oscillations in human episodic memory\n",
            "Authors: B. Griffiths, George Parish, Frederic Roux, Sebastian Michelmann, Mircea van der Plas, Luca D. Kolibius, R. Chelvarajah, D. Rollings, V. Sawlani, H. Hamer, S. Gollwitzer, G. Kreiselmeyer, B. Staresina, M. Wimber, S. Hanslmayr\n",
            "Year: 2018\n",
            "Venue: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Abstract: Significance Episodic memories detail our personally experienced past. The formation and retrieval of these memories have long been thought to be supported by a division of labor between the neocortex and the hippocampus, where the former processes event-related information and the latter binds this information together. However, it remains unclear how the 2 regions interact. We uncover directional coupling between these regions, with power decreases in the neocortex that precede and predict power increases in the hippocampus during memory formation. Fascinatingly, this process reverses during memory retrieval, with hippocampal power increases preceding and predicting neocortical power decreases. These results suggest a bidirectional flow of information between the neocortex and hippocampus is fundamental to the formation and retrieval of episodic memories. Episodic memories hinge upon our ability to process a wide range of multisensory information and bind this information into a coherent, memorable representation. On a neural level, these 2 processes are thought to be supported by neocortical alpha/beta desynchronization and hippocampal theta/gamma synchronization, respectively. Intuitively, these 2 processes should couple to successfully create and retrieve episodic memories, yet this hypothesis has not been tested empirically. We address this by analyzing human intracranial electroencephalogram data recorded during 2 associative memory tasks. We find that neocortical alpha/beta (8 to 20 Hz) power decreases reliably precede and predict hippocampal “fast” gamma (60 to 80 Hz) power increases during episodic memory formation; during episodic memory retrieval, however, hippocampal “slow” gamma (40 to 50 Hz) power increases reliably precede and predict later neocortical alpha/beta power decreases. We speculate that this coupling reflects the flow of information from the neocortex to the hippocampus during memory formation, and hippocampal pattern completion inducing information reinstatement in the neocortex during memory retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Rate limit exceeded. Waiting for 60 seconds before retrying...\n",
            "Title: Temporal Memory Is Shaped by Encoding Stability and Intervening Item Reactivation\n",
            "Authors: S. Dubrow, L. Davachi\n",
            "Year: 2014\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Making sense of previous experience requires remembering the order in which events unfolded in time. Prior work has implicated the hippocampus and medial temporal lobe cortex in memory for temporal information associated with individual episodes. However, the processes involved in encoding and retrieving temporal information across extended sequences is relatively poorly understood. Here we used fMRI during the encoding and retrieval of extended sequences to test specific predictions about the type of information used to resolve temporal order and the role of the hippocampus in this process. Participants studied sequences of images of celebrity faces and common objects followed by a recency discrimination test. The main conditions of interest were pairs of items that had been presented with three intervening items, half of which included an intervening category shift. During encoding, hippocampal pattern similarity across intervening items was associated with subsequent successful order memory. To test for evidence of associative retrieval, we trained a classifier to discriminate encoding patterns associated with faces versus objects and applied the classifier on fMRI patterns during recency discrimination. We found evidence that the category content of intervening items was reactivated during recency judgments, and this was related to hippocampal encoding-retrieval similarity. A follow-up behavioral priming experiment revealed additional evidence for intervening item reinstatement during temporal order judgments. Reinstatement did not differ according to whether the items occurred within a single context or across context boundaries. Thus, these data suggest that inter-item associative encoding and retrieval mediated by the hippocampus contribute to temporal order memory.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Reinforcement Learning to Rank with Markov Decision Process\n",
            "Authors: Zheng Wei, Jun Xu, Yanyan Lan, Jiafeng Guo, Xueqi Cheng\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: One of the central issues in learning to rank for information retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures such as normalized discounted cumulative gain~(ND CG). Existing methods usually focus on optimizing a specific evaluation measure calculated at a fixed position, e.g., NDCG calculated at a fixed position K. In information retrieval the evaluation measures, including the widely used NDCG and P@K, are usually designed to evaluate the document ranking at all of the ranking positions, which provide much richer information than only measuring the document ranking at a single position. Thus, it is interesting to ask if we can devise an algorithm that has the ability of leveraging the measures calculated at all of the ranking postilions, for learning a better ranking model. In this paper, we propose a novel learning to rank model on the basis of Markov decision process (MDP), referred to as MDPRank. In the learning phase of MDPRank, the construction of a document ranking is considered as a sequential decision making, each corresponds to an action of selecting a document for the corresponding position. The policy gradient algorithm of REINFORCE is adopted to train the model parameters. The evaluation measures calculated at every ranking positions are utilized as the immediate rewards to the corresponding actions, which guide the learning algorithm to adjust the model parameters so that the measure is optimized. Experimental results on LETOR benchmark datasets showed that MDPRank can outperform the state-of-the-art baselines.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of the TREC 2014 Clinical Decision Support Track\n",
            "Authors: Kirk Roberts, Dina Demner-Fushman, E. Voorhees, W. Hersh\n",
            "Year: 2014\n",
            "Venue: Text Retrieval Conference\n",
            "Abstract: Abstract : In making clinical decisions, physicians often seek out information about how to best care for their patients. Information relevant to a physician can be related to a variety of clinical tasks such as determining a patient s most likely diagnosis given a list of symptoms, deciding on the most effective treatment plan for a patient having a known condition, and determining if a particular test is indicated for a given situation. In some cases, physicians can find the information they seek in published biomedical literature. However, given the volume of the existing literature and the rapid pace at which new research is published, locating the most relevant and timely information for a particular clinical need can be a daunting and time-consuming task. To make biomedical information more accessible and to meet the requirements for the meaningful use of electronic health records, a goal of modern clinical decision support systems is to anticipate the needs of physicians by linking electronic health records with information relevant for patient care. The Clinical Decision Support Track aims to simulate the requirements of such systems and to encourage the creation of tools and resources necessary for their implementation. The focus of the 2014 track was the retrieval of biomedical articles relevant for answering generic clinical questions about medical records. In the absence of a reusable, de-identified collection of medical records, we used short case reports, such as those published in biomedical articles, as idealized representations of actual medical records. A case report typically describes a challenging medical case, and it is often organized as a well-formed narrative summarizing the portions of a patient s medical record that are pertinent to the case. Participants of the track were challenged with retrieving, for a given case report, full-text biomedical articles relevant for answering questions related to several types of clinical information needs.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Recovering and preventing loss of detailed memory: differential rates of forgetting for detail types in episodic memory\n",
            "Authors: M. Sekeres, K. Bonasia, Marie St-Laurent, S. Pishdadian, G. Winocur, C. Grady, M. Moscovitch\n",
            "Year: 2016\n",
            "Venue: Learning & memory (Cold Spring Harbor, N.Y.)\n",
            "Abstract: Episodic memories undergo qualitative changes with time, but little is known about how different aspects of memory are affected. Different types of information in a memory, such as perceptual detail, and central themes, may be lost at different rates. In patients with medial temporal lobe damage, memory for perceptual details is severely impaired, while memory for central details is relatively spared. Given the sensitivity of memory to loss of details, the present study sought to investigate factors that mediate the forgetting of different types of information from naturalistic episodic memories in young healthy adults. The study investigated (1) time-dependent loss of “central” and “peripheral” details from episodic memories, (2) the effectiveness of cuing with reminders to reinstate memory details, and (3) the role of retrieval in preventing forgetting. Over the course of 7 d, memory for naturalistic events (film clips) underwent a time-dependent loss of peripheral details, while memory for central details (the core or gist of events) showed significantly less loss. Giving brief reminders of the clips just before retrieval reinstated memory for peripheral details, suggesting that loss of details is not always permanent, and may reflect both a storage and retrieval deficit. Furthermore, retrieving a memory shortly after it was encoded prevented loss of both central and peripheral details, thereby promoting retention over time. We consider the implications of these results for behavioral and neurobiological models of retention and forgetting.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Extracting domain models from natural-language requirements: approach and industrial evaluation\n",
            "Authors: Chetan Arora, M. Sabetzadeh, L. Briand, Frank Zimmer\n",
            "Year: 2016\n",
            "Venue: ACM/IEEE International Conference on Model Driven Engineering Languages and Systems\n",
            "Abstract: Domain modeling is an important step in the transition from natural-language requirements to precise specifications. For large systems, building a domain model manually is a laborious task. Several approaches exist to assist engineers with this task, whereby candidate domain model elements are automatically extracted using Natural Language Processing (NLP). Despite the existing work on domain model extraction, important facets remain under-explored: (1) there is limited empirical evidence about the usefulness of existing extraction rules (heuristics) when applied in industrial settings; (2) existing extraction rules do not adequately exploit the natural-language dependencies detected by modern NLP technologies; and (3) an important class of rules developed by the information retrieval community for information extraction remains unutilized for building domain models. Motivated by addressing the above limitations, we develop a domain model extractor by bringing together existing extraction rules in the software engineering literature, extending these rules with complementary rules from the information retrieval literature, and proposing new rules to better exploit results obtained from modern NLP dependency parsers. We apply our model extractor to four industrial requirements documents, reporting on the frequency of different extraction rules being applied. We conduct an expert study over one of these documents, investigating the accuracy and overall effectiveness of our domain model extractor.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Word-Entity Duet Representations for Document Ranking\n",
            "Authors: Chenyan Xiong, Jamie Callan, Tie-Yan Liu\n",
            "Year: 2017\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This paper presents a word-entity duet framework for utilizing knowledge bases in ad-hoc retrieval. In this work, the query and documents are modeled by word-based representations and entity-based representations. Ranking features are generated by the interactions between the two representations, incorporating information from the word space, the entity space, and the cross-space connections through the knowledge graph. To handle the uncertainties from the automatically constructed entity representations, an attention-based ranking model AttR-Duet is developed. With back-propagation from ranking labels, the model learns simultaneously how to demote noisy entities and how to rank documents with the word-entity duet. Evaluation results on TREC Web Track ad-hoc task demonstrate that all of the four-way interactions in the duet are useful, the attention mechanism successfully steers the model away from noisy entities, and together they significantly outperform both word-based and entity-based learning to rank systems.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Relationship between the Average Precision and the Area Under the ROC Curve\n",
            "Authors: Wanhua Su, Yan Yuan, Mu Zhu\n",
            "Year: 2015\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: For similar evaluation tasks, the area under the receiver operating characteristic curve (AUC) is often used by researchers in machine learning, whereas the average precision (AP) is used more often by the information retrieval community. We establish some results to explain why this is the case. Specifically, we show that, when both the AUC and the AP are rescaled to lie in [0,1], the AP is approximately the AUC times the initial precision of the system.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TREC 2016 Total Recall Track Overview\n",
            "Authors: Maura R. Grossman, G. Cormack, Adam Roegiest\n",
            "Year: 2016\n",
            "Venue: Text Retrieval Conference\n",
            "Abstract: The primary purpose of the Total Recall Track is to evaluate, through controlled simulation, methods designed to achieve very high recall – as close as practicable to 100% – with a human assessor in the loop. Motivating applications include, among others, electronic discovery in legal proceedings [3], systematic review in evidencebased medicine [6], and the creation of fully labeled test collections for information retrieval (“IR”) evaluation [5]. A secondary, but no less important, purpose is to develop a sandboxed virtual test environment within which IR systems may be tested, while preventing the disclosure of sensitive test data to participants. At the same time, the test environment also operates as a “black box,” affording participants confidence that their proprietary systems cannot easily be reverse engineered. The task to be solved in the Total Recall Track is the following:\n",
            "\n",
            "---\n",
            "\n",
            "Title: When does Relevance Mean Usefulness and User Satisfaction in Web Search?\n",
            "Authors: Jiaxin Mao, Yiqun Liu, K. Zhou, Jian-Yun Nie, Jingtao Song, Min Zhang, Shaoping Ma, Jiashen Sun, Hengliang Luo\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Relevance is a fundamental concept in information retrieval (IR) studies. It is however often observed that relevance as annotated by secondary assessors may not necessarily mean usefulness and satisfaction perceived by users. In this study, we confirm the difference by a laboratory study in which we collect relevance annotations by external assessors, usefulness and user satisfaction information by users, for a set of search tasks. We also find that a measure based on usefulness rather than relevance annotated has a better correlation with user satisfaction. However, we show that external assessors are capable of annotating usefulness when provided with more search context information. In addition, we also show that it is possible to generate automatically usefulness labels when some training data is available. Our findings explain why traditional system-centric evaluation metrics are not well aligned with user satisfaction and suggest that a usefulness-based evaluation method can be defined to better reflect the quality of search systems perceived by the users.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Reinstatement of Associative Memories in Early Visual Cortex Is Signaled by the Hippocampus\n",
            "Authors: Sander Erik Bosch, J. Jehee, G. Fernández, Christian F. Doeller\n",
            "Year: 2014\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: The cortical reinstatement hypothesis of memory retrieval posits that content-specific cortical activity at encoding is reinstated at retrieval. Evidence for cortical reinstatement was found in higher-order sensory regions, reflecting reactivation of complex object-based information. However, it remains unclear whether the same detailed sensory, feature-based information perceived during encoding is subsequently reinstated in early sensory cortex and what the role of the hippocampus is in this process. In this study, we used a combination of visual psychophysics, functional neuroimaging, multivoxel pattern analysis, and a well controlled cued recall paradigm to address this issue. We found that the visual information human participants were retrieving could be predicted by the activation patterns in early visual cortex. Importantly, this reinstatement resembled the neural pattern elicited when participants viewed the visual stimuli passively, indicating shared representations between stimulus-driven activity and memory. Furthermore, hippocampal activity covaried with the strength of stimulus-specific cortical reinstatement on a trial-by-trial level during cued recall. These findings provide evidence for reinstatement of unique associative memories in early visual cortex and suggest that the hippocampus modulates the mnemonic strength of this reinstatement.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-track Infrared Sounder (CrIS) satellite observations of tropospheric ammonia\n",
            "Authors: M. Shephard, K. Cady-Pereira\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: Abstract. Observations of atmospheric ammonia are important in understanding and modelling the impact of ammonia on both human health and the natural environment. We present a detailed description of a robust retrieval algorithm that demonstrates the capabilities of utilizing Cross-track Infrared Sounder (CrIS) satellite observations to globally retrieval ammonia concentrations. Initial ammonia retrieval results using both simulated and real observations show that (i) CrIS is sensitive to ammonia in the boundary layer with peak vertical sensitivity typically around ~ 850–750 hPa (~ 1.5 to 2.5 km), which can dip down close to the surface (~ 900 hPa) under ideal conditions, (ii) it has a minimum detection limit of ~ 1 ppbv (peak profile value typically at the surface), and (iii) the information content can vary significantly with maximum values of ~ 1 degree-of-freedom for signal. Comparisons of the retrieval with simulated \"true\" profiles show a small positive retrieval bias of 6% with a standard deviation of ~ ± 20% (ranging from ± 12 to ± 30% over the vertical profile). Note that these uncertainty estimates are considered as lower bound values as no potential systematic errors are included in the simulations. The CrIS NH3 retrieval applied over the Central Valley in CA, USA, demonstrates that CrIS correlates well with the spatial variability of the boundary layer ammonia concentrations seen by the nearby Quantum Cascade-Laser (QCL) in situ surface and the Tropospheric Emission Spectrometer (TES) satellite observations as part of the DISCOVER-AQ campaign. The CrIS and TES ammonia observations show quantitatively similar retrieved boundary layer values that are often within the uncertainty of the two observations. Also demonstrated is CrIS's ability to capture the expected spatial distribution in the ammonia concentrations, from elevated values in the Central Valley from anthropogenic agriculture emissions, to much lower values in the unpolluted or clean surrounding mountainous regions. These initial results demonstrate the capabilities of the CrIS satellite to measure ammonia.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Pytrec_eval: An Extremely Fast Python Interface to trec_eval\n",
            "Authors: Christophe Van Gysel, M. de Rijke\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: We introduce pytrec_eval, a Python interface to the trec_eval information retrieval evaluation toolkit. pytrec_eval exposes the reference implementations of trec_eval within Python as a native extension. We show that pytrec_eval is around one order of magnitude faster than invoking trec_eval as a sub process from within Python. Compared to a native Python implementation of NDCG, pytrec_eval is twice as fast for practically-sized rankings. Finally, we demonstrate its effectiveness in an application where pytrec_eval is combined with Pyndri and the OpenAI Gym where query expansion is learned using Q-learning.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Linked Document Embedding for Classification\n",
            "Authors: Suhang Wang, Jiliang Tang, C. Aggarwal, Huan Liu\n",
            "Year: 2016\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Word and document embedding algorithms such as Skip-gram and Paragraph Vector have been proven to help various text analysis tasks such as document classification, document clustering and information retrieval. The vast majority of these algorithms are designed to work with independent and identically distributed documents. However, in many real-world applications, documents are inherently linked. For example, web documents such as blogs and online news often have hyperlinks to other web documents, and scientific articles usually cite other articles. Linked documents present new challenges to traditional document embedding algorithms. In addition, most existing document embedding algorithms are unsupervised and their learned representations may not be optimal for classification when labeling information is available. In this paper, we study the problem of linked document embedding for classification and propose a linked document embedding framework LDE, which combines link and label information with content information to learn document representations for classification. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the importance of link and label information in the proposed framework LDE.\n",
            "\n",
            "---\n",
            "\n",
            "Title: 20 Years of Automatic Chord Recognition from Audio\n",
            "Authors: J. Pauwels, K. O'Hanlon, E. Gómez, M. Sandler\n",
            "Year: 2019\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada a: 20th annual conference of the International Society for Music Information Retrieval (ISMIR) celebrat del 4 al 8 de novembre de 2019 a Delft, Paisos Baixos.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey on expert finding techniques\n",
            "Authors: Shuyi Lin, Wenxing Hong, Dingding Wang, Tao Li\n",
            "Year: 2017\n",
            "Venue: Journal of Intelligence and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Graph based Representation and Analysis of Text Document: A Survey of Techniques\n",
            "Authors: S. Sonawane, P. Kulkarni, H. Balinsky, A. Balinsky, Wei Jin, R. Srihari, Faguo Zhou, Fan Zhang, Francois Rousseau, Michalis Vazigiannis\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: A common and standard approach to model text document is bag-of-words. This model is suitable for capturing word frequency, however structural and semantic information is ignored. Graph representation is mathematical constructs and can model relationship and structural information effectively. A text can appropriately represented as Graph using vertex as feature term and edge relation can be significant relation between the feature terms. Text representation using Graph model provides computations related to various operations like term weight, ranking which is helpful in many applications in information retrieval. This paper presents a systematic survey of existing work on Graph based representation of text and also focused on Graph based analysis of text document for different operations in information retrieval. In this process taxonomy of Graph based representation and analysis of text document is derived and result of different methods of Graph based text representation and analysis are discussed. The survey results shows that Graph based representation is appropriate way of representing text document and improved result of analysis over traditional model for different text applications.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Semantic Multimodal Hashing Network for Scalable Image-Text and Video-Text Retrievals\n",
            "Authors: Lu Jin, Zechao Li, Jinhui Tang\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Neural Networks and Learning Systems\n",
            "Abstract: Hashing has been widely applied to multimodal retrieval on large-scale multimedia data due to its efficiency in computation and storage. In this article, we propose a novel deep semantic multimodal hashing network (DSMHN) for scalable image-text and video-text retrieval. The proposed deep hashing framework leverages 2-D convolutional neural networks (CNN) as the backbone network to capture the spatial information for image-text retrieval, while the 3-D CNN as the backbone network to capture the spatial and temporal information for video-text retrieval. In the DSMHN, two sets of modality-specific hash functions are jointly learned by explicitly preserving both intermodality similarities and intramodality semantic labels. Specifically, with the assumption that the learned hash codes should be optimal for the classification task, two stream networks are jointly trained to learn the hash functions by embedding the semantic labels on the resultant hash codes. Moreover, a unified deep multimodal hashing framework is proposed to learn compact and high-quality hash codes by exploiting the feature representation learning, intermodality similarity-preserving learning, semantic label-preserving learning, and hash function learning with different types of loss functions simultaneously. The proposed DSMHN method is a generic and scalable deep hashing framework for both image-text and video-text retrievals, which can be flexibly integrated with different types of loss functions. We conduct extensive experiments for both single-modal- and cross-modal-retrieval tasks on four widely used multimodal-retrieval data sets. Experimental results on both image-text- and video-text-retrieval tasks demonstrate that the DSMHN significantly outperforms the state-of-the-art methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modelling interaction with economic models of search\n",
            "Authors: L. Azzopardi\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Understanding how people interact when searching is central to the study of Interactive Information Retrieval (IIR). Most of the prior work has either been conceptual, observational or empirical. While this has led to numerous insights and findings regarding the interaction between users and systems, the theory has lagged behind. In this paper, we extend the recently proposed search economic theory to make the model more realistic. We then derive eight interaction based hypotheses regarding search behaviour. To validate the model, we explore whether the search behaviour of thirty-six participants from a lab based study is consistent with the theory. Our analysis shows that observed search behaviours are in line with predicted search behaviours and that it is possible to provide credible explanations for such behaviours. This work describes a concise and compact representation of search behaviour providing a strong theoretical basis for future IIR research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: NTCIR Lifelog: The First Test Collection for Lifelog Research\n",
            "Authors: C. Gurrin, Hideo Joho, F. Hopfgartner, Liting Zhou, Rami Albatal\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Test collections have a long history of supporting repeatable and comparable evaluation in Information Retrieval (IR). However, thus far, no shared test collection exists for IR systems that are designed to index and retrieve multimodal lifelog data. In this paper we introduce the first test collection for personal lifelog data, which has been employed for the NTCIR12-Lifelog task. In this paper, the requirements for the test collection are motivated, the process of creating the test collection is described, along with an overview of the test collection. Finally suggestions are given for possible applications of the test collection.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Search Result Diversification\n",
            "Authors: Rodrygo L. T. Santos, Craig Macdonald, I. Ounis\n",
            "Year: 2015\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Ranking in information retrieval has been traditionally approachedas a pursuit of relevant information, under the assumption that theusers' information needs are unambiguously conveyed by their submittedqueries. Nevertheless, as an inherently limited representation of amore complex information need, every query can arguably be consideredambiguous to some extent. In order to tackle query ambiguity,search result diversification approaches have recently been proposed toproduce rankings aimed to satisfy the multiple possible informationneeds underlying a query. In this survey, we review the published literatureon search result diversification. In particular, we discuss themotivations for diversifying the search results for an ambiguous queryand provide a formal definition of the search result diversification problem.In addition, we describe the most successful approaches in theliterature for producing and evaluating diversity in multiple search domains.Finally, we also discuss recent advances as well as open researchdirections in the field of search result diversification.\n",
            "\n",
            "---\n",
            "\n",
            "Title: What the F-measure doesn't measure: Features, Flaws, Fallacies and Fixes\n",
            "Authors: D. Powers\n",
            "Year: 2015\n",
            "Venue: arXiv.org\n",
            "Abstract: The F-measure or F-score is one of the most commonly used single number measures in Information Retrieval, Natural Language Processing and Machine Learning, but it is based on a mistake, and the flawed assumptions render it unsuitable for use in most contexts! Fortunately, there are better alternatives.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Supervised Deep Feature Embedding With Handcrafted Feature\n",
            "Authors: Shichao Kan, Yigang Cen, Zhihai He, Zhi Zhang, Linna Zhang, Yanhong Wang\n",
            "Year: 2019\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Image representation methods based on deep convolutional neural networks (CNNs) have achieved the state-of-the-art performance in various computer vision tasks, such as image retrieval and person re-identification. We recognize that more discriminative feature embeddings can be learned with supervised deep metric learning and handcrafted features for image retrieval and similar applications. In this paper, we propose a new supervised deep feature embedding with a handcrafted feature model. To fuse handcrafted feature information into CNNs and realize feature embeddings, a general fusion unit is proposed (called Fusion-Net). We also define a network loss function with image label information to realize supervised deep metric learning. Our extensive experimental results on the Stanford online products’ data set and the in-shop clothes retrieval data set demonstrate that our proposed methods outperform the existing state-of-the-art methods of image retrieval by a large margin. Moreover, we also explore the applications of the proposed methods in person re-identification and vehicle re-identification; the experimental results demonstrate both the effectiveness and efficiency of the proposed methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Real-time coherent diffraction inversion using deep generative networks\n",
            "Authors: M. Cherukara, Y. Nashed, R. Harder\n",
            "Year: 2018\n",
            "Venue: Scientific Reports\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Performance Prediction for Non-Factoid Question Answering\n",
            "Authors: Helia Hashemi, Hamed Zamani, W. Bruce Croft\n",
            "Year: 2019\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Estimating the quality of a result list, often referred to as query performance prediction (QPP), is a challenging and important task in information retrieval. It can be used as feedback to users, search engines, and system administrators. Although predicting the performance of retrieval models has been extensively studied for the ad-hoc retrieval task, the effectiveness of performance prediction methods for question answering (QA) systems is relatively unstudied. The short length of answers, the dominance of neural models in QA, and the re-ranking nature of most QA systems make performance prediction for QA a unique, important, and technically interesting task. In this paper, we introduce and motivate the task of performance prediction for non-factoid question answering and propose a neural performance predictor for this task. Our experiments on two recent datasets demonstrate that the proposed model outperforms competitive baselines in all settings.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Solving sparse non-negative tensor equations: algorithms and applications\n",
            "Authors: Xutao Li, M. Ng\n",
            "Year: 2014\n",
            "Venue: Frontiers of Mathematics in China\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Functional and Neuroanatomic Specificity of Episodic Memory Dysfunction in Schizophrenia: A Functional Magnetic Resonance Imaging Study of the Relational and Item-Specific Encoding Task.\n",
            "Authors: J. Ragland, C. Ranganath, M. Harms, D. M. Barch, James M Gold, E. Layher, Ba, T. Lesh, A. MacDonald III, T. Niendam, Joshua L. Phillips, S. Silverstein, A. Yonelinas, Cameron S. Carter, Davis\n",
            "Year: 2015\n",
            "Venue: JAMA psychiatry\n",
            "Abstract: IMPORTANCE\n",
            "Individuals with schizophrenia can encode item-specific information to support familiarity-based recognition but are disproportionately impaired encoding interitem relationships (relational encoding) and recollecting information. The Relational and Item-Specific Encoding (RiSE) paradigm has been used to disentangle these encoding and retrieval processes, which may depend on specific medial temporal lobe (MTL) and prefrontal cortex (PFC) subregions. Functional magnetic resonance (fMRI) imaging during RiSE task performance could help to specify dysfunctional neural circuits in schizophrenia that can be targeted for interventions to improve memory and functioning in the illness.\n",
            "\n",
            "\n",
            "OBJECTIVES\n",
            "To use fMRI to test the hypothesis that schizophrenia disproportionately affects MTL and PFC subregions during relational encoding and retrieval relative to item-specific memory processes, and to use fMRI results from healthy individuals serving as controls to establish neural construct validity for RiSE.\n",
            "\n",
            "\n",
            "DESIGN, SETTING, AND PARTICIPANTS\n",
            "This multisite, case-control, cross-sectional fMRI study was conducted between November 1, 2010, and May 30, 2012, at 5 Cognitive Neuroscience Test Reliability and Clinical Applications for Schizophrenia sites. The final sample included 52 outpatients with clinically stable schizophrenia and 57 demographically matched healthy control participants. Data analysis was performed between February 1, 2013, and May 30, 2014.\n",
            "\n",
            "\n",
            "MAIN OUTCOMES AND MEASURES\n",
            "Behavioral performance speed and accuracy (d') on item recognition and associative recognition tasks. Voxelwise statistical parametric maps for a priori MTL and PFC regions of interest to test activation differences between relational and item-specific memory during encoding and retrieval.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Item recognition was disproportionately impaired in patients with schizophrenia relative to healthy control participants following relational encoding (F1,107 = 4.7; P = .03). The differential deficit was accompanied by reduced dorsolateral PFC activation during relational encoding in patients with schizophrenia compared with healthy control participants (z > 2.3; P < .05 corrected). Retrieval success (hits > misses) was associated with hippocampal activation in healthy control participants during relational item recognition and associative recognition conditions, and hippocampal activation was specifically reduced in schizophrenia for recognition of relational but not item-specific information (z > 2.3; P < .05 corrected).\n",
            "\n",
            "\n",
            "CONCLUSIONS AND RELEVANCE\n",
            "In this unique, multisite fMRI study, results in the healthy control group supported RiSE construct validity by revealing expected memory effects in PFC and MTL subregions during encoding and retrieval. Comparison of schizophrenic and healthy control participants revealed disproportionate memory deficits in schizophrenia for relational vs item-specific information, accompanied by regionally and functionally specific deficits in dorsolateral PFC and hippocampal activation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to Rewrite Queries\n",
            "Authors: Yunlong He, Jiliang Tang, Ouyang Hua, Changsung Kang, Dawei Yin, Yi Chang\n",
            "Year: 2016\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: It is widely known that there exists a semantic gap between web documents and user queries and bridging this gap is crucial to advance information retrieval systems. The task of query rewriting, aiming to alter a given query to a rewrite query that can close the gap and improve information retrieval performance, has attracted increasing attention in recent years. However, the majority of existing query rewriters are not designed to boost search performance and consequently their rewrite queries could be sub-optimal. In this paper, we propose a learning to rewrite framework that consists of a candidate generating phase and a candidate ranking phase. The candidate generating phase provides us the flexibility to reuse most of existing query rewriters; while the candidate ranking phase allows us to explicitly optimize search relevance. Experimental results on a commercial search engine demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the important components of the proposed framework.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Axiomatic Approach to Diagnosing Neural IR Models\n",
            "Authors: D. Rennings, Felipe Moraes, C. Hauff\n",
            "Year: 2019\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Internet of Things for Healthcare\n",
            "Authors: M. Brian Blake\n",
            "Year: 2015\n",
            "Venue: IEEE Internet Computing\n",
            "Abstract: Mobile health technologies and the Internet of Things (IoT) could provide automatic approaches to diagnosing health concerns, taking a step beyond information retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Interactive Intent Modeling for Exploratory Search\n",
            "Authors: Tuukka Ruotsalo, J. Peltonen, M. Eugster, D. Głowacka, P. Floréen, P. Myllymäki, Giulio Jacucci, Samuel Kaski\n",
            "Year: 2018\n",
            "Venue: ACM Trans. Inf. Syst.\n",
            "Abstract: Exploratory search requires the system to assist the user in comprehending the information space and expressing evolving search intents for iterative exploration and retrieval of information. We introduce interactive intent modeling, a technique that models a user’s evolving search intents and visualizes them as keywords for interaction. The user can provide feedback on the keywords, from which the system learns and visualizes an improved intent estimate and retrieves information. We report experiments comparing variants of a system implementing interactive intent modeling to a control system. Data comprising search logs, interaction logs, essay answers, and questionnaires indicate significant improvements in task performance, information retrieval performance over the session, information comprehension performance, and user experience. The improvements in retrieval effectiveness can be attributed to the intent modeling and the effect on users’ task performance, breadth of information comprehension, and user experience are shown to be dependent on a richer visualization. Our results demonstrate the utility of combining interactive modeling of search intentions with interactive visualization of the models that can benefit both directing the exploratory search process and making sense of the information space. Our findings can help design personalized systems that support exploratory information seeking and discovery of novel information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Class-Weighted Convolutional Features for Visual Instance Search\n",
            "Authors: Albert Jiménez, J. Álvarez, Xavier Giró-i-Nieto\n",
            "Year: 2017\n",
            "Venue: British Machine Vision Conference\n",
            "Abstract: Image retrieval in realistic scenarios targets large dynamic datasets of unlabeled images. In these cases, training or fine-tuning a model every time new images are added to the database is neither efficient nor scalable. Convolutional neural networks trained for image classification over large datasets have been proven effective feature extractors for image retrieval. The most successful approaches are based on encoding the activations of convolutional layers, as they convey the image spatial information. In this paper, we go beyond this spatial information and propose a local-aware encoding of convolutional features based on semantic information predicted in the target image. To this end, we obtain the most discriminative regions of an image using Class Activation Maps (CAMs). CAMs are based on the knowledge contained in the network and therefore, our approach, has the additional advantage of not requiring external information. In addition, we use CAMs to generate object proposals during an unsupervised re-ranking stage after a first fast search. Our experiments on two public available datasets for instance retrieval, Oxford5k and Paris6k, demonstrate the competitiveness of our approach outperforming the current state-of-the-art when using off-the-shelf models trained on ImageNet. The source code and model used in this paper are publicly available at this http URL.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Stop-Word Removal Algorithm and its Implementation for Sanskrit Language\n",
            "Authors: Jaideepsinh K. Raulji, Jatinderkumar R. Saini\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: In the Information era, optimization of processes for Information Retrieval, Text Summarization, Text and Data Analytic systems becomes utmost important. Therefore in order to achieve accuracy, extraction of redundant words with low or no semantic meaning must be filtered out. Such words are known as stopwords. Stopwords list has been developed for languages like English, Chinese, Arabic, Hindi, etc. Stopword list is also available for Sanskrit language. Stop-word removal is an important preprocessing techniques used in Natural Language processing applications so as to improve the performance of the Information Retrieval System, Text Analytics & Processing System, Text Summarization, Question-Answering system, stemming etc. In this paper, a simple approach is used to design stop-word removal algorithm and its implementation for Sanskrit language. The algorithm and its implementation uses dictionary based approach. In dictionary based approach predefined list of stopwords is compared to the target text on which removal is required.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Why two heads apart are better than two heads together: multiple mechanisms underlie the collaborative inhibition effect in memory.\n",
            "Authors: S. Barber, Celia B. Harris, S. Rajaram\n",
            "Year: 2015\n",
            "Venue: Journal of Experimental Psychology. Learning, Memory and Cognition\n",
            "Abstract: Although a group of people working together remembers more than any one individual, they recall less than their predicted potential. This finding is known as collaborative inhibition and is generally thought to arise due to retrieval disruption. However, there is growing evidence that is inconsistent with the retrieval disruption account, suggesting that additional mechanisms also contribute to collaborative inhibition. In the current studies, we examined 2 alternate mechanisms: retrieval inhibition and retrieval blocking. To identify the contributions of retrieval disruption, retrieval inhibition, and retrieval blocking, we tested how collaborative recall of entirely unshared information influences subsequent individual recall and individual recognition memory. If collaborative inhibition is due solely to retrieval disruption, then there should be a release from the negative effects of collaboration on subsequent individual recall and recognition tests. If it is due to retrieval inhibition, then the negative effects of collaboration should persist on both individual recall and recognition memory tests. Finally, if it is due to retrieval blocking, then the impairment should persist on subsequent individual free recall, but not recognition, tests. Novel to the current study, results suggest that retrieval inhibition plays a role in the collaborative inhibition effect. The negative effects of collaboration persisted on a subsequent, always-individual, free-recall test (Experiment 1) and also on a subsequent, always-individual, recognition test (Experiment 2). However, consistent with the retrieval disruption account, this deficit was attenuated (Experiment 1). Together, these results suggest that, in addition to retrieval disruption, multiple mechanisms play a role in collaborative inhibition. (PsycINFO Database Record (c) 2015 APA, all rights reserved).\n",
            "\n",
            "---\n",
            "\n",
            "Title: CQADupStack: A Benchmark Data Set for Community Question-Answering Research\n",
            "Authors: Doris Hoogeveen, Karin M. Verspoor, Timothy Baldwin\n",
            "Year: 2015\n",
            "Venue: Australasian Document Computing Symposium\n",
            "Abstract: This paper presents a benchmark dataset, CQADupStack, for use in community question-answering (cQA) research. It contains threads from twelve StackExchange subforums, annotated with duplicate question information. We provide pre-defined training and test splits, both for retrieval and classification experiments, to ensure maximum comparability between different studies using the set. Furthermore, it comes with a script to manipulate the data in various ways. We give an analysis of the data in the set, and report benchmark results on a duplicate question retrieval task using well established retrieval models.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Methods and Challenges in Shot Boundary Detection: A Review\n",
            "Authors: S. Abdulhussain, A. Ramli, M. Saripan, Basheera M. Mahmmod, S. Al-Haddad, Wissam A. Jassim\n",
            "Year: 2018\n",
            "Venue: Entropy\n",
            "Abstract: The recent increase in the number of videos available in cyberspace is due to the availability of multimedia devices, highly developed communication technologies, and low-cost storage devices. These videos are simply stored in databases through text annotation. Content-based video browsing and retrieval are inefficient due to the method used to store videos in databases. Video databases are large in size and contain voluminous information, and these characteristics emphasize the need for automated video structure analyses. Shot boundary detection (SBD) is considered a substantial process of video browsing and retrieval. SBD aims to detect transition and their boundaries between consecutive shots; hence, shots with rich information are used in the content-based video indexing and retrieval. This paper presents a review of an extensive set for SBD approaches and their development. The advantages and disadvantages of each approach are comprehensively explored. The developed algorithms are discussed, and challenges and recommendations are presented.\n",
            "\n",
            "---\n",
            "\n",
            "Title: TREC 2018 News Track Overview\n",
            "Authors: I. Soboroff, Shudong Huang, D. Harman\n",
            "Year: 2018\n",
            "Venue: Text Retrieval Conference\n",
            "Abstract: The News track is a new track for TREC 2019, focused on information retrieval in the service of helping people read the news. In cooperation with the Washington Post 1 , we released a new collection of 600,000 news articles, and crafted two tasks related to how news is presented on the web.\n",
            "\n",
            "---\n",
            "\n",
            "Title: NTCIR-11 Math-2 Task Overview\n",
            "Authors: Akiko Aizawa, M. Kohlhase, I. Ounis, M. Schubotz\n",
            "Year: 2014\n",
            "Venue: NTCIR Conference on Evaluation of Information Access Technologies\n",
            "Abstract: This paper presents an overview of the NTCIR-11 Math-2 Task, which is speci cally dedicated to information access to mathematical content. In particular, the paper summarizes the task design, analysis of the submitted runs, and the main approaches deployed by the participating groups. It also contains an introduction to the optional free Wikipedia subtask, a newly introduced mathematical retrieval task using Wikipedia articles.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Overview of the TREC 2014 Session Track\n",
            "Authors: Ben Carterette, E. Kanoulas, M. Hall, Paul D. Clough\n",
            "Year: 2014\n",
            "Venue: Text Retrieval Conference\n",
            "Abstract: Abstract : The TREC Session track ran for the fourth time in 2014. The track has the primary goal of providing test collections and evaluation measures for studying information retrieval over user sessions rather than one-time queries. These test collections are meant to be portable, reusable, statistically powerful, and open to anyone that wishes to work on the problem of retrieval over sessions. The experimental design of the track was similar to that of the previous three years [5, 6, 1]: sessions were real user sessions with a search engine that include queries, retrieved results, clicks, and dwell times; retrieval tasks were designed to study the effect of using session data in retrieval for only the mth query in a session. For the 2014 track, sessions were obtained from workers on Amazon's Mechanical Turk. As a result, the 2014 data includes far more sessions than previous years1,257 unique sessions as compared to around 100 for each of the previous three years. Apart from that, there is little different from the 2013 track [1]. This overview is organized as follows: in Section 2 we describe the tasks participants were to perform. In Section 3 we describe the corpus, topics, and sessions that comprise the test collection. Section 4 gives some information about submitted runs. In Section 5 we describe relevance judging and evaluation measures, and Sections 6 present evaluation results and analysis.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Web2Text: Deep Structured Boilerplate Removal\n",
            "Authors: Thijs Vogels, O. Ganea, Carsten Eickhoff\n",
            "Year: 2018\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Initial Investigation of the Effects of an Experimentally Learned Schema on Spatial Associative Memory in Humans\n",
            "Authors: Mariët van Buuren, Marijn C. W. Kroes, Isabella C. Wagner, L. Genzel, R. Morris, G. Fernández\n",
            "Year: 2014\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Networks of interconnected neocortical representations of prior knowledge, “schemas,” facilitate memory for congruent information. This facilitation is thought to be mediated by augmented encoding and accelerated consolidation. However, it is less clear how schema affects retrieval. Rodent and human studies to date suggest that schema-related memories are differently retrieved. However, these studies differ substantially as most human studies implement pre-experimental world-knowledge as schemas and tested item or nonspatial associative memory, whereas animal studies have used intraexperimental schemas based on item-location associations within a complex spatial layout that, in humans, could engage more strategic retrieval processes. Here, we developed a paradigm conceptually linked to rodent studies to examine the effects of an experimentally learned spatial associative schema on learning and retrieval of new object-location associations and to investigate the neural mechanisms underlying schema-related retrieval. Extending previous findings, we show that retrieval of schema-defining associations is related to activity along anterior and posterior midline structures and angular gyrus. The existence of such spatial associative schema resulted in more accurate learning and retrieval of new, related associations, and increased time allocated to retrieve these associations. This retrieval was associated with right dorsolateral prefrontal and lateral parietal activity, as well as interactions between the right dorsolateral prefrontal cortex and medial and lateral parietal regions, and between the medial prefrontal cortex and posterior midline regions, supporting the hypothesis that retrieval of new, schema-related object-location associations in humans also involves augmented monitoring and systematic search processes.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Meta-Path-Based Ranking with Pseudo Relevance Feedback on Heterogeneous Graph for Citation Recommendation\n",
            "Authors: Xiaozhong Liu, Yingying Yu, Chun Guo, Yizhou Sun\n",
            "Year: 2014\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: The sheer volume of scholarly publications available online significantly challenges how scholars retrieve the new information available and locate the candidate reference papers. While classical text retrieval and pseudo relevance feedback (PRF) algorithms can assist scholars in accessing needed publications, in this study, we propose an innovative publication ranking method with PRF by leveraging a number of meta-paths on the heterogeneous bibliographic graph. Different meta-paths on the graph address different ranking hypotheses, whereas the pseudo-relevant papers (from the retrieval results) are used as the seed nodes on the graph. Meanwhile, unlike prior studies, we propose \"restricted meta-path\" facilitated by a new context-rich heterogeneous network extracted from full-text publication content along with citation context. By using learning-to-rank, we integrate 18 different meta-path-based ranking features to derive the final ranking scores for candidate cited papers. Experimental results with ACM full-text corpus show that meta-path-based ranking with PRF on the new graph significantly (p < 0.0001) outperforms text retrieval algorithms with text-based or PageRank-based PRF.\n",
            "\n",
            "---\n",
            "\n",
            "Title: SiMPle: Assessing Music Similarity Using Subsequences Joins\n",
            "Authors: Diego Furtado Silva, Chin-Chia Michael Yeh, Gustavo E. A. P. A. Batista, Eamonn J. Keogh\n",
            "Year: 2016\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Most algorithms for music information retrieval are based on the analysis of the similarity between feature sets extracted from the raw audio. A common approach to assessing similarities within or between recordings is by creating similarity matrices. However, this approach requires quadratic space for each comparison and typically requires a costly post-processing of the matrix. In this work, we propose a simple and efficient representation based on a subsequence similarity join, which may be used in several music information retrieval tasks. We apply our method to the cover song recognition problem and demonstrate that it is superior to state-of-the-art algorithms. In addition, we demonstrate how the proposed representation can be exploited for multiple applications in music processing.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Legal Question Answering using Ranking SVM and Deep Convolutional Neural Network\n",
            "Authors: Phong Do, Huy-Tien Nguyen, Chien-Xuan Tran, Minh-Tien Nguyen, M. Nguyen\n",
            "Year: 2017\n",
            "Venue: arXiv.org\n",
            "Abstract: This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Context-Aware Embeddings for Automatic Art Analysis\n",
            "Authors: Noa García, B. Renoust, Yuta Nakashima\n",
            "Year: 2019\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Automatic art analysis aims to classify and retrieve artistic representations from a collection of images by using computer vision and machine learning techniques. In this work, we propose to enhance visual representations from neural networks with contextual artistic information. Whereas visual representations are able to capture information about the content and the style of an artwork, our proposed context-aware embeddings additionally encode relationships between different artistic attributes, such as author, school, or historical period. We design two different approaches for using context in automatic art analysis. In the first one, contextual data is obtained through a multi-task learning model, in which several attributes are trained together to find visual relationships between elements. In the second approach, context is obtained through an art-specific knowledge graph, which encodes relationships between artistic attributes. An exhaustive evaluation of both of our models in several art analysis problems, such as author identification, type classification, or cross-modal retrieval, show that performance is improved by up to 7.3% in art classification and 37.24% in retrieval when context-aware embeddings are used.\n",
            "\n",
            "---\n",
            "\n",
            "Title: An Evaluation of Audio Feature Extraction Toolboxes\n",
            "Authors: D. Moffat, D. Ronan, J. Reiss\n",
            "Year: 2015\n",
            "Venue: \n",
            "Abstract: Audio feature extraction underpins a massive proportion of audio processing, music information retrieval, audio effect design and audio synthesis. Design, analysis, synthesis and evaluation often rely on audio features, but there are a large and diverse range of feature extraction tools presented to the community. An evaluation of existing audio feature extraction libraries was undertaken. Ten libraries and toolboxes were evaluated with the Cranﬁeld Model for evaluation of information retrieval systems, reviewing the coverage, effort, presentation and time lag of a system. Comparisons are undertaken of these tools and example use cases are presented as to when toolboxes are most suitable. This paper allows a software engineer or researcher to quickly and easily select a suitable audio feature extraction toolbox.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning Query and Document Relevance from a Web-scale Click Graph\n",
            "Authors: Shan Jiang, Yuening Hu, Changsung Kang, Tim Daly, Dawei Yin, Yi Chang, ChengXiang Zhai\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Click-through logs over query-document pairs provide rich and valuable information for multiple tasks in information retrieval. This paper proposes a vector propagation algorithm on the click graph to learn vector representations for both queries and documents in the same semantic space. The proposed approach incorporates both click and content information, and the produced vector representations can directly improve ranking performance for queries and documents that have been observed in the click log. For new queries and documents that are not in the click log, we propose a two-step framework to generate the vector representation, which significantly improves the coverage of our vectors while maintaining the high quality. Experiments on Web-scale search logs from a major commercial search engine demonstrate the effectiveness and scalability of the proposed method. Evaluation results show that NDCG scores are significantly improved against multiple baselines by using the proposed method both as a ranking model and as a feature in a learning-to-rank framework.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Time-Delayed Melody Surfaces for Rāga Recognition\n",
            "Authors: Sankalp Gulati, J. Serrà, K. Ganguli, Sertan Sentürk, Xavier Serra\n",
            "Year: 2016\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada a la 17th International Society for Music Information Retrieval Conference (ISMIR 2016), celebrada els dies 7 a 11 d'agost de 2016 a Nova York, EUA.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Neural Networks for Query Expansion using Word Embeddings\n",
            "Authors: Ayyoob Imani, Amir Vakili, Ali Montazer, A. Shakery\n",
            "Year: 2018\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Test Collection for Evaluating Legal Case Law Search\n",
            "Authors: Daniel Locke, G. Zuccon\n",
            "Year: 2018\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Test collection based evaluation represents the standard of evalua- tion for information retrieval systems. Legal IR, more speci cally case law retrieval, has no such standard test collection for evalua- tion. In this paper, we present a test collection for use in evaluating case law search, being the retrieval of judicial decisions relevant to a particular legal question. The collection is made available at ielab.io/caselaw.\n",
            "\n",
            "---\n",
            "\n",
            "Title: CiteSeer x : A Scholarly Big Dataset\n",
            "Authors: Cornelia Caragea, Jian Wu, A. Ciobanu, Kyle Williams, Juan Pablo Fernández Ramírez, Hung-Hsuan Chen, Zhaohui Wu, Colin Giles\n",
            "Year: 2014\n",
            "Venue: European Conference on Information Retrieval\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Bridging the Ultimate Semantic Gap: A Semantic Search Engine for Internet Videos\n",
            "Authors: Lu Jiang, Shoou-I Yu, Deyu Meng, T. Mitamura, Alexander Hauptmann\n",
            "Year: 2015\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Semantic search in video is a novel and challenging problem in information and multimedia retrieval. Existing solutions are mainly limited to text matching, in which the query words are matched against the textual metadata generated by users. This paper presents a state-of-the-art system for event search without any textual metadata or example videos. The system relies on substantial video content understanding and allows for semantic search over a large collection of videos. The novelty and practicality is demonstrated by the evaluation in NIST TRECVID 2014, where the proposed system achieves the best performance. We share our observations and lessons in building such a state-of-the-art system, which may be instrumental in guiding the design of the future system for semantic search in video.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Evolution of Cranfield\n",
            "Authors: E. Voorhees\n",
            "Year: 2019\n",
            "Venue: Information Retrieval Evaluation in a Changing World\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Answer Interaction in Non-factoid Question Answering Systems\n",
            "Authors: Chen Qu, Liu Yang, W. Bruce Croft, Falk Scholer, Yongfeng Zhang\n",
            "Year: 2019\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: Information retrieval systems are evolving from document retrieval to answer retrieval. Web search logs provide large amounts of data about how people interact with ranked lists of documents, but very little is known about interaction with answer texts. In this paper, we use Amazon Mechanical Turk to investigate three answer presentation and interaction approaches in a non-factoid question answering setting. We find that people perceive and react to good and bad answers very differently, and can identify good answers relatively quickly. Our results provide the basis for further investigation of effective answer interaction and feedback methods.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Angry expressions strengthen the encoding and maintenance of face identity representations in visual working memory\n",
            "Authors: Margaret C Jackson, D. Linden, J. Raymond\n",
            "Year: 2014\n",
            "Venue: Cognition & Emotion\n",
            "Abstract: Visual working memory (WM) for face identities is enhanced when faces express negative versus positive emotion. To determine the stage at which emotion exerts its influence on memory for person information, we isolated expression (angry/happy) to the encoding phase (Experiment 1; neutral test faces) or retrieval phase (Experiment 2; neutral study faces). WM was only enhanced by anger when expression was present at encoding, suggesting that retrieval mechanisms are not influenced by emotional expression. To examine whether emotional information is discarded on completion of encoding or sustained in WM, in Experiment 3 an emotional word categorisation task was inserted into the maintenance interval. Emotional congruence between word and face supported memory for angry but not for happy faces, suggesting that negative emotional information is preferentially sustained during WM maintenance. Our findings demonstrate that negative expressions exert sustained and beneficial effects on WM for faces that extend beyond encoding.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Temporal feedback for tweet search with non-parametric density estimation\n",
            "Authors: Miles Efron, Jimmy J. Lin, Jiyin He, A. D. Vries\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: This paper investigates the temporal cluster hypothesis: in search tasks where time plays an important role, do relevant documents tend to cluster together in time? We explore this question in the context of tweet search and temporal feedback: starting with an initial set of results from a baseline retrieval model, we estimate the temporal density of relevant documents, which is then used for result reranking. Our contributions lie in a method to characterize this temporal density function using kernel density estimation, with and without human relevance judgments, and an approach to integrating this information into a standard retrieval model. Experiments on TREC datasets confirm that our temporal feedback formulation improves search effectiveness, thus providing support for our hypothesis. Our approach out-performs both a standard baseline and previous temporal retrieval models. Temporal feedback improves over standard lexical feedback (with and without human judgments), illus- trating that temporal relevance signals exist independently of document content.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Looking for the Movie Seven or Sven from the Movie Frozen?: A Multi-perspective Strategy for Recommending Queries for Children\n",
            "Authors: Ion Madrazo Azpiazu, Nevena Dragovic, Oghenemaro Anuyah, M. S. Pera\n",
            "Year: 2018\n",
            "Venue: Conference on Human Information Interaction and Retrieval\n",
            "Abstract: Popular search engines are usually tuned to satisfy the information needs of a general audience. As a result, non-traditional, yet active groups of users, such as children, experience challenges composing queries that can lead them to the retrieval of adequate results. To aid young users in formulating keyword queries that can facilitate their information-seeking process, we introduce ReQuIK, a multi-perspective query suggestion system for children. ReQuIK informs its suggestion process by applying (i) a strategy based on search intent to capture the purpose of a query, (ii) a ranking strategy based on a wide and deep neural network that considers both raw text and traits commonly associated with kid-related queries, (iii) a filtering strategy based on the readability levels of documents potentially retrieved by a query to favor suggestions that trigger the retrieval of documents matching children»s reading skills, and (iv) a content-similarity strategy to ensure diversity among suggestions. For assessing the quality of the system, we conducted initial offline and online experiments based on 591 queries written by 97 children, ages 6 to 13. The results of this assessment verified the correctness of ReQuIK»s recommendation strategy, the fact that it provides suggestions that appeal to children and ReQuIK»s ability to recommend queries that lead to the retrieval of materials with readability levels that correlate with children»s reading skills.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Examining Multiple Features for Author Profiling\n",
            "Authors: Edson R. D. Weren, Anderson Uilian Kauer, Lucas Mizusaki, V. Moreira, J. Oliveira, Leandro Krug Wives\n",
            "Year: 2014\n",
            "Venue: Journal of Information and Data Management\n",
            "Abstract: Authorship analysis aims at classifying texts based on the stylistic choices of their authors. The idea is to discover characteristics of the authors of the texts. This task has a growing importance in forensics, security, and marketing. In this work, we focus on discovering age and gender from blog authors. With this goal in mind, we analyzed a large number of features -- ranging from Information Retrieval to Sentiment Analysis. This paper reports on the usefulness of these features. Experiments on a corpus of over 236K blogs show that a classifier using the features explored here have outperformed the state-of-the art. More importantly, the experiments show that the Information Retrieval features proposed in our work are the most discriminative and yield the best class predictions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Evaluation Measures for Relevance and Credibility in Ranked Lists\n",
            "Authors: C. Lioma, J. Simonsen, Birger Larsen\n",
            "Year: 2017\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: Recent discussions on alternative facts, fake news, and post truth politics have motivated research on creating technologies that allow people not only to access information, but also to assess the credibility of the information presented to them by information retrieval systems. Whereas technology is in place for filtering information according to relevance and/or credibility, no single measure currently exists for evaluating the accuracy or precision (and more generally effectiveness) of both the relevance and the credibility of retrieved results. One obvious way of doing so is to measure relevance and credibility effectiveness separately, and then consolidate the two measures into one. There at least two problems with such an approach: (I) it is not certain that the same criteria are applied to the evaluation of both relevance and credibility (and applying different criteria introduces bias to the evaluation); (II) many more and richer measures exist for assessing relevance effectiveness than for assessing credibility effectiveness (hence risking further bias). Motivated by the above, we present two novel types of evaluation measures that are designed to measure the effectiveness of both relevance and credibility in ranked lists of retrieval results. Experimental evaluation on a small human-annotated dataset (that we make freely available to the research community) shows that our measures are expressive and intuitive in their interpretation.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A survey of statistical approaches for query expansion\n",
            "Authors: M. A. Raza, Rahmah Mokhtar, A. Noraziah\n",
            "Year: 2018\n",
            "Venue: Knowledge and Information Systems\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Searching the Enterprise\n",
            "Authors: Udo Kruschwitz, Charlie Hull\n",
            "Year: 2017\n",
            "Venue: Foundations and Trends in Information Retrieval\n",
            "Abstract: Search has become ubiquitous but that does not mean that search has been solved. Enterprise search, which is broadly speaking the use of information retrieval technology to find information within organisations, is a good example to illustrate this. It is an area that is of huge importance for businesses, yet has attracted relatively little academic interest. This monograph will explore the main issues involved in enterprise search both from a research as well as a practical point of view. We will first plot the landscape of enterprise search and its links to related areas. This will allow us to identify key features before we survey the field in more detail. Throughout the monograph we will discuss the topic as part of the wider information retrieval research field, and we use Web search as a common reference point as this is likely the search application area that the average reader is most familiar with. U. Kruschwitz and C. Hull. Searching the Enterprise. Foundations and Trends © in Information Retrieval, vol. 11, no. 1, pp. 1–142, 2017. DOI: 10.1561/1500000053. Full text available at: http://dx.doi.org/10.1561/1500000053\n",
            "\n",
            "---\n",
            "\n",
            "Title: Question Answering System, Approaches and Techniques: A Review\n",
            "Authors: A. Pundge, Aurangabad Khillare, Aurangabad C. Namrata Mahender\n",
            "Year: 2016\n",
            "Venue: \n",
            "Abstract: As technology developed the use of internet has tremendously increased because of the availability of huge amount of data. Question answering is a specialized area in the field of information retrieval Text Processing. Question Answering system has many application based on source of answering like extracting information from document, language learning, online examination etc. General Terms Natural Language Processing, Question Answering System, Information Retrieval\n",
            "\n",
            "---\n",
            "\n",
            "Title: Monaural Score-Informed Source Separation for Classical Music Using Convolutional Neural Networks\n",
            "Authors: M. Miron, J. Janer, E. Gómez\n",
            "Year: 2017\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada a la 18th International Society for Music Information Retrieval Conference (ISMIR 2017), celebrada els dies 23 a 27 d'octubre de 2017 a Suzhou, Xina.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Survey of Volunteered Open Geo-Knowledge Bases in the Semantic Web\n",
            "Authors: Andrea Ballatore, David C. Wilson, M. Bertolotto\n",
            "Year: 2014\n",
            "Venue: Quality Issues in the Management of Web Information\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Search as Learning (SAL) Workshop 2016\n",
            "Authors: J. Gwizdka, P. Hansen, C. Hauff, Jiyin He, N. Kando\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The \"Search as Learning\" (SAL) workshop is focused on an area within the information retrieval field that is only beginning to emerge: supporting users in their learning whilst interacting with information content.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Improving Term Weighting for Community Question Answering Search Using Syntactic Analysis\n",
            "Authors: David Carmel, Avihai Mejer, Yuval Pinter, Idan Szpektor\n",
            "Year: 2014\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: Query term weighting is a fundamental task in information retrieval and most popular term weighting schemes are primarily based on statistical analysis of term occurrences within the document collection. In this work we study how term weighting may benefit from syntactic analysis of the corpus. Focusing on community question answering (CQA) sites, we take into account the syntactic function of the terms within CQA texts as an important factor affecting their relative importance for retrieval. We analyze a large log of web queries that landed on Yahoo Answers site, showing a strong deviation between the tendencies of different document words to appear in a landing (click-through) query given their syntactic function. To this end, we propose a novel term weighting method that makes use of the syntactic information available for each query term occurrence in the document, on top of term occurrence statistics. The relative importance of each feature is learned via a learning to rank algorithm that utilizes a click-through query log. We examine the new weighting scheme using manual evaluation based on editorial data and using automatic evaluation over the query log. Our experimental results show consistent improvement in retrieval when syntactic information is taken into account.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Exploring Customer Reviews for Music Genre Classification and Evolutionary Studies\n",
            "Authors: Sergio Oramas, Luis Espinosa Anke, A. Lawlor, Xavier Serra, Horacio Saggion\n",
            "Year: 2016\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: The 17th International Society for Music Information Retrieval Conference (ISMIR 2016), New York City, United States of America, 7-11 August 2016\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-Collection Evaluation for Music Classification Tasks\n",
            "Authors: D. Bogdanov, Alastair Porter, P. Herrera, Xavier Serra\n",
            "Year: 2016\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada a la 17th International Society for Music Information Retrieval Conference (ISMIR 2016), celebrada els dies 7 a 11 d'agost de 2016 a Nova York, EUA.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Creating a Corpus of Jingju (Beijing Opera) Music and Possibilities for Melodic Analysis\n",
            "Authors: Rafael Caro Repetto, Xavier Serra\n",
            "Year: 2014\n",
            "Venue: International Society for Music Information Retrieval Conference\n",
            "Abstract: Comunicacio presentada a la 15th International Society for Music Information Retrieval Conference (ISMIR 2014), celebrada els dies 27 a 31 d'octubre de 2014 a Taipei, Taiwan.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Axiomatic Result Re-Ranking\n",
            "Authors: Matthias Hagen, Michael Völske, Steve Goering, Benno Stein\n",
            "Year: 2016\n",
            "Venue: International Conference on Information and Knowledge Management\n",
            "Abstract: We consider the problem of re-ranking the top-k documents returned by a retrieval system given some search query. This setting is common to learning-to-rank scenarios, and it is often solved with machine learning and feature weighting based on user preferences such as clicks, dwell times, etc. In this paper, we combine the learning-to-rank paradigm with the recent developments on axioms for information retrieval. In particular, we suggest to re-rank the top-k documents of a retrieval system using carefully chosen axiom combinations. In recent years, research on axioms for information retrieval has focused on identifying reasonable constraints that retrieval systems should fulfill. Researchers have analyzed a wide range of standard retrieval models for conformance to the proposed axioms and, at times, suggested certain adjustments to the models. We take up this axiomatic view---but, instead of adjusting the retrieval models themselves, we suggest the following innovation: to adopt the learning-to-rank idea and to re-rank the top-k results directly using promising axiom combinations. This way, we can turn every reasonable basic retrieval model into an axiom-based retrieval model. In large-scale experiments on the ClueWeb corpora, we identify promising axiom combinations for a variety of retrieval models. Our experiments show that for most of these models our axiom-based re-ranking significantly improves the original retrieval performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Session Search by Direct Policy Learning\n",
            "Authors: Jiyun Luo, Xuchu Dong, G. Yang\n",
            "Year: 2015\n",
            "Venue: International Conference on the Theory of Information Retrieval\n",
            "Abstract: This paper proposes a novel retrieval model for session search. Through gradient descent, the model finds optimal policies for the best search engine actions from what is observed in the user and search engine interactions. The proposed framework applies direct policy learning to session search such that it greatly reduce the model complexity than prior work. It is also a flexible design, which includes a wide range of features describing the rich interactions in session search. The framework is shown to be highly effective evaluated on the recent TREC Session Tracks. As part of the efforts to bring reinforcement learning to information retrieval, this paper makes a novel contribution in theoretical modeling for session search.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Anonymizing Query Logs by Differential Privacy\n",
            "Authors: Sicong Zhang, G. Yang, L. Singh\n",
            "Year: 2016\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: Query logs are valuable resources for Information Retrieval (IR) research. However, because they are also rich in private and personal information, the huge concern of leaking user privacy prevents query logs from being shared from the search companies to the broad research community. Bothered by the lack of good research data for years, the authors of this paper are motivated to explore ways to generate anonymized query logs that can still be effectively used to support the search task. We introduce a framework to anonymize query logs by differential privacy, the latest development in privacy research. The framework is empirically evaluated against multiple search algorithms on their retrieval utility, measured in standard IR evaluation metrics, using the anonymized logs. The experiments show that our framework is able to achieve a good balance between retrieval utility and privacy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Knowledge-Based Query Expansion in Real-Time Microblog Search\n",
            "Authors: Chao Lv, Runwei Qiang, Feifan Fan, Jianwu Yang\n",
            "Year: 2015\n",
            "Venue: Asia Information Retrieval Symposium\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Beyond use statistics: Recall, precision, and relevance in the assessment and management of academic libraries\n",
            "Authors: W. H. Walters\n",
            "Year: 2016\n",
            "Venue: Journal of Library and Information Sciences\n",
            "Abstract: Although use statistics are often used in the assessment of library collections and services, they are of limited value in evaluating the library’s effectiveness as an information system. This essay highlights three concepts from the information retrieval literature—recall, precision, and relevance—and describes a standard of relevance that accounts for the learning goals of the academic community as well as the performance goals of students. It also demonstrates how the academic mission of the university can be incorporated into the assessment and management of the library as an information retrieval system. The discussion concludes with guidelines for the assessment of recall and precision as well as suggestions for the integration of these concepts into library collection development, cataloging/access, reference, and instruction.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Efficient object identification and multiple regions of interest using CBIR based on relative locations and matching regions\n",
            "Authors: Muhammad Hammad Memon, Jian-ping Li, I. Memon, R. Shaikh, F. Mangi\n",
            "Year: 2015\n",
            "Venue: 2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)\n",
            "Abstract: Nowadays information retrieval systems get more attention due to the increasing use of multimedia technologies. The information may be in the form of video, image, sound and/or text. Application of surveillance, digital libraries, web applications and various other applications that handle enormous volume of data essentially have information retrieval components. This paper demonstrates an image retrieval system based on multiple regions that give a client interface for helping to identify the watershed regions-of-interest inside of an input image. The relationship between semantic ideas and visual elements is established by supervised Bayesian learning from positive bags. For comparison, feature vectors of regions which have similar regions code to the regions of query image can be used during retrieval. On standard datasets the proposed algorithm has been applied and accomplishes great annotation performance.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Learning to translate queries for CLIR\n",
            "Authors: Artem Sokolov, F. Hieber, S. Riezler\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The statistical machine translation (SMT) component of cross-lingual information retrieval (CLIR) systems is often regarded as black box that is optimized for translation quality independent from the retrieval task. In recent work [10], SMT has been tuned for retrieval by training a reranker on $k$-best translations ordered according to their retrieval performance. In this paper we propose a decomposable proxy for retrieval quality that obviates the need for costly intermediate retrieval. Furthermore, we explore the full search space of the SMT decoder by directly optimizing decoder parameters under a retrieval-based objective. Experimental results for patent retrieval show our approach to be a promising alternative to the standard pipeline approach.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Wikipedia-based query performance prediction\n",
            "Authors: Gilad Katz, Anna Shtok, Oren Kurland, Bracha Shapira, L. Rokach\n",
            "Year: 2014\n",
            "Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
            "Abstract: The query-performance prediction task is to estimate retrieval effectiveness with no relevance judgments. Pre-retrieval prediction methods operate prior to retrieval time. Hence, these predictors are often based on analyzing the query and the corpus upon which retrieval is performed. We propose a {\\em corpus-independent} approach to pre-retrieval prediction which relies on information extracted from Wikipedia. Specifically, we present Wikipedia-based features that can attest to the effectiveness of retrieval performed in response to a query {\\em regardless} of the corpus upon which search is performed. Empirical evaluation demonstrates the merits of our approach. As a case in point, integrating the Wikipedia-based features with state-of-the-art pre-retrieval predictors that analyze the corpus yields prediction quality that is consistently better than that of using the latter alone.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Deep Supervised Hashing for Fast Image Retrieval\n",
            "Authors: Haomiao Liu, Ruiping Wang, S. Shan, Xilin Chen\n",
            "Year: 2016\n",
            "Venue: International Journal of Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Scalable Deep Hashing for Large-Scale Social Image Retrieval\n",
            "Authors: Hui Cui, Lei Zhu, Jingjing Li, Yang Yang, Liqiang Nie\n",
            "Year: 2020\n",
            "Venue: IEEE Transactions on Image Processing\n",
            "Abstract: Recent years have witnessed the wide application of hashing for large-scale image retrieval, because of its high computation efficiency and low storage cost. Particularly, benefiting from current advances in deep learning, supervised deep hashing methods have greatly boosted the retrieval performance, under the strong supervision of large amounts of manually annotated semantic labels. However, their performance is highly dependent upon the supervised labels, which significantly limits the scalability. In contrast, unsupervised deep hashing without label dependence enjoys the advantages of well scalability. Nevertheless, due to the relaxed hash optimization, and more importantly, the lack of semantic guidance, existing methods suffer from limited retrieval performance. In this paper, we propose a SCAlable Deep Hashing (SCADH) to learn enhanced hash codes for social image retrieval. We formulate a unified scalable deep hash learning framework which explores the weak but free supervision of discriminative user tags that are commonly accompanied with social images. It jointly learns image representations and hash functions with deep neural networks, and simultaneously enhances the discriminative capability of image hash codes with the refined semantics from the accompanied social tags. Further, instead of simple relaxed hash optimization, we propose a discrete hash optimization method based on Augmented Lagrangian Multiplier to directly solve the hash codes and avoid the binary quantization information loss. Experiments on two standard social image datasets demonstrate the superiority of the proposed approach compared with state-of-the-art shallow and deep hashing techniques.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Preparing a collection of radiology examinations for distribution and retrieval\n",
            "Authors: Dina Demner-Fushman, M. Kohli, M. Rosenman, S. E. Shooshan, Laritza M. Rodriguez, Sameer Kiran Antani, G. Thoma, C. McDonald\n",
            "Year: 2015\n",
            "Venue: J. Am. Medical Informatics Assoc.\n",
            "Abstract: OBJECTIVE\n",
            "Clinical documents made available for secondary use play an increasingly important role in discovery of clinical knowledge, development of research methods, and education. An important step in facilitating secondary use of clinical document collections is easy access to descriptions and samples that represent the content of the collections. This paper presents an approach to developing a collection of radiology examinations, including both the images and radiologist narrative reports, and making them publicly available in a searchable database.\n",
            "\n",
            "\n",
            "MATERIALS AND METHODS\n",
            "The authors collected 3996 radiology reports from the Indiana Network for Patient Care and 8121 associated images from the hospitals' picture archiving systems. The images and reports were de-identified automatically and then the automatic de-identification was manually verified. The authors coded the key findings of the reports and empirically assessed the benefits of manual coding on retrieval.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "The automatic de-identification of the narrative was aggressive and achieved 100% precision at the cost of rendering a few findings uninterpretable. Automatic de-identification of images was not quite as perfect. Images for two of 3996 patients (0.05%) showed protected health information. Manual encoding of findings improved retrieval precision.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "Stringent de-identification methods can remove all identifiers from text radiology reports. DICOM de-identification of images does not remove all identifying information and needs special attention to images scanned from film. Adding manual coding to the radiologist narrative reports significantly improved relevancy of the retrieved clinical documents. The de-identified Indiana chest X-ray collection is available for searching and downloading from the National Library of Medicine (http://openi.nlm.nih.gov/).\n",
            "\n",
            "---\n",
            "\n",
            "Title: Doodle to Search: Practical Zero-Shot Sketch-Based Image Retrieval\n",
            "Authors: S. Dey, Pau Riba, Anjan Dutta, J. Lladós, Yi-Zhe Song\n",
            "Year: 2019\n",
            "Venue: Computer Vision and Pattern Recognition\n",
            "Abstract: In this paper, we investigate the problem of zero-shot sketch-based image retrieval (ZS-SBIR), where human sketches are used as queries to conduct retrieval of photos from unseen categories. We importantly advance prior arts by proposing a novel ZS-SBIR scenario that represents a firm step forward in its practical application. The new setting uniquely recognizes two important yet often neglected challenges of practical ZS-SBIR, (i) the large domain gap between amateur sketch and photo, and (ii) the necessity for moving towards large-scale retrieval. We first contribute to the community a novel ZS-SBIR dataset, QuickDraw-Extended, that consists of 330,000 sketches and 204,000 photos spanning across 110 categories. Highly abstract amateur human sketches are purposefully sourced to maximize the domain gap, instead of ones included in existing datasets that can often be semi-photorealistic. We then formulate a ZS-SBIR framework to jointly model sketches and photos into a common embedding space. A novel strategy to mine the mutual information among domains is specifically engineered to alleviate the domain gap. External semantic knowledge is further embedded to aid semantic transfer. We show that, rather surprisingly, retrieval performance significantly outperforms that of state-of-the-art on existing datasets that can already be achieved using a reduced version of our model. We further demonstrate the superior performance of our full model by comparing with a number of alternatives on the newly proposed dataset. The new dataset, plus all training and testing code of our model, will be publicly released to facilitate future research.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval\n",
            "Authors: Sijin Wang, Ruiping Wang, Ziwei Yao, S. Shan, Xilin Chen\n",
            "Year: 2019\n",
            "Venue: IEEE Workshop/Winter Conference on Applications of Computer Vision\n",
            "Abstract: Image-text retrieval of natural scenes has been a popular research topic. Since image and text are heterogeneous cross-modal data, one of the key challenges is how to learn comprehensive yet unified representations to express the multi-modal data. A natural scene image mainly involves two kinds of visual concepts, objects and their relationships, which are equally essential to image-text retrieval. Therefore, a good representation should account for both of them. In the light of recent success of scene graph in many CV and NLP tasks for describing complex natural scenes, we propose to represent image and text with two kinds of scene graphs: visual scene graph (VSG) and textual scene graph (TSG), each of which is exploited to jointly characterize objects and relationships in the corresponding modality. The image-text retrieval task is then naturally formulated as cross-modal scene graph matching. Specifically, we design two particular scene graph encoders in our model for VSG and TSG, which can refine the representation of each node on the graph by aggregating neighborhood information. As a result, both object-level and relationship-level cross-modal features can be obtained, which favorably enables us to evaluate the similarity of image and text in the two levels in a more plausible way. We achieve state-of-the-art results on Flickr30k and MS COCO, which verifies the advantages of our graph matching based approach for image-text retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Memorability of Words in Arbitrary Verbal Associations Modulates Memory Retrieval in the Anterior Temporal Lobe\n",
            "Authors: Weizhen Xie, Wilma A. Bainbridge, S. Inati, C. Baker, K. Zaghloul\n",
            "Year: 2020\n",
            "Venue: Nature Human Behaviour\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Adversary Guided Asymmetric Hashing for Cross-Modal Retrieval\n",
            "Authors: Wen Gu, Xiaoyan Gu, Jingzi Gu, B. Li, Zhi Xiong, Weiping Wang\n",
            "Year: 2019\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Cross-modal hashing has attracted considerable attention for large-scale multimodal retrieval task. A majority of hashing methods have been proposed for cross-modal retrieval. However, these methods inadequately focus on feature learning process and cannot fully preserve higher-ranking correlation of various item pairs as well as the multi-label semantics of each item, so that the quality of binary codes may be downgraded. To tackle these problems, in this paper, we propose a novel deep cross-modal hashing method, called Adversary Guided Asymmetric Hashing (AGAH). Specifically, it employs an adversarial learning guided multi-label attention module to enhance the feature learning part which can learn discriminative feature representations and keep the cross-modal invariability. Furthermore, in order to generate hash codes which can fully preserve the multi-label semantics of all items, we propose an asymmetric hashing method which utilizes a multi-label binary code map that can equip the hash codes with multi-label semantic information. In addition, to ensure higher-ranking correlation of all similar item pairs than those of dissimilar ones, we adopt a new triplet-margin constraint and a cosine quantization technique for Hamming space similarity preservation. Extensive empirical studies show that AGAH outperforms several state-of-the-art methods for cross-modal retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Zero-Shot Framework for Sketch-based Image Retrieval\n",
            "Authors: Sasi Kiran Yelamarthi, M. K. Reddy, Ashish Mishra, Anurag Mittal\n",
            "Year: 2018\n",
            "Venue: European Conference on Computer Vision\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Transformed Neural Pattern Reinstatement during Episodic Memory Retrieval\n",
            "Authors: Xiaoqian Xiao, Q. Dong, Jia-Hong Gao, Weiwei Men, R. Poldrack, G. Xue\n",
            "Year: 2017\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Contemporary models of episodic memory posit that remembering involves the reenactment of encoding processes. Although encoding-retrieval similarity has been consistently reported and linked to memory success, the nature of neural pattern reinstatement is poorly understood. Using high-resolution fMRI on human subjects, our results obtained clear evidence for item-specific pattern reinstatement in the frontoparietal cortex, even when the encoding-retrieval pairs shared no perceptual similarity. No item-specific pattern reinstatement was found in the ventral visual cortex. Importantly, the brain regions and voxels carrying item-specific representation differed significantly between encoding and retrieval, and the item specificity for encoding-retrieval similarity was smaller than that for encoding or retrieval, suggesting different nature of representations between encoding and retrieval. Moreover, cross-region representational similarity analysis suggests that the encoded representation in the ventral visual cortex was reinstated in the frontoparietal cortex during retrieval. Together, these results suggest that, in addition to reinstatement of the originally encoded pattern in the brain regions that perform encoding processes, retrieval may also involve the reinstatement of a transformed representation of the encoded information. These results emphasize the constructive nature of memory retrieval that helps to serve important adaptive functions. SIGNIFICANCE STATEMENT Episodic memory enables humans to vividly reexperience past events, yet how this is achieved at the neural level is barely understood. A long-standing hypothesis posits that memory retrieval involves the faithful reinstatement of encoding-related activity. We tested this hypothesis by comparing the neural representations during encoding and retrieval. We found strong pattern reinstatement in the frontoparietal cortex, but not in the ventral visual cortex, that represents visual details. Critically, even within the same brain regions, the nature of representation during retrieval was qualitatively different from that during encoding. These results suggest that memory retrieval is not a faithful replay of past event but rather involves additional constructive processes to serve adaptive functions.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Automatic and Controlled Semantic Retrieval: TMS Reveals Distinct Contributions of Posterior Middle Temporal Gyrus and Angular Gyrus\n",
            "Authors: James Davey, P. Cornelissen, H. Thompson, Saurabh Sonkusare, Glyn Hallam, J. Smallwood, E. Jefferies\n",
            "Year: 2015\n",
            "Venue: Journal of Neuroscience\n",
            "Abstract: Semantic retrieval involves both (1) automatic spreading activation between highly related concepts and (2) executive control processes that tailor this activation to suit the current context or goals. Two structures in left temporoparietal cortex, angular gyrus (AG) and posterior middle temporal gyrus (pMTG), are thought to be crucial to semantic retrieval and are often recruited together during semantic tasks; however, they show strikingly different patterns of functional connectivity at rest (coupling with the “default mode network” and “frontoparietal control system,” respectively). Here, transcranial magnetic stimulation (TMS) was used to establish a causal yet dissociable role for these sites in semantic cognition in human volunteers. TMS to AG disrupted thematic judgments particularly when the link between probe and target was strong (e.g., a picture of an Alsatian with a bone), and impaired the identification of objects at a specific but not a superordinate level (for the verbal label “Alsatian” not “animal”). In contrast, TMS to pMTG disrupted thematic judgments for weak but not strong associations (e.g., a picture of an Alsatian with razor wire), and impaired identity matching for both superordinate and specific-level labels. Thus, stimulation to AG interfered with the automatic retrieval of specific concepts from the semantic store while stimulation of pMTG impaired semantic cognition when there was a requirement to flexibly shape conceptual activation in line with the task requirements. These results demonstrate that AG and pMTG make a dissociable contribution to automatic and controlled aspects of semantic retrieval. SIGNIFICANCE STATEMENT We demonstrate a novel functional dissociation between the angular gyrus (AG) and posterior middle temporal gyrus (pMTG) in conceptual processing. These sites are often coactivated during neuroimaging studies using semantic tasks, but their individual contributions are unclear. Using transcranial magnetic stimulation and tasks designed to assess different aspects of semantics (item identity and thematic matching), we tested two alternative theoretical accounts. Neither site showed the pattern expected for a “thematic hub” (i.e., a site storing associations between concepts) since stimulation disrupted both tasks. Instead, the data indicated that pMTG contributes to the controlled retrieval of conceptual knowledge, while AG is critical for the efficient automatic retrieval of specific semantic information.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Modal-adversarial Semantic Learning Network for Extendable Cross-modal Retrieval\n",
            "Authors: Xing Xu, Jingkuan Song, Huimin Lu, Yang Yang, Fumin Shen, Zi Huang\n",
            "Year: 2018\n",
            "Venue: International Conference on Multimedia Retrieval\n",
            "Abstract: Cross-modal retrieval, e.g., using an image query to search related text and vice-versa, has become a highlighted research topic, to provide flexible retrieval experience across multi-modal data. Existing approaches usually consider the so-called non-extendable cross-modal retrieval task. In this task, they learn a common latent subspace from a source set containing labeled instances of image-text pairs and then generate common representation for the instances in a target set to perform cross-modal matching. However, these method may not generalize well when the instances of the target set contains unseen classes since the instances of both the source and target set are assumed to share the same range of classes in the non-extensive cross-modal retrieval task. In this paper, we consider a more practical issue of extendable cross-modal retrieval task where instances in source and target set have disjoint classes. We propose a novel framework, termed Modal-adversarial Semantic Learning Network (MASLN), to tackle the limitation of existing methods on this practical task. Specifically, the proposed MASLN consists two subnetworks of cross-modal reconstruction and modal-adversarial semantic learning. The former minimizes the cross-modal distribution discrepancy by reconstructing each modality data mutually, with the guidelines of class embeddings as side information in the reconstruction procedure. The latter generates semantic representation to be indiscriminative for modalities, while to distinguish the modalities from the common representation via an adversarial learning mechanism. The two subnetworks are jointly trained to enhance the cross-modal semantic consistency in the learned common subspace and the knowledge transfer to instances in the target set. Comprehensive experiment on three widely-used multi-modal datasets show its effectiveness and robustness on both non-extendable and extendable cross-modal retrieval task.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Reinstatement of Individual Past Events Revealed by the Similarity of Distributed Activation Patterns during Encoding and Retrieval\n",
            "Authors: Erik A. Wing, Maureen Ritchey, R. Cabeza\n",
            "Year: 2015\n",
            "Venue: Journal of Cognitive Neuroscience\n",
            "Abstract: Neurobiological memory models assume memory traces are stored in neocortex, with pointers in the hippocampus, and are then reactivated during retrieval, yielding the experience of remembering. Whereas most prior neuroimaging studies on reactivation have focused on the reactivation of sets or categories of items, the current study sought to identify cortical patterns pertaining to memory for individual scenes. During encoding, participants viewed pictures of scenes paired with matching labels (e.g., “barn,” “tunnel”), and, during retrieval, they recalled the scenes in response to the labels and rated the quality of their visual memories. Using representational similarity analyses, we interrogated the similarity between activation patterns during encoding and retrieval both at the item level (individual scenes) and the set level (all scenes). The study yielded four main findings. First, in occipitotemporal cortex, memory success increased with encoding-retrieval similarity (ERS) at the item level but not at the set level, indicating the reactivation of individual scenes. Second, in ventrolateral pFC, memory increased with ERS for both item and set levels, indicating the recapitulation of memory processes that benefit encoding and retrieval of all scenes. Third, in retrosplenial/posterior cingulate cortex, ERS was sensitive to individual scene information irrespective of memory success, suggesting automatic activation of scene contexts. Finally, consistent with neurobiological models, hippocampal activity during encoding predicted the subsequent reactivation of individual items. These findings show the promise of studying memory with greater specificity by isolating individual mnemonic representations and determining their relationship to factors like the detail with which past events are remembered.\n",
            "\n",
            "---\n",
            "\n",
            "Title: A Review of Irrigation Information Retrievals from Space and Their Utility for Users\n",
            "Authors: C. Massari, S. Modanesi, J. Dari, A. Gruber, G. Lannoy, M. Girotto, P. Quintana-Seguí, M. L. Page, L. Jarlan, M. Zribi, N. Ouaadi, M. Vreugdenhil, L. Zappa, W. Dorigo, W. Wagner, Joost Brombacher, H. Pelgrum, Pauline Jaquot, V. Freeman, E. Volden, D. Fernández-Prieto, A. Tarpanelli, S. Barbetta, L. Brocca\n",
            "Year: 2021\n",
            "Venue: Remote Sensing\n",
            "Abstract: Irrigation represents one of the most impactful human interventions in the terrestrial water cycle. Knowing the distribution and extent of irrigated areas as well as the amount of water used for irrigation plays a central role in modeling irrigation water requirements and quantifying the impact of irrigation on regional climate, river discharge, and groundwater depletion. Obtaining high-quality global information about irrigation is challenging, especially in terms of quantification of the water actually used for irrigation. Here, we review existing Earth observation datasets, models, and algorithms used for irrigation mapping and quantification from the field to the global scale. The current observation capacities are confronted with the results of a survey on user requirements on satellite-observed irrigation for agricultural water resources’ management. Based on this information, we identify current shortcomings of irrigation monitoring capabilities from space and phrase guidelines for potential future satellite missions and observation strategies.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Global Estimates of Fine Particulate Matter using a Combined Geophysical-Statistical Method with Information from Satellites, Models, and Monitors.\n",
            "Authors: A. van Donkelaar, R. Martin, M. Brauer, N. C. Hsu, R. Kahn, R. Levy, A. Lyapustin, A. Sayer, D. Winker\n",
            "Year: 2016\n",
            "Venue: Environmental Science and Technology\n",
            "Abstract: We estimated global fine particulate matter (PM2.5) concentrations using information from satellite-, simulation- and monitor-based sources by applying a Geographically Weighted Regression (GWR) to global geophysically based satellite-derived PM2.5 estimates. Aerosol optical depth from multiple satellite products (MISR, MODIS Dark Target, MODIS and SeaWiFS Deep Blue, and MODIS MAIAC) was combined with simulation (GEOS-Chem) based upon their relative uncertainties as determined using ground-based sun photometer (AERONET) observations for 1998-2014. The GWR predictors included simulated aerosol composition and land use information. The resultant PM2.5 estimates were highly consistent (R(2) = 0.81) with out-of-sample cross-validated PM2.5 concentrations from monitors. The global population-weighted annual average PM2.5 concentrations were 3-fold higher than the 10 μg/m(3) WHO guideline, driven by exposures in Asian and African regions. Estimates in regions with high contributions from mineral dust were associated with higher uncertainty, resulting from both sparse ground-based monitoring, and challenging conditions for retrieval and simulation. This approach demonstrates that the addition of even sparse ground-based measurements to more globally continuous PM2.5 data sources can yield valuable improvements to PM2.5 characterization on a global scale.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Getting more from visual working memory: Retro-cues enhance retrieval and protect from visual interference.\n",
            "Authors: Alessandra S. Souza, Laura Rerko, K. Oberauer\n",
            "Year: 2015\n",
            "Venue: Journal of Experimental Psychology: Human Perception and Performance\n",
            "Abstract: Visual working memory (VWM) has a limited capacity. This limitation can be mitigated by the use of focused attention: if attention is drawn to the relevant working memory content before test, performance improves (the so-called retro-cue benefit). This study tests 2 explanations of the retro-cue benefit: (a) Focused attention protects memory representations from interference by visual input at test, and (b) focusing attention enhances retrieval. Across 6 experiments using color recognition and color reproduction tasks, we varied the amount of color interference at test, and the delay between a retrieval cue (i.e., the retro-cue) and the memory test. Retro-cue benefits were larger when the memory test introduced interfering visual stimuli, showing that the retro-cue effect is in part because of protection from visual interference. However, when visual interference was held constant, retro-cue benefits were still obtained whenever the retro-cue enabled retrieval of an object from VWM but delayed response selection. Our results show that accessible information in VWM might be lost in the processes of testing memory because of visual interference and incomplete retrieval. This is not an inevitable state of affairs, though: Focused attention can be used to get the most out of VWM. (PsycINFO Database Record\n",
            "\n",
            "---\n",
            "\n",
            "Title: Multiple interacting brain areas underlie successful spatiotemporal memory retrieval in humans\n",
            "Authors: Amber Schedlbauer, Milagros S. Copara, Andrew J. Watrous, Arne D. Ekstrom\n",
            "Year: 2014\n",
            "Venue: Scientific Reports\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: Retrieval of river discharge solely from satellite imagery and at‐many‐stations hydraulic geometry: Sensitivity to river form and optimization parameters\n",
            "Authors: C. Gleason, L. Smith, Jinny Lee\n",
            "Year: 2014\n",
            "Venue: \n",
            "Abstract: Knowledge of river discharge is critically important for water resource management, climate modeling, and improved understanding of the global water cycle, yet discharge is poorly known in much of the world. Remote sensing holds promise to mitigate this gap, yet current approaches for quantitative retrievals of river discharge require in situ calibration or a priori knowledge of river hydraulics, limiting their utility in unmonitored regions. Recently, Gleason and Smith (2014) demonstrated discharge retrievals within 20–30% of in situ observations solely from Landsat TM satellite images through discovery of a river‐specific geomorphic scaling phenomenon termed at‐many‐stations hydraulic geometry (AMHG). This paper advances the AMHG discharge retrieval approach via additional parameter optimizations and validation on 34 gauged rivers spanning a diverse range of geomorphic and climatic settings. Sensitivity experiments reveal that discharge retrieval accuracy varies with river morphology, reach averaging procedure, and optimization parameters. Quality of remotely sensed river flow widths is also important. Recommended best practices include a proposed global parameter set for use when a priori information is unavailable. Using this global parameterization, AMHG discharge retrievals are successful for most investigated river morphologies (median RRMSE 33% of in situ gauge observations), except braided rivers (median RRMSE 74%), rivers having low at‐a‐station hydraulic geometry b exponents (reach‐averaged b < 0.1, median RRMSE 86%), and arid rivers having extreme discharge variability (median RRMSE > 1000%). Excluding such environments, 26–41% RRMSE agreement between AMHG discharge retrievals and in situ gauge observations suggests AMHG can meaningfully address global discharge knowledge gaps solely from repeat satellite imagery.\n",
            "\n",
            "---\n",
            "\n",
            "Title: The Role of Familiarity in Correcting Inaccurate Information\n",
            "Authors: Briony Swire, Ullrich K. H. Ecker, S. Lewandowsky\n",
            "Year: 2017\n",
            "Venue: Journal of Experimental Psychology. Learning, Memory and Cognition\n",
            "Abstract: People frequently continue to use inaccurate information in their reasoning even after a credible retraction has been presented. This phenomenon is often referred to as the continued influence effect of misinformation. The repetition of the original misconception within a retraction could contribute to this phenomenon, as it could inadvertently make the “myth” more familiar—and familiar information is more likely to be accepted as true. From a dual-process perspective, familiarity-based acceptance of myths is most likely to occur in the absence of strategic memory processes. Thus, we examined factors known to affect whether strategic memory processes can be utilized: age, detail, and time. Participants rated their belief in various statements of unclear veracity, and facts were subsequently affirmed and myths were retracted. Participants then rerated their belief either immediately or after a delay. We compared groups of young and older participants, and we manipulated the amount of detail presented in the affirmative or corrective explanations, as well as the retention interval between encoding and a retrieval attempt. We found that (a) older adults over the age of 65 were worse at sustaining their postcorrection belief that myths were inaccurate, (b) a greater level of explanatory detail promoted more sustained belief change, and (c) fact affirmations promoted more sustained belief change in comparison with myth retractions over the course of 1 week (but not over 3 weeks), This supports the notion that familiarity is indeed a driver of continued influence effects.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Consumer health information and question answering: helping consumers find answers to their health-related information needs\n",
            "Authors: Dina Demner-Fushman, Yassine Mrabet, Asma Ben Abacha\n",
            "Year: 2019\n",
            "Venue: J. Am. Medical Informatics Assoc.\n",
            "Abstract: OBJECTIVE\n",
            "Consumers increasingly turn to the internet in search of health-related information; and they want their questions answered with short and precise passages, rather than needing to analyze lists of relevant documents returned by search engines and reading each document to find an answer. We aim to answer consumer health questions with information from reliable sources.\n",
            "\n",
            "\n",
            "MATERIALS AND METHODS\n",
            "We combine knowledge-based, traditional machine and deep learning approaches to understand consumers' questions and select the best answers from consumer-oriented sources. We evaluate the end-to-end system and its components on simple questions generated in a pilot development of MedlinePlus Alexa skill, as well as the short and long real-life questions submitted to the National Library of Medicine by consumers.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Our system achieves 78.7% mean average precision and 87.9% mean reciprocal rank on simple Alexa questions, and 44.5% mean average precision and 51.6% mean reciprocal rank on real-life questions submitted by National Library of Medicine consumers.\n",
            "\n",
            "\n",
            "DISCUSSION\n",
            "The ensemble of deep learning, domain knowledge, and traditional approaches recognizes question type and focus well in the simple questions, but it leaves room for improvement on the real-life consumers' questions. Information retrieval approaches alone are sufficient for finding answers to simple Alexa questions. Answering real-life questions, however, benefits from a combination of information retrieval and inference approaches.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "A pilot practical implementation of research needed to help consumers find reliable answers to their health-related questions demonstrates that for most questions the reliable answers exist and can be found automatically with acceptable accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Neural reactivation in parietal cortex enhances memory for episodically linked information\n",
            "Authors: Tanya R. Jonker, Halle R. Dimsdale-Zucker, Maureen Ritchey, Alex Clarke, C. Ranganath\n",
            "Year: 2018\n",
            "Venue: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Abstract: Significance Recalling information is useful for more than just accessing memories; it is also a powerful way to enhance long-term memory. Using brain imaging, we discovered that, when trying to remember, people reactivate the specific information they are searching for, along with other information from the same event. The results demonstrate that memories of the past are organized in terms of integrated events and the act of recalling even a small part of an event engages brain networks that have powerful effects on the ability to retain information from the entire event. Remembering is a complex process that involves recalling specific details, such as who you were with when you celebrated your last birthday, as well as contextual information, such as the place where you celebrated. It is well established that the act of remembering enhances long-term retention of the retrieved information, but the neural and cognitive mechanisms that drive memory enhancement are not yet understood. One possibility is that the process of remembering results in reactivation of the broader episodic context. Consistent with this idea, in two experiments, we found that multiple retrieval attempts enhanced long-term retention of both the retrieved object and the nontarget object that shared scene context, compared with a restudy control. Using representational similarity analysis of fMRI data in experiment 2, we found that retrieval resulted in greater neural reactivation of both the target objects and contextually linked objects compared with restudy. Furthermore, this reactivation occurred in a network of medial and lateral parietal lobe regions that have been linked to episodic recollection. The results demonstrate that retrieving a memory can enhance retention of information that is linked in the broader event context and the hippocampus and a posterior medial network of parietal cortical areas (also known as the Default Network) play complementary roles in supporting the reactivation of episodically linked information during retrieval.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Information theoretic evaluation of satellite soil moisture retrievals.\n",
            "Authors: Sujay V. Kumar, P. Dirmeyer, C. Peters-Lidard, R. Bindlish, J. Bolten\n",
            "Year: 2018\n",
            "Venue: Remote Sensing of Environment\n",
            "Abstract: None\n",
            "\n",
            "---\n",
            "\n",
            "Title: When and why vision-language models behave like bags-of-words, and what to do about it?\n",
            "Authors: Mert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, James Y. Zou\n",
            "Year: 2022\n",
            "Venue: International Conference on Learning Representations\n",
            "Abstract: Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode compositional information. Here, we create the Attribution, Relation, and Order (ARO) benchmark to systematically evaluate the ability of VLMs to understand different types of relationships, attributes, and order. ARO consists of Visual Genome Attribution, to test the understanding of objects' properties; Visual Genome Relation, to test for relational understanding; and COCO&Flickr30k-Order, to test for order sensitivity. ARO is orders of magnitude larger than previous benchmarks of compositionality, with more than 50,000 test cases. We show where state-of-the-art VLMs have poor relational understanding, can blunder when linking objects to their attributes, and demonstrate a severe lack of order sensitivity. VLMs are predominantly trained and evaluated on large datasets with rich compositional structure in the images and captions. Yet, training on these datasets has not been enough to address the lack of compositional understanding, and evaluating on these datasets has failed to surface this deficiency. To understand why these limitations emerge and are not represented in the standard tests, we zoom into the evaluation and training procedures. We demonstrate that it is possible to perform well on retrieval over existing datasets without using the composition and order information. Given that contrastive pretraining optimizes for retrieval on datasets with similar shortcuts, we hypothesize that this can explain why the models do not need to learn to represent compositional information. This finding suggests a natural solution: composition-aware hard negative mining. We show that a simple-to-implement modification of contrastive learning significantly improves the performance on tasks requiring understanding of order and compositionality.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Align before Fuse: Vision and Language Representation Learning with Momentum Distillation\n",
            "Authors: Junnan Li, Ramprasaath R. Selvaraju, Akhilesh Deepak Gotmare, Shafiq R. Joty, Caiming Xiong, S. Hoi\n",
            "Year: 2021\n",
            "Venue: Neural Information Processing Systems\n",
            "Abstract: Large-scale vision and language representation learning has shown promising improvements on various vision-language tasks. Most existing methods employ a transformer-based multimodal encoder to jointly model visual tokens (region-based image features) and word tokens. Because the visual tokens and word tokens are unaligned, it is challenging for the multimodal encoder to learn image-text interactions. In this paper, we introduce a contrastive loss to ALign the image and text representations BEfore Fusing (ALBEF) them through cross-modal attention, which enables more grounded vision and language representation learning. Unlike most existing methods, our method does not require bounding box annotations nor high-resolution images. In order to improve learning from noisy web data, we propose momentum distillation, a self-training method which learns from pseudo-targets produced by a momentum model. We provide a theoretical analysis of ALBEF from a mutual information maximization perspective, showing that different training tasks can be interpreted as different ways to generate views for an image-text pair. ALBEF achieves state-of-the-art performance on multiple downstream vision-language tasks. On image-text retrieval, ALBEF outperforms methods that are pre-trained on orders of magnitude larger datasets. On VQA and NLVR$^2$, ALBEF achieves absolute improvements of 2.37% and 3.84% compared to the state-of-the-art, while enjoying faster inference speed. Code and pre-trained models are available at https://github.com/salesforce/ALBEF/.\n",
            "\n",
            "---\n",
            "\n",
            "Title: Memory engrams: Recalling the past and imagining the future\n",
            "Authors: S. Josselyn, S. Tonegawa\n",
            "Year: 2020\n",
            "Venue: Science\n",
            "Abstract: The neural substrate of memory The ability to form memory is an essential trait that allows learning and the accumulation of knowledge. But what is a memory? There has been a long history of searching for the neuronal substrate that forms memory in the brain, and the emerging view is that ensembles of engram cells explain how memories are formed and retrieved. In a Review, Josselyn and Tonegawa discuss the evidence for engram cells as a substrate of memory, particularly in rodents; what we have learned so far about the features of memory, including memory formation, retrieval over time, and loss; and future directions to understand how memory becomes knowledge. Science, this issue p. eaaw4325 BACKGROUND The idea that memory is stored as enduring changes in the brain dates back at least to the time of Plato and Aristotle (circa 350 BCE), but its scientific articulation emerged in the 20th century when Richard Semon introduced the term “engram” to describe the neural substrate for storing and recalling memories. Essentially, Semon proposed that an experience activates a population of neurons that undergo persistent chemical and/or physical changes to become an engram. Subsequent reactivation of the engram by cues available at the time of the experience induces memory retrieval. After Karl Lashley failed to find the engram in a rat brain, studies attempting to localize an engram were largely abandoned. Spurred by Donald O. Hebb’s theory that augmented synaptic strength and neuronal connectivity are critical for memory formation, many researchers showed that enhanced synaptic strength was correlated with memory. Nonetheless, the causal relationship between these enduring changes in synaptic connectivity with a specific, behaviorally identifiable memory at the level of the cell ensemble (an engram) awaited further advances in experimental technologies. ADVANCES The resurgence in research examining engrams may be linked to two complementary studies that applied intervention strategies to target individual neurons in an engram supporting a specific memory in mice. One study showed that ablating the subset of lateral amygdala neurons allocated to a putative engram disrupted subsequent memory retrieval (loss of function). The second study showed that artificially reactivating a subset of hippocampal dentate gyrus neurons that were active during a fearful experience (and, therefore, part of a putative engram) induced memory retrieval in the absence of external retrieval cues (gain of function). Subsequent findings from many labs used similar strategies to identify engrams in other brain regions supporting different types of memory. There are several recent advances in engram research. First, eligible neurons within a given brain region were shown to compete for allocation to an engram, and relative neuronal excitability determines the outcome of this competition. Excitability-based competition also guides the organization of multiple engrams in the brain and determines how these engrams interact. Second, research examining the nature of the off-line, enduring changes in engram cells (neurons that are critical components of an engram) found increased synaptic strength and spine density in these neurons as well as preferential connectivity to other downstream engram cells. Therefore, both increased intrinsic excitability and synaptic plasticity work hand in hand to form engrams, and these mechanisms are also implicated in memory consolidation and retrieval processes. Third, it is now possible to artificially manipulate memory encoding and retrieval processes to generate false memories, or even create a memory in mice without any natural sensory experience (implantation of a memory for an experience that did not occur). Fourth, “silent” engrams were discovered in amnesic mice; artificial reactivation of silent engrams induces memory retrieval, whereas natural cues cannot. Endogenous engram silencing may contribute to the change in memory over time (e.g., systems memory consolidation) or in different circumstances (e.g., fear memory extinction). These findings suggest that once formed, an engram may exist in different states (from silent to active) on the basis of their retrievability. Although initial engram studies focused on single brain regions, an emerging concept is that a given memory is supported by an engram complex, composed of functionally connected engram cell ensembles dispersed across multiple brain regions, with each ensemble supporting a component of the overall memory. OUTLOOK The ability to identify and manipulate engram cells and brainwide engram complexes has introduced an exciting new era of memory research. The findings from many labs are beginning to define an engram as the basic unit of memory. However, many questions remain. In the short term, it is critical to characterize how information is stored in an engram, including how engram architecture affects memory quality, strength, and precision; how multiple engrams interact; how engrams change over time; and the role of engram silencing in these processes. The long-term goal of engram research is to leverage the fundamental findings from rodent engram studies to understand how information is acquired, stored, and used in humans and facilitate the treatment of human memory, or other information-processing, disorders. The development of low- to noninvasive technology may enable new human therapies based on the growing knowledge of engrams in rodents. An engram cell alongside a nonengram cell. Within the hippocampus, dentate gyrus cells were filled with biocytin (white) to examine morphology. Engram cells active during context fear conditioning were engineered to express the red fluorescent protein mCherry, which appears pink owing to overlap with biocytin signals. Axons of the perforant path (green) express the excitatory opsin channelrhodopsin 2 and a fluorescent marker (enhanced yellow fluorescent protein). The upper blade of the dentate gyrus granule cell layer is revealed by the nuclear stain 4′,6-diamidino-2-phenylindole (DAPI, blue). CREDIT: ADAPTED FROM T. J. RYAN ET AL., SCIENCE 348, 1007 (2015). In 1904, Richard Semon introduced the term “engram” to describe the neural substrate for storing memories. An experience, Semon proposed, activates a subset of cells that undergo off-line, persistent chemical and/or physical changes to become an engram. Subsequent reactivation of this engram induces memory retrieval. Although Semon’s contributions were largely ignored in his lifetime, new technologies that allow researchers to image and manipulate the brain at the level of individual neurons has reinvigorated engram research. We review recent progress in studying engrams, including an evaluation of evidence for the existence of engrams, the importance of intrinsic excitability and synaptic plasticity in engrams, and the lifetime of an engram. Together, these findings are beginning to define an engram as the basic unit of memory.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import instaloader\n",
        "import pandas as pd\n",
        "iloader = instaloader.Instaloader()\n",
        "profile_name = instaloader.Profile.from_username(iloader.context, 'urstrulymahesh')\n",
        "num_posts_to_collect = 1000\n",
        "collected_data = []\n",
        "for post in profile_name.get_posts():\n",
        "    if len(collected_data) >= num_posts_to_collect:\n",
        "        break\n",
        "\n",
        "    user_name = post.owner_username\n",
        "    posted_time = post.date_utc\n",
        "    text = post.caption\n",
        "\n",
        "    collected_data.append({\n",
        "        'User_name': user_name,\n",
        "        'Posted_time': posted_time,\n",
        "        'Text': text,\n",
        "    })\n",
        "df = pd.DataFrame(collected_data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "Hkffx7GmsA0_",
        "outputId": "d8f98c58-2262-46b3-fd38-2496f11a32d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query [retrying; skip with ^C]\n",
            "JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22urstrulymahesh%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true [retrying; skip with ^C]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ConnectionException",
          "evalue": "JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22urstrulymahesh%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionException\u001b[0m: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionException\u001b[0m: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22urstrulymahesh%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionException\u001b[0m: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22urstrulymahesh%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e4fe1233b092>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_posts_to_collect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcollected_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprofile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollected_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_posts_to_collect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/structures.py\u001b[0m in \u001b[0;36mget_posts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         :rtype: NodeIterator[Post]\"\"\"\n\u001b[1;32m   1185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obtain_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         return NodeIterator(\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0medge_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xdt_api__v1__feed__user_timeline_graphql_connection'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/nodeiterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, context, query_hash, edge_extractor, node_wrapper, query_variables, query_referer, first_data, is_first, doc_id)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNodeIterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shelf_life\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/nodeiterator.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, after)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_doc_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_doc_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_doc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_hash\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/nodeiterator.py\u001b[0m in \u001b[0;36m_query_doc_id\u001b[0;34m(self, doc_id, after)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mpagination_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         data = self._edge_extractor(\n\u001b[0;32m--> 119\u001b[0;31m             self._context.doc_id_graphql_query(\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpagination_variables\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_referer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mdoc_id_graphql_query\u001b[0;34m(self, doc_id, variables, referer)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mvariables_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             resp_json = self.get_json('graphql/query',\n\u001b[0m\u001b[1;32m    544\u001b[0m                                       params={'variables': variables_json,\n\u001b[1;32m    545\u001b[0m                                               \u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    478\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_other_query\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_429\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'other'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 return self.get_json(path=path, params=params, host=host, session=sess, _attempt=_attempt + 1,\n\u001b[0m\u001b[1;32m    481\u001b[0m                                      response_headers=response_headers)\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    478\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_other_query\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_429\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'other'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 return self.get_json(path=path, params=params, host=host, session=sess, _attempt=_attempt + 1,\n\u001b[0m\u001b[1;32m    481\u001b[0m                                      response_headers=response_headers)\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instaloader/instaloadercontext.py\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    466\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mQueryReturnedNotFoundException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mConnectionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" [retrying; skip with ^C]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionException\u001b[0m: JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22urstrulymahesh%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n",
        "\"C:\\Users\\gm0657\\OneDrive - UNT System\\5731 exercise 2\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Personally, I find these tools beneficial when quick, reliable data extraction is needed without investing too much time in constructing custom scrapers. However, their limitations, such as restricted control over customizations and potential costs for large-scale projects, make them less tempting for developers who need more granular control, which is achievable using Python packages like BeautifulSoup and Selenium.\n",
        "\n",
        "\n",
        "The process of integrating a tool like ParseHub and exporting the data to formats such as CSV or Excel is efficient for data analysis and reporting. It's a fantastic answer for circumstances where coding might not be the most practical technique. Overall, I feel these tools strike a compromise between usability and functionality, delivering a viable solution for web scraping applications.\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}